{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e70558e64eaa4da2a9c284be63c4870a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d0bcd79e39043e59ac2766f0cfce71b",
              "IPY_MODEL_0c772b5fbc6d42fdb417c2189d69b918",
              "IPY_MODEL_c053426055cd4a3bb03f9100ff261586"
            ],
            "layout": "IPY_MODEL_4dc14c0434274db8bdc5a826a2326dac"
          }
        },
        "8d0bcd79e39043e59ac2766f0cfce71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a3208a556f4940ae1c15f6d08de3d2",
            "placeholder": "​",
            "style": "IPY_MODEL_b0fdaa85deff4cddb68c76f7b568e5dd",
            "value": "Downloading builder script: 100%"
          }
        },
        "0c772b5fbc6d42fdb417c2189d69b918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28fb41aa5344aa4a71dc69e78dcaaf6",
            "max": 8440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_168dec66ad5d4644ba887924cecc8271",
            "value": 8440
          }
        },
        "c053426055cd4a3bb03f9100ff261586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4132fad4f64cbd9a2354e7f2959bb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a4dcf079a140f2ae29c156ce328c63",
            "value": " 8.44k/8.44k [00:00&lt;00:00, 417kB/s]"
          }
        },
        "4dc14c0434274db8bdc5a826a2326dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a3208a556f4940ae1c15f6d08de3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fdaa85deff4cddb68c76f7b568e5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28fb41aa5344aa4a71dc69e78dcaaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168dec66ad5d4644ba887924cecc8271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d4132fad4f64cbd9a2354e7f2959bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a4dcf079a140f2ae29c156ce328c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3b23b23e88b41aeabe1e2c9649db917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_302391418b3f4e858d69c213ca85fdbb",
              "IPY_MODEL_12899216aa844e95b77be65e5ba8672e",
              "IPY_MODEL_fb2de6d8c35f42aeb8ab9518b62ab971"
            ],
            "layout": "IPY_MODEL_8f4513e0ebe94ec6a20cdf62f8bb580c"
          }
        },
        "302391418b3f4e858d69c213ca85fdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9fd8a5e0d8425c936ead412d691c57",
            "placeholder": "​",
            "style": "IPY_MODEL_95dccdc5bccd4aa78395c39cb69aae34",
            "value": "Downloading readme: 100%"
          }
        },
        "12899216aa844e95b77be65e5ba8672e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ed024eb1b8498bb6603c6fa3e28796",
            "max": 12909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c18e42237d54c7ca4431f5400072a05",
            "value": 12909
          }
        },
        "fb2de6d8c35f42aeb8ab9518b62ab971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0355884d1b047a48229461dceb21fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_db31a67f671f4761b2565f43bfaf776f",
            "value": " 12.9k/12.9k [00:00&lt;00:00, 543kB/s]"
          }
        },
        "8f4513e0ebe94ec6a20cdf62f8bb580c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9fd8a5e0d8425c936ead412d691c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95dccdc5bccd4aa78395c39cb69aae34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01ed024eb1b8498bb6603c6fa3e28796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c18e42237d54c7ca4431f5400072a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0355884d1b047a48229461dceb21fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db31a67f671f4761b2565f43bfaf776f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9c525d371af498ab5aaba4aad77db77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3961ce1760b451685ce8e888de1e664",
              "IPY_MODEL_8135b2018fc147b7bce00919255952be",
              "IPY_MODEL_699c6088614a43ed94f39acd98e04d0e"
            ],
            "layout": "IPY_MODEL_ad963dde4a444b4d932530aee0a78f32"
          }
        },
        "d3961ce1760b451685ce8e888de1e664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56274eecc7c4220b297888ecbc6a473",
            "placeholder": "​",
            "style": "IPY_MODEL_e4802037e36b465bad41c111d872c342",
            "value": "Downloading data: 100%"
          }
        },
        "8135b2018fc147b7bce00919255952be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647a22388d74479bba9b0e730f6cbd58",
            "max": 940909997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ddd008adf144ffcb051b653bf738575",
            "value": 940909997
          }
        },
        "699c6088614a43ed94f39acd98e04d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ba5dff46f043f7891162f0045bc099",
            "placeholder": "​",
            "style": "IPY_MODEL_9720a260d147408989c4db644d57b109",
            "value": " 941M/941M [00:22&lt;00:00, 41.6MB/s]"
          }
        },
        "ad963dde4a444b4d932530aee0a78f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56274eecc7c4220b297888ecbc6a473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4802037e36b465bad41c111d872c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "647a22388d74479bba9b0e730f6cbd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddd008adf144ffcb051b653bf738575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ba5dff46f043f7891162f0045bc099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9720a260d147408989c4db644d57b109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7888ebb4247241b09ecefac479eac303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78b0eb5ed6c649ae9c3cde4618adaf61",
              "IPY_MODEL_45a95393788f42f1b0d56a1f45d98b7d",
              "IPY_MODEL_d02afd474e47470f99ddcb0b4caeefbd"
            ],
            "layout": "IPY_MODEL_2dd91e516d394fc28a5345c4de66561e"
          }
        },
        "78b0eb5ed6c649ae9c3cde4618adaf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0725667c5cb04400b8cdda5896d8a549",
            "placeholder": "​",
            "style": "IPY_MODEL_23a3f6c5ea2f460e8807f96a57f92770",
            "value": "Generating train split: 100%"
          }
        },
        "45a95393788f42f1b0d56a1f45d98b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75bebed6ac74ea28df51b4e20eacc73",
            "max": 412178,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_014e5b673fdd46c883c3860a575ad405",
            "value": 412178
          }
        },
        "d02afd474e47470f99ddcb0b4caeefbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798b8e1c93134c66803e9f38c3f765b0",
            "placeholder": "​",
            "style": "IPY_MODEL_946dd8eb831843beb5de47b095792bf8",
            "value": " 412178/412178 [04:10&lt;00:00, 1404.50 examples/s]"
          }
        },
        "2dd91e516d394fc28a5345c4de66561e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0725667c5cb04400b8cdda5896d8a549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a3f6c5ea2f460e8807f96a57f92770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75bebed6ac74ea28df51b4e20eacc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014e5b673fdd46c883c3860a575ad405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798b8e1c93134c66803e9f38c3f765b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946dd8eb831843beb5de47b095792bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa69ff40e1844738b7ff97cdca680ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba996959a48d4ecc9b9e636d4478ff82",
              "IPY_MODEL_fbe78a4f740544c7ae79cc3175445a80",
              "IPY_MODEL_799a2bdafc01486ebf0ea1a57e929381"
            ],
            "layout": "IPY_MODEL_a062a9d518974a5b9b62d93c486ec9ad"
          }
        },
        "ba996959a48d4ecc9b9e636d4478ff82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d7dfcfc4d143b0ad25053b44a00ea8",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3efd8dd376466290ddb6a412673378",
            "value": "Generating test split: 100%"
          }
        },
        "fbe78a4f740544c7ae79cc3175445a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1350f2195304d9f97c168fa3eef969f",
            "max": 22176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81e0da5d6c16474f96b62d4249eeabce",
            "value": 22176
          }
        },
        "799a2bdafc01486ebf0ea1a57e929381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7a133548b5453c85e4c56bb4b9cc36",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ee03b3a1fa4a47944241eccabf2c39",
            "value": " 22176/22176 [00:12&lt;00:00, 1148.22 examples/s]"
          }
        },
        "a062a9d518974a5b9b62d93c486ec9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d7dfcfc4d143b0ad25053b44a00ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3efd8dd376466290ddb6a412673378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1350f2195304d9f97c168fa3eef969f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e0da5d6c16474f96b62d4249eeabce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d7a133548b5453c85e4c56bb4b9cc36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ee03b3a1fa4a47944241eccabf2c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ab3d4a4dce4164b6def8058ba61bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a03424da51124c39859a4d33b3e167d3",
              "IPY_MODEL_574db7c3efe74de5a02ffd962d927b5e",
              "IPY_MODEL_fe0665fad27e4eb09544ef054704f172"
            ],
            "layout": "IPY_MODEL_941077beff6442ddab168f30810ef5d3"
          }
        },
        "a03424da51124c39859a4d33b3e167d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdd0a5bb37a4d8c90b29d4afbd2d80a",
            "placeholder": "​",
            "style": "IPY_MODEL_33438cb8d9c24843a0e2d48777d89381",
            "value": "Generating validation split: 100%"
          }
        },
        "574db7c3efe74de5a02ffd962d927b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c99cdecee24bed8475499e60c6fed9",
            "max": 23107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e81cd14ba6fc45d1a6e2dffb747ec664",
            "value": 23107
          }
        },
        "fe0665fad27e4eb09544ef054704f172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641a60bbfcb840f48bc2215a1df8b7cf",
            "placeholder": "​",
            "style": "IPY_MODEL_858f4af00e804baa9a1df6d6b2e0eaca",
            "value": " 23107/23107 [00:14&lt;00:00, 1294.41 examples/s]"
          }
        },
        "941077beff6442ddab168f30810ef5d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdd0a5bb37a4d8c90b29d4afbd2d80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33438cb8d9c24843a0e2d48777d89381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27c99cdecee24bed8475499e60c6fed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81cd14ba6fc45d1a6e2dffb747ec664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "641a60bbfcb840f48bc2215a1df8b7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858f4af00e804baa9a1df6d6b2e0eaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc534b5e77f4196ba1dc97a5f3642a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e34fc443e8146cf83aa7c124297ac6b",
              "IPY_MODEL_6c25c2b9c8d84c999038003e4ff80fee",
              "IPY_MODEL_4b9f257dd5274f81bc2102075c36e769"
            ],
            "layout": "IPY_MODEL_f0200445412840128331d3312f33a4cb"
          }
        },
        "4e34fc443e8146cf83aa7c124297ac6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a9dab0fd3c45efa84026d20405ed86",
            "placeholder": "​",
            "style": "IPY_MODEL_729dedb4ae034e8391dcd1afe8d115a1",
            "value": "config.json: 100%"
          }
        },
        "6c25c2b9c8d84c999038003e4ff80fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb1fb43f4b043d4aae01c2254823c64",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95ac75f6f742428190bc02d70ea89e42",
            "value": 665
          }
        },
        "4b9f257dd5274f81bc2102075c36e769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64532f3725f458494c1b7ef651fa842",
            "placeholder": "​",
            "style": "IPY_MODEL_02cb706af9d840b2b190e56a982bb00a",
            "value": " 665/665 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "f0200445412840128331d3312f33a4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a9dab0fd3c45efa84026d20405ed86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729dedb4ae034e8391dcd1afe8d115a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb1fb43f4b043d4aae01c2254823c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ac75f6f742428190bc02d70ea89e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a64532f3725f458494c1b7ef651fa842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02cb706af9d840b2b190e56a982bb00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e23209f83cc4d649906088ffb9c963e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aab26e0c11724c7e9faeb6258ff57242",
              "IPY_MODEL_d0e12b5721fd49b7b411cf85ef06b491",
              "IPY_MODEL_899e9827300448e4a26163fbd3f00c44"
            ],
            "layout": "IPY_MODEL_cbbd043ce86149b8837891d65aef3180"
          }
        },
        "aab26e0c11724c7e9faeb6258ff57242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f40edc124d6489c88018edbdf724b7b",
            "placeholder": "​",
            "style": "IPY_MODEL_e440f3c8e7634466b76ae9611ff16761",
            "value": "vocab.json: 100%"
          }
        },
        "d0e12b5721fd49b7b411cf85ef06b491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71bf96931af94855bb0af90ef5a4211c",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d232d6515b144e8ea4eafcf0accd9ccb",
            "value": 1042301
          }
        },
        "899e9827300448e4a26163fbd3f00c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef355b5ce01b410695645f1408db62b3",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd30177f4924527b44948b2bc069c48",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 21.2MB/s]"
          }
        },
        "cbbd043ce86149b8837891d65aef3180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f40edc124d6489c88018edbdf724b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e440f3c8e7634466b76ae9611ff16761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71bf96931af94855bb0af90ef5a4211c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d232d6515b144e8ea4eafcf0accd9ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef355b5ce01b410695645f1408db62b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd30177f4924527b44948b2bc069c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d2ebd98d38a4126b86e394003595040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10df03706c334d53a0b8eadd0c105c4a",
              "IPY_MODEL_43a3419d0314421d8efeb1740646e67b",
              "IPY_MODEL_0e5aecd6321d4a2795f8989d58124a9b"
            ],
            "layout": "IPY_MODEL_b8de4a3e767c45808e876417b6a44a6d"
          }
        },
        "10df03706c334d53a0b8eadd0c105c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05795f578a724298893b0cddcfb302c1",
            "placeholder": "​",
            "style": "IPY_MODEL_c656c19246a643a2b44e816331019ec4",
            "value": "merges.txt: 100%"
          }
        },
        "43a3419d0314421d8efeb1740646e67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_637a759ee9d24e67994af7ae75f83880",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4582cf6eb8fc4054bfc7ec71bd82ecc4",
            "value": 456318
          }
        },
        "0e5aecd6321d4a2795f8989d58124a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2108359836d14bb584b697a2e6875f4c",
            "placeholder": "​",
            "style": "IPY_MODEL_90eff44863864a2fad4ba04e1314e117",
            "value": " 456k/456k [00:00&lt;00:00, 12.2MB/s]"
          }
        },
        "b8de4a3e767c45808e876417b6a44a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05795f578a724298893b0cddcfb302c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c656c19246a643a2b44e816331019ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "637a759ee9d24e67994af7ae75f83880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4582cf6eb8fc4054bfc7ec71bd82ecc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2108359836d14bb584b697a2e6875f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90eff44863864a2fad4ba04e1314e117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d50dee5a82480b8d1fddbeedeef9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9044b7e776a4ff5be018ee43ae73787",
              "IPY_MODEL_37df6a80f68042999fd6013fe80a2a24",
              "IPY_MODEL_dd7027f6d2874a87a64be31fbc8b51ca"
            ],
            "layout": "IPY_MODEL_c0b8f109707545bc805f75c4466755ce"
          }
        },
        "c9044b7e776a4ff5be018ee43ae73787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f39c08f8c2e4719a7692c37f9976cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_52f8275a53ac46d8ac05f578edc6dea5",
            "value": "tokenizer.json: 100%"
          }
        },
        "37df6a80f68042999fd6013fe80a2a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077238a875a543e18648b2490007404b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75a606b7144c41f6a0b30a4878c83ce0",
            "value": 1355256
          }
        },
        "dd7027f6d2874a87a64be31fbc8b51ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06d053a68a54fa7ace3e81a91b53349",
            "placeholder": "​",
            "style": "IPY_MODEL_670ffd26ed1849ac9605fe1f1a2bf528",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "c0b8f109707545bc805f75c4466755ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f39c08f8c2e4719a7692c37f9976cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f8275a53ac46d8ac05f578edc6dea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077238a875a543e18648b2490007404b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a606b7144c41f6a0b30a4878c83ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f06d053a68a54fa7ace3e81a91b53349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670ffd26ed1849ac9605fe1f1a2bf528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b7fea71f3e4e5499537c51e5d6087a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b168ce39b1024fe7a64c8c0f725aefa4",
              "IPY_MODEL_9f150582f6b149ea8641c2b1d321752d",
              "IPY_MODEL_22ac7b6fe3bb4b08a4a705c11ac2e017",
              "IPY_MODEL_00cac6a63ecb45e99fa5bdf7e46c70f9"
            ],
            "layout": "IPY_MODEL_09c05eb970244a72a22374fe123d4353"
          }
        },
        "b6c915a84ce7449785007bb3d3eee20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342c9f96d62742e9bb7780c554b774d0",
            "placeholder": "​",
            "style": "IPY_MODEL_98c09c0228d84460b3a29c6b9f57d02e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "eedba1ac65be4ef89b412ef057d32ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3ba7aa597e324bd1b4ac81813f297361",
            "placeholder": "​",
            "style": "IPY_MODEL_67914d252256431bacf57db529b7e384",
            "value": ""
          }
        },
        "c7462a587b434a7c95ed2ed75295dbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_115b1a2371f245edb07d9c070d3693a9",
            "style": "IPY_MODEL_c50d03b673a2403f8dfa5b08789245a3",
            "value": true
          }
        },
        "ab4ec019b2b24c8787bcac2120885823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_905ac4703aca4a72aefb9ec68a4edb71",
            "style": "IPY_MODEL_c88117409ba840be982ffdb9596fe3d2",
            "tooltip": ""
          }
        },
        "d16a1366c05c40f5b5b40c7ffd9b152a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c49dd5564a134f7e9b9651704f025f84",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb3483657e84c15815683927e020adf",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "09c05eb970244a72a22374fe123d4353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "342c9f96d62742e9bb7780c554b774d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c09c0228d84460b3a29c6b9f57d02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ba7aa597e324bd1b4ac81813f297361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67914d252256431bacf57db529b7e384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115b1a2371f245edb07d9c070d3693a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50d03b673a2403f8dfa5b08789245a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "905ac4703aca4a72aefb9ec68a4edb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88117409ba840be982ffdb9596fe3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c49dd5564a134f7e9b9651704f025f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb3483657e84c15815683927e020adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c00e4f85c98b4c00ac8e48a8d9d3dc78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14d6d45ca460488d9fc74c20ef80f52b",
            "placeholder": "​",
            "style": "IPY_MODEL_f606b2cd36154badbb8969f5ee333409",
            "value": "Connecting..."
          }
        },
        "14d6d45ca460488d9fc74c20ef80f52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f606b2cd36154badbb8969f5ee333409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b168ce39b1024fe7a64c8c0f725aefa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de13064efea2492788b2e5e7ba1a4119",
            "placeholder": "​",
            "style": "IPY_MODEL_0c1d7178fa614bde86903533792d417f",
            "value": "Token is valid (permission: write)."
          }
        },
        "9f150582f6b149ea8641c2b1d321752d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b6df818b2a4db4847c428fb4e202d6",
            "placeholder": "​",
            "style": "IPY_MODEL_43ae61b95da748d8a5932eea0ca041ed",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "22ac7b6fe3bb4b08a4a705c11ac2e017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ed5bd1d90db42f386b2b677a62d862d",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f21a93f76f4f329a55410c0e30418b",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "00cac6a63ecb45e99fa5bdf7e46c70f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a188be61ad6746bbbe143e2b8babca3c",
            "placeholder": "​",
            "style": "IPY_MODEL_d5495d3288e64fd593124a867d28222c",
            "value": "Login successful"
          }
        },
        "de13064efea2492788b2e5e7ba1a4119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1d7178fa614bde86903533792d417f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53b6df818b2a4db4847c428fb4e202d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ae61b95da748d8a5932eea0ca041ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ed5bd1d90db42f386b2b677a62d862d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f21a93f76f4f329a55410c0e30418b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a188be61ad6746bbbe143e2b8babca3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5495d3288e64fd593124a867d28222c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA8Tzmu1gFdk",
        "outputId": "d52082fe-716a-40d6-c422-c08c1dad46dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4e914tyh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-4e914tyh\n",
            "  Resolved https://github.com/huggingface/transformers to commit 3f69f415adcbdaedec154ba8eac220ef3276975d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8404406 sha256=a22d0eb0e7b3236214781af5406057ff0b44f229f8d33bcf8264369d9215a52c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-llf5rs4u/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.38.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading datasets on which we want to train tokenizer\n",
        "from datasets import load_dataset\n",
        "raw_dataset  = load_dataset(\"code_search_net\", \"python\")\n",
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697,
          "referenced_widgets": [
            "e70558e64eaa4da2a9c284be63c4870a",
            "8d0bcd79e39043e59ac2766f0cfce71b",
            "0c772b5fbc6d42fdb417c2189d69b918",
            "c053426055cd4a3bb03f9100ff261586",
            "4dc14c0434274db8bdc5a826a2326dac",
            "80a3208a556f4940ae1c15f6d08de3d2",
            "b0fdaa85deff4cddb68c76f7b568e5dd",
            "f28fb41aa5344aa4a71dc69e78dcaaf6",
            "168dec66ad5d4644ba887924cecc8271",
            "1d4132fad4f64cbd9a2354e7f2959bb0",
            "b9a4dcf079a140f2ae29c156ce328c63",
            "a3b23b23e88b41aeabe1e2c9649db917",
            "302391418b3f4e858d69c213ca85fdbb",
            "12899216aa844e95b77be65e5ba8672e",
            "fb2de6d8c35f42aeb8ab9518b62ab971",
            "8f4513e0ebe94ec6a20cdf62f8bb580c",
            "9e9fd8a5e0d8425c936ead412d691c57",
            "95dccdc5bccd4aa78395c39cb69aae34",
            "01ed024eb1b8498bb6603c6fa3e28796",
            "8c18e42237d54c7ca4431f5400072a05",
            "f0355884d1b047a48229461dceb21fd8",
            "db31a67f671f4761b2565f43bfaf776f",
            "c9c525d371af498ab5aaba4aad77db77",
            "d3961ce1760b451685ce8e888de1e664",
            "8135b2018fc147b7bce00919255952be",
            "699c6088614a43ed94f39acd98e04d0e",
            "ad963dde4a444b4d932530aee0a78f32",
            "c56274eecc7c4220b297888ecbc6a473",
            "e4802037e36b465bad41c111d872c342",
            "647a22388d74479bba9b0e730f6cbd58",
            "8ddd008adf144ffcb051b653bf738575",
            "c5ba5dff46f043f7891162f0045bc099",
            "9720a260d147408989c4db644d57b109",
            "7888ebb4247241b09ecefac479eac303",
            "78b0eb5ed6c649ae9c3cde4618adaf61",
            "45a95393788f42f1b0d56a1f45d98b7d",
            "d02afd474e47470f99ddcb0b4caeefbd",
            "2dd91e516d394fc28a5345c4de66561e",
            "0725667c5cb04400b8cdda5896d8a549",
            "23a3f6c5ea2f460e8807f96a57f92770",
            "b75bebed6ac74ea28df51b4e20eacc73",
            "014e5b673fdd46c883c3860a575ad405",
            "798b8e1c93134c66803e9f38c3f765b0",
            "946dd8eb831843beb5de47b095792bf8",
            "3fa69ff40e1844738b7ff97cdca680ba",
            "ba996959a48d4ecc9b9e636d4478ff82",
            "fbe78a4f740544c7ae79cc3175445a80",
            "799a2bdafc01486ebf0ea1a57e929381",
            "a062a9d518974a5b9b62d93c486ec9ad",
            "e4d7dfcfc4d143b0ad25053b44a00ea8",
            "eb3efd8dd376466290ddb6a412673378",
            "c1350f2195304d9f97c168fa3eef969f",
            "81e0da5d6c16474f96b62d4249eeabce",
            "8d7a133548b5453c85e4c56bb4b9cc36",
            "b9ee03b3a1fa4a47944241eccabf2c39",
            "e8ab3d4a4dce4164b6def8058ba61bd9",
            "a03424da51124c39859a4d33b3e167d3",
            "574db7c3efe74de5a02ffd962d927b5e",
            "fe0665fad27e4eb09544ef054704f172",
            "941077beff6442ddab168f30810ef5d3",
            "0bdd0a5bb37a4d8c90b29d4afbd2d80a",
            "33438cb8d9c24843a0e2d48777d89381",
            "27c99cdecee24bed8475499e60c6fed9",
            "e81cd14ba6fc45d1a6e2dffb747ec664",
            "641a60bbfcb840f48bc2215a1df8b7cf",
            "858f4af00e804baa9a1df6d6b2e0eaca"
          ]
        },
        "id": "lKyxfnLeiFkf",
        "outputId": "80d0ca25-991b-4b84-cbdd-a5e7924ac004"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e70558e64eaa4da2a9c284be63c4870a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3b23b23e88b41aeabe1e2c9649db917"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9c525d371af498ab5aaba4aad77db77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7888ebb4247241b09ecefac479eac303"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fa69ff40e1844738b7ff97cdca680ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8ab3d4a4dce4164b6def8058ba61bd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "        num_rows: 412178\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "        num_rows: 22176\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "        num_rows: 23107\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset[\"train\"][0][\"whole_func_string\"]                     # inspecting training columns of dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "vb56AssAieqS",
        "outputId": "3c4d6847-145e-4aeb-e1fd-301a5608c5f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def update(self, field_dict, where_clause=None):\\n        '''\\n        update db entry\\n\\n        :param field_dict: dictionary of fields and values\\n        :param where_clause: where clause for the update\\n        '''\\n        query = '''\\n        UPDATE %s SET %s\\n        ''' % (\\n            self._name,\\n            ','.join('%s=:%s' % (k, k) for k in field_dict)\\n        )\\n        if where_clause:\\n            query += ' WHERE %s' % (where_clause)\\n        self._cursor.execute(query, field_dict)\\n        self._connection.commit()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus(raw_datasets):\n",
        "  for start_idx in range(0,len(raw_datasets[\"train\"]),1000):                          # taking data with 1k jump steps\n",
        "    data = raw_datasets[\"train\"][start_idx: start_idx+1000][\"whole_func_string\"]      # taking data between jump steps\n",
        "    yield data                                                                        # yield return data in iterable way"
      ],
      "metadata": {
        "id": "LVF7-PIJijTl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_corpus = get_training_corpus(raw_dataset)                                    # making data ready to train tokenizer"
      ],
      "metadata": {
        "id": "vVTI7QKNmIK9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(training_corpus))                                                           # inspecting corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpddt4lmMks",
        "outputId": "58d5c267-f8f1-4998-f4b2-9678e55a805c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['def fbeta_score(df, col_true=None, col_pred=\\'precision_result\\', beta=1.0, pos_label=1, average=None):\\n    r\"\"\"\\n    Compute f-beta score of a predicted DataFrame. f-beta is defined as\\n\\n    .. math::\\n\\n        \\\\frac{1 + \\\\beta^2 \\\\cdot precision \\\\cdot recall}{\\\\beta^2 \\\\cdot precision + recall}\\n\\n    F-beta score is a generalization of f-1 score.\\n\\n    :Parameters:\\n        - **df** - predicted data frame\\n        - **col_true** - column name of true label\\n        - **col_pred** - column name of predicted label, \\'prediction_result\\' by default.\\n        - **pos_label** - denote the desired class label when ``average`` == `binary`\\n        - **average** - denote the method to compute average.\\n    :Returns:\\n        Recall score\\n    :Return type:\\n        float | numpy.array[float]\\n\\n    The parameter ``average`` controls the behavior of the function.\\n\\n    * When ``average`` == None (by default), f-beta of every class is given as a list.\\n\\n    * When ``average`` == \\'binary\\', f-beta of class specified in ``pos_label`` is given.\\n\\n    * When ``average`` == \\'micro\\', f-beta of overall precision and recall is given, where overall precision and recall are computed in micro-average mode.\\n\\n    * When ``average`` == \\'macro\\', average f-beta of all the class is given.\\n\\n    * When ``average`` == `weighted`, average f-beta of all the class weighted by support of every true classes is given.\\n\\n    :Example:\\n\\n    Assume we have a table named \\'predicted\\' as follows:\\n\\n    ======== ===================\\n    label    prediction_result\\n    ======== ===================\\n    0        1\\n    1        2\\n    2        1\\n    1        1\\n    1        0\\n    2        2\\n    ======== ===================\\n\\n    Different options of ``average`` parameter outputs different values:\\n\\n.. code-block:: python\\n\\n    >>> fbeta_score(predicted, \\'label\\', average=None, beta=0.5)\\n    array([ 0.        ,  0.33333333,  0.5       ])\\n    >>> fbeta_score(predicted, \\'label\\', average=\\'macro\\', beta=0.5)\\n    0.27\\n    >>> fbeta_score(predicted, \\'label\\', average=\\'micro\\', beta=0.5)\\n    0.33\\n    >>> fbeta_score(predicted, \\'label\\', average=\\'weighted\\', beta=0.5)\\n    0.33\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    mat, label_list = _run_cm_node(df, col_true, col_pred)\\n    class_dict = dict((label, idx) for idx, label in enumerate(label_list))\\n    tps = np.diag(mat)\\n    pred_count = np.sum(mat, axis=0)\\n    supp_count = np.sum(mat, axis=1)\\n    beta2 = beta ** 2\\n\\n    precision = tps * 1.0 / pred_count\\n    recall = tps * 1.0 / supp_count\\n    ppr = precision * beta2 + recall\\n    ppr[ppr == 0] = 1e-6\\n\\n    fbeta = (1 + beta2) * precision * recall / ppr\\n\\n    if average is None:\\n        return fbeta\\n    elif average == \\'binary\\':\\n        class_idx = class_dict[pos_label]\\n        return fbeta[class_idx]\\n    elif average == \\'micro\\':\\n        g_precision = np.sum(tps) * 1.0 / np.sum(supp_count)\\n        g_recall = np.sum(tps) * 1.0 / np.sum(pred_count)\\n        return (1 + beta2) * g_precision * g_recall / (beta2 * g_precision + g_recall)\\n    elif average == \\'macro\\':\\n        return np.mean(fbeta)\\n    elif average == \\'weighted\\':\\n        return sum(fbeta * supp_count) / sum(supp_count)',\n",
              " 'def f1_score(df, col_true=None, col_pred=\\'precision_result\\', pos_label=1, average=None):\\n    r\"\"\"\\n    Compute f-1 score of a predicted DataFrame. f-1 is defined as\\n\\n    .. math::\\n\\n        \\\\frac{2 \\\\cdot precision \\\\cdot recall}{precision + recall}\\n\\n\\n    :Parameters:\\n        - **df** - predicted data frame\\n        - **col_true** - column name of true label\\n        - **col_pred** - column name of predicted label, \\'prediction_result\\' by default.\\n        - **pos_label** - denote the desired class label when ``average`` == `binary`\\n        - **average** - denote the method to compute average.\\n    :Returns:\\n        Recall score\\n    :Return type:\\n        float | numpy.array[float]\\n\\n    The parameter ``average`` controls the behavior of the function.\\n\\n    * When ``average`` == None (by default), f-1 of every class is given as a list.\\n\\n    * When ``average`` == \\'binary\\', f-1 of class specified in ``pos_label`` is given.\\n\\n    * When ``average`` == \\'micro\\', f-1 of overall precision and recall is given, where overall precision and recall are computed in micro-average mode.\\n\\n    * When ``average`` == \\'macro\\', average f-1 of all the class is given.\\n\\n    * When ``average`` == `weighted`, average f-1 of all the class weighted by support of every true classes is given.\\n\\n\\n    :Example:\\n\\n    Assume we have a table named \\'predicted\\' as follows:\\n\\n    ======== ===================\\n    label    prediction_result\\n    ======== ===================\\n    0        1\\n    1        2\\n    2        1\\n    1        1\\n    1        0\\n    2        2\\n    ======== ===================\\n\\n    Different options of ``average`` parameter outputs different values:\\n\\n.. code-block:: python\\n\\n    >>> f1_score(predicted, \\'label\\', average=None)\\n    array([ 0.        ,  0.33333333,  0.5       ])\\n    >>> f1_score(predicted, \\'label\\', average=\\'macro\\')\\n    0.27\\n    >>> f1_score(predicted, \\'label\\', average=\\'micro\\')\\n    0.33\\n    >>> f1_score(predicted, \\'label\\', average=\\'weighted\\')\\n    0.33\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    return fbeta_score(df, col_true, col_pred, pos_label=pos_label, average=average)',\n",
              " 'def roc_curve(df, col_true=None, col_pred=None, col_scores=None, pos_label=1):\\n    r\"\"\"\\n    Compute true positive rate (TPR), false positive rate (FPR) and threshold from predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param pos_label: positive label\\n    :type pos_label: str\\n    :param col_true: true column\\n    :type col_true: str\\n    :param col_pred: predicted column, \\'prediction_result\\' if absent.\\n    :type col_pred: str\\n    :param col_scores: score column, \\'prediction_score\\' if absent.\\n    :type col_scores: str\\n\\n    :return: False positive rate, true positive rate and threshold, in numpy array format.\\n\\n    :Example:\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fpr, tpr, thresh = roc_curve(predicted, \"class\")\\n    >>> plt.plot(fpr, tpr)\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    if not col_scores:\\n        col_scores = get_field_name_by_role(df, FieldRole.PREDICTED_SCORE)\\n    thresh, tp, fn, tn, fp = _run_roc_node(df, pos_label, col_true, col_pred, col_scores)\\n\\n    if np is not None:\\n        tpr = tp * 1.0 / (tp + fn)\\n        fpr = fp * 1.0 / (fp + tn)\\n    else:\\n        tpr = [tp[i] * 1.0 / (tp[i] + fn[i]) for i in range(len(tp))]\\n        fpr = [fp[i] * 1.0 / (fp[i] + tn[i]) for i in range(len(fp))]\\n\\n    roc_result = namedtuple(\\'ROCResult\\', \\'fpr tpr thresh\\')\\n    return roc_result(fpr=fpr, tpr=tpr, thresh=thresh)',\n",
              " 'def gain_chart(df, col_true=None, col_pred=None, col_scores=None, pos_label=1):\\n    r\"\"\"\\n    Compute positive proportion, true positive rate (TPR) and threshold from predicted DataFrame. The trace can be plotted as a cumulative gain chart\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param pos_label: positive label\\n    :type pos_label: str\\n    :param col_true: true column\\n    :type col_true: str\\n    :param col_pred: predicted column, \\'prediction_result\\' if absent.\\n    :type col_pred: str\\n    :param col_scores: score column, \\'prediction_score\\' if absent.\\n    :type col_scores: str\\n\\n    :return: positive proportion, true positive rate and threshold, in numpy array format.\\n\\n    :Example:\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> depth, tpr, thresh = gain_chart(predicted)\\n    >>> plt.plot(depth, tpr)\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    if not col_scores:\\n        col_scores = get_field_name_by_role(df, FieldRole.PREDICTED_SCORE)\\n    thresh, tp, fn, tn, fp = _run_roc_node(df, pos_label, col_true, col_pred, col_scores)\\n\\n    depth = (tp + fp) * 1.0 / (tp + fp + tn + fn)\\n    tpr = tp * 1.0 / (tp + fn)\\n\\n    gain_result = namedtuple(\\'GainChartResult\\', \\'depth tpr thresh\\')\\n    return gain_result(depth=depth, tpr=tpr, thresh=thresh)',\n",
              " 'def lift_chart(df, col_true=None, col_pred=None, col_scores=None, pos_label=1):\\n    r\"\"\"\\n    Compute life value, true positive rate (TPR) and threshold from predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param pos_label: positive label\\n    :type pos_label: str\\n    :param col_true: true column\\n    :type col_true: str\\n    :param col_pred: predicted column, \\'prediction_result\\' if absent.\\n    :type col_pred: str\\n    :param col_scores: score column, \\'prediction_score\\' if absent.\\n    :type col_scores: str\\n\\n    :return: lift value, true positive rate and threshold, in numpy array format.\\n\\n    :Example:\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> depth, lift, thresh = lift_chart(predicted)\\n    >>> plt.plot(depth, lift)\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    if not col_scores:\\n        col_scores = get_field_name_by_role(df, FieldRole.PREDICTED_SCORE)\\n    thresh, tp, fn, tn, fp = _run_roc_node(df, pos_label, col_true, col_pred, col_scores)\\n\\n    depth = (tp + fp) * 1.0 / (tp + fp + tn + fn)\\n    tpr = tp * 1.0 / (tp + fn)\\n    lift = tpr / depth\\n\\n    lift_result = namedtuple(\\'LiftResult\\', \\'depth lift thresh\\')\\n    return lift_result(depth=depth, lift=lift, thresh=thresh)',\n",
              " 'def roc_auc_score(df, col_true=None, col_pred=None, col_scores=None, pos_label=1):\\n    \"\"\"\\n    Compute Area Under the Curve (AUC) from prediction scores with trapezoidal rule.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param pos_label: positive label\\n    :type pos_label: str\\n    :param col_true: true column\\n    :type col_true: str\\n    :param col_pred: predicted column, \\'prediction_result\\' if absent.\\n    :type col_pred: str\\n    :param col_scores: score column, \\'prediction_score\\' if absent.\\n    :type col_scores: str\\n    :return: AUC value\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    if not col_scores:\\n        col_scores = get_field_name_by_role(df, FieldRole.PREDICTED_SCORE)\\n    thresh, tp, fn, tn, fp = _run_roc_node(df, pos_label, col_true, col_pred, col_scores)\\n    tpr = tp * 1.0 / (tp + fn)\\n    fpr = fp * 1.0 / (fp + tn)\\n    return auc(tpr, fpr)',\n",
              " 'def average_precision_score(df, col_true=None, col_pred=None, col_scores=None, pos_label=1):\\n    \"\"\"\\n    Compute average precision score, i.e., the area under precision-recall curve.\\n    \\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param pos_label: positive label\\n    :type pos_label: str\\n    :param col_true: true column\\n    :type col_true: str\\n    :param col_pred: predicted column, \\'prediction_result\\' if absent.\\n    :type col_pred: str\\n    :param col_scores: score column, \\'prediction_score\\' if absent.\\n    :type col_scores: str\\n    :return: Average precision score\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_CLASS)\\n    if not col_scores:\\n        col_scores = get_field_name_by_role(df, FieldRole.PREDICTED_SCORE)\\n    thresh, tp, fn, tn, fp = _run_roc_node(df, pos_label, col_true, col_pred, col_scores)\\n\\n    precisions = np.squeeze(np.asarray(tp * 1.0 / (tp + fp)))\\n    recalls = np.squeeze(np.asarray(tp * 1.0 / (tp + fn)))\\n\\n    return np.trapz(precisions, recalls)',\n",
              " 'def pack_tag(field_number, wire_type):\\n    \"\"\"Returns an unsigned 32-bit integer that encodes the field number and\\n    wire type information in standard protocol message wire format.\\n\\n    Args:\\n      field_number: Expected to be an integer in the range [1, 1 << 29)\\n      wire_type: One of the WIRETYPE_* constants.\\n    \"\"\"\\n    if not 0 <= wire_type <= _WIRETYPE_MAX:\\n        raise errors.EncodeError(\\'Unknown wire type: %d\\' % wire_type)\\n    return (field_number << TAG_TYPE_BITS) | wire_type',\n",
              " 'def _var_uint64_byte_size_no_tag(uint64):\\n    \"\"\"Returns the bytes required to serialize a single varint.\\n    uint64 must be unsigned.\\n    \"\"\"\\n    if uint64 > UINT64_MAX:\\n        raise errors.EncodeError(\\'Value out of range: %d\\' % uint64)\\n    bytes = 1\\n    while uint64 > 0x7f:\\n        bytes += 1\\n        uint64 >>= 7\\n    return bytes',\n",
              " 'def train(self, *args, **kwargs):\\n        \"\"\"\\n        Perform training on a DataFrame.\\n        The label field is specified by the ``label_field`` method.\\n\\n        :param train_data: DataFrame to be trained. Label field must be specified.\\n        :type train_data: DataFrame\\n\\n        :return: Trained model\\n        :rtype: MLModel\\n        \"\"\"\\n        objs = self._do_transform(*args, **kwargs)\\n        obj_list = [objs, ] if not isinstance(objs, Iterable) else objs\\n        for obj in obj_list:\\n            if not isinstance(obj, ODPSModelExpr):\\n                continue\\n            for meta in [\\'predictor\\', \\'recommender\\']:\\n                if meta not in self._metas:\\n                    continue\\n                mod = __import__(self.__class__.__module__.__name__, fromlist=[\\'\\'])\\\\\\n                    if not hasattr(self, \\'_env\\') else self._env\\n                action_cls_name = underline_to_capitalized(self._metas[meta])\\n                if not hasattr(mod, action_cls_name):\\n                    action_cls_name = \\'_\\' + action_cls_name\\n                setattr(obj, \\'_\\' + meta, mod + \\'.\\' + action_cls_name)\\n\\n        return objs',\n",
              " 'def calc(self, *args, **kwargs):\\n        \"\"\"\\n        :type args: list[DataFrame]\\n        \"\"\"\\n        cases = kwargs.pop(\\'_cases\\', [])\\n        if not isinstance(cases, Iterable):\\n            cases = [cases, ]\\n        result_callback = kwargs.pop(\\'_result_callback\\', None)\\n        execute_now = kwargs.pop(\\'execute_now\\', True)\\n\\n        exec_id = self._get_exec_id()\\n        params = dict((k, v.value) for k, v in six.iteritems(self._parameters))\\n\\n        obj_dict = self._map_inputs_from_args(*args, **kwargs)\\n        engine_kw = dict(p for p in six.iteritems(kwargs) if p[0] not in obj_dict)\\n\\n        expr_kw = dict(_params=params, _exec_id=exec_id, _engine_kw=engine_kw)\\n        if cases:\\n            expr_kw[\\'_cases\\'] = cases\\n\\n        expr_kw.update((ML_ARG_PREFIX + k, v) for k, v in six.iteritems(obj_dict))\\n        if result_callback:\\n            expr_kw[\\'_result_callback\\'] = result_callback\\n        expr = self._metrics_expr(**expr_kw)\\n\\n        if execute_now:\\n            return expr.execute()\\n        else:\\n            return expr',\n",
              " 'def as_completed(fs, timeout=None):\\n    \"\"\"An iterator over the given futures that yields each as it completes.\\n\\n    Args:\\n        fs: The sequence of Futures (possibly created by different Executors) to\\n            iterate over.\\n        timeout: The maximum number of seconds to wait. If None, then there\\n            is no limit on the wait time.\\n\\n    Returns:\\n        An iterator that yields the given Futures as they complete (finished or\\n        cancelled). If any given Futures are duplicated, they will be returned\\n        once.\\n\\n    Raises:\\n        TimeoutError: If the entire result iterator could not be generated\\n            before the given timeout.\\n    \"\"\"\\n    if timeout is not None:\\n        end_time = timeout + time.time()\\n\\n    fs = set(fs)\\n    with _AcquireFutures(fs):\\n        finished = set(\\n                f for f in fs\\n                if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])\\n        pending = fs - finished\\n        waiter = _create_and_install_waiters(fs, _AS_COMPLETED)\\n\\n    try:\\n        for future in finished:\\n            yield future\\n\\n        while pending:\\n            if timeout is None:\\n                wait_timeout = None\\n            else:\\n                wait_timeout = end_time - time.time()\\n                if wait_timeout < 0:\\n                    raise TimeoutError(\\n                            \\'%d (of %d) futures unfinished\\' % (\\n                            len(pending), len(fs)))\\n\\n            waiter.event.wait(wait_timeout)\\n\\n            with waiter.lock:\\n                finished = waiter.finished_futures\\n                waiter.finished_futures = []\\n                waiter.event.clear()\\n\\n            for future in finished:\\n                yield future\\n                pending.remove(future)\\n\\n    finally:\\n        for f in fs:\\n            with f._condition:\\n                f._waiters.remove(waiter)',\n",
              " 'def wait(fs, timeout=None, return_when=ALL_COMPLETED):\\n    \"\"\"Wait for the futures in the given sequence to complete.\\n\\n    Args:\\n        fs: The sequence of Futures (possibly created by different Executors) to\\n            wait upon.\\n        timeout: The maximum number of seconds to wait. If None, then there\\n            is no limit on the wait time.\\n        return_when: Indicates when this function should return. The options\\n            are:\\n\\n            FIRST_COMPLETED - Return when any future finishes or is\\n                              cancelled.\\n            FIRST_EXCEPTION - Return when any future finishes by raising an\\n                              exception. If no future raises an exception\\n                              then it is equivalent to ALL_COMPLETED.\\n            ALL_COMPLETED -   Return when all futures finish or are cancelled.\\n\\n    Returns:\\n        A named 2-tuple of sets. The first set, named \\'done\\', contains the\\n        futures that completed (is finished or cancelled) before the wait\\n        completed. The second set, named \\'not_done\\', contains uncompleted\\n        futures.\\n    \"\"\"\\n    with _AcquireFutures(fs):\\n        done = set(f for f in fs\\n                   if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])\\n        not_done = set(fs) - done\\n\\n        if (return_when == FIRST_COMPLETED) and done:\\n            return DoneAndNotDoneFutures(done, not_done)\\n        elif (return_when == FIRST_EXCEPTION) and done:\\n            if any(f for f in done\\n                   if not f.cancelled() and f.exception() is not None):\\n                return DoneAndNotDoneFutures(done, not_done)\\n\\n        if len(done) == len(fs):\\n            return DoneAndNotDoneFutures(done, not_done)\\n\\n        waiter = _create_and_install_waiters(fs, return_when)\\n\\n    waiter.event.wait(timeout)\\n    for f in fs:\\n        with f._condition:\\n            f._waiters.remove(waiter)\\n\\n    done.update(waiter.finished_futures)\\n    return DoneAndNotDoneFutures(done, set(fs) - done)',\n",
              " 'def cancel(self):\\n        \"\"\"Cancel the future if possible.\\n\\n        Returns True if the future was cancelled, False otherwise. A future\\n        cannot be cancelled if it is running or has already completed.\\n        \"\"\"\\n        with self._condition:\\n            if self._state in [RUNNING, FINISHED]:\\n                return False\\n\\n            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\\n                return True\\n\\n            self._state = CANCELLED\\n            self._condition.notify_all()\\n\\n        self._invoke_callbacks()\\n        return True',\n",
              " 'def add_done_callback(self, fn):\\n        \"\"\"Attaches a callable that will be called when the future finishes.\\n\\n        Args:\\n            fn: A callable that will be called with this future as its only\\n                argument when the future completes or is cancelled. The callable\\n                will always be called by a thread in the same process in which\\n                it was added. If the future has already completed or been\\n                cancelled then the callable will be called immediately. These\\n                callables are called in the order that they were added.\\n        \"\"\"\\n        with self._condition:\\n            if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED]:\\n                self._done_callbacks.append(fn)\\n                return\\n        fn(self)',\n",
              " 'def result(self, timeout=None):\\n        \"\"\"Return the result of the call that the future represents.\\n\\n        Args:\\n            timeout: The number of seconds to wait for the result if the future\\n                isn\\'t done. If None, then there is no limit on the wait time.\\n\\n        Returns:\\n            The result of the call that the future represents.\\n\\n        Raises:\\n            CancelledError: If the future was cancelled.\\n            TimeoutError: If the future didn\\'t finish executing before the given\\n                timeout.\\n            Exception: If the call raised then that exception will be raised.\\n        \"\"\"\\n        with self._condition:\\n            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\\n                raise CancelledError()\\n            elif self._state == FINISHED:\\n                return self.__get_result()\\n\\n            self._condition.wait(timeout)\\n\\n            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\\n                raise CancelledError()\\n            elif self._state == FINISHED:\\n                return self.__get_result()\\n            else:\\n                raise TimeoutError()',\n",
              " 'def exception_info(self, timeout=None):\\n        \"\"\"Return a tuple of (exception, traceback) raised by the call that the\\n        future represents.\\n\\n        Args:\\n            timeout: The number of seconds to wait for the exception if the\\n                future isn\\'t done. If None, then there is no limit on the wait\\n                time.\\n\\n        Returns:\\n            The exception raised by the call that the future represents or None\\n            if the call completed without raising.\\n\\n        Raises:\\n            CancelledError: If the future was cancelled.\\n            TimeoutError: If the future didn\\'t finish executing before the given\\n                timeout.\\n        \"\"\"\\n        with self._condition:\\n            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\\n                raise CancelledError()\\n            elif self._state == FINISHED:\\n                return self._exception, self._traceback\\n\\n            self._condition.wait(timeout)\\n\\n            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\\n                raise CancelledError()\\n            elif self._state == FINISHED:\\n                return self._exception, self._traceback\\n            else:\\n                raise TimeoutError()',\n",
              " 'def set_exception_info(self, exception, traceback):\\n        \"\"\"Sets the result of the future as being the given exception\\n        and traceback.\\n\\n        Should only be used by Executor implementations and unit tests.\\n        \"\"\"\\n        with self._condition:\\n            self._exception = exception\\n            self._traceback = traceback\\n            self._state = FINISHED\\n            for waiter in self._waiters:\\n                waiter.add_exception(self)\\n            self._condition.notify_all()\\n        self._invoke_callbacks()',\n",
              " 'def map(self, fn, *iterables, **kwargs):\\n        \"\"\"Returns a iterator equivalent to map(fn, iter).\\n\\n        Args:\\n            fn: A callable that will take as many arguments as there are\\n                passed iterables.\\n            timeout: The maximum number of seconds to wait. If None, then there\\n                is no limit on the wait time.\\n\\n        Returns:\\n            An iterator equivalent to: map(func, *iterables) but the calls may\\n            be evaluated out-of-order.\\n\\n        Raises:\\n            TimeoutError: If the entire result iterator could not be generated\\n                before the given timeout.\\n            Exception: If fn(*args) raises for any values.\\n        \"\"\"\\n        timeout = kwargs.get(\\'timeout\\')\\n        if timeout is not None:\\n            end_time = timeout + time.time()\\n\\n        fs = [self.submit(fn, *args) for args in itertools.izip(*iterables)]\\n\\n        # Yield must be hidden in closure so that the futures are submitted\\n        # before the first iterator value is required.\\n        def result_iterator():\\n            try:\\n                for future in fs:\\n                    if timeout is None:\\n                        yield future.result()\\n                    else:\\n                        yield future.result(end_time - time.time())\\n            finally:\\n                for future in fs:\\n                    future.cancel()\\n        return result_iterator()',\n",
              " 'def dump(obj, file, protocol=None, dump_code=False):\\n    \"\"\"Serialize obj as bytes streamed into file\\n\\n    protocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\\n    pickle.HIGHEST_PROTOCOL. This setting favors maximum communication speed\\n    between processes running the same Python version.\\n\\n    Set protocol=pickle.DEFAULT_PROTOCOL instead if you need to ensure\\n    compatibility with older versions of Python.\\n    \"\"\"\\n    CloudPickler(file, protocol=protocol, dump_code=dump_code).dump(obj)',\n",
              " 'def _make_skel_func(code, cell_count, base_globals=None):\\n    \"\"\" Creates a skeleton function object that contains just the provided\\n        code and the correct number of cells in func_closure.  All other\\n        func attributes (e.g. func_globals) are empty.\\n    \"\"\"\\n    if base_globals is None:\\n        base_globals = {}\\n    elif isinstance(base_globals, string_types):\\n        base_globals_name = base_globals\\n        try:\\n            # First try to reuse the globals from the module containing the\\n            # function. If it is not possible to retrieve it, fallback to an\\n            # empty dictionary.\\n            if importlib is not None:\\n                base_globals = vars(importlib.import_module(base_globals))\\n            elif sys.modules.get(base_globals, None) is not None:\\n                base_globals = vars(sys.modules[base_globals])\\n            else:\\n                raise ImportError\\n        except ImportError:\\n            base_globals = _dynamic_modules_globals.get(\\n                    base_globals_name, None)\\n            if base_globals is None:\\n                base_globals = _DynamicModuleFuncGlobals()\\n            _dynamic_modules_globals[base_globals_name] = base_globals\\n\\n    base_globals[\\'__builtins__\\'] = __builtins__\\n\\n    closure = (\\n        tuple(_make_empty_cell() for _ in range(cell_count))\\n        if cell_count >= 0 else\\n        None\\n    )\\n    return types.FunctionType(code, base_globals, None, None, closure)',\n",
              " 'def save_module(self, obj):\\n        \"\"\"\\n        Save a module as an import\\n        \"\"\"\\n        self.modules.add(obj)\\n        if _is_dynamic(obj):\\n            self.save_reduce(dynamic_subimport, (obj.__name__, vars(obj)),\\n                             obj=obj)\\n        else:\\n            self.save_reduce(subimport, (obj.__name__,), obj=obj)',\n",
              " 'def save_codeobject(self, obj):\\n        \"\"\"\\n        Save a code object\\n        \"\"\"\\n        if self.dump_code:\\n            print(obj.co_name)\\n            dis.dis(obj.co_code)\\n        self.save_reduce(types.CodeType, self._extract_code_args(obj), obj=obj)',\n",
              " 'def extract_func_data(self, func):\\n        \"\"\"\\n        Turn the function into a tuple of data necessary to recreate it:\\n            code, globals, defaults, closure_values, dict\\n        \"\"\"\\n        code = func.__code__\\n\\n        # extract all global ref\\'s\\n        func_global_refs = self.extract_code_globals(code)\\n\\n        # process all variables referenced by global environment\\n        f_globals = {}\\n        for var in func_global_refs:\\n            if var in func.__globals__:\\n                f_globals[var] = func.__globals__[var]\\n\\n        # defaults requires no processing\\n        defaults = func.__defaults__\\n\\n        # process closure\\n        closure = (\\n            list(map(_get_cell_contents, func.__closure__))\\n            if func.__closure__ is not None\\n            else None\\n        )\\n\\n        # save the dict\\n        dct = func.__dict__\\n\\n        base_globals = self.globals_ref.get(id(func.__globals__), None)\\n        if base_globals is None:\\n            # For functions defined in a well behaved module use\\n            # vars(func.__module__) for base_globals. This is necessary to\\n            # share the global variables across multiple pickled functions from\\n            # this module.\\n            if hasattr(func, \\'__module__\\') and func.__module__ is not None:\\n                base_globals = func.__module__\\n            else:\\n                base_globals = {}\\n        self.globals_ref[id(func.__globals__)] = base_globals\\n\\n        return (code, f_globals, defaults, closure, dct, base_globals)',\n",
              " 'def persist(self, name, project=None, drop_model=False, **kwargs):\\n        \"\"\"\\n        Persist the execution into a new model.\\n\\n        :param name: model name\\n        :param project: name of the project\\n        :param drop_model: drop model before creation\\n        \"\"\"\\n        return super(ODPSModelExpr, self).persist(name, project=project, drop_model=drop_model, **kwargs)',\n",
              " 'def predict(self, *args, **kwargs):\\n        \"\"\"\\n        Predict given DataFrame using the given model. Actual prediction steps will not\\n        be executed till an operational step is called.\\n\\n        After execution, three columns will be appended to the table:\\n\\n        +-------------------+--------+----------------------------------------------------+\\n        | Field name        | Type   | Comments                                           |\\n        +===================+========+====================================================+\\n        | prediction_result | string | field indicating the predicted label, absent if    |\\n        |                   |        | the model is a regression model                    |\\n        +-------------------+--------+----------------------------------------------------+\\n        | prediction_score  | double | field indicating the score value if the model is   |\\n        |                   |        | a classification model, or the predicted value if  |\\n        |                   |        | the model is a regression model.                   |\\n        +-------------------+--------+----------------------------------------------------+\\n        | prediction_detail | string | field in JSON format indicating the score for      |\\n        |                   |        | every class.                                       |\\n        +-------------------+--------+----------------------------------------------------+\\n\\n        :type df: DataFrame\\n        :rtype: DataFrame\\n\\n        :Example:\\n\\n        >>> model = PmmlModel(odps.get_offline_model(\\'model_name\\'))\\n        >>> data = DataFrame(odps.get_table(\\'table_name\\'))\\n        >>> # prediction below will not be executed till predicted.persist is called\\n        >>> predicted = model.predict(data)\\n        >>> predicted.persist(\\'predicted\\')\\n        \"\"\"\\n        return super(PmmlModel, self).predict(*args, **kwargs)',\n",
              " 'def predict(self, *args, **kwargs):\\n        \"\"\"\\n        Predict given DataFrame using the given model. Actual prediction steps will not\\n        be executed till an operational step is called.\\n\\n        :param list[DataFrame] args: input DataFrames to be predicted\\n        :param kwargs: named input DataFrames or prediction parameters, details can be found in \\'\\'Predictor Parameters\\'\\' section of training algorithms.\\n\\n        A :class:`DataFrame` object will be generated for input data. Output fields may be referenced in the\\n        documents of training algorithms.\\n        \"\"\"\\n        return super(TablesModel, self).predict(*args, **kwargs)',\n",
              " 'def get_log(self, log_type, size=0):\\n        \"\"\"\\n        Get logs from worker.\\n\\n        :param log_type: type of logs. Possible log types contains {log_types}\\n        :param size: length of the log to retrieve\\n        :return: log content\\n        \"\"\"\\n        return self.parent.get_worker_log(self.log_id, log_type, size=size)',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        fields = self._get_fields_list_from_eps(sources)\\n        target._ml_fields = copy.deepcopy(fields[0])',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        fields = self._get_fields_list_from_eps(sources)\\n        feature_set = set(self.feature_names)\\n        target._ml_fields = list(self._add_field_roles(fields[0], feature_set, self.role, self.augment))',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        fields = self._get_fields_list_from_eps(sources)\\n        feature_set = set(self.exclude_names)\\n        target._ml_fields = list(self._clear_field_roles(fields[0], feature_set))',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        fields = self._get_fields_list_from_eps(sources)\\n        ret_fields = fields[0]\\n        if self.clear_feature:\\n            ret_fields = list(self._remove_field_roles(ret_fields, set(six.iterkeys(self.field_mapping)),\\n                                                       FieldRole.FEATURE))\\n        target._ml_fields = list(self._set_singleton_role(ret_fields, self.field_mapping))',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        fields = self._get_fields_list_from_eps(sources)\\n        for f in fields[0]:\\n            if f.name in self.continuity:\\n                f.continuity = self.continuity[f.name]\\n        for field_name in set(six.iterkeys(self.continuity)) - set(f.name for f in fields[0]):\\n            fields[0].append(MLField(field_name, \\'EXPECTED\\', None, continuity=self.continuity[field_name]))\\n        target._ml_fields = fields[0]',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        existing_ml_fields = self._get_fields_list_from_eps(sources)\\n        dup_ml_fields = [f.copy() for f in self.fields]\\n        if self.is_append:\\n            src = list([copy.deepcopy(f) for f in existing_ml_fields[0]])\\n            src.extend(dup_ml_fields)\\n            target._ml_fields = src\\n        else:\\n            target._ml_fields = self.fields',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        existing_ml_fields = self._get_fields_list_from_eps(sources)\\n\\n        def gen_field(field_str):\\n            parts = field_str.split(\\':\\')\\n            if len(parts) > 2:\\n                roles = set(MLField.translate_role_name(rn) for rn in parts[2].strip().split(\\'#\\')) - set([None])\\n            else:\\n                roles = set([FieldRole.FEATURE, ])\\n            return MLField(parts[0].strip(), parts[1].strip(), roles)\\n\\n        fields = [gen_field(fstr) for fstr in self.evaluator().split(\\',\\')\\n                  if fstr.strip() != \\'\\']\\n\\n        dup_ml_fields = [f.copy(None) for f in fields]\\n        if self.is_append:\\n            src = list([copy.deepcopy(f) for f in existing_ml_fields[0]])\\n            src.extend(dup_ml_fields)\\n            target._ml_fields = src\\n        else:\\n            target._ml_fields = fields',\n",
              " 'def execute(self, sources, target):\\n        \"\"\"\\n        :type sources: list[DFAdapter]\\n        :type target: DFAdapter\\n        \"\"\"\\n        existing_fields = self._get_fields_list_from_eps(sources)\\n\\n        def trans_columns(tid, fields):\\n            sel_cols = self._selected_cols.get(tid)\\n            exc_cols = self._excluded_cols.get(tid)\\n            for field in fields:\\n                if field.role is None:\\n                    continue\\n                if sel_cols and field.name not in sel_cols:\\n                    continue\\n                if exc_cols and field.name in exc_cols:\\n                    continue\\n                new_col = field.copy(field.role)\\n                if self._auto_rename:\\n                    new_col.name = \\'t%d_%s\\' % (tid, field.name)\\n                yield new_col\\n\\n        new_fields = map(lambda tp: list(trans_columns(tp[0], tp[1])), enumerate(existing_fields))\\n        target._ml_fields = list(reduce(lambda fa, fb: fa + fb, new_fields, []))\\n        target._ml_uplink = sources',\n",
              " 'def count(expr):\\n    \"\"\"\\n    Value counts\\n\\n    :param expr:\\n    :return:\\n    \"\"\"\\n\\n    if isinstance(expr, SequenceExpr):\\n        unique_input = _extract_unique_input(expr)\\n        if unique_input:\\n            return nunique(unique_input).rename(\\'count\\')\\n        else:\\n            return Count(_value_type=types.int64, _input=expr)\\n    elif isinstance(expr, SequenceGroupBy):\\n        return GroupedCount(_data_type=types.int64, _input=expr.to_column(),\\n                            _grouped=expr.input)\\n    elif isinstance(expr, CollectionExpr):\\n        return Count(_value_type=types.int64, _input=expr).rename(\\'count\\')\\n    elif isinstance(expr, GroupBy):\\n        return GroupedCount(_data_type=types.int64, _input=expr.input,\\n                            _grouped=expr).rename(\\'count\\')',\n",
              " 'def var(expr, **kw):\\n    \"\"\"\\n    Variance\\n\\n    :param expr:\\n    :param ddof: degree of freedom\\n    :param kw:\\n    :return:\\n    \"\"\"\\n\\n    ddof = kw.get(\\'ddof\\', kw.get(\\'_ddof\\', 1))\\n\\n    output_type = _stats_type(expr)\\n    return _reduction(expr, Var, output_type, _ddof=ddof)',\n",
              " 'def sum_(expr):\\n    \"\"\"\\n    Sum value\\n\\n    :param expr:\\n    :return:\\n    \"\"\"\\n\\n    output_type = None\\n    if isinstance(expr, (SequenceExpr, SequenceGroupBy)):\\n        if expr._data_type == types.boolean:\\n            output_type = types.int64\\n        else:\\n            output_type = expr._data_type\\n    return _reduction(expr, Sum, output_type)',\n",
              " 'def std(expr, **kw):\\n    \"\"\"\\n    Standard deviation.\\n\\n    :param expr:\\n    :param kw:\\n    :return:\\n    \"\"\"\\n\\n    ddof = kw.get(\\'ddof\\', kw.get(\\'_ddof\\', 1))\\n\\n    output_type = _stats_type(expr)\\n    return _reduction(expr, Std, output_type, _ddof=ddof)',\n",
              " 'def quantile(expr, prob=None, **kw):\\n    \"\"\"\\n    Percentile value.\\n\\n    :param expr:\\n    :param prob: probability or list of probabilities, in [0, 1]\\n    :return:\\n    \"\"\"\\n\\n    prob = kw.get(\\'_prob\\', prob)\\n    output_type = _stats_type(expr)\\n    if isinstance(prob, (list, set)) and not isinstance(expr, GroupBy):\\n        output_type = types.List(output_type)\\n    return _reduction(expr, Quantile, output_type, _prob=prob)',\n",
              " 'def nunique(expr):\\n    \"\"\"\\n    The distinct count.\\n\\n    :param expr:\\n    :return:\\n    \"\"\"\\n    output_type = types.int64\\n\\n    if isinstance(expr, SequenceExpr):\\n        return NUnique(_value_type=output_type, _inputs=[expr])\\n    elif isinstance(expr, SequenceGroupBy):\\n        return GroupedNUnique(_data_type=output_type, _inputs=[expr.to_column()], _grouped=expr.input)\\n    elif isinstance(expr, CollectionExpr):\\n        unique_input = _extract_unique_input(expr)\\n        if unique_input:\\n            return nunique(unique_input)\\n        else:\\n            return NUnique(_value_type=types.int64, _inputs=expr._project_fields)\\n    elif isinstance(expr, GroupBy):\\n        if expr._to_agg:\\n            inputs = expr.input[expr._to_agg.names]._project_fields\\n        else:\\n            inputs = expr.input._project_fields\\n        return GroupedNUnique(_data_type=types.int64, _inputs=inputs,\\n                              _grouped=expr)',\n",
              " 'def cat(expr, others=None, sep=None, na_rep=None):\\n    \"\"\"\\n    Concatenate strings in sequence with given separator\\n\\n    :param expr:\\n    :param others: other sequences\\n    :param sep: string or None, default None\\n    :param na_rep: string or None default None, if None, NA in the sequence are ignored\\n    :return:\\n    \"\"\"\\n\\n    if others is not None:\\n        from .strings import _cat as cat_str\\n\\n        return cat_str(expr, others, sep=sep, na_rep=na_rep)\\n\\n    return _cat(expr, sep=sep, na_rep=na_rep)',\n",
              " 'def moment(expr, order, central=False):\\n    \"\"\"\\n    Calculate the n-th order moment of the sequence\\n\\n    :param expr:\\n    :param order: moment order, must be an integer\\n    :param central: if central moments are to be computed.\\n    :return:\\n    \"\"\"\\n    if not isinstance(order, six.integer_types):\\n        raise ValueError(\\'Only integer-ordered moments are supported.\\')\\n    if order < 0:\\n        raise ValueError(\\'Only non-negative orders are supported.\\')\\n    output_type = _stats_type(expr)\\n    return _reduction(expr, Moment, output_type, _order=order, _center=central)',\n",
              " 'def tolist(expr, **kwargs):\\n    \"\"\"\\n    Pack all data in the sequence into a list\\n    :param expr:\\n    :param unique: make every elements in the sequence to be unique\\n    :return:\\n    \"\"\"\\n    unique = kwargs.get(\\'unique\\', kwargs.get(\\'_unique\\', False))\\n    output_type = None\\n\\n    if isinstance(expr, (SequenceExpr, SequenceGroupBy)):\\n        output_type = types.List(expr._data_type)\\n    return _reduction(expr, ToList, output_type, _unique=unique)',\n",
              " 'def stop(self):\\n        \"\"\"\\n        Stop this instance.\\n\\n        :return: None\\n        \"\"\"\\n\\n        instance_status = Instance.InstanceStatus(status=\\'Terminated\\')\\n        xml_content = instance_status.serialize()\\n\\n        headers = {\\'Content-Type\\': \\'application/xml\\'}\\n        self._client.put(self.resource(), xml_content, headers=headers)',\n",
              " 'def get_task_results(self):\\n        \"\"\"\\n        Get all the task results.\\n\\n        :return: a dict which key is task name, and value is the task result as string\\n        :rtype: dict\\n        \"\"\"\\n\\n        results = self.get_task_results_without_format()\\n        if options.tunnel.string_as_binary:\\n            return compat.OrderedDict([(k, bytes(result)) for k, result in six.iteritems(results)])\\n        else:\\n            return compat.OrderedDict([(k, str(result)) for k, result in six.iteritems(results)])',\n",
              " 'def get_task_summary(self, task_name):\\n        \"\"\"\\n        Get a task\\'s summary, mostly used for MapReduce.\\n\\n        :param task_name: task name\\n        :return: summary as a dict parsed from JSON\\n        :rtype: dict\\n        \"\"\"\\n\\n        params = {\\'instancesummary\\': \\'\\', \\'taskname\\': task_name}\\n        resp = self._client.get(self.resource(), params=params)\\n\\n        map_reduce = resp.json().get(\\'Instance\\')\\n        if map_reduce:\\n            json_summary = map_reduce.get(\\'JsonSummary\\')\\n            if json_summary:\\n                summary = Instance.TaskSummary(json.loads(json_summary))\\n                summary.summary_text = map_reduce.get(\\'Summary\\')\\n                summary.json_summary = json_summary\\n\\n                return summary',\n",
              " 'def get_task_statuses(self):\\n        \"\"\"\\n        Get all tasks\\' statuses\\n\\n        :return: a dict which key is the task name and value is the :class:`odps.models.Instance.Task` object\\n        :rtype: dict\\n        \"\"\"\\n\\n        params = {\\'taskstatus\\': \\'\\'}\\n\\n        resp = self._client.get(self.resource(), params=params)\\n        self.parse(self._client, resp, obj=self)\\n\\n        return dict([(task.name, task) for task in self._tasks])',\n",
              " 'def get_task_cost(self, task_name):\\n        \"\"\"\\n        Get task cost\\n\\n        :param task_name: name of the task\\n        :return: task cost\\n        :rtype: Instance.TaskCost\\n\\n        :Example:\\n\\n        >>> cost = instance.get_task_cost(instance.get_task_names()[0])\\n        >>> cost.cpu_cost\\n        200\\n        >>> cost.memory_cost\\n        4096\\n        >>> cost.input_size\\n        0\\n        \"\"\"\\n        summary = self.get_task_summary(task_name)\\n        if summary is None:\\n            return None\\n\\n        if \\'Cost\\' in summary:\\n            task_cost = summary[\\'Cost\\']\\n\\n            cpu_cost = task_cost.get(\\'CPU\\')\\n            memory = task_cost.get(\\'Memory\\')\\n            input_size = task_cost.get(\\'Input\\')\\n\\n            return Instance.TaskCost(cpu_cost, memory, input_size)',\n",
              " 'def get_task_info(self, task_name, key):\\n        \"\"\"\\n        Get task related information.\\n\\n        :param task_name: name of the task\\n        :param key: key of the information item\\n        :return: a string of the task information\\n        \"\"\"\\n        params = OrderedDict([(\\'info\\', \\'\\'), (\\'taskname\\', task_name), (\\'key\\', key)])\\n\\n        resp = self._client.get(self.resource(), params=params)\\n        return resp.text',\n",
              " 'def put_task_info(self, task_name, key, value):\\n        \"\"\"\\n        Put information into a task.\\n\\n        :param task_name: name of the task\\n        :param key: key of the information item\\n        :param value: value of the information item\\n        \"\"\"\\n        params = OrderedDict([(\\'info\\', \\'\\'), (\\'taskname\\', task_name)])\\n        headers = {\\'Content-Type\\': \\'application/xml\\'}\\n        body = self.TaskInfo(key=key, value=value).serialize()\\n\\n        self._client.put(self.resource(), params=params, headers=headers, data=body)',\n",
              " 'def get_task_quota(self, task_name):\\n        \"\"\"\\n        Get queueing info of the task.\\n        Note that time between two calls should larger than 30 seconds, otherwise empty dict is returned.\\n\\n        :param task_name: name of the task\\n        :return: quota info in dict format\\n        \"\"\"\\n        params = OrderedDict([(\\'instancequota\\', \\'\\'), (\\'taskname\\', task_name)])\\n        resp = self._client.get(self.resource(), params=params)\\n        return json.loads(resp.text)',\n",
              " 'def get_sql_task_cost(self):\\n        \"\"\"\\n        Get cost information of the sql task.\\n        Including input data size, number of UDF, Complexity of the sql task\\n\\n        :return: cost info in dict format\\n        \"\"\"\\n        resp = self.get_task_result(self.get_task_names()[0])\\n        cost = json.loads(resp)\\n        sql_cost = cost[\\'Cost\\'][\\'SQL\\']\\n\\n        udf_num = sql_cost.get(\\'UDF\\')\\n        complexity = sql_cost.get(\\'Complexity\\')\\n        input_size = sql_cost.get(\\'Input\\')\\n        return Instance.SQLCost(udf_num, complexity, input_size)',\n",
              " 'def is_terminated(self, retry=False):\\n        \"\"\"\\n        If this instance has finished or not.\\n\\n        :return: True if finished else False\\n        :rtype: bool\\n        \"\"\"\\n        retry_num = options.retry_times\\n        while retry_num > 0:\\n            try:\\n                return self.status == Instance.Status.TERMINATED\\n            except (errors.InternalServerError, errors.RequestTimeTooSkewed):\\n                retry_num -= 1\\n                if not retry or retry_num <= 0:\\n                    raise',\n",
              " 'def is_successful(self, retry=False):\\n        \"\"\"\\n        If the instance runs successfully.\\n\\n        :return: True if successful else False\\n        :rtype: bool\\n        \"\"\"\\n\\n        if not self.is_terminated(retry=retry):\\n            return False\\n        retry_num = options.retry_times\\n        while retry_num > 0:\\n            try:\\n                statuses = self.get_task_statuses()\\n                return all(task.status == Instance.Task.TaskStatus.SUCCESS\\n                           for task in statuses.values())\\n            except (errors.InternalServerError, errors.RequestTimeTooSkewed):\\n                retry_num -= 1\\n                if not retry or retry_num <= 0:\\n                    raise',\n",
              " 'def wait_for_completion(self, interval=1):\\n        \"\"\"\\n        Wait for the instance to complete, and neglect the consequence.\\n\\n        :param interval: time interval to check\\n        :return: None\\n        \"\"\"\\n\\n        while not self.is_terminated(retry=True):\\n            try:\\n                time.sleep(interval)\\n            except KeyboardInterrupt:\\n                break',\n",
              " 'def wait_for_success(self, interval=1):\\n        \"\"\"\\n        Wait for instance to complete, and check if the instance is successful.\\n\\n        :param interval: time interval to check\\n        :return: None\\n        :raise: :class:`odps.errors.ODPSError` if the instance failed\\n        \"\"\"\\n\\n        self.wait_for_completion(interval=interval)\\n\\n        if not self.is_successful(retry=True):\\n            for task_name, task in six.iteritems(self.get_task_statuses()):\\n                exc = None\\n                if task.status == Instance.Task.TaskStatus.FAILED:\\n                    exc = errors.parse_instance_error(self.get_task_result(task_name))\\n                elif task.status != Instance.Task.TaskStatus.SUCCESS:\\n                    exc = errors.ODPSError(\\'%s, status=%s\\' % (task_name, task.status.value))\\n                if exc:\\n                    exc.instance_id = self.id\\n                    raise exc',\n",
              " 'def get_task_progress(self, task_name):\\n        \"\"\"\\n        Get task\\'s current progress\\n\\n        :param task_name: task_name\\n        :return: the task\\'s progress\\n        :rtype: :class:`odps.models.Instance.Task.TaskProgress`\\n        \"\"\"\\n\\n        params = {\\'instanceprogress\\': task_name, \\'taskname\\': task_name}\\n\\n        resp = self._client.get(self.resource(), params=params)\\n        return Instance.Task.TaskProgress.parse(self._client, resp)',\n",
              " 'def get_task_detail(self, task_name):\\n        \"\"\"\\n        Get task\\'s detail\\n\\n        :param task_name: task name\\n        :return: the task\\'s detail\\n        :rtype: list or dict according to the JSON\\n        \"\"\"\\n        def _get_detail():\\n            from ..compat import json  # fix object_pairs_hook parameter for Py2.6\\n\\n            params = {\\'instancedetail\\': \\'\\',\\n                      \\'taskname\\': task_name}\\n\\n            resp = self._client.get(self.resource(), params=params)\\n            return json.loads(resp.text if six.PY3 else resp.content,\\n                              object_pairs_hook=OrderedDict)\\n\\n        result = _get_detail()\\n        if not result:\\n            # todo: this is a workaround for the bug that get_task_detail returns nothing.\\n            self.get_task_detail2(task_name)\\n            return _get_detail()\\n        else:\\n            return result',\n",
              " 'def get_task_detail2(self, task_name):\\n        \"\"\"\\n        Get task\\'s detail v2\\n\\n        :param task_name: task name\\n        :return: the task\\'s detail\\n        :rtype: list or dict according to the JSON\\n        \"\"\"\\n\\n        from ..compat import json  # fix object_pairs_hook parameter for Py2.6\\n\\n        params = {\\'detail\\': \\'\\',\\n                  \\'taskname\\': task_name}\\n\\n        resp = self._client.get(self.resource(), params=params)\\n        res = resp.text if six.PY3 else resp.content\\n        try:\\n            return json.loads(res, object_pairs_hook=OrderedDict)\\n        except ValueError:\\n            return res',\n",
              " 'def get_task_workers(self, task_name=None, json_obj=None):\\n        \"\"\"\\n        Get workers from task\\n        :param task_name: task name\\n        :param json_obj: json object parsed from get_task_detail2\\n        :return: list of workers\\n\\n        .. seealso:: :class:`odps.models.Worker`\\n        \"\"\"\\n        if task_name is None and json_obj is None:\\n            raise ValueError(\\'Either task_name or json_obj should be provided\\')\\n\\n        if json_obj is None:\\n            json_obj = self.get_task_detail2(task_name)\\n        return WorkerDetail2.extract_from_json(json_obj, client=self._client, parent=self)',\n",
              " 'def get_worker_log(self, log_id, log_type, size=0):\\n        \"\"\"\\n        Get logs from worker.\\n\\n        :param log_id: id of log, can be retrieved from details.\\n        :param log_type: type of logs. Possible log types contains {log_types}\\n        :param size: length of the log to retrieve\\n        :return: log content\\n        \"\"\"\\n        params = OrderedDict([(\\'log\\', \\'\\'), (\\'id\\', log_id)])\\n        if log_type is not None:\\n            log_type = log_type.lower()\\n            if log_type not in LOG_TYPES_MAPPING:\\n                raise ValueError(\\'log_type should choose a value in \\' +\\n                                 \\' \\'.join(six.iterkeys(LOG_TYPES_MAPPING)))\\n            params[\\'logtype\\'] = LOG_TYPES_MAPPING[log_type]\\n        if size > 0:\\n            params[\\'size\\'] = str(size)\\n        resp = self._client.get(self.resource(), params=params)\\n        return resp.text',\n",
              " 'def get_logview_address(self, hours=None):\\n        \"\"\"\\n        Get logview address of the instance object by hours.\\n\\n        :param hours:\\n        :return: logview address\\n        :rtype: str\\n        \"\"\"\\n        hours = hours or options.log_view_hours\\n\\n        project = self.project\\n        url = \\'%s/authorization\\' % project.resource()\\n\\n        policy = {\\n            \\'expires_in_hours\\': hours,\\n            \\'policy\\': {\\n                \\'Statement\\': [{\\n                    \\'Action\\': [\\'odps:Read\\'],\\n                    \\'Effect\\': \\'Allow\\',\\n                    \\'Resource\\': \\'acs:odps:*:projects/%s/instances/%s\\' % \\\\\\n                                (project.name, self.id)\\n                }],\\n                \\'Version\\': \\'1\\',\\n            }\\n        }\\n        headers = {\\'Content-Type\\': \\'application/json\\'}\\n        params = {\\'sign_bearer_token\\': \\'\\'}\\n        data = json.dumps(policy)\\n        res = self._client.post(url, data, headers=headers, params=params)\\n\\n        content = res.text if six.PY3 else res.content\\n        root = ElementTree.fromstring(content)\\n        token = root.find(\\'Result\\').text\\n\\n        link = options.log_view_host + \"/logview/?h=\" + self._client.endpoint + \"&p=\" \\\\\\n               + project.name + \"&i=\" + self.id + \"&token=\" + token\\n        return link',\n",
              " 'def open_reader(self, *args, **kwargs):\\n        \"\"\"\\n        Open the reader to read records from the result of the instance. If `tunnel` is `True`,\\n        instance tunnel will be used. Otherwise conventional routine will be used. If instance tunnel\\n        is not available and `tunnel` is not specified,, the method will fall back to the\\n        conventional routine.\\n        Note that the number of records returned is limited unless `options.limited_instance_tunnel`\\n        is set to `True` or `limit=True` is configured under instance tunnel mode. Otherwise\\n        the number of records returned is always limited.\\n\\n        :param tunnel: if true, use instance tunnel to read from the instance.\\n                       if false, use conventional routine.\\n                       if absent, `options.tunnel.use_instance_tunnel` will be used and automatic fallback\\n                       is enabled.\\n        :param reopen: the reader will reuse last one, reopen is true means open a new reader.\\n        :type reopen: bool\\n        :param endpoint: the tunnel service URL\\n        :param compress_option: compression algorithm, level and strategy\\n        :type compress_option: :class:`odps.tunnel.CompressOption`\\n        :param compress_algo: compression algorithm, work when ``compress_option`` is not provided,\\n                              can be ``zlib``, ``snappy``\\n        :param compress_level: used for ``zlib``, work when ``compress_option`` is not provided\\n        :param compress_strategy: used for ``zlib``, work when ``compress_option`` is not provided\\n        :return: reader, ``count`` means the full size, ``status`` means the tunnel status\\n\\n        :Example:\\n\\n        >>> with instance.open_reader() as reader:\\n        >>>     count = reader.count  # How many records of a table or its partition\\n        >>>     for record in reader[0: count]:\\n        >>>         # read all data, actually better to split into reading for many times\\n        \"\"\"\\n        use_tunnel = kwargs.get(\\'use_tunnel\\', kwargs.get(\\'tunnel\\'))\\n        auto_fallback_result = use_tunnel is None\\n        if use_tunnel is None:\\n            use_tunnel = options.tunnel.use_instance_tunnel\\n        result_fallback_errors = (errors.InvalidProjectTable, errors.InvalidArgument)\\n        if use_tunnel:\\n            # for compatibility\\n            if \\'limit_enabled\\' in kwargs:\\n                kwargs[\\'limit\\'] = kwargs[\\'limit_enabled\\']\\n                del kwargs[\\'limit_enabled\\']\\n\\n            if \\'limit\\' not in kwargs:\\n                kwargs[\\'limit\\'] = options.tunnel.limit_instance_tunnel\\n\\n            auto_fallback_protection = False\\n            if kwargs[\\'limit\\'] is None:\\n                kwargs[\\'limit\\'] = False\\n                auto_fallback_protection = True\\n\\n            try:\\n                return self._open_tunnel_reader(**kwargs)\\n            except result_fallback_errors:\\n                # service version too low to support instance tunnel.\\n                if not auto_fallback_result:\\n                    raise\\n                if not kwargs.get(\\'limit\\'):\\n                    warnings.warn(\\'Instance tunnel not supported, will fallback to \\'\\n                                  \\'conventional ways. 10000 records will be limited.\\')\\n            except requests.Timeout:\\n                # tunnel creation timed out, which might be caused by too many files\\n                # on the service.\\n                if not auto_fallback_result:\\n                    raise\\n                if not kwargs.get(\\'limit\\'):\\n                    warnings.warn(\\'Instance tunnel timed out, will fallback to \\'\\n                                  \\'conventional ways. 10000 records will be limited.\\')\\n            except (Instance.DownloadSessionCreationError, errors.InstanceTypeNotSupported):\\n                # this is for DDL sql instances such as `show partitions` which raises\\n                # InternalServerError when creating download sessions.\\n                if not auto_fallback_result:\\n                    raise\\n            except errors.NoPermission:\\n                # project is protected\\n                if not auto_fallback_protection:\\n                    raise\\n                if not kwargs.get(\\'limit\\'):\\n                    warnings.warn(\\'Project under protection, 10000 records will be limited.\\')\\n                    kwargs[\\'limit\\'] = True\\n                    return self._open_tunnel_reader(**kwargs)\\n\\n        return self._open_result_reader(*args, **kwargs)',\n",
              " 'def in_qtconsole():\\n    \"\"\"\\n    check if we\\'re inside an IPython qtconsole\\n\\n    DEPRECATED: This is no longer needed, or working, in IPython 3 and above.\\n    \"\"\"\\n    try:\\n        ip = get_ipython()\\n        front_end = (\\n            ip.config.get(\\'KernelApp\\', {}).get(\\'parent_appname\\', \"\") or\\n            ip.config.get(\\'IPKernelApp\\', {}).get(\\'parent_appname\\', \"\")\\n        )\\n        if \\'qtconsole\\' in front_end.lower():\\n            return True\\n    except:\\n        return False\\n    return False',\n",
              " 'def get_console_size():\\n    \"\"\"Return console size as tuple = (width, height).\\n\\n    Returns (None,None) in non-interactive session.\\n    \"\"\"\\n    display_width = options.display.width\\n    # deprecated.\\n    display_height = options.display.max_rows\\n\\n    # Consider\\n    # interactive shell terminal, can detect term size\\n    # interactive non-shell terminal (ipnb/ipqtconsole), cannot detect term\\n    # size non-interactive script, should disregard term size\\n\\n    # in addition\\n    # width,height have default values, but setting to \\'None\\' signals\\n    # should use Auto-Detection, But only in interactive shell-terminal.\\n    # Simple. yeah.\\n\\n    if in_interactive_session():\\n        if in_ipython_frontend():\\n            # sane defaults for interactive non-shell terminal\\n            # match default for width,height in config_init\\n            try:\\n                from pandas.core.config import get_default_val\\n                terminal_width = get_default_val(\\'display.width\\')\\n                terminal_height = get_default_val(\\'display.max_rows\\')\\n            except ImportError:\\n                terminal_width, terminal_height = None, None\\n        else:\\n            # pure terminal\\n            terminal_width, terminal_height = get_terminal_size()\\n    else:\\n        terminal_width, terminal_height = None, None\\n\\n    # Note if the User sets width/Height to None (auto-detection)\\n    # and we\\'re in a script (non-inter), this will return (None,None)\\n    # caller needs to deal.\\n    return (display_width or terminal_width, display_height or terminal_height)',\n",
              " 'def _get_stdout(stderr=False):\\n    \"\"\"\\n    This utility function contains the logic to determine what streams to use\\n    by default for standard out/err.\\n\\n    Typically this will just return `sys.stdout`, but it contains additional\\n    logic for use in IPython on Windows to determine the correct stream to use\\n    (usually ``IPython.util.io.stdout`` but only if sys.stdout is a TTY).\\n    \"\"\"\\n\\n    if stderr:\\n        stream = \\'stderr\\'\\n    else:\\n        stream = \\'stdout\\'\\n\\n    sys_stream = getattr(sys, stream)\\n\\n    if IPythonIOStream is None:\\n        return sys_stream\\n\\n    ipyio_stream = getattr(ipyio, stream)\\n\\n    if isatty(sys_stream) and isatty(ipyio_stream):\\n        # Use the IPython console output stream\\n        return ipyio_stream\\n    else:\\n        # sys.stdout was set to some other non-TTY stream (a file perhaps)\\n        # so just use it directly\\n        return sys_stream',\n",
              " 'def isatty(file):\\n    \"\"\"\\n    Returns `True` if `file` is a tty.\\n\\n    Most built-in Python file-like objects have an `isatty` member,\\n    but some user-defined types may not, so this assumes those are not\\n    ttys.\\n    \"\"\"\\n    if (multiprocessing.current_process().name != \\'MainProcess\\' or\\n        threading.current_thread().getName() != \\'MainThread\\'):\\n        return False\\n\\n    if hasattr(file, \\'isatty\\'):\\n        return file.isatty()\\n    elif (OutStream is not None and\\n          isinstance(file, (OutStream, IPythonIOStream)) and\\n          ((hasattr(file, \\'name\\') and file.name == \\'stdout\\') or\\n           (hasattr(file, \\'stream\\') and\\n               isinstance(file.stream, PyreadlineConsole)))):\\n        # File is an IPython OutStream or IOStream and\\n        #    File name is \\'stdout\\' or\\n        #    File wraps a Console\\n        return True\\n    return False',\n",
              " 'def _terminal_size(file=None):\\n    \"\"\"\\n    Returns a tuple (height, width) containing the height and width of\\n    the terminal.\\n\\n    This function will look for the width in height in multiple areas\\n    before falling back on the width and height in astropy\\'s\\n    configuration.\\n    \"\"\"\\n\\n    if file is None:\\n        file = _get_stdout()\\n\\n    try:\\n        s = struct.pack(str(\"HHHH\"), 0, 0, 0, 0)\\n        x = fcntl.ioctl(file, termios.TIOCGWINSZ, s)\\n        (lines, width, xpixels, ypixels) = struct.unpack(str(\"HHHH\"), x)\\n        if lines > 12:\\n            lines -= 6\\n        if width > 10:\\n            width -= 1\\n        return (lines, width)\\n    except:\\n        try:\\n            # see if POSIX standard variables will work\\n            return (int(os.environ.get(\\'LINES\\')),\\n                    int(os.environ.get(\\'COLUMNS\\')))\\n        except TypeError:\\n            # fall back on configuration variables, or if not\\n            # set, (25, 80)\\n            lines = options.console.max_lines\\n            width = options.console.max_width\\n            if lines is None:\\n                lines = 25\\n            if width is None:\\n                width = 80\\n            return lines, width',\n",
              " 'def _color_text(text, color):\\n    \"\"\"\\n    Returns a string wrapped in ANSI color codes for coloring the\\n    text in a terminal::\\n\\n        colored_text = color_text(\\'Here is a message\\', \\'blue\\')\\n\\n    This won\\'t actually effect the text until it is printed to the\\n    terminal.\\n\\n    Parameters\\n    ----------\\n    text : str\\n        The string to return, bounded by the color codes.\\n    color : str\\n        An ANSI terminal color name. Must be one of:\\n        black, red, green, brown, blue, magenta, cyan, lightgrey,\\n        default, darkgrey, lightred, lightgreen, yellow, lightblue,\\n        lightmagenta, lightcyan, white, or \\'\\' (the empty string).\\n    \"\"\"\\n    color_mapping = {\\n        \\'black\\': \\'0;30\\',\\n        \\'red\\': \\'0;31\\',\\n        \\'green\\': \\'0;32\\',\\n        \\'brown\\': \\'0;33\\',\\n        \\'blue\\': \\'0;34\\',\\n        \\'magenta\\': \\'0;35\\',\\n        \\'cyan\\': \\'0;36\\',\\n        \\'lightgrey\\': \\'0;37\\',\\n        \\'default\\': \\'0;39\\',\\n        \\'darkgrey\\': \\'1;30\\',\\n        \\'lightred\\': \\'1;31\\',\\n        \\'lightgreen\\': \\'1;32\\',\\n        \\'yellow\\': \\'1;33\\',\\n        \\'lightblue\\': \\'1;34\\',\\n        \\'lightmagenta\\': \\'1;35\\',\\n        \\'lightcyan\\': \\'1;36\\',\\n        \\'white\\': \\'1;37\\'}\\n\\n    if sys.platform == \\'win32\\' and OutStream is None:\\n        # On Windows do not colorize text unless in IPython\\n        return text\\n\\n    color_code = color_mapping.get(color, \\'0;39\\')\\n    return \\'\\\\033[{0}m{1}\\\\033[0m\\'.format(color_code, text)',\n",
              " 'def _decode_preferred_encoding(s):\\n    \"\"\"Decode the supplied byte string using the preferred encoding\\n    for the locale (`locale.getpreferredencoding`) or, if the default encoding\\n    is invalid, fall back first on utf-8, then on latin-1 if the message cannot\\n    be decoded with utf-8.\\n    \"\"\"\\n\\n    enc = locale.getpreferredencoding()\\n    try:\\n        try:\\n            return s.decode(enc)\\n        except LookupError:\\n            enc = _DEFAULT_ENCODING\\n        return s.decode(enc)\\n    except UnicodeDecodeError:\\n        return s.decode(\\'latin-1\\')',\n",
              " 'def _write_with_fallback(s, write, fileobj):\\n    \"\"\"Write the supplied string with the given write function like\\n    ``write(s)``, but use a writer for the locale\\'s preferred encoding in case\\n    of a UnicodeEncodeError.  Failing that attempt to write with \\'utf-8\\' or\\n    \\'latin-1\\'.\\n    \"\"\"\\n\\n    if IPythonIOStream is not None and isinstance(fileobj, IPythonIOStream):\\n        # If the output stream is an IPython.utils.io.IOStream object that\\'s\\n        # not going to be very helpful to us since it doesn\\'t raise any\\n        # exceptions when an error occurs writing to its underlying stream.\\n        # There\\'s no advantage to us using IOStream.write directly though;\\n        # instead just write directly to its underlying stream:\\n        write = fileobj.stream.write\\n\\n    try:\\n        write(s)\\n        return write\\n    except UnicodeEncodeError:\\n        # Let\\'s try the next approach...\\n        pass\\n\\n    enc = locale.getpreferredencoding()\\n    try:\\n        Writer = codecs.getwriter(enc)\\n    except LookupError:\\n        Writer = codecs.getwriter(_DEFAULT_ENCODING)\\n\\n    f = Writer(fileobj)\\n    write = f.write\\n\\n    try:\\n        write(s)\\n        return write\\n    except UnicodeEncodeError:\\n        Writer = codecs.getwriter(\\'latin-1\\')\\n        f = Writer(fileobj)\\n        write = f.write\\n\\n    # If this doesn\\'t work let the exception bubble up; I\\'m out of ideas\\n    write(s)\\n    return write',\n",
              " 'def color_print(*args, **kwargs):\\n    \"\"\"\\n    Prints colors and styles to the terminal uses ANSI escape\\n    sequences.\\n\\n    ::\\n\\n       color_print(\\'This is the color \\', \\'default\\', \\'GREEN\\', \\'green\\')\\n\\n    Parameters\\n    ----------\\n    positional args : str\\n        The positional arguments come in pairs (*msg*, *color*), where\\n        *msg* is the string to display and *color* is the color to\\n        display it in.\\n\\n        *color* is an ANSI terminal color name.  Must be one of:\\n        black, red, green, brown, blue, magenta, cyan, lightgrey,\\n        default, darkgrey, lightred, lightgreen, yellow, lightblue,\\n        lightmagenta, lightcyan, white, or \\'\\' (the empty string).\\n\\n    file : writeable file-like object, optional\\n        Where to write to.  Defaults to `sys.stdout`.  If file is not\\n        a tty (as determined by calling its `isatty` member, if one\\n        exists), no coloring will be included.\\n\\n    end : str, optional\\n        The ending of the message.  Defaults to ``\\\\\\\\n``.  The end will\\n        be printed after resetting any color or font state.\\n    \"\"\"\\n\\n    file = kwargs.get(\\'file\\', _get_stdout())\\n\\n    end = kwargs.get(\\'end\\', \\'\\\\n\\')\\n\\n    write = file.write\\n    if isatty(file) and options.console.use_color:\\n        for i in range(0, len(args), 2):\\n            msg = args[i]\\n            if i + 1 == len(args):\\n                color = \\'\\'\\n            else:\\n                color = args[i + 1]\\n\\n            if color:\\n                msg = _color_text(msg, color)\\n\\n            # Some file objects support writing unicode sensibly on some Python\\n            # versions; if this fails try creating a writer using the locale\\'s\\n            # preferred encoding. If that fails too give up.\\n            if not six.PY3 and isinstance(msg, bytes):\\n                msg = _decode_preferred_encoding(msg)\\n\\n            write = _write_with_fallback(msg, write, file)\\n\\n        write(end)\\n    else:\\n        for i in range(0, len(args), 2):\\n            msg = args[i]\\n            if not six.PY3 and isinstance(msg, bytes):\\n                # Support decoding bytes to unicode on Python 2; use the\\n                # preferred encoding for the locale (which is *sometimes*\\n                # sensible)\\n                msg = _decode_preferred_encoding(msg)\\n            write(msg)\\n        write(end)',\n",
              " 'def human_time(seconds):\\n    \"\"\"\\n    Returns a human-friendly time string that is always exactly 6\\n    characters long.\\n\\n    Depending on the number of seconds given, can be one of::\\n\\n        1w 3d\\n        2d 4h\\n        1h 5m\\n        1m 4s\\n          15s\\n\\n    Will be in color if console coloring is turned on.\\n\\n    Parameters\\n    ----------\\n    seconds : int\\n        The number of seconds to represent\\n\\n    Returns\\n    -------\\n    time : str\\n        A human-friendly representation of the given number of seconds\\n        that is always exactly 6 characters.\\n    \"\"\"\\n    units = [\\n        (\\'y\\', 60 * 60 * 24 * 7 * 52),\\n        (\\'w\\', 60 * 60 * 24 * 7),\\n        (\\'d\\', 60 * 60 * 24),\\n        (\\'h\\', 60 * 60),\\n        (\\'m\\', 60),\\n        (\\'s\\', 1),\\n    ]\\n\\n    seconds = int(seconds)\\n\\n    if seconds < 60:\\n        return \\'   {0:2d}s\\'.format(seconds)\\n    for i in range(len(units) - 1):\\n        unit1, limit1 = units[i]\\n        unit2, limit2 = units[i + 1]\\n        if seconds >= limit1:\\n            return \\'{0:2d}{1}{2:2d}{3}\\'.format(\\n                seconds // limit1, unit1,\\n                (seconds % limit1) // limit2, unit2)\\n    return \\'  ~inf\\'',\n",
              " 'def human_file_size(size):\\n    \"\"\"\\n    Returns a human-friendly string representing a file size\\n    that is 2-4 characters long.\\n\\n    For example, depending on the number of bytes given, can be one\\n    of::\\n\\n        256b\\n        64k\\n        1.1G\\n\\n    Parameters\\n    ----------\\n    size : int\\n        The size of the file (in bytes)\\n\\n    Returns\\n    -------\\n    size : str\\n        A human-friendly representation of the size of the file\\n    \"\"\"\\n    suffixes = \\' kMGTPEZY\\'\\n    if size == 0:\\n        num_scale = 0\\n    else:\\n        num_scale = int(math.floor(math.log(size) / math.log(1000)))\\n    num_scale = max(num_scale, 0)\\n    if num_scale >= len(suffixes):\\n        suffix = \\'?\\'\\n    else:\\n        suffix = suffixes[num_scale]\\n    num_scale = int(math.pow(1000, num_scale))\\n    value = float(size) / num_scale\\n    str_value = str(value)\\n    if suffix == \\' \\':\\n        if \\'.\\' in str_value:\\n            str_value = str_value[:str_value.index(\\'.\\')]\\n    elif str_value[2] == \\'.\\':\\n        str_value = str_value[:2]\\n    else:\\n        str_value = str_value[:3]\\n    return \"{0:>3s}{1}\".format(str_value, suffix)',\n",
              " 'def update(self, value=None):\\n        \"\"\"\\n        Update progress bar via the console or notebook accordingly.\\n        \"\"\"\\n\\n        # Update self.value\\n        if value is None:\\n            value = self._current_value + 1\\n        self._current_value = value\\n\\n        # Choose the appropriate environment\\n        if self._ipython_widget:\\n            try:\\n                self._update_ipython_widget(value)\\n            except RuntimeError:\\n                pass\\n        else:\\n            self._update_console(value)',\n",
              " 'def _update_console(self, value=None):\\n        \"\"\"\\n        Update the progress bar to the given value (out of the total\\n        given to the constructor).\\n        \"\"\"\\n\\n        if self._total == 0:\\n            frac = 1.0\\n        else:\\n            frac = float(value) / float(self._total)\\n\\n        file = self._file\\n        write = file.write\\n\\n        if frac > 1:\\n            bar_fill = int(self._bar_length)\\n        else:\\n            bar_fill = int(float(self._bar_length) * frac)\\n        write(\\'\\\\r|\\')\\n        color_print(\\'=\\' * bar_fill, \\'blue\\', file=file, end=\\'\\')\\n        if bar_fill < self._bar_length:\\n            color_print(\\'>\\', \\'green\\', file=file, end=\\'\\')\\n            write(\\'-\\' * (self._bar_length - bar_fill - 1))\\n        write(\\'|\\')\\n\\n        if value >= self._total:\\n            t = time.time() - self._start_time\\n            prefix = \\'     \\'\\n        elif value <= 0:\\n            t = None\\n            prefix = \\'\\'\\n        else:\\n            t = ((time.time() - self._start_time) * (1.0 - frac)) / frac\\n            prefix = \\' ETA \\'\\n        write(\\' {0:>4s}/{1:>4s}\\'.format(\\n            human_file_size(value),\\n            self._human_total))\\n        write(\\' ({0:>6s}%)\\'.format(\\'{0:.2f}\\'.format(frac * 100.0)))\\n        write(prefix)\\n        if t is not None:\\n            write(human_time(t))\\n        self._file.flush()',\n",
              " 'def _update_ipython_widget(self, value=None):\\n        \"\"\"\\n        Update the progress bar to the given value (out of a total\\n        given to the constructor).\\n\\n        This method is for use in the IPython notebook 2+.\\n        \"\"\"\\n\\n        # Create and display an empty progress bar widget,\\n        # if none exists.\\n        if not hasattr(self, \\'_widget\\'):\\n            self._widget = create_progress_widget()\\n            if in_ipython_frontend() and is_widgets_available():\\n                display(self._widget)\\n            self._widget.value = 0\\n\\n        # Calculate percent completion, and update progress bar\\n        percent = (float(value)/self._total) * 100.0\\n        self._widget.value = percent\\n        self._widget.description =\\' ({0:>6s}%)\\'.format(\\'{0:.2f}\\'.format(percent))',\n",
              " 'def map(cls, function, items, multiprocess=False, file=None):\\n        \"\"\"\\n        Does a `map` operation while displaying a progress bar with\\n        percentage complete.\\n\\n        ::\\n\\n            def work(i):\\n                print(i)\\n\\n            ProgressBar.map(work, range(50))\\n\\n        Parameters\\n        ----------\\n        function : function\\n            Function to call for each step\\n\\n        items : sequence\\n            Sequence where each element is a tuple of arguments to pass to\\n            *function*.\\n\\n        multiprocess : bool, optional\\n            If `True`, use the `multiprocessing` module to distribute each\\n            task to a different processor core.\\n\\n        file : writeable file-like object, optional\\n            The file to write the progress bar to.  Defaults to\\n            `sys.stdout`.  If `file` is not a tty (as determined by\\n            calling its `isatty` member, if any), the scrollbar will\\n            be completely silent.\\n        \"\"\"\\n\\n        results = []\\n\\n        if file is None:\\n            file = _get_stdout()\\n\\n        with cls(len(items), file=file) as bar:\\n            step_size = max(200, bar._bar_length)\\n            steps = max(int(float(len(items)) / step_size), 1)\\n            if not multiprocess:\\n                for i, item in enumerate(items):\\n                    results.append(function(item))\\n                    if (i % steps) == 0:\\n                        bar.update(i)\\n            else:\\n                p = multiprocessing.Pool()\\n                for i, result in enumerate(\\n                    p.imap_unordered(function, items, steps)):\\n                    bar.update(i)\\n                    results.append(result)\\n                p.close()\\n                p.join()\\n\\n        return results',\n",
              " 'def hll_count(expr, error_rate=0.01, splitter=None):\\n    \"\"\"\\n    Calculate HyperLogLog count\\n\\n    :param expr:\\n    :param error_rate: error rate\\n    :type error_rate: float\\n    :param splitter: the splitter to split the column value\\n    :return: sequence or scalar\\n\\n    :Example:\\n\\n    >>> df = DataFrame(pd.DataFrame({\\'a\\': np.random.randint(100000, size=100000)}))\\n    >>> df.a.hll_count()\\n    63270\\n    >>> df.a.nunique()\\n    63250\\n    \"\"\"\\n\\n    # to make the class pickled right by the cloudpickle\\n    with open(os.path.join(path, \\'lib\\', \\'hll.py\\')) as hll_file:\\n        local = {}\\n        six.exec_(hll_file.read(), local)\\n        HyperLogLog = local[\\'HyperLogLog\\']\\n\\n        return expr.agg(HyperLogLog, rtype=types.int64, args=(error_rate, splitter))',\n",
              " 'def bloomfilter(collection, on, column, capacity=3000, error_rate=0.01):\\n    \"\"\"\\n    Filter collection on the `on` sequence by BloomFilter built by `column`\\n\\n    :param collection:\\n    :param on: sequence or column name\\n    :param column: instance of Column\\n    :param capacity: numbers of capacity\\n    :type capacity: int\\n    :param error_rate: error rate\\n    :type error_rate: float\\n    :return: collection\\n\\n    :Example:\\n\\n    >>> df1 = DataFrame(pd.DataFrame({\\'a\\': [\\'name1\\', \\'name2\\', \\'name3\\', \\'name1\\'], \\'b\\': [1, 2, 3, 4]}))\\n    >>> df2 = DataFrame(pd.DataFrame({\\'a\\': [\\'name1\\']}))\\n    >>> df1.bloom_filter(\\'a\\', df2.a)\\n           a  b\\n    0  name1  1\\n    1  name1  4\\n    \"\"\"\\n\\n\\n    if not isinstance(column, Column):\\n        raise TypeError(\\'bloomfilter can only filter on the column of a collection\\')\\n\\n    # to make the class pickled right by the cloudpickle\\n    with open(os.path.join(path, \\'lib\\', \\'bloomfilter.py\\')) as bloomfilter_file:\\n        local = {}\\n        six.exec_(bloomfilter_file.read(), local)\\n        BloomFilter = local[\\'BloomFilter\\']\\n\\n        col_name = column.source_name or column.name\\n\\n        on_name = on.name if isinstance(on, SequenceExpr) else on\\n        rand_name = \\'%s_%s\\'% (on_name, str(uuid.uuid4()).replace(\\'-\\', \\'_\\'))\\n        on_col = collection._get_field(on).rename(rand_name)\\n        src_collection = collection\\n        collection = collection[collection, on_col]\\n\\n        @output(src_collection.schema.names, src_collection.schema.types)\\n        class Filter(object):\\n            def __init__(self, resources):\\n                table = resources[0]\\n\\n                bloom = BloomFilter(capacity, error_rate)\\n                for row in table:\\n                    bloom.add(str(getattr(row, col_name)))\\n\\n                self.bloom = bloom\\n\\n            def __call__(self, row):\\n                if str(getattr(row, rand_name)) not in self.bloom:\\n                    return\\n                return row[:-1]\\n\\n        return collection.apply(Filter, axis=1, resources=[column.input, ])',\n",
              " 'def cumsum(expr, sort=None, ascending=True, unique=False,\\n           preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative summation of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    if expr._data_type == types.boolean:\\n        output_type = types.int64\\n    else:\\n        output_type = expr._data_type\\n    return _cumulative_op(expr, CumSum, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following, data_type=output_type)',\n",
              " 'def cummax(expr, sort=None, ascending=True, unique=False,\\n           preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative maximum of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    return _cumulative_op(expr, CumMax, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following)',\n",
              " 'def cummin(expr, sort=None, ascending=True, unique=False,\\n           preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative minimum of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    return _cumulative_op(expr, CumMin, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following)',\n",
              " 'def cummean(expr, sort=None, ascending=True, unique=False,\\n            preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative mean of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    data_type = _stats_type(expr)\\n    return _cumulative_op(expr, CumMean, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following, data_type=data_type)',\n",
              " 'def cummedian(expr, sort=None, ascending=True, unique=False,\\n              preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative median of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    data_type = _stats_type(expr)\\n    return _cumulative_op(expr, CumMedian, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following, data_type=data_type)',\n",
              " 'def cumcount(expr, sort=None, ascending=True, unique=False,\\n             preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative count of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    data_type = types.int64\\n    return _cumulative_op(expr, CumCount, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following, data_type=data_type)',\n",
              " 'def cumstd(expr, sort=None, ascending=True, unique=False,\\n           preceding=None, following=None):\\n    \"\"\"\\n    Calculate cumulative standard deviation of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :param unique: whether to eliminate duplicate entries\\n    :param preceding: the start point of a window\\n    :param following: the end point of a window\\n    :return: calculated column\\n    \"\"\"\\n    data_type = _stats_type(expr)\\n    return _cumulative_op(expr, CumStd, sort=sort, ascending=ascending,\\n                          unique=unique, preceding=preceding,\\n                          following=following, data_type=data_type)',\n",
              " 'def nth_value(expr, nth, skip_nulls=False, sort=None, ascending=True):\\n    \"\"\"\\n    Get nth value of a grouped and sorted expression.\\n\\n    :param expr: expression for calculation\\n    :param nth: integer position\\n    :param skip_nulls: whether to skip null values, False by default\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _cumulative_op(expr, NthValue, data_type=expr._data_type, sort=sort,\\n                          ascending=ascending, _nth=nth, _skip_nulls=skip_nulls)',\n",
              " 'def rank(expr, sort=None, ascending=True):\\n    \"\"\"\\n    Calculate rank of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _rank_op(expr, Rank, types.int64, sort=sort, ascending=ascending)',\n",
              " 'def dense_rank(expr, sort=None, ascending=True):\\n    \"\"\"\\n    Calculate dense rank of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _rank_op(expr, DenseRank, types.int64, sort=sort, ascending=ascending)',\n",
              " 'def percent_rank(expr, sort=None, ascending=True):\\n    \"\"\"\\n    Calculate percentage rank of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _rank_op(expr, PercentRank, types.float64, sort=sort, ascending=ascending)',\n",
              " 'def row_number(expr, sort=None, ascending=True):\\n    \"\"\"\\n    Calculate row number of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _rank_op(expr, RowNumber, types.int64, sort=sort, ascending=ascending)',\n",
              " 'def qcut(expr, bins, labels=False, sort=None, ascending=True):\\n    \"\"\"\\n    Get quantile-based bin indices of every element of a grouped and sorted expression.\\n    The indices of bins start from 0. If cuts are not of equal sizes, extra items will\\n    be appended into the first group.\\n\\n    :param expr: expression for calculation\\n    :param bins: number of bins\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    if labels is None or labels:\\n        raise NotImplementedError(\\'Showing bins or customizing labels not supported\\')\\n    return _rank_op(expr, QCut, types.int64, sort=sort, ascending=ascending,\\n                    _bins=bins)',\n",
              " 'def cume_dist(expr, sort=None, ascending=True):\\n    \"\"\"\\n    Calculate cumulative ratio of a sequence expression.\\n\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _rank_op(expr, CumeDist, types.float64, sort=sort, ascending=ascending)',\n",
              " 'def lag(expr, offset, default=None, sort=None, ascending=True):\\n    \"\"\"\\n    Get value in the row ``offset`` rows prior to the current row.\\n\\n    :param offset: the offset value\\n    :param default: default value for the function, when there are no rows satisfying the offset\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _shift_op(expr, Lag, offset, default=default,\\n                     sort=sort, ascending=ascending)',\n",
              " 'def lead(expr, offset, default=None, sort=None, ascending=True):\\n    \"\"\"\\n    Get value in the row ``offset`` rows after to the current row.\\n\\n    :param offset: the offset value\\n    :param default: default value for the function, when there are no rows satisfying the offset\\n    :param expr: expression for calculation\\n    :param sort: name of the sort column\\n    :param ascending: whether to sort in ascending order\\n    :return: calculated column\\n    \"\"\"\\n    return _shift_op(expr, Lead, offset, default=default,\\n                     sort=sort, ascending=ascending)',\n",
              " 'def get_model(self):\\n        \"\"\"\\n        Get PMML text of the current model. Note that model file obtained\\n        via this method might be incomplete due to size limitations.\\n        \"\"\"\\n        url = self.resource()\\n        params = {\\'data\\': \\'\\'}\\n        resp = self._client.get(url, params=params)\\n\\n        return resp.text',\n",
              " 'def parse_response(resp):\\n    \"\"\"Parses the content of response and returns an exception object.\\n    \"\"\"\\n    host_id, msg, code = None, None, None\\n    try:\\n        content = resp.content\\n        root = ET.fromstring(content)\\n        code = root.find(\\'./Code\\').text\\n        msg = root.find(\\'./Message\\').text\\n        request_id = root.find(\\'./RequestId\\').text\\n        host_id = root.find(\\'./HostId\\').text\\n    except ETParseError:\\n        request_id = resp.headers.get(\\'x-odps-request-id\\', None)\\n        if len(resp.content) > 0:\\n            obj = json.loads(resp.text)\\n            msg = obj[\\'Message\\']\\n            code = obj.get(\\'Code\\')\\n            host_id = obj.get(\\'HostId\\')\\n            if request_id is None:\\n                request_id = obj.get(\\'RequestId\\')\\n        else:\\n            return\\n    clz = globals().get(code, ODPSError)\\n    return clz(msg, request_id=request_id, code=code, host_id=host_id)',\n",
              " 'def throw_if_parsable(resp):\\n    \"\"\"Try to parse the content of the response and raise an exception\\n    if neccessary.\\n    \"\"\"\\n    e = None\\n    try:\\n        e = parse_response(resp)\\n    except:\\n        # Error occurred during parsing the response. We ignore it and delegate\\n        # the situation to caller to handle.\\n        LOG.debug(utils.stringify_expt())\\n\\n    if e is not None:\\n        raise e\\n\\n    if resp.status_code == 404:\\n        raise NoSuchObject(\\'No such object.\\')\\n    else:\\n        text = resp.text if six.PY3 else resp.content\\n        if text:\\n            raise ODPSError(text, code=str(resp.status_code))\\n        else:\\n            raise ODPSError(str(resp.status_code))',\n",
              " 'def merge_data(*data_frames, **kwargs):\\n    \"\"\"\\n    Merge DataFrames by column. Number of rows in tables must be the same.\\n\\n    This method can be called both outside and as a DataFrame method.\\n\\n    :param list[DataFrame] data_frames: DataFrames to be merged.\\n    :param bool auto_rename: if True, fields in source DataFrames will be renamed in the output.\\n\\n    :return: merged data frame.\\n    :rtype: DataFrame\\n\\n    :Example:\\n    >>> merged1 = merge_data(df1, df2)\\n    >>> merged2 = df1.merge_with(df2, auto_rename_col=True)\\n    \"\"\"\\n    from .specialized import build_merge_expr\\n    from ..utils import ML_ARG_PREFIX\\n\\n    if len(data_frames) <= 1:\\n        raise ValueError(\\'Count of DataFrames should be at least 2.\\')\\n\\n    norm_data_pairs = []\\n    df_tuple = collections.namedtuple(\\'MergeTuple\\', \\'df cols exclude\\')\\n    for pair in data_frames:\\n        if isinstance(pair, tuple):\\n            if len(pair) == 2:\\n                df, cols = pair\\n                exclude = False\\n            else:\\n                df, cols, exclude = pair\\n            if isinstance(cols, six.string_types):\\n                cols = cols.split(\\',\\')\\n        else:\\n            df, cols, exclude = pair, None, False\\n        norm_data_pairs.append(df_tuple(df, cols, exclude))\\n\\n    auto_rename = kwargs.get(\\'auto_rename\\', False)\\n\\n    sel_cols_dict = dict((idx, tp.cols) for idx, tp in enumerate(norm_data_pairs) if tp.cols and not tp.exclude)\\n    ex_cols_dict = dict((idx, tp.cols) for idx, tp in enumerate(norm_data_pairs) if tp.cols and tp.exclude)\\n\\n    merge_expr = build_merge_expr(len(norm_data_pairs))\\n    arg_dict = dict(_params={\\'autoRenameCol\\': str(auto_rename)},\\n                    selected_cols=sel_cols_dict, excluded_cols=ex_cols_dict)\\n    for idx, dp in enumerate(norm_data_pairs):\\n        arg_dict[ML_ARG_PREFIX + \\'input%d\\' % (1 + idx)] = dp.df\\n\\n    out_df = merge_expr(register_expr=True, _exec_id=uuid.uuid4(), _output_name=\\'output\\', **arg_dict)\\n\\n    out_df._ml_uplink = [dp.df for dp in norm_data_pairs]\\n    out_df._perform_operation(op.MergeFieldsOperation(auto_rename, sel_cols_dict, ex_cols_dict))\\n    out_df._rebuild_df_schema()\\n    return out_df',\n",
              " 'def exclude_fields(self, *args):\\n        \"\"\"\\n        Exclude one or more fields from feature fields.\\n\\n        :rtype: DataFrame\\n        \"\"\"\\n        if not args:\\n            raise ValueError(\"Field list cannot be None.\")\\n        new_df = copy_df(self)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        new_df._perform_operation(op.ExcludeFieldsOperation(fields))\\n        return new_df',\n",
              " 'def select_features(self, *args, **kwargs):\\n        \"\"\"\\n        Select one or more fields as feature fields.\\n\\n        :rtype: DataFrame\\n        \"\"\"\\n        if not args:\\n            raise ValueError(\"Field list cannot be empty.\")\\n        # generate selected set from args\\n        augment = kwargs.get(\\'add\\', False)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        return _batch_change_roles(self, fields, FieldRole.FEATURE, augment)',\n",
              " 'def weight_field(self, f):\\n        \"\"\"\\n        Select one field as the weight field.\\n\\n        Note that this field will be exclude from feature fields.\\n\\n        :param f: Selected weight field\\n        :type f: str\\n        :rtype: DataFrame\\n        \"\"\"\\n        if f is None:\\n            raise ValueError(\"Field name cannot be None.\")\\n        self._assert_ml_fields_valid(f)\\n        return _change_singleton_roles(self, {f: FieldRole.WEIGHT}, clear_feature=True)',\n",
              " 'def label_field(self, f):\\n        \"\"\"\\n        Select one field as the label field.\\n\\n        Note that this field will be exclude from feature fields.\\n\\n        :param f: Selected label field\\n        :type f: str\\n        :rtype: DataFrame\\n        \"\"\"\\n        if f is None:\\n            raise ValueError(\"Label field name cannot be None.\")\\n        self._assert_ml_fields_valid(f)\\n        return _change_singleton_roles(self, {_get_field_name(f): FieldRole.LABEL}, clear_feature=True)',\n",
              " 'def continuous(self, *args):\\n        \"\"\"\\n        Set fields to be continuous.\\n\\n        :rtype: DataFrame\\n\\n        :Example:\\n\\n        >>> # Table schema is create table test(f1 double, f2 string)\\n        >>> # Original continuity: f1=DISCRETE, f2=DISCRETE\\n        >>> # Now we want to set ``f1`` and ``f2`` into continuous\\n        >>> new_ds = df.continuous(\\'f1 f2\\')\\n        \"\"\"\\n        new_df = copy_df(self)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        new_df._perform_operation(op.FieldContinuityOperation(dict((_get_field_name(f), True) for f in fields)))\\n        return new_df',\n",
              " 'def discrete(self, *args):\\n        \"\"\"\\n        Set fields to be discrete.\\n\\n        :rtype: DataFrame\\n\\n        :Example:\\n\\n        >>> # Table schema is create table test(f1 double, f2 string)\\n        >>> # Original continuity: f1=CONTINUOUS, f2=CONTINUOUS\\n        >>> # Now we want to set ``f1`` and ``f2`` into continuous\\n        >>> new_ds = df.discrete(\\'f1 f2\\')\\n        \"\"\"\\n        new_df = copy_df(self)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        new_df._perform_operation(op.FieldContinuityOperation(dict((_get_field_name(f), False) for f in fields)))\\n        return new_df',\n",
              " 'def key_value(self, *args, **kwargs):\\n        \"\"\"\\n        Set fields to be key-value represented.\\n\\n        :rtype: DataFrame\\n\\n        :Example:\\n\\n        >>> new_ds = df.key_value(\\'f1 f2\\', kv=\\':\\', item=\\',\\')\\n        \"\"\"\\n        new_df = copy_df(self)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        new_df._perform_operation(\\n            op.FieldKVConfigOperation(dict((_get_field_name(f), KVConfig(**kwargs)) for f in fields)))\\n        return new_df',\n",
              " 'def erase_key_value(self, *args):\\n        \"\"\"\\n        Erase key-value represented fields.\\n\\n        :rtype: DataFrame\\n\\n        :Example:\\n\\n        >>> new_ds = df.erase_key_value(\\'f1 f2\\')\\n        \"\"\"\\n        new_df = copy_df(self)\\n        fields = _render_field_set(args)\\n        self._assert_ml_fields_valid(*fields)\\n        new_df._perform_operation(op.FieldKVConfigOperation(dict((_get_field_name(f), None) for f in fields)))\\n        return new_df',\n",
              " 'def roles(self, clear_features=True, **field_roles):\\n        \"\"\"\\n        Set roles of fields\\n\\n        :param clear_features: Clear feature roles on fields\\n        :param field_roles:\\n        :return:\\n        \"\"\"\\n        field_roles = dict((k, v.name if isinstance(v, SequenceExpr) else v)\\n                           for k, v in six.iteritems(field_roles))\\n        self._assert_ml_fields_valid(*list(six.itervalues(field_roles)))\\n        field_roles = dict((_get_field_name(f), MLField.translate_role_name(role))\\n                           for role, f in six.iteritems(field_roles))\\n        if field_roles:\\n            return _change_singleton_roles(self, field_roles, clear_features)\\n        else:\\n            return self',\n",
              " 'def split(self, frac):\\n        \"\"\"\\n        Split the DataFrame into two DataFrames with certain ratio.\\n\\n        :param frac: Split ratio\\n        :type frac: float\\n\\n        :return: two split DataFrame objects\\n        :rtype: list[DataFrame]\\n        \"\"\"\\n        from .. import preprocess\\n        split_obj = getattr(preprocess, \\'_Split\\')(fraction=frac)\\n        return split_obj.transform(self)',\n",
              " 'def append_id(self, id_col_name=\\'append_id\\', cols=None):\\n        \"\"\"\\n        Append an ID column to current DataFrame.\\n\\n        :param str id_col_name: name of appended ID field.\\n        :param str cols: fields contained in output. All fields by default.\\n\\n        :return: DataFrame with ID field\\n        :rtype: DataFrame\\n        \"\"\"\\n        from .. import preprocess\\n        if id_col_name in self.schema:\\n            raise ValueError(\\'ID column collides with existing columns.\\')\\n        append_id_obj = getattr(preprocess, \\'_AppendID\\')(id_col=id_col_name, selected_cols=cols)\\n        return append_id_obj.transform(self)',\n",
              " 'def continuous(self):\\n        \"\"\"\\n        Set sequence to be continuous.\\n\\n        :rtype: Column\\n\\n        :Example:\\n\\n        >>> # Table schema is create table test(f1 double, f2 string)\\n        >>> # Original continuity: f1=DISCRETE, f2=DISCRETE\\n        >>> # Now we want to set ``f1`` and ``f2`` into continuous\\n        >>> new_ds = df.continuous(\\'f1 f2\\')\\n        \"\"\"\\n        field_name = self.name\\n        new_df = copy_df(self)\\n        new_df._perform_operation(op.FieldContinuityOperation({field_name: True}))\\n        return new_df',\n",
              " 'def discrete(self):\\n        \"\"\"\\n        Set sequence to be discrete.\\n\\n        :rtype: Column\\n\\n        :Example:\\n\\n        >>> # Table schema is create table test(f1 double, f2 string)\\n        >>> # Original continuity: f1=CONTINUOUS, f2=CONTINUOUS\\n        >>> # Now we want to set ``f1`` and ``f2`` into continuous\\n        >>> new_ds = df.discrete(\\'f1 f2\\')\\n        \"\"\"\\n        field_name = self.name\\n        new_df = copy_df(self)\\n        new_df._perform_operation(op.FieldContinuityOperation({field_name: False}))\\n        return new_df',\n",
              " 'def key_value(self, **kwargs):\\n        \"\"\"\\n        Set fields to be key-value represented.\\n\\n        :rtype: Column\\n\\n        :Example:\\n\\n        >>> new_ds = df.key_value(\\'f1 f2\\', kv=\\':\\', item=\\',\\')\\n        \"\"\"\\n        field_name = self.name\\n        new_df = copy_df(self)\\n        new_df._perform_operation(op.FieldKVConfigOperation({field_name: KVConfig(**kwargs)}))\\n        return new_df',\n",
              " 'def erase_key_value(self):\\n        \"\"\"\\n        Erase key-value represented fields.\\n\\n        :rtype: Column\\n\\n        :Example:\\n\\n        >>> new_ds = df.erase_key_value(\\'f1 f2\\')\\n        \"\"\"\\n        field_name = self.name\\n        new_df = copy_df(self)\\n        new_df._perform_operation(op.FieldKVConfigOperation({field_name: None}))\\n        return new_df',\n",
              " 'def role(self, role_name):\\n        \"\"\"\\n        Set role of current column\\n\\n        :param role_name: name of the role to be selected.\\n        :return:\\n        \"\"\"\\n        field_name = self.name\\n        field_roles = {field_name: MLField.translate_role_name(role_name)}\\n        if field_roles:\\n            return _change_singleton_roles(self, field_roles, True)\\n        else:\\n            return self',\n",
              " 'def _init(self, *args, **kwargs):\\n        \"\"\"\\n        _deps is used for common dependencies.\\n        When a expr depend on other exprs, and the expr is not calculated from the others,\\n        the _deps are specified to identify the dependencies.\\n        \"\"\"\\n        self._init_attr(\\'_deps\\', None)\\n\\n        self._init_attr(\\'_ban_optimize\\', False)\\n        self._init_attr(\\'_engine\\', None)\\n        self._init_attr(\\'_Expr__execution\\', None)\\n\\n        self._init_attr(\\'_need_cache\\', False)\\n        self._init_attr(\\'_mem_cache\\', False)\\n\\n        if \\'_id\\' not in kwargs:\\n            kwargs[\\'_id\\'] = new_id()\\n\\n        super(Expr, self)._init(*args, **kwargs)',\n",
              " 'def execute(self, **kwargs):\\n        \"\"\"\\n        :param hints: settings for SQL, e.g. `odps.sql.mapper.split.size`\\n        :type hints: dict\\n        :param priority: instance priority, 9 as default\\n        :type priority: int\\n        :param running_cluster: cluster to run this instance\\n        :return: execution result\\n        :rtype: :class:`odps.df.backends.frame.ResultFrame`\\n        \"\"\"\\n        _wrapper = kwargs.pop(\\'wrapper\\', None)\\n\\n        def wrapper(result):\\n            self.__execution = result\\n            if _wrapper is not None:\\n                return _wrapper(result)\\n            else:\\n                return result\\n\\n        return self._handle_delay_call(\\'execute\\', self, wrapper=wrapper, **kwargs)',\n",
              " 'def compile(self):\\n        \"\"\"\\n        Compile this expression into an ODPS SQL\\n\\n        :return: compiled DAG\\n        :rtype: str\\n        \"\"\"\\n\\n        from ..engines import get_default_engine\\n\\n        engine = get_default_engine(self)\\n        return engine.compile(self)',\n",
              " 'def persist(self, name, partitions=None, partition=None, lifecycle=None, project=None, **kwargs):\\n        \"\"\"\\n        Persist the execution into a new table. If `partitions` not specified,\\n        will create a new table without partitions if the table does not exist,\\n        and insert the SQL result into it.\\n        If `partitions` are specified, they will be the partition fields of the new table.\\n        If `partition` is specified, the data will be inserted into the exact partition of the table.\\n\\n        :param name: table name\\n        :param partitions: list of string, the partition fields\\n        :type partitions: list\\n        :param partition: persist to a specified partition\\n        :type partition: string or PartitionSpec\\n        :param lifecycle: table lifecycle. If absent, `options.lifecycle` will be used.\\n        :type lifecycle: int\\n        :param project: project name, if not provided, will be the default project\\n        :param hints: settings for SQL, e.g. `odps.sql.mapper.split.size`\\n        :type hints: dict\\n        :param priority: instance priority, 9 as default\\n        :type priority: int\\n        :param running_cluster: cluster to run this instance\\n        :param overwrite: overwrite the table, True as default\\n        :type overwrite: bool\\n        :param drop_table: drop table if exists, False as default\\n        :type drop_table: bool\\n        :param create_table: create table first if not exits, True as default\\n        :type create_table: bool\\n        :param drop_partition: drop partition if exists, False as default\\n        :type drop_partition: bool\\n        :param create_partition: create partition if not exists, None as default\\n        :type create_partition: bool\\n        :param cast: cast all columns\\' types as the existed table, False as default\\n        :type cast: bool\\n        :return: :class:`odps.df.DataFrame`\\n\\n        :Example:\\n\\n        >>> df = df[\\'name\\', \\'id\\', \\'ds\\']\\n        >>> df.persist(\\'odps_new_table\\')\\n        >>> df.persist(\\'odps_new_table\\', partition=\\'pt=test\\')\\n        >>> df.persist(\\'odps_new_table\\', partitions=[\\'ds\\'])\\n        \"\"\"\\n        if lifecycle is None and options.lifecycle is not None:\\n            lifecycle = \\\\\\n                options.lifecycle if not name.startswith(TEMP_TABLE_PREFIX) \\\\\\n                    else options.temp_lifecycle\\n\\n        return self._handle_delay_call(\\'persist\\', self, name, partitions=partitions, partition=partition,\\n                                       lifecycle=lifecycle, project=project, **kwargs)',\n",
              " 'def query(self, expr):\\n        \"\"\"\\n        Query the data with a boolean expression.\\n\\n        :param expr: the query string, you can use \\'@\\' character refer to environment variables.\\n        :return: new collection\\n        :rtype: :class:`odps.df.expr.expressions.CollectionExpr`\\n\\n        \"\"\"\\n        from .query import CollectionVisitor\\n\\n        if not isinstance(expr, six.string_types):\\n            raise ValueError(\\'expr must be a string\\')\\n\\n        frame = sys._getframe(2).f_locals\\n        try:\\n            env = frame.copy()\\n        finally:\\n            del frame\\n\\n        visitor = CollectionVisitor(self, env)\\n        predicate = visitor.eval(expr)\\n        return self.filter(predicate)',\n",
              " 'def filter(self, *predicates):\\n        \"\"\"\\n        Filter the data by predicates\\n\\n        :param predicates: the conditions to filter\\n        :return: new collection\\n        :rtype: :class:`odps.df.expr.expressions.CollectionExpr`\\n        \"\"\"\\n        predicates = self._get_fields(predicates)\\n\\n        predicate = reduce(operator.and_, predicates)\\n        return FilterCollectionExpr(self, predicate, _schema=self._schema)',\n",
              " 'def filter_parts(self, predicate=\\'\\', exclude=True):\\n        \"\"\"\\n        Filter the data by partition string. A partition string looks like `pt1=1,pt2=2/pt1=2,pt2=1`, where\\n        comma (,) denotes \\'and\\', while (/) denotes \\'or\\'.\\n\\n        :param str|Partition predicate: predicate string of partition filter\\n        :param bool exclude: True if you want to exclude partition fields, otherwise False. True for default.\\n        :return: new collection\\n        :rtype: :class:`odps.df.expr.expressions.CollectionExpr`\\n        \"\"\"\\n        source = self._source_data\\n        if source is None:\\n            raise ExpressionError(\\'Can only filter on data sources.\\')\\n\\n        def _parse_partition_predicate(p):\\n            if \\'=\\' not in p:\\n                raise ExpressionError(\\'Illegal partition predicate.\\')\\n            field_name, field_value = [s.strip() for s in p.split(\\'=\\', 1)]\\n            if not hasattr(source, \\'schema\\'):\\n                raise ExpressionError(\\'filter_partition can only be applied on ODPS DataFrames\\')\\n            if field_name not in source.schema:\\n                raise ExpressionError(\\'Column `%s` not exists in input collection\\' % field_name)\\n            if field_name not in source.schema._partition_schema:\\n                raise ExpressionError(\\'`%s` is not a partition column\\' % field_name)\\n            part_col = self[field_name]\\n            if field_value.startswith(\\'\\\\\\'\\') or field_value.startswith(\\'\\\\\"\\'):\\n                encoding = \\'string-escape\\' if six.PY2 else \\'unicode-escape\\'\\n                field_value = to_binary(field_value.strip(\\'\"\\\\\\'\\')).decode(encoding)\\n\\n            if isinstance(part_col.data_type, types.Integer):\\n                field_value = int(field_value)\\n            elif isinstance(part_col.data_type, types.Float):\\n                field_value = float(field_value)\\n            return part_col == field_value\\n\\n        from ...models.partition import Partition\\n        from ...types import PartitionSpec\\n\\n        if isinstance(predicate, Partition):\\n            predicate = predicate.partition_spec\\n        if isinstance(predicate, PartitionSpec):\\n            predicate = \\',\\'.join(\"%s=\\'%s\\'\" % (k, v) for k, v in six.iteritems(predicate.kv))\\n\\n        if isinstance(predicate, list):\\n            predicate = \\'/\\'.join(str(s) for s in predicate)\\n        elif not isinstance(predicate, six.string_types):\\n            raise ExpressionError(\\'Only accept string predicates.\\')\\n\\n        if not predicate:\\n            predicate_obj = None\\n        else:\\n            part_formatter = lambda p: reduce(operator.and_, map(_parse_partition_predicate, p.split(\\',\\')))\\n            predicate_obj = reduce(operator.or_, map(part_formatter, predicate.split(\\'/\\')))\\n\\n        if not source.schema.partitions:\\n            raise ExpressionError(\\'No partition columns in the collection.\\')\\n        if exclude:\\n            columns = [c for c in self.schema if c.name not in source.schema._partition_schema]\\n            new_schema = types.Schema.from_lists([c.name for c in columns], [c.type for c in columns])\\n            return FilterPartitionCollectionExpr(self, predicate_obj, _schema=new_schema, _predicate_string=predicate)\\n        else:\\n            return self.filter(predicate_obj)',\n",
              " 'def select(self, *fields, **kw):\\n        \"\"\"\\n        Projection columns. Remember to avoid column names\\' conflict.\\n\\n        :param fields: columns to project\\n        :param kw: columns and their names to project\\n        :return: new collection\\n        :rtype: :class:`odps.df.expr.expression.CollectionExpr`\\n        \"\"\"\\n        if len(fields) == 1 and isinstance(fields[0], list):\\n            fields = fields[0]\\n        else:\\n            fields = list(fields)\\n        if kw:\\n            def handle(it):\\n                it = self._defunc(it)\\n                if not isinstance(it, Expr):\\n                    it = Scalar(it)\\n                return it\\n            fields.extend([handle(f).rename(new_name)\\n                           for new_name, f in six.iteritems(kw)])\\n\\n        return self._project(fields)',\n",
              " 'def exclude(self, *fields):\\n        \"\"\"\\n        Projection columns which not included in the fields\\n\\n        :param fields: field names\\n        :return: new collection\\n        :rtype: :class:`odps.df.expr.expression.CollectionExpr`\\n        \"\"\"\\n\\n        if len(fields) == 1 and isinstance(fields[0], list):\\n            exclude_fields = fields[0]\\n        else:\\n            exclude_fields = list(fields)\\n\\n        exclude_fields = [self._defunc(it) for it in exclude_fields]\\n        exclude_fields = [field.name if not isinstance(field, six.string_types) else field\\n                          for field in exclude_fields]\\n\\n        fields = [name for name in self._schema.names\\n                  if name not in exclude_fields]\\n\\n        return self._project(fields)',\n",
              " 'def head(self, n=None, **kwargs):\\n        \"\"\"\\n        Return the first n rows. Execute at once.\\n\\n        :param n:\\n        :return: result frame\\n        :rtype: :class:`odps.df.backends.frame.ResultFrame`\\n        \"\"\"\\n        if n is None:\\n            n = options.display.max_rows\\n        return self._handle_delay_call(\\'execute\\', self, head=n, **kwargs)',\n",
              " 'def tail(self, n=None, **kwargs):\\n        \"\"\"\\n        Return the last n rows. Execute at once.\\n\\n        :param n:\\n        :return: result frame\\n        :rtype: :class:`odps.df.backends.frame.ResultFrame`\\n        \"\"\"\\n        if n is None:\\n            n = options.display.max_rows\\n        return self._handle_delay_call(\\'execute\\', self, tail=n, **kwargs)',\n",
              " 'def to_pandas(self, wrap=False, **kwargs):\\n        \"\"\"\\n        Convert to pandas DataFrame. Execute at once.\\n\\n        :param wrap: if True, wrap the pandas DataFrame into a PyODPS DataFrame\\n        :return: pandas DataFrame\\n        \"\"\"\\n\\n        try:\\n            import pandas as pd\\n        except ImportError:\\n            raise DependencyNotInstalledError(\\n                    \\'to_pandas requires `pandas` library\\')\\n\\n        def wrapper(result):\\n            res = result.values\\n            if wrap:\\n                from .. import DataFrame\\n                return DataFrame(res, schema=self.schema)\\n            return res\\n\\n        return self.execute(wrapper=wrapper, **kwargs)',\n",
              " 'def view(self):\\n        \"\"\"\\n        Clone a same collection. useful for self-join.\\n\\n        :return:\\n        \"\"\"\\n        proxied = get_proxied_expr(self)\\n        kv = dict((attr, getattr(proxied, attr)) for attr in get_attrs(proxied))\\n        return type(proxied)(**kv)',\n",
              " 'def to_pandas(self, wrap=False, **kwargs):\\n        \"\"\"\\n        Convert to pandas Series. Execute at once.\\n\\n        :param wrap: if True, wrap the pandas DataFrame into a PyODPS DataFrame\\n        :return: pandas Series\\n        \"\"\"\\n\\n        try:\\n            import pandas as pd\\n        except ImportError:\\n            raise DependencyNotInstalledError(\\n                    \\'to_pandas requires for `pandas` library\\')\\n\\n        def wrapper(result):\\n            df = result.values\\n            if wrap:\\n                from .. import DataFrame\\n                df = DataFrame(df)\\n            return df[self.name]\\n\\n        return self.execute(wrapper=wrapper, **kwargs)',\n",
              " 'def astype(self, data_type):\\n        \"\"\"\\n        Cast to a new data type.\\n\\n        :param data_type: the new data type\\n        :return: casted sequence\\n\\n        :Example:\\n\\n        >>> df.id.astype(\\'float\\')\\n        \"\"\"\\n\\n        data_type = types.validate_data_type(data_type)\\n\\n        if data_type == self._data_type:\\n            return self\\n\\n        attr_dict = dict()\\n        attr_dict[\\'_data_type\\'] = data_type\\n        attr_dict[\\'_source_data_type\\'] = self._source_data_type\\n        attr_dict[\\'_input\\'] = self\\n\\n        new_sequence = AsTypedSequenceExpr(**attr_dict)\\n\\n        return new_sequence',\n",
              " 'def iterate(self):\\n        \"\"\"\\n        :return:\\n        \"\"\"\\n        if not self._iter_local:\\n            params = dict()\\n            url = self.resource()\\n            resp = self._client.get(url, params=params)\\n\\n            Users.parse(self._client, resp, obj=self)\\n\\n        for user in self.users:\\n            yield user',\n",
              " 'def explode(expr, *args, **kwargs):\\n    \"\"\"\\n    Expand list or dict data into multiple rows\\n\\n    :param expr: list / dict sequence / scalar\\n    :return:\\n    \"\"\"\\n    if not isinstance(expr, Column):\\n        expr = to_collection(expr)[expr.name]\\n\\n    if isinstance(expr, SequenceExpr):\\n        dtype = expr.data_type\\n    else:\\n        dtype = expr.value_type\\n\\n    func_name = \\'EXPLODE\\'\\n    if args and isinstance(args[0], (list, tuple, set)):\\n        names = list(args[0])\\n    else:\\n        names = args\\n    pos = kwargs.get(\\'pos\\', False)\\n    if isinstance(expr, ListSequenceExpr):\\n        if pos:\\n            func_name = \\'POSEXPLODE\\'\\n            typos = [df_types.int64, dtype.value_type]\\n            if not names:\\n                names = [expr.name + \\'_pos\\', expr.name]\\n            if len(names) == 1:\\n                names = [names[0] + \\'_pos\\', names[0]]\\n            if len(names) != 2:\\n                raise ValueError(\"The length of parameter \\'names\\' should be exactly 1.\")\\n        else:\\n            typos = [dtype.value_type]\\n            if not names:\\n                names = [expr.name]\\n            if len(names) != 1:\\n                raise ValueError(\"The length of parameter \\'names\\' should be exactly 1.\")\\n    elif isinstance(expr, DictSequenceExpr):\\n        if pos:\\n            raise ValueError(\\'Cannot support explosion with pos on dicts.\\')\\n        typos = [dtype.key_type, dtype.value_type]\\n        if not names:\\n            names = [expr.name + \\'_key\\', expr.name + \\'_value\\']\\n        if len(names) != 2:\\n            raise ValueError(\"The length of parameter \\'names\\' should be exactly 2.\")\\n    else:\\n        raise ValueError(\\'Cannot explode expression with type %s\\' % type(expr).__name__)\\n    schema = Schema.from_lists(names, typos)\\n    return RowAppliedCollectionExpr(_input=expr.input, _func=func_name, _schema=schema,\\n                                    _fields=[expr], _keep_nulls=kwargs.get(\\'keep_nulls\\', False))',\n",
              " 'def _contains(expr, value):\\n    \"\"\"\\n    Check whether certain value is in the inspected list\\n\\n    :param expr: list sequence / scalar\\n    :param value: value to inspect\\n    :return:\\n    \"\"\"\\n    return composite_op(expr, ListContains, df_types.boolean, _value=_scalar(value))',\n",
              " 'def _keys(expr):\\n    \"\"\"\\n    Retrieve keys of a dict\\n\\n    :param expr: dict sequence / scalar\\n    :return:\\n    \"\"\"\\n    if isinstance(expr, SequenceExpr):\\n        dtype = expr.data_type\\n    else:\\n        dtype = expr.value_type\\n    return composite_op(expr, DictKeys, df_types.List(dtype.key_type))',\n",
              " 'def _values(expr):\\n    \"\"\"\\n    Retrieve values of a dict\\n\\n    :param expr: dict sequence / scalar\\n    :return:\\n    \"\"\"\\n    if isinstance(expr, SequenceExpr):\\n        dtype = expr.data_type\\n    else:\\n        dtype = expr.value_type\\n    return composite_op(expr, DictValues, df_types.List(dtype.value_type))',\n",
              " 'def mean_squared_error(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute mean squared error of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean squared error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'mse\\']',\n",
              " 'def mean_absolute_error(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute mean absolute error of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'mae\\']',\n",
              " 'def mean_absolute_percentage_error(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute mean absolute percentage error of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'mape\\']',\n",
              " 'def total_sum_of_squares(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute total sum of squares (SST) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'sst\\']',\n",
              " 'def explained_sum_of_squares(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute explained sum of squares (SSE) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'sse\\']',\n",
              " 'def r2_score(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute determination coefficient (R2) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'r2\\']',\n",
              " 'def multi_corr(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute multiple correlation coefficient (R) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'r\\']',\n",
              " 'def rooted_mean_squared_error(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute rooted mean squared error (RMSE) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'rmse\\']',\n",
              " 'def mean_absolute_deviation(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute mean absolute deviation (MAD) of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: Mean absolute percentage error\\n    :rtype: float\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'mad\\']',\n",
              " 'def residual_histogram(df, col_true, col_pred=None):\\n    \"\"\"\\n    Compute histogram of residuals of a predicted DataFrame.\\n\\n    Note that this method will trigger the defined flow to execute.\\n\\n    :param df: predicted data frame\\n    :type df: DataFrame\\n    :param col_true: column name of true value\\n    :type col_true: str\\n    :param col_true: column name of predicted value, \\'prediction_score\\' by default.\\n    :type col_pred: str\\n    :return: histograms for every columns, containing histograms and bins.\\n    \"\"\"\\n    if not col_pred:\\n        col_pred = get_field_name_by_role(df, FieldRole.PREDICTED_VALUE)\\n    return _run_evaluation_node(df, col_true, col_pred)[\\'hist\\']',\n",
              " 'def put_info(self, key, value):\\n        \"\"\"\\n        Put associated information of the task.\\n        \"\"\"\\n        return self.instance.put_task_info(self.name, key, value)',\n",
              " 'def append_little_endian32(self, unsigned_value):\\n        \"\"\"Appends an unsigned 32-bit integer to the internal buffer,\\n        in little-endian byte order.\\n        \"\"\"\\n        if not 0 <= unsigned_value <= wire_format.UINT32_MAX:\\n            raise errors.EncodeError(\\n                \\'Unsigned 32-bit out of range: %d\\' % unsigned_value)\\n        self.append_raw_bytes(struct.pack(\\n            wire_format.FORMAT_UINT32_LITTLE_ENDIAN, unsigned_value))',\n",
              " 'def append_little_endian64(self, unsigned_value):\\n        \"\"\"Appends an unsigned 64-bit integer to the internal buffer,\\n        in little-endian byte order.\\n        \"\"\"\\n        if not 0 <= unsigned_value <= wire_format.UINT64_MAX:\\n            raise errors.EncodeError(\\n                \\'Unsigned 64-bit out of range: %d\\' % unsigned_value)\\n        self.append_raw_bytes(struct.pack(\\n            wire_format.FORMAT_UINT64_LITTLE_ENDIAN, unsigned_value))',\n",
              " 'def append_varint32(self, value):\\n        \"\"\"Appends a signed 32-bit integer to the internal buffer,\\n        encoded as a varint.  (Note that a negative varint32 will\\n        always require 10 bytes of space.)\\n        \"\"\"\\n        if not wire_format.INT32_MIN <= value <= wire_format.INT32_MAX:\\n            raise errors.EncodeError(\\'Value out of range: %d\\' % value)\\n        self.append_varint64(value)',\n",
              " 'def append_var_uint32(self, value):\\n        \"\"\"Appends an unsigned 32-bit integer to the internal buffer,\\n        encoded as a varint.\\n        \"\"\"\\n        if not 0 <= value <= wire_format.UINT32_MAX:\\n            raise errors.EncodeError(\\'Value out of range: %d\\' % value)\\n        self.append_var_uint64(value)',\n",
              " 'def append_varint64(self, value):\\n        \"\"\"Appends a signed 64-bit integer to the internal buffer,\\n        encoded as a varint.\\n        \"\"\"\\n        if not wire_format.INT64_MIN <= value <= wire_format.INT64_MAX:\\n            raise errors.EncodeError(\\'Value out of range: %d\\' % value)\\n        if value < 0:\\n            value += (1 << 64)\\n        self.append_var_uint64(value)',\n",
              " 'def append_var_uint64(self, unsigned_value):\\n        \"\"\"Appends an unsigned 64-bit integer to the internal buffer,\\n        encoded as a varint.\\n        \"\"\"\\n        if not 0 <= unsigned_value <= wire_format.UINT64_MAX:\\n            raise errors.EncodeError(\\'Value out of range: %d\\' % unsigned_value)\\n        while True:\\n            bits = unsigned_value & 0x7f\\n            unsigned_value >>= 7\\n            if unsigned_value:\\n                bits |= 0x80\\n            self._buffer.append(bits)\\n            if not unsigned_value:\\n                break',\n",
              " 'def groupby(expr, by, *bys):\\n    \"\"\"\\n    Group collection by a series of sequences.\\n\\n    :param expr: collection\\n    :param by: columns to group\\n    :param bys: columns to group\\n    :return: GroupBy instance\\n    :rtype: :class:`odps.df.expr.groupby.GroupBy`\\n    \"\"\"\\n\\n    if not isinstance(by, list):\\n        by = [by, ]\\n    if len(bys) > 0:\\n        by = by + list(bys)\\n    return GroupBy(_input=expr, _by=by)',\n",
              " 'def value_counts(expr, sort=True, ascending=False, dropna=False):\\n    \"\"\"\\n    Return object containing counts of unique values.\\n\\n    The resulting object will be in descending order so that the first element is the most frequently-occuring\\n    element. Exclude NA values by default\\n\\n    :param expr: sequence\\n    :param sort: if sort\\n    :type sort: bool\\n    :param dropna: Don’t include counts of None, default False\\n    :return: collection with two columns\\n    :rtype: :class:`odps.df.expr.expressions.CollectionExpr`\\n    \"\"\"\\n\\n    names = [expr.name, \\'count\\']\\n    typos = [expr.dtype, types.int64]\\n    return ValueCounts(_input=expr, _schema=Schema.from_lists(names, typos),\\n                       _sort=sort, _ascending=ascending, _dropna=dropna)',\n",
              " 'def create_hash(self, initial, capacity, error):\\n        \"\"\"\\n        Calculates a Bloom filter with the specified parameters.\\n        Initalizes with a string or list/set/tuple of strings. No output.\\n\\n        Reference material: http://bitworking.org/news/380/bloom-filter-resources\\n        \"\"\"\\n        self.hash = 0\\n        self.hashbits, self.num_hashes = self._optimal_size(capacity, error)\\n\\n        if len(initial):\\n            if type(initial) == str:\\n                self.add(initial)\\n            else:\\n                for t in initial:\\n                    self.add(t)',\n",
              " 'def _hashes(self, item):\\n        \"\"\"\\n        To create the hash functions we use the SHA-1 hash of the\\n        string and chop that up into 20 bit values and then\\n        mod down to the length of the Bloom filter.\\n        \"\"\"\\n        item = self._binary(item)\\n\\n        m = hashlib.sha1()\\n        m.update(item)\\n        digits = m.hexdigest()\\n\\n        # Add another 160 bits for every 8 (20-bit long) hashes we need\\n        for i in range(int(self.num_hashes // 8)):\\n            m.update(self._binary(str(i)))\\n            digits += m.hexdigest()\\n\\n        hashes = [int(digits[i*5:i*5+5], 16) % self.hashbits for i in range(self.num_hashes)]\\n        return hashes',\n",
              " 'def _optimal_size(self, capacity, error):\\n        \"\"\"Calculates minimum number of bits in filter array and\\n        number of hash functions given a number of enteries (maximum)\\n        and the desired error rate (falese positives).\\n\\n        Example:\\n            m, k = self._optimal_size(3000, 0.01)   # m=28756, k=7\\n        \"\"\"\\n        m = math.ceil((capacity * math.log(error)) / math.log(1.0 / (math.pow(2.0, math.log(2.0)))))\\n        k = math.ceil(math.log(2.0) * m / capacity)\\n        return int(m), int(k)',\n",
              " 'def add(self, item):\\n        \"Add an item (string) to the filter. Cannot be removed later!\"\\n        for pos in self._hashes(item):\\n            self.hash |= (2 ** pos)',\n",
              " 'def join(left, right, on=None, how=\\'inner\\', suffixes=(\\'_x\\', \\'_y\\'), mapjoin=False):\\n    \"\"\"\\n    Join two collections.\\n\\n    If `on` is not specified, we will find the common fields of the left and right collection.\\n    `suffixes` means that if column names conflict, the suffixes will be added automatically.\\n    For example, both left and right has a field named `col`,\\n    there will be col_x, and col_y in the joined collection.\\n\\n    :param left: left collection\\n    :param right: right collection\\n    :param on: fields to join on\\n    :param how: \\'inner\\', \\'left\\', \\'right\\', or \\'outer\\'\\n    :param suffixes: when name conflict, the suffix will be added to both columns.\\n    :param mapjoin: set use mapjoin or not, default value False.\\n    :return: collection\\n\\n    :Example:\\n\\n    >>> df.dtypes.names\\n    [\\'name\\', \\'id\\']\\n    >>> df2.dtypes.names\\n    [\\'name\\', \\'id1\\']\\n    >>> df.join(df2)\\n    >>> df.join(df2, on=\\'name\\')\\n    >>> df.join(df2, on=(\\'id\\', \\'id1\\'))\\n    >>> df.join(df2, on=[\\'name\\', (\\'id\\', \\'id1\\')])\\n    >>> df.join(df2, on=[df.name == df2.name, df.id == df2.id1])\\n    >>> df.join(df2, mapjoin=False)\\n    \"\"\"\\n    if on is None and not mapjoin:\\n        on = [name for name in left.schema.names if name in right.schema._name_indexes]\\n\\n    if isinstance(suffixes, (tuple, list)) and len(suffixes) == 2:\\n        left_suffix, right_suffix = suffixes\\n    else:\\n        raise ValueError(\\'suffixes must be a tuple or list with two elements, got %s\\' % suffixes)\\n    if not isinstance(on, list):\\n        on = [on, ]\\n    for i in range(len(on)):\\n        it = on[i]\\n        if inspect.isfunction(it):\\n            on[i] = it(left, right)\\n\\n    left, right = _make_different_sources(left, right, on)\\n\\n    try:\\n        return _join_dict[how.upper()](_lhs=left, _rhs=right, _predicate=on, _left_suffix=left_suffix,\\n                                       _right_suffix=right_suffix, _mapjoin=mapjoin)\\n    except KeyError:\\n        return JoinCollectionExpr(_lhs=left, _rhs=right, _predicate=on, _how=how, _left_suffix=left_suffix,\\n                                  _right_suffix=right_suffix, _mapjoin=mapjoin)',\n",
              " 'def inner_join(left, right, on=None, suffixes=(\\'_x\\', \\'_y\\'), mapjoin=False):\\n    \"\"\"\\n    Inner join two collections.\\n\\n    If `on` is not specified, we will find the common fields of the left and right collection.\\n    `suffixes` means that if column names conflict, the suffixes will be added automatically.\\n    For example, both left and right has a field named `col`,\\n    there will be col_x, and col_y in the joined collection.\\n\\n    :param left: left collection\\n    :param right: right collection\\n    :param on: fields to join on\\n    :param suffixes: when name conflict, the suffixes will be added to both columns.\\n    :return: collection\\n\\n    :Example:\\n\\n    >>> df.dtypes.names\\n    [\\'name\\', \\'id\\']\\n    >>> df2.dtypes.names\\n    [\\'name\\', \\'id1\\']\\n    >>> df.inner_join(df2)\\n    >>> df.inner_join(df2, on=\\'name\\')\\n    >>> df.inner_join(df2, on=(\\'id\\', \\'id1\\'))\\n    >>> df.inner_join(df2, on=[\\'name\\', (\\'id\\', \\'id1\\')])\\n    >>> df.inner_join(df2, on=[df.name == df2.name, df.id == df2.id1])\\n    \"\"\"\\n\\n    return join(left, right, on, suffixes=suffixes, mapjoin=mapjoin)',\n",
              " 'def left_join(left, right, on=None, suffixes=(\\'_x\\', \\'_y\\'), mapjoin=False, merge_columns=None):\\n    \"\"\"\\n    Left join two collections.\\n\\n    If `on` is not specified, we will find the common fields of the left and right collection.\\n    `suffixes` means that if column names conflict, the suffixes will be added automatically.\\n    For example, both left and right has a field named `col`,\\n    there will be col_x, and col_y in the joined collection.\\n\\n    :param left: left collection\\n    :param right: right collection\\n    :param on: fields to join on\\n    :param suffixes: when name conflict, the suffixes will be added to both columns.\\n    :param mapjoin: set use mapjoin or not, default value False.\\n    :param merge_columns: whether to merge columns with the same name into one column without suffix.\\n                          If the value is True, columns in the predicate with same names will be merged,\\n                          with non-null value. If the value is \\'left\\' or \\'right\\', the values of predicates\\n                          on the left / right collection will be taken. You can also pass a dictionary to\\n                          describe the behavior of each column, such as { \\'a\\': \\'auto\\', \\'b\\': \\'left\\' }.\\n    :return: collection\\n\\n    :Example:\\n\\n    >>> df.dtypes.names\\n    [\\'name\\', \\'id\\']\\n    >>> df2.dtypes.names\\n    [\\'name\\', \\'id1\\']\\n    >>> df.left_join(df2)\\n    >>> df.left_join(df2, on=\\'name\\')\\n    >>> df.left_join(df2, on=(\\'id\\', \\'id1\\'))\\n    >>> df.left_join(df2, on=[\\'name\\', (\\'id\\', \\'id1\\')])\\n    >>> df.left_join(df2, on=[df.name == df2.name, df.id == df2.id1])\\n    \"\"\"\\n    joined = join(left, right, on, how=\\'left\\', suffixes=suffixes, mapjoin=mapjoin)\\n    return joined._merge_joined_fields(merge_columns)',\n",
              " 'def union(left, right, distinct=False):\\n    \"\"\"\\n    Union two collections.\\n\\n    :param left: left collection\\n    :param right: right collection\\n    :param distinct:\\n    :return: collection\\n\\n    :Example:\\n    >>> df[\\'name\\', \\'id\\'].union(df2[\\'id\\', \\'name\\'])\\n    \"\"\"\\n    left, right = _make_different_sources(left, right)\\n    return UnionCollectionExpr(_lhs=left, _rhs=right, _distinct=distinct)',\n",
              " 'def concat(left, rights, distinct=False, axis=0):\\n    \"\"\"\\n    Concat collections.\\n\\n    :param left: left collection\\n    :param rights: right collections, can be a DataFrame object or a list of DataFrames\\n    :param distinct: whether to remove duplicate entries. only available when axis == 0\\n    :param axis: when axis == 0, the DataFrames are merged vertically, otherwise horizontally.\\n    :return: collection\\n\\n    Note that axis==1 can only be used under Pandas DataFrames or XFlow.\\n\\n    :Example:\\n    >>> df[\\'name\\', \\'id\\'].concat(df2[\\'score\\'], axis=1)\\n    \"\"\"\\n    from ..utils import to_collection\\n\\n    if isinstance(rights, Node):\\n        rights = [rights, ]\\n    if not rights:\\n        raise ValueError(\\'At least one DataFrame should be provided.\\')\\n\\n    if axis == 0:\\n        for right in rights:\\n            left = union(left, right, distinct=distinct)\\n        return left\\n    else:\\n        rights = [to_collection(r) for r in rights]\\n\\n    ConcatCollectionExpr.validate_input(left, *rights)\\n\\n    if hasattr(left, \\'_xflow_concat\\'):\\n        return left._xflow_concat(rights)\\n    else:\\n        return __horz_concat(left, rights)',\n",
              " 'def _drop(expr, data, axis=0, columns=None):\\n    \"\"\"\\n    Drop data from a DataFrame.\\n\\n    :param expr: collection to drop data from\\n    :param data: data to be removed\\n    :param axis: 0 for deleting rows, 1 for columns.\\n    :param columns: columns of data to select, only useful when axis == 0\\n    :return: collection\\n\\n    :Example:\\n    >>> import pandas as pd\\n    >>> df1 = DataFrame(pd.DataFrame({\\'a\\': [1, 2, 3], \\'b\\': [4, 5, 6], \\'c\\': [7, 8, 9]}))\\n    >>> df2 = DataFrame(pd.DataFrame({\\'a\\': [2, 3], \\'b\\': [5, 7]}))\\n    >>> df1.drop(df2)\\n       a  b  c\\n    0  1  4  7\\n    1  3  6  9\\n    >>> df1.drop(df2, columns=\\'a\\')\\n       a  b  c\\n    0  1  4  7\\n    >>> df1.drop([\\'a\\'], axis=1)\\n       b  c\\n    0  4  7\\n    1  5  8\\n    2  6  9\\n    >>> df1.drop(df2, axis=1)\\n       c\\n    0  7\\n    1  8\\n    2  9\\n    \"\"\"\\n    from ..utils import to_collection\\n    expr = to_collection(expr)\\n\\n    if axis == 0:\\n        if not isinstance(data, (CollectionExpr, SequenceExpr)):\\n            raise ExpressionError(\\'data should be a collection or sequence when axis == 1.\\')\\n\\n        data = to_collection(data)\\n        if columns is None:\\n            columns = [n for n in data.schema.names]\\n        if isinstance(columns, six.string_types):\\n            columns = [columns, ]\\n\\n        data = data.select(*columns).distinct()\\n\\n        drop_predicates = [data[n].isnull() for n in data.schema.names]\\n        return expr.left_join(data, on=columns, suffixes=(\\'\\', \\'_dp\\')).filter(*drop_predicates) \\\\\\n            .select(*expr.schema.names)\\n    else:\\n        if isinstance(data, (CollectionExpr, SequenceExpr)):\\n            data = to_collection(data).schema.names\\n        return expr.exclude(data)',\n",
              " 'def setdiff(left, *rights, **kwargs):\\n    \"\"\"\\n    Exclude data from a collection, like `except` clause in SQL. All collections involved should\\n    have same schema.\\n\\n    :param left: collection to drop data from\\n    :param rights: collection or list of collections\\n    :param distinct: whether to preserve duplicate entries\\n    :return: collection\\n\\n    :Examples:\\n    >>> import pandas as pd\\n    >>> df1 = DataFrame(pd.DataFrame({\\'a\\': [1, 2, 3, 3, 3], \\'b\\': [1, 2, 3, 3, 3]}))\\n    >>> df2 = DataFrame(pd.DataFrame({\\'a\\': [1, 3], \\'b\\': [1, 3]}))\\n    >>> df1.setdiff(df2)\\n       a  b\\n    0  2  2\\n    1  3  3\\n    2  3  3\\n    >>> df1.setdiff(df2, distinct=True)\\n       a  b\\n    0  2  2\\n    \"\"\"\\n    import time\\n    from ..utils import output\\n\\n    distinct = kwargs.get(\\'distinct\\', False)\\n\\n    if isinstance(rights[0], list):\\n        rights = rights[0]\\n\\n    cols = [n for n in left.schema.names]\\n    types = [n for n in left.schema.types]\\n\\n    counter_col_name = \\'exc_counter_%d\\' % int(time.time())\\n    left = left[left, Scalar(1).rename(counter_col_name)]\\n    rights = [r[r, Scalar(-1).rename(counter_col_name)] for r in rights]\\n\\n    unioned = left\\n    for r in rights:\\n        unioned = unioned.union(r)\\n\\n    if distinct:\\n        aggregated = unioned.groupby(*cols).agg(**{counter_col_name: unioned[counter_col_name].min()})\\n        return aggregated.filter(aggregated[counter_col_name] == 1).select(*cols)\\n    else:\\n        aggregated = unioned.groupby(*cols).agg(**{counter_col_name: unioned[counter_col_name].sum()})\\n\\n        @output(cols, types)\\n        def exploder(row):\\n            import sys\\n            irange = xrange if sys.version_info[0] < 3 else range\\n            for _ in irange(getattr(row, counter_col_name)):\\n                yield row[:-1]\\n\\n        return aggregated.map_reduce(mapper=exploder).select(*cols)',\n",
              " 'def intersect(left, *rights, **kwargs):\\n    \"\"\"\\n    Calc intersection among datasets,\\n\\n    :param left: collection\\n    :param rights: collection or list of collections\\n    :param distinct: whether to preserve duolicate entries\\n    :return: collection\\n\\n    :Examples:\\n    >>> import pandas as pd\\n    >>> df1 = DataFrame(pd.DataFrame({\\'a\\': [1, 2, 3, 3, 3], \\'b\\': [1, 2, 3, 3, 3]}))\\n    >>> df2 = DataFrame(pd.DataFrame({\\'a\\': [1, 3, 3], \\'b\\': [1, 3, 3]}))\\n    >>> df1.intersect(df2)\\n       a  b\\n    0  1  1\\n    1  3  3\\n    2  3  3\\n    >>> df1.intersect(df2, distinct=True)\\n       a  b\\n    0  1  1\\n    1  3  3\\n    \"\"\"\\n    import time\\n    from ..utils import output\\n\\n    distinct = kwargs.get(\\'distinct\\', False)\\n\\n    if isinstance(rights[0], list):\\n        rights = rights[0]\\n\\n    cols = [n for n in left.schema.names]\\n    types = [n for n in left.schema.types]\\n\\n    collections = (left, ) + rights\\n\\n    idx_col_name = \\'idx_%d\\' % int(time.time())\\n    counter_col_name = \\'exc_counter_%d\\' % int(time.time())\\n\\n    collections = [c[c, Scalar(idx).rename(idx_col_name)] for idx, c in enumerate(collections)]\\n\\n    unioned = reduce(lambda a, b: a.union(b), collections)\\n    src_agg = unioned.groupby(*(cols + [idx_col_name])) \\\\\\n        .agg(**{counter_col_name: unioned.count()})\\n\\n    aggregators = {\\n        idx_col_name: src_agg[idx_col_name].nunique(),\\n        counter_col_name: src_agg[counter_col_name].min(),\\n    }\\n    final_agg = src_agg.groupby(*cols).agg(**aggregators)\\n    final_agg = final_agg.filter(final_agg[idx_col_name] == len(collections))\\n\\n    if distinct:\\n        return final_agg.filter(final_agg[counter_col_name] > 0).select(*cols)\\n    else:\\n        @output(cols, types)\\n        def exploder(row):\\n            import sys\\n            irange = xrange if sys.version_info[0] < 3 else range\\n            for _ in irange(getattr(row, counter_col_name)):\\n                yield row[:-2]\\n\\n        return final_agg.map_reduce(mapper=exploder).select(*cols)',\n",
              " 'def _verify_and_add_jwt():\\n    \"\"\"\\n    This helper method just checks and adds jwt data to the app context. Will\\n    not add jwt data if it is already present. Only use in this module\\n    \"\"\"\\n    if not app_context_has_jwt_data():\\n        guard = current_guard()\\n        token = guard.read_token_from_header()\\n        jwt_data = guard.extract_jwt_token(token)\\n        add_jwt_data_to_app_context(jwt_data)',\n",
              " 'def auth_required(method):\\n    \"\"\"\\n    This decorator is used to ensure that a user is authenticated before\\n    being able to access a flask route. It also adds the current user to the\\n    current flask context.\\n    \"\"\"\\n    @functools.wraps(method)\\n    def wrapper(*args, **kwargs):\\n        _verify_and_add_jwt()\\n        try:\\n            return method(*args, **kwargs)\\n        finally:\\n            remove_jwt_data_from_app_context()\\n    return wrapper',\n",
              " 'def roles_required(*required_rolenames):\\n    \"\"\"\\n    This decorator ensures that any uses accessing the decorated route have all\\n    the needed roles to access it. If an @auth_required decorator is not\\n    supplied already, this decorator will implicitly check @auth_required first\\n    \"\"\"\\n    def decorator(method):\\n        @functools.wraps(method)\\n        def wrapper(*args, **kwargs):\\n            role_set = set([str(n) for n in required_rolenames])\\n            _verify_and_add_jwt()\\n            try:\\n                MissingRoleError.require_condition(\\n                    current_rolenames().issuperset(role_set),\\n                    \"This endpoint requires all the following roles: {}\",\\n                    [\\', \\'.join(role_set)],\\n                )\\n                return method(*args, **kwargs)\\n            finally:\\n                remove_jwt_data_from_app_context()\\n        return wrapper\\n    return decorator',\n",
              " 'def roles_accepted(*accepted_rolenames):\\n    \"\"\"\\n    This decorator ensures that any uses accessing the decorated route have one\\n    of the needed roles to access it. If an @auth_required decorator is not\\n    supplied already, this decorator will implicitly check @auth_required first\\n    \"\"\"\\n    def decorator(method):\\n        @functools.wraps(method)\\n        def wrapper(*args, **kwargs):\\n            role_set = set([str(n) for n in accepted_rolenames])\\n            _verify_and_add_jwt()\\n            try:\\n                MissingRoleError.require_condition(\\n                    not current_rolenames().isdisjoint(role_set),\\n                    \"This endpoint requires one of the following roles: {}\",\\n                    [\\', \\'.join(role_set)],\\n                )\\n                return method(*args, **kwargs)\\n            finally:\\n                remove_jwt_data_from_app_context()\\n        return wrapper\\n    return decorator',\n",
              " 'def init_app(self, app, user_class, is_blacklisted=None):\\n        \"\"\"\\n        Initializes the Praetorian extension\\n\\n        :param: app:            The flask app to bind this extension to\\n        :param: user_class:     The class used to interact with user data\\n        :param: is_blacklisted: A method that may optionally be used to\\n                                check the token against a blacklist when\\n                                access or refresh is requested\\n                                Should take the jti for the token to check\\n                                as a single argument. Returns True if\\n                                the jti is blacklisted, False otherwise.\\n                                By default, always returns False.\\n        \"\"\"\\n        PraetorianError.require_condition(\\n            app.config.get(\\'SECRET_KEY\\') is not None,\\n            \"There must be a SECRET_KEY app config setting set\",\\n        )\\n\\n        possible_schemes = [\\n            \\'argon2\\',\\n            \\'bcrypt\\',\\n            \\'pbkdf2_sha512\\',\\n        ]\\n        self.pwd_ctx = CryptContext(\\n            default=\\'pbkdf2_sha512\\',\\n            schemes=possible_schemes + [\\'plaintext\\'],\\n            deprecated=[],\\n        )\\n\\n        self.hash_scheme = app.config.get(\\'PRAETORIAN_HASH_SCHEME\\')\\n        valid_schemes = self.pwd_ctx.schemes()\\n        PraetorianError.require_condition(\\n            self.hash_scheme in valid_schemes or self.hash_scheme is None,\\n            \"If {} is set, it must be one of the following schemes: {}\",\\n            \\'PRAETORIAN_HASH_SCHEME\\',\\n            valid_schemes,\\n        )\\n\\n        self.user_class = self._validate_user_class(user_class)\\n        self.is_blacklisted = is_blacklisted or (lambda t: False)\\n\\n        self.encode_key = app.config[\\'SECRET_KEY\\']\\n        self.allowed_algorithms = app.config.get(\\n            \\'JWT_ALLOWED_ALGORITHMS\\',\\n            DEFAULT_JWT_ALLOWED_ALGORITHMS,\\n        )\\n        self.encode_algorithm = app.config.get(\\n            \\'JWT_ALGORITHM\\',\\n            DEFAULT_JWT_ALGORITHM,\\n        )\\n        self.access_lifespan = pendulum.Duration(**app.config.get(\\n            \\'JWT_ACCESS_LIFESPAN\\',\\n            DEFAULT_JWT_ACCESS_LIFESPAN,\\n        ))\\n        self.refresh_lifespan = pendulum.Duration(**app.config.get(\\n            \\'JWT_REFRESH_LIFESPAN\\',\\n            DEFAULT_JWT_REFRESH_LIFESPAN,\\n        ))\\n        self.header_name = app.config.get(\\n            \\'JWT_HEADER_NAME\\',\\n            DEFAULT_JWT_HEADER_NAME,\\n        )\\n        self.header_type = app.config.get(\\n            \\'JWT_HEADER_TYPE\\',\\n            DEFAULT_JWT_HEADER_TYPE,\\n        )\\n        self.user_class_validation_method = app.config.get(\\n            \\'USER_CLASS_VALIDATION_METHOD\\',\\n            DEFAULT_USER_CLASS_VALIDATION_METHOD,\\n        )\\n\\n        if not app.config.get(\\'DISABLE_PRAETORIAN_ERROR_HANDLER\\'):\\n            app.register_error_handler(\\n                PraetorianError,\\n                PraetorianError.build_error_handler(),\\n            )\\n\\n        self.is_testing = app.config.get(\\'TESTING\\', False)\\n\\n        if not hasattr(app, \\'extensions\\'):\\n            app.extensions = {}\\n        app.extensions[\\'praetorian\\'] = self',\n",
              " 'def _validate_user_class(cls, user_class):\\n        \"\"\"\\n        Validates the supplied user_class to make sure that it has the\\n        class methods necessary to function correctly.\\n\\n        Requirements:\\n\\n        - ``lookup`` method. Accepts a string parameter, returns instance\\n        - ``identify`` method. Accepts an identity parameter, returns instance\\n        \"\"\"\\n        PraetorianError.require_condition(\\n            getattr(user_class, \\'lookup\\', None) is not None,\\n            textwrap.dedent(\"\"\"\\n                The user_class must have a lookup class method:\\n                user_class.lookup(<str>) -> <user instance>\\n            \"\"\"),\\n        )\\n        PraetorianError.require_condition(\\n            getattr(user_class, \\'identify\\', None) is not None,\\n            textwrap.dedent(\"\"\"\\n                The user_class must have an identify class method:\\n                user_class.identify(<identity>) -> <user instance>\\n            \"\"\"),\\n        )\\n        # TODO: Figure out how to check for an identity property\\n        return user_class',\n",
              " 'def authenticate(self, username, password):\\n        \"\"\"\\n        Verifies that a password matches the stored password for that username.\\n        If verification passes, the matching user instance is returned\\n        \"\"\"\\n        PraetorianError.require_condition(\\n            self.user_class is not None,\\n            \"Praetorian must be initialized before this method is available\",\\n        )\\n        user = self.user_class.lookup(username)\\n        MissingUserError.require_condition(\\n            user is not None,\\n            \\'Could not find the requested user\\',\\n        )\\n        AuthenticationError.require_condition(\\n            self._verify_password(password, user.password),\\n            \\'The password is incorrect\\',\\n        )\\n        return user',\n",
              " 'def _verify_password(self, raw_password, hashed_password):\\n        \"\"\"\\n        Verifies that a plaintext password matches the hashed version of that\\n        password using the stored passlib password context\\n        \"\"\"\\n        PraetorianError.require_condition(\\n            self.pwd_ctx is not None,\\n            \"Praetorian must be initialized before this method is available\",\\n        )\\n        return self.pwd_ctx.verify(raw_password, hashed_password)',\n",
              " 'def encrypt_password(self, raw_password):\\n        \"\"\"\\n        Encrypts a plaintext password using the stored passlib password context\\n        \"\"\"\\n        PraetorianError.require_condition(\\n            self.pwd_ctx is not None,\\n            \"Praetorian must be initialized before this method is available\",\\n        )\\n        return self.pwd_ctx.encrypt(raw_password, scheme=self.hash_scheme)',\n",
              " 'def error_handler(self, error):\\n        \"\"\"\\n        Provides a flask error handler that is used for PraetorianErrors\\n        (and derived exceptions).\\n        \"\"\"\\n        warnings.warn(\\n            \"\"\"\\n            error_handler is deprecated.\\n            Use FlaskBuzz.build_error_handler instead\\n            \"\"\",\\n            warnings.DeprecationWarning,\\n        )\\n        return error.jsonify(), error.status_code, error.headers',\n",
              " 'def _check_user(self, user):\\n        \"\"\"\\n        Checks to make sure that a user is valid. First, checks that the user\\n        is not None. If this check fails, a MissingUserError is raised. Next,\\n        checks if the user has a validation method. If the method does not\\n        exist, the check passes. If the method exists, it is called. If the\\n        result of the call is not truthy, an InvalidUserError is raised\\n        \"\"\"\\n        MissingUserError.require_condition(\\n            user is not None,\\n            \\'Could not find the requested user\\',\\n        )\\n        user_validate_method = getattr(\\n            user, self.user_class_validation_method, None\\n        )\\n        if user_validate_method is None:\\n            return\\n        InvalidUserError.require_condition(\\n            user_validate_method(),\\n            \"The user is not valid or has had access revoked\",\\n        )',\n",
              " 'def encode_jwt_token(\\n            self, user,\\n            override_access_lifespan=None, override_refresh_lifespan=None,\\n            **custom_claims\\n    ):\\n        \"\"\"\\n        Encodes user data into a jwt token that can be used for authorization\\n        at protected endpoints\\n\\n        :param: override_access_lifespan:  Override\\'s the instance\\'s access\\n                                           lifespan to set a custom duration\\n                                           after which the new token\\'s\\n                                           accessability will expire. May not\\n                                           exceed the refresh_lifespan\\n        :param: override_refresh_lifespan: Override\\'s the instance\\'s refresh\\n                                           lifespan to set a custom duration\\n                                           after which the new token\\'s\\n                                           refreshability will expire.\\n        :param: custom_claims:             Additional claims that should\\n                                           be packed in the payload. Note that\\n                                           any claims supplied here must be\\n                                           JSON compatible types\\n        \"\"\"\\n        ClaimCollisionError.require_condition(\\n            set(custom_claims.keys()).isdisjoint(RESERVED_CLAIMS),\\n            \"The custom claims collide with required claims\",\\n        )\\n        self._check_user(user)\\n\\n        moment = pendulum.now(\\'UTC\\')\\n\\n        if override_refresh_lifespan is None:\\n            refresh_lifespan = self.refresh_lifespan\\n        else:\\n            refresh_lifespan = override_refresh_lifespan\\n        refresh_expiration = (moment + refresh_lifespan).int_timestamp\\n\\n        if override_access_lifespan is None:\\n            access_lifespan = self.access_lifespan\\n        else:\\n            access_lifespan = override_access_lifespan\\n        access_expiration = min(\\n            (moment + access_lifespan).int_timestamp,\\n            refresh_expiration,\\n        )\\n\\n        payload_parts = dict(\\n            iat=moment.int_timestamp,\\n            exp=access_expiration,\\n            rf_exp=refresh_expiration,\\n            jti=str(uuid.uuid4()),\\n            id=user.identity,\\n            rls=\\',\\'.join(user.rolenames),\\n            **custom_claims\\n        )\\n        return jwt.encode(\\n            payload_parts, self.encode_key, self.encode_algorithm,\\n        ).decode(\\'utf-8\\')',\n",
              " 'def encode_eternal_jwt_token(self, user, **custom_claims):\\n        \"\"\"\\n        This utility function encodes a jwt token that never expires\\n\\n        .. note:: This should be used sparingly since the token could become\\n                  a security concern if it is ever lost. If you use this\\n                  method, you should be sure that your application also\\n                  implements a blacklist so that a given token can be blocked\\n                  should it be lost or become a security concern\\n        \"\"\"\\n        return self.encode_jwt_token(\\n            user,\\n            override_access_lifespan=VITAM_AETERNUM,\\n            override_refresh_lifespan=VITAM_AETERNUM,\\n            **custom_claims\\n        )',\n",
              " 'def refresh_jwt_token(self, token, override_access_lifespan=None):\\n        \"\"\"\\n        Creates a new token for a user if and only if the old token\\'s access\\n        permission is expired but its refresh permission is not yet expired.\\n        The new token\\'s refresh expiration moment is the same as the old\\n        token\\'s, but the new token\\'s access expiration is refreshed\\n\\n        :param: token:                     The existing jwt token that needs to\\n                                           be replaced with a new, refreshed\\n                                           token\\n        :param: override_access_lifespan:  Override\\'s the instance\\'s access\\n                                           lifespan to set a custom duration\\n                                           after which the new token\\'s\\n                                           accessability will expire. May not\\n                                           exceed the refresh lifespan\\n        \"\"\"\\n        moment = pendulum.now(\\'UTC\\')\\n        # Note: we disable exp verification because we do custom checks here\\n        with InvalidTokenHeader.handle_errors(\\'failed to decode JWT token\\'):\\n            data = jwt.decode(\\n                token,\\n                self.encode_key,\\n                algorithms=self.allowed_algorithms,\\n                options={\\'verify_exp\\': False},\\n            )\\n\\n        self._validate_jwt_data(data, access_type=AccessType.refresh)\\n\\n        user = self.user_class.identify(data[\\'id\\'])\\n        self._check_user(user)\\n\\n        if override_access_lifespan is None:\\n            access_lifespan = self.access_lifespan\\n        else:\\n            access_lifespan = override_access_lifespan\\n        refresh_expiration = data[\\'rf_exp\\']\\n        access_expiration = min(\\n            (moment + access_lifespan).int_timestamp,\\n            refresh_expiration,\\n        )\\n\\n        custom_claims = {\\n            k: v for (k, v) in data.items() if k not in RESERVED_CLAIMS\\n        }\\n        payload_parts = dict(\\n            iat=moment.int_timestamp,\\n            exp=access_expiration,\\n            rf_exp=refresh_expiration,\\n            jti=data[\\'jti\\'],\\n            id=data[\\'id\\'],\\n            rls=\\',\\'.join(user.rolenames),\\n            **custom_claims\\n        )\\n        return jwt.encode(\\n            payload_parts, self.encode_key, self.encode_algorithm,\\n        ).decode(\\'utf-8\\')',\n",
              " 'def extract_jwt_token(self, token):\\n        \"\"\"\\n        Extracts a data dictionary from a jwt token\\n        \"\"\"\\n        # Note: we disable exp verification because we will do it ourselves\\n        with InvalidTokenHeader.handle_errors(\\'failed to decode JWT token\\'):\\n            data = jwt.decode(\\n                token,\\n                self.encode_key,\\n                algorithms=self.allowed_algorithms,\\n                options={\\'verify_exp\\': False},\\n            )\\n        self._validate_jwt_data(data, access_type=AccessType.access)\\n        return data',\n",
              " 'def _validate_jwt_data(self, data, access_type):\\n        \"\"\"\\n        Validates that the data for a jwt token is valid\\n        \"\"\"\\n        MissingClaimError.require_condition(\\n            \\'jti\\' in data,\\n            \\'Token is missing jti claim\\',\\n        )\\n        BlacklistedError.require_condition(\\n            not self.is_blacklisted(data[\\'jti\\']),\\n            \\'Token has a blacklisted jti\\',\\n        )\\n        MissingClaimError.require_condition(\\n            \\'id\\' in data,\\n            \\'Token is missing id field\\',\\n        )\\n        MissingClaimError.require_condition(\\n            \\'exp\\' in data,\\n            \\'Token is missing exp claim\\',\\n        )\\n        MissingClaimError.require_condition(\\n            \\'rf_exp\\' in data,\\n            \\'Token is missing rf_exp claim\\',\\n        )\\n        moment = pendulum.now(\\'UTC\\').int_timestamp\\n        if access_type == AccessType.access:\\n            ExpiredAccessError.require_condition(\\n                moment <= data[\\'exp\\'],\\n                \\'access permission has expired\\',\\n            )\\n        elif access_type == AccessType.refresh:\\n            EarlyRefreshError.require_condition(\\n                moment > data[\\'exp\\'],\\n                \\'access permission for token has not expired. may not refresh\\',\\n            )\\n            ExpiredRefreshError.require_condition(\\n                moment <= data[\\'rf_exp\\'],\\n                \\'refresh permission for token has expired\\',\\n            )',\n",
              " 'def _unpack_header(self, headers):\\n        \"\"\"\\n        Unpacks a jwt token from a request header\\n        \"\"\"\\n        jwt_header = headers.get(self.header_name)\\n        MissingTokenHeader.require_condition(\\n            jwt_header is not None,\\n            \"JWT token not found in headers under \\'{}\\'\",\\n            self.header_name,\\n        )\\n\\n        match = re.match(self.header_type + r\\'\\\\s*([\\\\w\\\\.-]+)\\', jwt_header)\\n        InvalidTokenHeader.require_condition(\\n            match is not None,\\n            \"JWT header structure is invalid\",\\n        )\\n        token = match.group(1)\\n        return token',\n",
              " 'def pack_header_for_user(\\n            self, user,\\n            override_access_lifespan=None, override_refresh_lifespan=None,\\n            **custom_claims\\n    ):\\n        \"\"\"\\n        Encodes a jwt token and packages it into a header dict for a given user\\n\\n        :param: user:                      The user to package the header for\\n        :param: override_access_lifespan:  Override\\'s the instance\\'s access\\n                                           lifespan to set a custom duration\\n                                           after which the new token\\'s\\n                                           accessability will expire. May not\\n                                           exceed the refresh_lifespan\\n        :param: override_refresh_lifespan: Override\\'s the instance\\'s refresh\\n                                           lifespan to set a custom duration\\n                                           after which the new token\\'s\\n                                           refreshability will expire.\\n        :param: custom_claims:             Additional claims that should\\n                                           be packed in the payload. Note that\\n                                           any claims supplied here must be\\n                                           JSON compatible types\\n        \"\"\"\\n        token = self.encode_jwt_token(\\n            user,\\n            override_access_lifespan=override_access_lifespan,\\n            override_refresh_lifespan=override_refresh_lifespan,\\n            **custom_claims\\n        )\\n        return {self.header_name: self.header_type + \\' \\' + token}',\n",
              " 'def login():\\n    \"\"\"\\n    Logs a user in by parsing a POST request containing user credentials and\\n    issuing a JWT token.\\n\\n    .. example::\\n       $ curl http://localhost:5000/login -X POST \\\\\\n         -d \\'{\"username\":\"Walter\",\"password\":\"calmerthanyouare\"}\\'\\n    \"\"\"\\n    req = flask.request.get_json(force=True)\\n    username = req.get(\\'username\\', None)\\n    password = req.get(\\'password\\', None)\\n    user = guard.authenticate(username, password)\\n    ret = {\\'access_token\\': guard.encode_jwt_token(user)}\\n    return (flask.jsonify(ret), 200)',\n",
              " 'def refresh():\\n    \"\"\"\\n    Refreshes an existing JWT by creating a new one that is a copy of the old\\n    except that it has a refrehsed access expiration.\\n\\n    .. example::\\n       $ curl http://localhost:5000/refresh -X GET \\\\\\n         -H \"Authorization: Bearer <your_token>\"\\n    \"\"\"\\n    old_token = guard.read_token_from_header()\\n    new_token = guard.refresh_jwt_token(old_token)\\n    ret = {\\'access_token\\': new_token}\\n    return flask.jsonify(ret), 200',\n",
              " 'def disable_user():\\n    \"\"\"\\n    Disables a user in the data store\\n\\n    .. example::\\n        $ curl http://localhost:5000/disable_user -X POST \\\\\\n          -H \"Authorization: Bearer <your_token>\" \\\\\\n          -d \\'{\"username\":\"Walter\"}\\'\\n    \"\"\"\\n    req = flask.request.get_json(force=True)\\n    usr = User.query.filter_by(username=req.get(\\'username\\', None)).one()\\n    usr.is_active = False\\n    db.session.commit()\\n    return flask.jsonify(message=\\'disabled user {}\\'.format(usr.username))',\n",
              " 'def blacklist_token():\\n    \"\"\"\\n    Blacklists an existing JWT by registering its jti claim in the blacklist.\\n\\n    .. example::\\n       $ curl http://localhost:5000/blacklist_token -X POST \\\\\\n         -d \\'{\"token\":\"<your_token>\"}\\'\\n    \"\"\"\\n    req = flask.request.get_json(force=True)\\n    data = guard.extract_jwt_token(req[\\'token\\'])\\n    blacklist.add(data[\\'jti\\'])\\n    return flask.jsonify(message=\\'token blacklisted ({})\\'.format(req[\\'token\\']))',\n",
              " 'def login():\\n    \"\"\"\\n    Logs a user in by parsing a POST request containing user credentials and\\n    issuing a JWT token.\\n\\n    .. example::\\n       $ curl http://localhost:5000/login -X POST \\\\\\n         -d \\'{\"username\":\"Walter\",\"password\":\"calmerthanyouare\"}\\'\\n    \"\"\"\\n    req = flask.request.get_json(force=True)\\n    username = req.pop(\\'username\\', None)\\n    password = req.pop(\\'password\\', None)\\n\\n    user = guard.authenticate(username, password)\\n    ret = {\\'access_token\\': guard.encode_jwt_token(\\n        user,\\n        firstname=user.firstname,\\n        nickname=user.nickname,\\n        surname=user.surname,\\n    )}\\n\\n    return (flask.jsonify(ret), 200)',\n",
              " 'def protected():\\n    \"\"\"\\n    A protected endpoint. The auth_required decorator will require a header\\n    containing a valid JWT\\n\\n    .. example::\\n       $ curl http://localhost:5000/protected -X GET \\\\\\n         -H \"Authorization: Bearer <your_token>\"\\n    \"\"\"\\n    custom_claims = flask_praetorian.current_custom_claims()\\n    firstname = custom_claims.pop(\\'firstname\\', None)\\n    nickname = custom_claims.pop(\\'nickname\\', None)\\n    surname = custom_claims.pop(\\'surname\\', None)\\n\\n    if nickname is None:\\n        user_string = \"{} {}\".format(firstname, surname)\\n    else:\\n        user_string = \"{} \\'{}\\' {}\".format(firstname, nickname, surname)\\n\\n    return flask.jsonify(\\n        message=\"protected endpoint (allowed user {u})\".format(u=user_string),\\n    )',\n",
              " 'def current_guard():\\n    \"\"\"\\n    Fetches the current instance of flask-praetorian that is attached to the\\n    current flask app\\n    \"\"\"\\n    guard = flask.current_app.extensions.get(\\'praetorian\\', None)\\n    PraetorianError.require_condition(\\n        guard is not None,\\n        \"No current guard found; Praetorian must be initialized first\",\\n    )\\n    return guard',\n",
              " 'def get_jwt_data_from_app_context():\\n    \"\"\"\\n    Fetches a dict of jwt token data from the top of the flask app\\'s context\\n    \"\"\"\\n    ctx = flask._app_ctx_stack.top\\n    jwt_data = getattr(ctx, \\'jwt_data\\', None)\\n    PraetorianError.require_condition(\\n        jwt_data is not None,\\n        \"\"\"\\n        No jwt_data found in app context.\\n        Make sure @auth_required decorator is specified *first* for route\\n        \"\"\",\\n    )\\n    return jwt_data',\n",
              " 'def current_user_id():\\n    \"\"\"\\n    This method returns the user id retrieved from jwt token data attached to\\n    the current flask app\\'s context\\n    \"\"\"\\n    jwt_data = get_jwt_data_from_app_context()\\n    user_id = jwt_data.get(\\'id\\')\\n    PraetorianError.require_condition(\\n        user_id is not None,\\n        \"Could not fetch an id for the current user\",\\n    )\\n    return user_id',\n",
              " 'def current_user():\\n    \"\"\"\\n    This method returns a user instance for jwt token data attached to the\\n    current flask app\\'s context\\n    \"\"\"\\n    user_id = current_user_id()\\n    guard = current_guard()\\n    user = guard.user_class.identify(user_id)\\n    PraetorianError.require_condition(\\n        user is not None,\\n        \"Could not identify the current user from the current id\",\\n    )\\n    return user',\n",
              " 'def current_rolenames():\\n    \"\"\"\\n    This method returns the names of all roles associated with the current user\\n    \"\"\"\\n    jwt_data = get_jwt_data_from_app_context()\\n    if \\'rls\\' not in jwt_data:\\n        # This is necessary so our set arithmetic works correctly\\n        return set([\\'non-empty-but-definitely-not-matching-subset\\'])\\n    else:\\n        return set(r.strip() for r in jwt_data[\\'rls\\'].split(\\',\\'))',\n",
              " 'def current_custom_claims():\\n    \"\"\"\\n    This method returns any custom claims in the current jwt\\n    \"\"\"\\n    jwt_data = get_jwt_data_from_app_context()\\n    return {k: v for (k, v) in jwt_data.items() if k not in RESERVED_CLAIMS}',\n",
              " 'def check_redirect_uris(uris, client_type=None):\\n    \"\"\"\\n    This function checks all return uris provided and tries to deduce\\n    as what type of client we should register.\\n\\n    :param uris: The redirect URIs to check.\\n    :type uris: list\\n    :param client_type: An indicator of which client type you are expecting\\n        to be used. If this does not match the deduced type, an error will\\n        be raised.\\n    :type client_type: str\\n    :returns: The deduced client type.\\n    :rtype: str\\n    :raises ValueError: An error occured while checking the redirect uris.\\n\\n    .. versionadded:: 1.0\\n    \"\"\"\\n    if client_type not in [None, \\'native\\', \\'web\\']:\\n        raise ValueError(\\'Invalid client type indicator used\\')\\n\\n    if not isinstance(uris, list):\\n        raise ValueError(\\'uris needs to be a list of strings\\')\\n\\n    if len(uris) < 1:\\n        raise ValueError(\\'At least one return URI needs to be provided\\')\\n\\n    for uri in uris:\\n        if uri.startswith(\\'https://\\'):\\n            if client_type == \\'native\\':\\n                raise ValueError(\\'https url with native client\\')\\n            client_type = \\'web\\'\\n        elif uri.startswith(\\'http://localhost\\'):\\n            if client_type == \\'web\\':\\n                raise ValueError(\\'http://localhost url with web client\\')\\n            client_type = \\'native\\'\\n        else:\\n            if (uri.startswith(\\'http://\\') and \\n                    not uri.startswith(\\'http://localhost\\')):\\n                raise ValueError(\\'http:// url with non-localhost is illegal\\')\\n            else:\\n                raise ValueError(\\'Invalid uri provided: %s\\' % uri)\\n\\n    return client_type',\n",
              " 'def register_client(provider_info, redirect_uris):\\n    \"\"\"\\n    This function registers a new client with the specified OpenID Provider,\\n    and then returns the regitered client ID and other information.\\n\\n    :param provider_info: The contents of the discovery endpoint as\\n        specified by the OpenID Connect Discovery 1.0 specifications.\\n    :type provider_info: dict\\n    :param redirect_uris: The redirect URIs the application wants to\\n        register.\\n    :type redirect_uris: list\\n    :returns: An object containing the information needed to configure the\\n        actual client code to communicate with the OpenID Provider.\\n    :rtype: dict\\n    :raises ValueError: The same error as used by check_redirect_uris.\\n    :raises RegistrationError: Indicates an error was returned by the OpenID\\n        Provider during registration.\\n\\n    .. versionadded:: 1.0\\n    \"\"\"\\n    client_type = check_redirect_uris(redirect_uris)\\n\\n    submit_info = {\\'redirect_uris\\': redirect_uris,\\n                   \\'application_type\\': client_type,\\n                   \\'token_endpoint_auth_method\\': \\'client_secret_post\\'}\\n\\n    headers = {\\'Content-type\\': \\'application/json\\'}\\n\\n    resp, content = httplib2.Http().request(\\n        provider_info[\\'registration_endpoint\\'], \\'POST\\',\\n        json.dumps(submit_info), headers=headers)\\n\\n    if int(resp[\\'status\\']) >= 400:\\n        raise Exception(\\'Error: the server returned HTTP \\' + resp[\\'status\\'])\\n\\n    client_info = _json_loads(content)\\n\\n    if \\'error\\' in client_info:\\n        raise Exception(\\'Error occured during registration: %s (%s)\\'\\n                        % (client_info[\\'error\\'],\\n                           client_info.get(\\'error_description\\')))\\n\\n    json_file = {\\'web\\': {\\n        \\'client_id\\': client_info[\\'client_id\\'],\\n        \\'client_secret\\': client_info[\\'client_secret\\'],\\n        \\'auth_uri\\': provider_info[\\'authorization_endpoint\\'],\\n        \\'token_uri\\': provider_info[\\'token_endpoint\\'],\\n        \\'userinfo_uri\\': provider_info[\\'userinfo_endpoint\\'],\\n        \\'redirect_uris\\': redirect_uris,\\n        \\'issuer\\': provider_info[\\'issuer\\'],\\n    }}\\n\\n    return json_file',\n",
              " 'def discover_OP_information(OP_uri):\\n    \"\"\"\\n    Discovers information about the provided OpenID Provider.\\n\\n    :param OP_uri: The base URI of the Provider information is requested for.\\n    :type OP_uri: str\\n    :returns: The contents of the Provider metadata document.\\n    :rtype: dict\\n\\n    .. versionadded:: 1.0\\n    \"\"\"\\n    _, content = httplib2.Http().request(\\n        \\'%s/.well-known/openid-configuration\\' % OP_uri)\\n    return _json_loads(content)',\n",
              " 'def init_app(self, app):\\n        \"\"\"\\n        Do setup that requires a Flask app.\\n\\n        :param app: The application to initialize.\\n        :type app: Flask\\n        \"\"\"\\n        secrets = self.load_secrets(app)\\n        self.client_secrets = list(secrets.values())[0]\\n        secrets_cache = DummySecretsCache(secrets)\\n\\n        # Set some default configuration options\\n        app.config.setdefault(\\'OIDC_SCOPES\\', [\\'openid\\', \\'email\\'])\\n        app.config.setdefault(\\'OIDC_GOOGLE_APPS_DOMAIN\\', None)\\n        app.config.setdefault(\\'OIDC_ID_TOKEN_COOKIE_NAME\\', \\'oidc_id_token\\')\\n        app.config.setdefault(\\'OIDC_ID_TOKEN_COOKIE_PATH\\', \\'/\\')\\n        app.config.setdefault(\\'OIDC_ID_TOKEN_COOKIE_TTL\\', 7 * 86400)  # 7 days\\n        # should ONLY be turned off for local debugging\\n        app.config.setdefault(\\'OIDC_COOKIE_SECURE\\', True)\\n        app.config.setdefault(\\'OIDC_VALID_ISSUERS\\',\\n                              (self.client_secrets.get(\\'issuer\\') or\\n                               GOOGLE_ISSUERS))\\n        app.config.setdefault(\\'OIDC_CLOCK_SKEW\\', 60)  # 1 minute\\n        app.config.setdefault(\\'OIDC_REQUIRE_VERIFIED_EMAIL\\', False)\\n        app.config.setdefault(\\'OIDC_OPENID_REALM\\', None)\\n        app.config.setdefault(\\'OIDC_USER_INFO_ENABLED\\', True)\\n        app.config.setdefault(\\'OIDC_CALLBACK_ROUTE\\', \\'/oidc_callback\\')\\n        app.config.setdefault(\\'OVERWRITE_REDIRECT_URI\\', False)\\n        app.config.setdefault(\"OIDC_EXTRA_REQUEST_AUTH_PARAMS\", {})\\n        # Configuration for resource servers\\n        app.config.setdefault(\\'OIDC_RESOURCE_SERVER_ONLY\\', False)\\n        app.config.setdefault(\\'OIDC_RESOURCE_CHECK_AUD\\', False)\\n\\n        # We use client_secret_post, because that\\'s what the Google\\n        # oauth2client library defaults to\\n        app.config.setdefault(\\'OIDC_INTROSPECTION_AUTH_METHOD\\', \\'client_secret_post\\')\\n        app.config.setdefault(\\'OIDC_TOKEN_TYPE_HINT\\', \\'access_token\\')\\n\\n        if not \\'openid\\' in app.config[\\'OIDC_SCOPES\\']:\\n            raise ValueError(\\'The value \"openid\" must be in the OIDC_SCOPES\\')\\n\\n        # register callback route and cookie-setting decorator\\n        if not app.config[\\'OIDC_RESOURCE_SERVER_ONLY\\']:\\n            app.route(app.config[\\'OIDC_CALLBACK_ROUTE\\'])(self._oidc_callback)\\n            app.before_request(self._before_request)\\n            app.after_request(self._after_request)\\n\\n        # Initialize oauth2client\\n        self.flow = flow_from_clientsecrets(\\n            app.config[\\'OIDC_CLIENT_SECRETS\\'],\\n            scope=app.config[\\'OIDC_SCOPES\\'],\\n            cache=secrets_cache)\\n        assert isinstance(self.flow, OAuth2WebServerFlow)\\n\\n        # create signers using the Flask secret key\\n        self.extra_data_serializer = JSONWebSignatureSerializer(\\n            app.config[\\'SECRET_KEY\\'], salt=\\'flask-oidc-extra-data\\')\\n        self.cookie_serializer = JSONWebSignatureSerializer(\\n            app.config[\\'SECRET_KEY\\'], salt=\\'flask-oidc-cookie\\')\\n\\n        try:\\n            self.credentials_store = app.config[\\'OIDC_CREDENTIALS_STORE\\']\\n        except KeyError:\\n            pass',\n",
              " 'def user_getfield(self, field, access_token=None):\\n        \"\"\"\\n        Request a single field of information about the user.\\n\\n        :param field: The name of the field requested.\\n        :type field: str\\n        :returns: The value of the field. Depending on the type, this may be\\n            a string, list, dict, or something else.\\n        :rtype: object\\n\\n        .. versionadded:: 1.0\\n        \"\"\"\\n        info = self.user_getinfo([field], access_token)\\n        return info.get(field)',\n",
              " 'def user_getinfo(self, fields, access_token=None):\\n        \"\"\"\\n        Request multiple fields of information about the user.\\n\\n        :param fields: The names of the fields requested.\\n        :type fields: list\\n        :returns: The values of the current user for the fields requested.\\n            The keys are the field names, values are the values of the\\n            fields as indicated by the OpenID Provider. Note that fields\\n            that were not provided by the Provider are absent.\\n        :rtype: dict\\n        :raises Exception: If the user was not authenticated. Check this with\\n            user_loggedin.\\n\\n        .. versionadded:: 1.0\\n        \"\"\"\\n        if g.oidc_id_token is None and access_token is None:\\n            raise Exception(\\'User was not authenticated\\')\\n        info = {}\\n        all_info = None\\n        for field in fields:\\n            if access_token is None and field in g.oidc_id_token:\\n                info[field] = g.oidc_id_token[field]\\n            elif current_app.config[\\'OIDC_USER_INFO_ENABLED\\']:\\n                # This was not in the id_token. Let\\'s get user information\\n                if all_info is None:\\n                    all_info = self._retrieve_userinfo(access_token)\\n                    if all_info is None:\\n                        # To make sure we don\\'t retry for every field\\n                        all_info = {}\\n                if field in all_info:\\n                    info[field] = all_info[field]\\n                else:\\n                    # We didn\\'t get this information\\n                    pass\\n        return info',\n",
              " 'def get_access_token(self):\\n        \"\"\"Method to return the current requests\\' access_token.\\n\\n        :returns: Access token or None\\n        :rtype: str\\n\\n        .. versionadded:: 1.2\\n        \"\"\"\\n        try:\\n            credentials = OAuth2Credentials.from_json(\\n                self.credentials_store[g.oidc_id_token[\\'sub\\']])\\n            return credentials.access_token\\n        except KeyError:\\n            logger.debug(\"Expired ID token, credentials missing\",\\n                         exc_info=True)\\n            return None',\n",
              " 'def get_refresh_token(self):\\n        \"\"\"Method to return the current requests\\' refresh_token.\\n\\n        :returns: Access token or None\\n        :rtype: str\\n\\n        .. versionadded:: 1.2\\n        \"\"\"\\n        try:\\n            credentials = OAuth2Credentials.from_json(\\n                self.credentials_store[g.oidc_id_token[\\'sub\\']])\\n            return credentials.refresh_token\\n        except KeyError:\\n            logger.debug(\"Expired ID token, credentials missing\",\\n                         exc_info=True)\\n            return None',\n",
              " 'def _retrieve_userinfo(self, access_token=None):\\n        \"\"\"\\n        Requests extra user information from the Provider\\'s UserInfo and\\n        returns the result.\\n\\n        :returns: The contents of the UserInfo endpoint.\\n        :rtype: dict\\n        \"\"\"\\n        if \\'userinfo_uri\\' not in self.client_secrets:\\n            logger.debug(\\'Userinfo uri not specified\\')\\n            raise AssertionError(\\'UserInfo URI not specified\\')\\n\\n        # Cache the info from this request\\n        if \\'_oidc_userinfo\\' in g:\\n            return g._oidc_userinfo\\n\\n        http = httplib2.Http()\\n        if access_token is None:\\n            try:\\n                credentials = OAuth2Credentials.from_json(\\n                    self.credentials_store[g.oidc_id_token[\\'sub\\']])\\n            except KeyError:\\n                logger.debug(\"Expired ID token, credentials missing\",\\n                             exc_info=True)\\n                return None\\n            credentials.authorize(http)\\n            resp, content = http.request(self.client_secrets[\\'userinfo_uri\\'])\\n        else:\\n            # We have been manually overriden with an access token\\n            resp, content = http.request(\\n                self.client_secrets[\\'userinfo_uri\\'],\\n                \"POST\",\\n                body=urlencode({\"access_token\": access_token}),\\n                headers={\\'Content-Type\\': \\'application/x-www-form-urlencoded\\'})\\n\\n        logger.debug(\\'Retrieved user info: %s\\' % content)\\n        info = _json_loads(content)\\n\\n        g._oidc_userinfo = info\\n\\n        return info',\n",
              " 'def _after_request(self, response):\\n        \"\"\"\\n        Set a new ID token cookie if the ID token has changed.\\n        \"\"\"\\n        # This means that if either the new or the old are False, we set\\n        # insecure cookies.\\n        # We don\\'t define OIDC_ID_TOKEN_COOKIE_SECURE in init_app, because we\\n        # don\\'t want people to find it easily.\\n        cookie_secure = (current_app.config[\\'OIDC_COOKIE_SECURE\\'] and\\n                         current_app.config.get(\\'OIDC_ID_TOKEN_COOKIE_SECURE\\',\\n                                                True))\\n\\n        if getattr(g, \\'oidc_id_token_dirty\\', False):\\n            if g.oidc_id_token:\\n                signed_id_token = self.cookie_serializer.dumps(g.oidc_id_token)\\n                response.set_cookie(\\n                    current_app.config[\\'OIDC_ID_TOKEN_COOKIE_NAME\\'],\\n                    signed_id_token,\\n                    secure=cookie_secure,\\n                    httponly=True,\\n                    max_age=current_app.config[\\'OIDC_ID_TOKEN_COOKIE_TTL\\'])\\n            else:\\n                # This was a log out\\n                response.set_cookie(\\n                    current_app.config[\\'OIDC_ID_TOKEN_COOKIE_NAME\\'],\\n                    \\'\\',\\n                    path=current_app.config[\\'OIDC_ID_TOKEN_COOKIE_PATH\\'],\\n                    secure=cookie_secure,\\n                    httponly=True,\\n                    expires=0)\\n        return response',\n",
              " 'def authenticate_or_redirect(self):\\n        \"\"\"\\n        Helper function suitable for @app.before_request and @check.\\n        Sets g.oidc_id_token to the ID token if the user has successfully\\n        authenticated, else returns a redirect object so they can go try\\n        to authenticate.\\n\\n        :returns: A redirect object, or None if the user is logged in.\\n        :rtype: Redirect\\n\\n        .. deprecated:: 1.0\\n           Use :func:`require_login` instead.\\n        \"\"\"\\n        # the auth callback and error pages don\\'t need user to be authenticated\\n        if request.endpoint in frozenset([\\'_oidc_callback\\', \\'_oidc_error\\']):\\n            return None\\n\\n        # retrieve signed ID token cookie\\n        id_token = self._get_cookie_id_token()\\n        if id_token is None:\\n            return self.redirect_to_auth_server(request.url)\\n\\n        # ID token expired\\n        # when Google is the IdP, this happens after one hour\\n        if time.time() >= id_token[\\'exp\\']:\\n            # get credentials from store\\n            try:\\n                credentials = OAuth2Credentials.from_json(\\n                    self.credentials_store[id_token[\\'sub\\']])\\n            except KeyError:\\n                logger.debug(\"Expired ID token, credentials missing\",\\n                             exc_info=True)\\n                return self.redirect_to_auth_server(request.url)\\n\\n            # refresh and store credentials\\n            try:\\n                credentials.refresh(httplib2.Http())\\n                if credentials.id_token:\\n                    id_token = credentials.id_token\\n                else:\\n                    # It is not guaranteed that we will get a new ID Token on\\n                    # refresh, so if we do not, let\\'s just update the id token\\n                    # expiry field and reuse the existing ID Token.\\n                    if credentials.token_expiry is None:\\n                        logger.debug(\\'Expired ID token, no new expiry. Falling\\'\\n                                     \\' back to assuming 1 hour\\')\\n                        id_token[\\'exp\\'] = time.time() + 3600\\n                    else:\\n                        id_token[\\'exp\\'] = calendar.timegm(\\n                            credentials.token_expiry.timetuple())\\n                self.credentials_store[id_token[\\'sub\\']] = credentials.to_json()\\n                self._set_cookie_id_token(id_token)\\n            except AccessTokenRefreshError:\\n                # Can\\'t refresh. Wipe credentials and redirect user to IdP\\n                # for re-authentication.\\n                logger.debug(\"Expired ID token, can\\'t refresh credentials\",\\n                             exc_info=True)\\n                del self.credentials_store[id_token[\\'sub\\']]\\n                return self.redirect_to_auth_server(request.url)\\n\\n        # make ID token available to views\\n        g.oidc_id_token = id_token\\n\\n        return None',\n",
              " 'def require_login(self, view_func):\\n        \"\"\"\\n        Use this to decorate view functions that require a user to be logged\\n        in. If the user is not already logged in, they will be sent to the\\n        Provider to log in, after which they will be returned.\\n\\n        .. versionadded:: 1.0\\n           This was :func:`check` before.\\n        \"\"\"\\n        @wraps(view_func)\\n        def decorated(*args, **kwargs):\\n            if g.oidc_id_token is None:\\n                return self.redirect_to_auth_server(request.url)\\n            return view_func(*args, **kwargs)\\n        return decorated',\n",
              " 'def require_keycloak_role(self, client, role):\\n        \"\"\"\\n        Function to check for a KeyCloak client role in JWT access token.\\n\\n        This is intended to be replaced with a more generic \\'require this value\\n        in token or claims\\' system, at which point backwards compatibility will\\n        be added.\\n\\n        .. versionadded:: 1.5.0\\n        \"\"\"\\n        def wrapper(view_func):\\n            @wraps(view_func)\\n            def decorated(*args, **kwargs):\\n                pre, tkn, post = self.get_access_token().split(\\'.\\')\\n                access_token = json.loads(b64decode(tkn))\\n                if role in access_token[\\'resource_access\\'][client][\\'roles\\']:\\n                    return view_func(*args, **kwargs)\\n                else:\\n                    return abort(403)\\n            return decorated\\n        return wrapper',\n",
              " 'def _flow_for_request(self):\\n        \"\"\"\\n        Build a flow with the correct absolute callback URL for this request.\\n        :return:\\n        \"\"\"\\n        flow = copy(self.flow)\\n        redirect_uri = current_app.config[\\'OVERWRITE_REDIRECT_URI\\']\\n        if not redirect_uri:\\n            flow.redirect_uri = url_for(\\'_oidc_callback\\', _external=True)\\n        else:\\n            flow.redirect_uri = redirect_uri\\n        return flow',\n",
              " 'def redirect_to_auth_server(self, destination=None, customstate=None):\\n        \"\"\"\\n        Set a CSRF token in the session, and redirect to the IdP.\\n\\n        :param destination: The page that the user was going to,\\n            before we noticed they weren\\'t logged in.\\n        :type destination: Url to return the client to if a custom handler is\\n            not used. Not available with custom callback.\\n        :param customstate: The custom data passed via the ODIC state.\\n            Note that this only works with a custom_callback, and this will\\n            ignore destination.\\n        :type customstate: Anything that can be serialized\\n        :returns: A redirect response to start the login process.\\n        :rtype: Flask Response\\n\\n        .. deprecated:: 1.0\\n           Use :func:`require_login` instead.\\n        \"\"\"\\n        if not self._custom_callback and customstate:\\n            raise ValueError(\\'Custom State is only avilable with a custom \\'\\n                             \\'handler\\')\\n        if \\'oidc_csrf_token\\' not in session:\\n            csrf_token = urlsafe_b64encode(os.urandom(24)).decode(\\'utf-8\\')\\n            session[\\'oidc_csrf_token\\'] = csrf_token\\n        state = {\\n            \\'csrf_token\\': session[\\'oidc_csrf_token\\'],\\n        }\\n        statefield = \\'destination\\'\\n        statevalue = destination\\n        if customstate is not None:\\n            statefield = \\'custom\\'\\n            statevalue = customstate\\n        state[statefield] = self.extra_data_serializer.dumps(\\n            statevalue).decode(\\'utf-8\\')\\n\\n        extra_params = {\\n            \\'state\\': urlsafe_b64encode(json.dumps(state).encode(\\'utf-8\\')),\\n        }\\n        extra_params.update(current_app.config[\\'OIDC_EXTRA_REQUEST_AUTH_PARAMS\\'])\\n        if current_app.config[\\'OIDC_GOOGLE_APPS_DOMAIN\\']:\\n            extra_params[\\'hd\\'] = current_app.config[\\'OIDC_GOOGLE_APPS_DOMAIN\\']\\n        if current_app.config[\\'OIDC_OPENID_REALM\\']:\\n            extra_params[\\'openid.realm\\'] = current_app.config[\\n                \\'OIDC_OPENID_REALM\\']\\n\\n        flow = self._flow_for_request()\\n        auth_url = \\'{url}&{extra_params}\\'.format(\\n            url=flow.step1_get_authorize_url(),\\n            extra_params=urlencode(extra_params))\\n        # if the user has an ID token, it\\'s invalid, or we wouldn\\'t be here\\n        self._set_cookie_id_token(None)\\n        return redirect(auth_url)',\n",
              " 'def _is_id_token_valid(self, id_token):\\n        \"\"\"\\n        Check if `id_token` is a current ID token for this application,\\n        was issued by the Apps domain we expected,\\n        and that the email address has been verified.\\n\\n        @see: http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation\\n        \"\"\"\\n        if not id_token:\\n            return False\\n\\n        # step 2: check issuer\\n        if id_token[\\'iss\\'] not in current_app.config[\\'OIDC_VALID_ISSUERS\\']:\\n            logger.error(\\'id_token issued by non-trusted issuer: %s\\'\\n                         % id_token[\\'iss\\'])\\n            return False\\n\\n        if isinstance(id_token[\\'aud\\'], list):\\n            # step 3 for audience list\\n            if self.flow.client_id not in id_token[\\'aud\\']:\\n                logger.error(\\'We are not a valid audience\\')\\n                return False\\n            # step 4\\n            if \\'azp\\' not in id_token and len(id_token[\\'aud\\']) > 1:\\n                logger.error(\\'Multiple audiences and not authorized party\\')\\n                return False\\n        else:\\n            # step 3 for single audience\\n            if id_token[\\'aud\\'] != self.flow.client_id:\\n                logger.error(\\'We are not the audience\\')\\n                return False\\n\\n        # step 5\\n        if \\'azp\\' in id_token and id_token[\\'azp\\'] != self.flow.client_id:\\n            logger.error(\\'Authorized Party is not us\\')\\n            return False\\n\\n        # step 6-8: TLS checked\\n\\n        # step 9: check exp\\n        if int(time.time()) >= int(id_token[\\'exp\\']):\\n            logger.error(\\'Token has expired\\')\\n            return False\\n\\n        # step 10: check iat\\n        if id_token[\\'iat\\'] < (time.time() -\\n                              current_app.config[\\'OIDC_CLOCK_SKEW\\']):\\n            logger.error(\\'Token issued in the past\\')\\n            return False\\n\\n        # (not required if using HTTPS?) step 11: check nonce\\n\\n        # step 12-13: not requested acr or auth_time, so not needed to test\\n\\n        # additional steps specific to our usage\\n        if current_app.config[\\'OIDC_GOOGLE_APPS_DOMAIN\\'] and \\\\\\n                id_token.get(\\'hd\\') != current_app.config[\\n                    \\'OIDC_GOOGLE_APPS_DOMAIN\\']:\\n            logger.error(\\'Invalid google apps domain\\')\\n            return False\\n\\n        if not id_token.get(\\'email_verified\\', False) and \\\\\\n                current_app.config[\\'OIDC_REQUIRE_VERIFIED_EMAIL\\']:\\n            logger.error(\\'Email not verified\\')\\n            return False\\n\\n        return True',\n",
              " 'def custom_callback(self, view_func):\\n        \"\"\"\\n        Wrapper function to use a custom callback.\\n        The custom OIDC callback will get the custom state field passed in with\\n        redirect_to_auth_server.\\n        \"\"\"\\n        @wraps(view_func)\\n        def decorated(*args, **kwargs):\\n            plainreturn, data = self._process_callback(\\'custom\\')\\n            if plainreturn:\\n                return data\\n            else:\\n                return view_func(data, *args, **kwargs)\\n        self._custom_callback = decorated\\n        return decorated',\n",
              " 'def _process_callback(self, statefield):\\n        \"\"\"\\n        Exchange the auth code for actual credentials,\\n        then redirect to the originally requested page.\\n        \"\"\"\\n        # retrieve session and callback variables\\n        try:\\n            session_csrf_token = session.get(\\'oidc_csrf_token\\')\\n\\n            state = _json_loads(urlsafe_b64decode(request.args[\\'state\\'].encode(\\'utf-8\\')))\\n            csrf_token = state[\\'csrf_token\\']\\n\\n            code = request.args[\\'code\\']\\n        except (KeyError, ValueError):\\n            logger.debug(\"Can\\'t retrieve CSRF token, state, or code\",\\n                         exc_info=True)\\n            return True, self._oidc_error()\\n\\n        # check callback CSRF token passed to IdP\\n        # against session CSRF token held by user\\n        if csrf_token != session_csrf_token:\\n            logger.debug(\"CSRF token mismatch\")\\n            return True, self._oidc_error()\\n\\n        # make a request to IdP to exchange the auth code for OAuth credentials\\n        flow = self._flow_for_request()\\n        credentials = flow.step2_exchange(code)\\n        id_token = credentials.id_token\\n        if not self._is_id_token_valid(id_token):\\n            logger.debug(\"Invalid ID token\")\\n            if id_token.get(\\'hd\\') != current_app.config[\\n                    \\'OIDC_GOOGLE_APPS_DOMAIN\\']:\\n                return True, self._oidc_error(\\n                    \"You must log in with an account from the {0} domain.\"\\n                    .format(current_app.config[\\'OIDC_GOOGLE_APPS_DOMAIN\\']),\\n                    self.WRONG_GOOGLE_APPS_DOMAIN)\\n            return True, self._oidc_error()\\n\\n        # store credentials by subject\\n        # when Google is the IdP, the subject is their G+ account number\\n        self.credentials_store[id_token[\\'sub\\']] = credentials.to_json()\\n\\n        # Retrieve the extra statefield data\\n        try:\\n            response = self.extra_data_serializer.loads(state[statefield])\\n        except BadSignature:\\n            logger.error(\\'State field was invalid\\')\\n            return True, self._oidc_error()\\n\\n        # set a persistent signed cookie containing the ID token\\n        # and redirect to the final destination\\n        self._set_cookie_id_token(id_token)\\n        return False, response',\n",
              " 'def validate_token(self, token, scopes_required=None):\\n        \"\"\"\\n        This function can be used to validate tokens.\\n\\n        Note that this only works if a token introspection url is configured,\\n        as that URL will be queried for the validity and scopes of a token.\\n\\n        :param scopes_required: List of scopes that are required to be\\n            granted by the token before returning True.\\n        :type scopes_required: list\\n\\n        :returns: True if the token was valid and contained the required\\n            scopes. An ErrStr (subclass of string for which bool() is False) if\\n            an error occured.\\n        :rtype: Boolean or String\\n\\n        .. versionadded:: 1.1\\n        \"\"\"\\n        valid = self._validate_token(token, scopes_required)\\n        if valid is True:\\n            return True\\n        else:\\n            return ErrStr(valid)',\n",
              " 'def _validate_token(self, token, scopes_required=None):\\n        \"\"\"The actual implementation of validate_token.\"\"\"\\n        if scopes_required is None:\\n            scopes_required = []\\n        scopes_required = set(scopes_required)\\n\\n        token_info = None\\n        valid_token = False\\n        has_required_scopes = False\\n        if token:\\n            try:\\n                token_info = self._get_token_info(token)\\n            except Exception as ex:\\n                token_info = {\\'active\\': False}\\n                logger.error(\\'ERROR: Unable to get token info\\')\\n                logger.error(str(ex))\\n\\n            valid_token = token_info.get(\\'active\\', False)\\n\\n            if \\'aud\\' in token_info and \\\\\\n                    current_app.config[\\'OIDC_RESOURCE_CHECK_AUD\\']:\\n                valid_audience = False\\n                aud = token_info[\\'aud\\']\\n                clid = self.client_secrets[\\'client_id\\']\\n                if isinstance(aud, list):\\n                    valid_audience = clid in aud\\n                else:\\n                    valid_audience = clid == aud\\n\\n                if not valid_audience:\\n                    logger.error(\\'Refused token because of invalid \\'\\n                                 \\'audience\\')\\n                    valid_token = False\\n\\n            if valid_token:\\n                token_scopes = token_info.get(\\'scope\\', \\'\\').split(\\' \\')\\n            else:\\n                token_scopes = []\\n            has_required_scopes = scopes_required.issubset(\\n                set(token_scopes))\\n\\n            if not has_required_scopes:\\n                logger.debug(\\'Token missed required scopes\\')\\n\\n        if (valid_token and has_required_scopes):\\n            g.oidc_token_info = token_info\\n            return True\\n\\n        if not valid_token:\\n            return \\'Token required but invalid\\'\\n        elif not has_required_scopes:\\n            return \\'Token does not have required scopes\\'\\n        else:\\n            return \\'Something went wrong checking your token\\'',\n",
              " 'def accept_token(self, require_token=False, scopes_required=None,\\n                           render_errors=True):\\n        \"\"\"\\n        Use this to decorate view functions that should accept OAuth2 tokens,\\n        this will most likely apply to API functions.\\n\\n        Tokens are accepted as part of the query URL (access_token value) or\\n        a POST form value (access_token).\\n\\n        Note that this only works if a token introspection url is configured,\\n        as that URL will be queried for the validity and scopes of a token.\\n\\n        :param require_token: Whether a token is required for the current\\n            function. If this is True, we will abort the request if there\\n            was no token provided.\\n        :type require_token: bool\\n        :param scopes_required: List of scopes that are required to be\\n            granted by the token before being allowed to call the protected\\n            function.\\n        :type scopes_required: list\\n        :param render_errors: Whether or not to eagerly render error objects\\n            as JSON API responses. Set to False to pass the error object back\\n            unmodified for later rendering.\\n        :type render_errors: callback(obj) or None\\n\\n        .. versionadded:: 1.0\\n        \"\"\"\\n\\n        def wrapper(view_func):\\n            @wraps(view_func)\\n            def decorated(*args, **kwargs):\\n                token = None\\n                if \\'Authorization\\' in request.headers and request.headers[\\'Authorization\\'].startswith(\\'Bearer \\'):\\n                    token = request.headers[\\'Authorization\\'].split(None,1)[1].strip()\\n                if \\'access_token\\' in request.form:\\n                    token = request.form[\\'access_token\\']\\n                elif \\'access_token\\' in request.args:\\n                    token = request.args[\\'access_token\\']\\n\\n                validity = self.validate_token(token, scopes_required)\\n                if (validity is True) or (not require_token):\\n                    return view_func(*args, **kwargs)\\n                else:\\n                    response_body = {\\'error\\': \\'invalid_token\\',\\n                                     \\'error_description\\': validity}\\n                    if render_errors:\\n                        response_body = json.dumps(response_body)\\n                    return response_body, 401, {\\'WWW-Authenticate\\': \\'Bearer\\'}\\n\\n            return decorated\\n        return wrapper',\n",
              " 'def delete_rows_csr(mat, indices):\\n    \"\"\"\\n    Remove the rows denoted by ``indices`` form the CSR sparse matrix ``mat``.\\n    \"\"\"\\n    if not isinstance(mat, scipy.sparse.csr_matrix):\\n        raise ValueError(\"works only for CSR format -- use .tocsr() first\")\\n    indices = list(indices)\\n    mask = np.ones(mat.shape[0], dtype=bool)\\n    mask[indices] = False\\n    return mat[mask]',\n",
              " \"def strip_non_ascii(string):\\n    ''' Returns the string without non ASCII characters'''\\n    stripped = (c for c in string if 0 < ord(c) < 127)\\n    return ''.join(stripped)\",\n",
              " 'def restrict(self, support):\\n        \"\"\"Restrict the features to those in support using feature selection.\\n\\n        This function modifies the estimator in-place.\\n\\n        \"\"\"\\n        if self.has_been_restricted == True:\\n            return self\\n\\n        new_numerical_cols = []\\n        new_categorical_cols = []\\n        new_additional_numerical_cols = []\\n        new_feature_names = []\\n        new_vocab = {}\\n\\n        for idx, val in enumerate(support):\\n            if val == True:\\n                feature_name = self.feature_names_[idx]\\n                if self.separator in feature_name:\\n                    base_feature_name = feature_name[:feature_name.rfind(self.separator)]\\n                else:\\n                    base_feature_name = feature_name\\n                new_feature_names.append(feature_name)\\n                new_vocab[feature_name] = len(new_vocab)\\n                if feature_name in self.numerical_columns:\\n                    new_numerical_cols.append(feature_name)\\n                elif base_feature_name in self.categorical_columns and base_feature_name not in new_categorical_cols:\\n                    new_categorical_cols.append(base_feature_name)\\n                elif feature_name in self.additional_numerical_cols:\\n                    new_additional_numerical_cols.append(feature_name)\\n\\n        self.feature_names_ = new_feature_names\\n        self.vocabulary_ = new_vocab\\n        self.numerical_columns = new_numerical_cols\\n        self.categorical_columns = new_categorical_cols\\n        self.additional_numerical_cols = new_additional_numerical_cols\\n\\n        self.has_been_restricted = True\\n        return self',\n",
              " 'def agents(self):\\n        \"\"\"\\n        |  Description: IDs of agents involved in the chat\\n        \"\"\"\\n        if self.api and self.agent_ids:\\n            return self.api._get_agents(self.agent_ids)',\n",
              " 'def department(self):\\n        \"\"\"\\n        |  Description: The ID of the department to which the chat is directed\\n        \"\"\"\\n        if self.api and self.department_id:\\n            return self.api._get_department(self.department_id)',\n",
              " 'def zendesk_ticket(self):\\n        \"\"\"\\n        |  Description: The ID of the Zendesk Support ticket created from this chat. Available only if using version 2 of the Zendesk Chat-Support integration\\n        \"\"\"\\n        if self.api and self.zendesk_ticket_id:\\n            return self.api._get_zendesk_ticket(self.zendesk_ticket_id)',\n",
              " 'def check_type(self, zenpy_objects):\\n        \"\"\" Ensure the passed type matches this API\\'s object_type. \"\"\"\\n        expected_type = self.api._object_mapping.class_for_type(self.api.object_type)\\n        if not isinstance(zenpy_objects, collections.Iterable):\\n            zenpy_objects = [zenpy_objects]\\n        for zenpy_object in zenpy_objects:\\n            if type(zenpy_object) is not expected_type:\\n                raise ZenpyException(\\n                    \"Invalid type - expected {} found {}\".format(expected_type, type(zenpy_object))\\n                )',\n",
              " 'def to_snake_case(name):\\n    \"\"\" Given a name in camelCase return in snake_case \"\"\"\\n    s1 = FIRST_CAP_REGEX.sub(r\\'\\\\1_\\\\2\\', name)\\n    return ALL_CAP_REGEX.sub(r\\'\\\\1_\\\\2\\', s1).lower()',\n",
              " 'def to_unix_ts(start_time):\\n    \"\"\"Given a datetime object, returns its value as a unix timestamp\"\"\"\\n    if isinstance(start_time, datetime):\\n        if is_timezone_aware(start_time):\\n            start_time = start_time.astimezone(pytz.utc)\\n        else:\\n            log.warning(\\n                \"Non timezone-aware datetime object passed to IncrementalEndpoint. \"\\n                \"The Zendesk API expects UTC time, if this is not the case results will be incorrect!\"\\n            )\\n        unix_time = calendar.timegm(start_time.timetuple())\\n    else:\\n        unix_time = start_time\\n\\n    return int(unix_time)',\n",
              " 'def is_iterable_but_not_string(obj):\\n    \"\"\"\\n    Determine whether or not obj is iterable but not a string (eg, a list, set, tuple etc).\\n    \"\"\"\\n    return hasattr(obj, \\'__iter__\\') and not isinstance(obj, str) and not isinstance(obj, bytes)',\n",
              " 'def as_singular(result_key):\\n    \"\"\"\\n    Given a result key, return in the singular form\\n    \"\"\"\\n    if result_key.endswith(\\'ies\\'):\\n        return re.sub(\\'ies$\\', \\'y\\', result_key)\\n    elif result_key.endswith(\\'uses\\'):\\n        return re.sub(\"uses$\", \"us\", result_key)\\n    elif result_key.endswith(\\'addresses\\'):  # Special case for \\'*addresses\\'\\n        return result_key[:-2]\\n    elif result_key.endswith(\\'s\\'):\\n        return result_key[:-1]\\n    else:\\n        return result_key',\n",
              " 'def as_plural(result_key):\\n    \"\"\"\\n    Given a result key, return in the plural form.\\n    \"\"\"\\n    # Not at all guaranteed to work in all cases...\\n    if result_key.endswith(\\'y\\'):\\n        return re.sub(\"y$\", \"ies\", result_key)\\n    elif result_key.endswith(\\'address\\'):\\n        return result_key + \\'es\\'\\n    elif result_key.endswith(\\'us\\'):\\n        return re.sub(\"us$\", \"uses\", result_key)\\n    elif not result_key.endswith(\\'s\\'):\\n        return result_key + \\'s\\'\\n    else:\\n        return result_key',\n",
              " 'def extract_id(*object_types):\\n    \"\"\"\\n    Decorator for extracting id from passed parameters for specific types.\\n    \"\"\"\\n\\n    def outer(func):\\n        def inner(*args, **kwargs):\\n            def id_of(x):\\n                return x.id if type(x) in object_types else x\\n\\n            new_args = [id_of(arg) for arg in args]\\n            new_kwargs = {k: id_of(v) for k, v in kwargs.items()}\\n            return func(*new_args, **new_kwargs)\\n\\n        return inner\\n\\n    return outer',\n",
              " 'def json_encode(obj, serialize):\\n    \"\"\" Handle encoding complex types. \"\"\"\\n    if hasattr(obj, \\'to_dict\\'):\\n        return obj.to_dict(serialize=serialize)\\n    elif isinstance(obj, datetime):\\n        return obj.date().isoformat()\\n    elif isinstance(obj, date):\\n        return obj.isoformat()\\n    elif isinstance(obj, ProxyDict):\\n        return dict(obj)\\n    elif isinstance(obj, ProxyList):\\n        return list(obj)\\n    elif is_iterable_but_not_string(obj):\\n        return list(obj)',\n",
              " 'def _call_api(self, http_method, url, **kwargs):\\n        \"\"\"\\n        Execute a call to the Zendesk API. Handles rate limiting, checking the response\\n        from Zendesk and deserialization of the Zendesk response. All\\n        communication with Zendesk should go through this method.\\n\\n        :param http_method: The requests method to call (eg post, put, get).\\n        :param url: The url to pass to to the requests method.\\n        :param kwargs: Any additional kwargs to pass on to requests.\\n        \"\"\"\\n        log.debug(\"{}: {} - {}\".format(http_method.__name__.upper(), url, kwargs))\\n        if self.ratelimit is not None:\\n            # This path indicates we\\'re taking a proactive approach to not hit the rate limit\\n            response = self._ratelimit(http_method=http_method, url=url, **kwargs)\\n        else:\\n            response = http_method(url, **kwargs)\\n\\n        # If we are being rate-limited, wait the required period before trying again.\\n        if response.status_code == 429:\\n            while \\'retry-after\\' in response.headers and int(response.headers[\\'retry-after\\']) > 0:\\n                retry_after_seconds = int(response.headers[\\'retry-after\\'])\\n                log.warning(\\n                    \"Waiting for requested retry-after period: %s seconds\" % retry_after_seconds\\n                )\\n                while retry_after_seconds > 0:\\n                    retry_after_seconds -= 1\\n                    self.check_ratelimit_budget(1)\\n                    log.debug(\"    -> sleeping: %s more seconds\" % retry_after_seconds)\\n                    sleep(1)\\n                response = http_method(url, **kwargs)\\n\\n        self._check_response(response)\\n        self._update_callsafety(response)\\n        return response',\n",
              " 'def check_ratelimit_budget(self, seconds_waited):\\n        \"\"\" If we have a ratelimit_budget, ensure it is not exceeded. \"\"\"\\n        if self.ratelimit_budget is not None:\\n            self.ratelimit_budget -= seconds_waited\\n            if self.ratelimit_budget < 1:\\n                raise RatelimitBudgetExceeded(\"Rate limit budget exceeded!\")',\n",
              " 'def _ratelimit(self, http_method, url, **kwargs):\\n        \"\"\" Ensure we do not hit the rate limit. \"\"\"\\n\\n        def time_since_last_call():\\n            if self.callsafety[\\'lastcalltime\\'] is not None:\\n                return int(time() - self.callsafety[\\'lastcalltime\\'])\\n            else:\\n                return None\\n\\n        lastlimitremaining = self.callsafety[\\'lastlimitremaining\\']\\n\\n        if time_since_last_call() is None or time_since_last_call() >= self.ratelimit_request_interval or \\\\\\n                lastlimitremaining >= self.ratelimit:\\n            response = http_method(url, **kwargs)\\n        else:\\n            # We hit our limit floor and aren\\'t quite at ratelimit_request_interval value in seconds yet..\\n            log.warning(\\n                \"Safety Limit Reached of %s remaining calls and time since last call is under %s seconds\"\\n                % (self.ratelimit, self.ratelimit_request_interval)\\n            )\\n            while time_since_last_call() < self.ratelimit_request_interval:\\n                remaining_sleep = int(self.ratelimit_request_interval - time_since_last_call())\\n                log.debug(\"  -> sleeping: %s more seconds\" % remaining_sleep)\\n                self.check_ratelimit_budget(1)\\n                sleep(1)\\n            response = http_method(url, **kwargs)\\n\\n        self.callsafety[\\'lastcalltime\\'] = time()\\n        self.callsafety[\\'lastlimitremaining\\'] = int(response.headers.get(\\'X-Rate-Limit-Remaining\\', 0))\\n        return response',\n",
              " 'def _update_callsafety(self, response):\\n        \"\"\" Update the callsafety data structure \"\"\"\\n        if self.ratelimit is not None:\\n            self.callsafety[\\'lastcalltime\\'] = time()\\n            self.callsafety[\\'lastlimitremaining\\'] = int(response.headers.get(\\'X-Rate-Limit-Remaining\\', 0))',\n",
              " 'def _process_response(self, response, object_mapping=None):\\n        \"\"\"\\n        Attempt to find a ResponseHandler that knows how to process this response.\\n        If no handler can be found, raise an Exception.\\n        \"\"\"\\n        try:\\n            pretty_response = response.json()\\n        except ValueError:\\n            pretty_response = response\\n        for handler in self._response_handlers:\\n            if handler.applies_to(self, response):\\n                log.debug(\"{} matched: {}\".format(handler.__name__, pretty_response))\\n                r = handler(self, object_mapping).build(response)\\n                self._clean_dirty_objects()\\n                return r\\n        raise ZenpyException(\"Could not handle response: {}\".format(pretty_response))',\n",
              " 'def _clean_dirty_objects(self):\\n        \"\"\"\\n        Clear all dirty attributes for the last object or list of objects successfully submitted to Zendesk.\\n        \"\"\"\\n        if self._dirty_object is None:\\n            return\\n        if not is_iterable_but_not_string(self._dirty_object):\\n            self._dirty_object = [self._dirty_object]\\n\\n        log.debug(\"Cleaning objects: {}\".format(self._dirty_object))\\n        for o in self._dirty_object:\\n            if isinstance(o, BaseObject):\\n                o._clean_dirty()\\n        self._dirty_object = None',\n",
              " 'def _serialize(self, zenpy_object):\\n        \"\"\" Serialize a Zenpy object to JSON \"\"\"\\n        # If it\\'s a dict this object has already been serialized.\\n        if not type(zenpy_object) == dict:\\n            log.debug(\"Setting dirty object: {}\".format(zenpy_object))\\n            self._dirty_object = zenpy_object\\n        return json.loads(json.dumps(zenpy_object, default=json_encode_for_zendesk))',\n",
              " 'def _query_zendesk(self, endpoint, object_type, *endpoint_args, **endpoint_kwargs):\\n        \"\"\"\\n        Query Zendesk for items. If an id or list of ids are passed, attempt to locate these items\\n         in the relevant cache. If they cannot be found, or no ids are passed, execute a call to Zendesk\\n         to retrieve the items.\\n\\n        :param endpoint: target endpoint.\\n        :param object_type: object type we are expecting.\\n        :param endpoint_args: args for endpoint\\n        :param endpoint_kwargs: kwargs for endpoint\\n\\n        :return: either a ResultGenerator or a Zenpy object.\\n        \"\"\"\\n\\n        _id = endpoint_kwargs.get(\\'id\\', None)\\n        if _id:\\n            item = self.cache.get(object_type, _id)\\n            if item:\\n                return item\\n            else:\\n                return self._get(url=self._build_url(endpoint(*endpoint_args, **endpoint_kwargs)))\\n        elif \\'ids\\' in endpoint_kwargs:\\n            cached_objects = []\\n            # Check to see if we have all objects in the cache.\\n            # If we are missing even one we request them all again.\\n            # This could be optimized to only request the missing objects.\\n            for _id in endpoint_kwargs[\\'ids\\']:\\n                obj = self.cache.get(object_type, _id)\\n                if not obj:\\n                    return self._get(self._build_url(endpoint=endpoint(*endpoint_args, **endpoint_kwargs)))\\n                cached_objects.append(obj)\\n            return ZendeskResultGenerator(self, {}, response_objects=cached_objects, object_type=object_type)\\n        else:\\n            return self._get(self._build_url(endpoint=endpoint(*endpoint_args, **endpoint_kwargs)))',\n",
              " 'def _check_response(self, response):\\n        \"\"\"\\n        Check the response code returned by Zendesk. If it is outside the 200 range, raise an exception of the correct type.\\n\\n        :param response: requests Response object.\\n        \"\"\"\\n        if response.status_code > 299 or response.status_code < 200:\\n            log.debug(\"Received response code [%s] - headers: %s\" % (response.status_code, str(response.headers)))\\n            try:\\n                _json = response.json()\\n                err_type = _json.get(\"error\", \\'\\')\\n                if err_type == \\'RecordNotFound\\':\\n                    raise RecordNotFoundException(json.dumps(_json), response=response)\\n                elif err_type == \"TooManyValues\":\\n                    raise TooManyValuesException(json.dumps(_json), response=response)\\n                else:\\n                    raise APIException(json.dumps(_json), response=response)\\n            except ValueError:\\n                response.raise_for_status()',\n",
              " 'def _build_url(self, endpoint):\\n        \"\"\" Build complete URL \"\"\"\\n        if not issubclass(type(self), ChatApiBase) and not self.subdomain:\\n            raise ZenpyException(\"subdomain is required when accessing the Zendesk API!\")\\n\\n        if self.subdomain:\\n            endpoint.netloc = \\'{}.{}\\'.format(self.subdomain, self.domain)\\n        else:\\n            endpoint.netloc = self.domain\\n\\n        endpoint.prefix_path(self.api_prefix)\\n        return endpoint.build()',\n",
              " 'def update_by_external_id(self, api_objects):\\n        \"\"\"\\n        Update (PUT) one or more API objects by external_id.\\n\\n        :param api_objects:\\n        \"\"\"\\n        if not isinstance(api_objects, collections.Iterable):\\n            api_objects = [api_objects]\\n        return CRUDRequest(self).put(api_objects, update_many_external=True)',\n",
              " 'def delete_by_external_id(self, api_objects):\\n        \"\"\"\\n        Delete (DELETE) one or more API objects by external_id.\\n\\n        :param api_objects:\\n        \"\"\"\\n        if not isinstance(api_objects, collections.Iterable):\\n            api_objects = [api_objects]\\n        return CRUDRequest(self).delete(api_objects, destroy_many_external=True)',\n",
              " 'def tags(self, ticket_id):\\n        \"\"\"\\n        Lists the most popular recent tags in decreasing popularity from a specific ticket.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.tags, \\'tag\\', id=ticket_id)',\n",
              " 'def incremental(self, start_time, include=None):\\n        \"\"\"\\n        Retrieve bulk data from the incremental API.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param start_time: The time of the oldest object you are interested in.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.incremental, self.object_type, start_time=start_time, include=include)',\n",
              " 'def incremental(self, start_time, **kwargs):\\n        \"\"\"\\n        Retrieve bulk data from the chat incremental API.\\n\\n        :param fields: list of fields to retrieve. `Chat API Docs\\n            <https://developer.zendesk.com/rest_api/docs/chat/incremental_export#usage-notes-resource-expansion>`__.\\n        :param start_time: The time of the oldest object you are interested in.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.incremental, self.object_type, start_time=start_time, **kwargs)',\n",
              " 'def show(self, user, identity):\\n        \"\"\"\\n        Show the specified identity for the specified user.\\n\\n        :param user: user id or User object\\n        :param identity: identity id object\\n        :return: Identity\\n        \"\"\"\\n        url = self._build_url(self.endpoint.show(user, identity))\\n        return self._get(url)',\n",
              " 'def update(self, user, identity):\\n        \"\"\"\\n        Update specified identity for the specified user\\n\\n        :param user: User object or id\\n        :param identity: Identity object to be updated.\\n        :return: The updated Identity\\n        \"\"\"\\n        return UserIdentityRequest(self).put(self.endpoint.update, user, identity)',\n",
              " 'def make_primary(self, user, identity):\\n        \"\"\"\\n        Set the specified user as primary for the specified user.\\n\\n        :param user: User object or id\\n        :param identity: Identity object or id\\n        :return: list of user\\'s Identities\\n        \"\"\"\\n        return UserIdentityRequest(self).put(self.endpoint.make_primary, user, identity)',\n",
              " 'def request_verification(self, user, identity):\\n        \"\"\"\\n        Sends the user a verification email with a link to verify ownership of the email address.\\n\\n        :param user: User id or object\\n        :param identity: Identity id or object\\n        :return: requests Response object\\n        \"\"\"\\n        return UserIdentityRequest(self).put(self.endpoint.request_verification, user, identity)',\n",
              " 'def verify(self, user, identity):\\n        \"\"\"\\n        Verify an identity for a user\\n\\n        :param user: User id or object\\n        :param identity: Identity id or object\\n        :return: the verified Identity\\n        \"\"\"\\n        return UserIdentityRequest(self).put(self.endpoint.verify, user, identity)',\n",
              " 'def groups(self, user, include=None):\\n        \"\"\"\\n        Retrieve the groups for this user.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.groups, \\'group\\', id=user, include=include)',\n",
              " 'def organizations(self, user, include=None):\\n        \"\"\"\\n        Retrieve the organizations for this user.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.organizations, \\'organization\\', id=user, include=include)',\n",
              " 'def requested(self, user, include=None):\\n        \"\"\"\\n        Retrieve the requested tickets for this user.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.requested, \\'ticket\\', id=user, include=include)',\n",
              " 'def cced(self, user, include=None):\\n        \"\"\"\\n        Retrieve the tickets this user is cc\\'d into.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.cced, \\'ticket\\', id=user, include=include)',\n",
              " 'def assigned(self, user, include=None):\\n        \"\"\"\\n        Retrieve the assigned tickets for this user.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.assigned, \\'ticket\\', id=user, include=include)',\n",
              " 'def group_memberships(self, user, include=None):\\n        \"\"\"\\n        Retrieve the group memberships for this user.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.group_memberships, \\'group_membership\\', id=user, include=include)',\n",
              " 'def related(self, user):\\n        \"\"\"\\n        Returns the UserRelated information for the requested User\\n\\n        :param user: User object or id\\n        :return: UserRelated\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.related, \\'user_related\\', id=user)',\n",
              " 'def me(self, include=None):\\n        \"\"\"\\n        Return the logged in user\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading#abilities>`__.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.me, \\'user\\', include=include)',\n",
              " 'def user_fields(self, user):\\n        \"\"\"\\n        Retrieve the user fields for this user.\\n\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.user_fields, \\'user_field\\', id=user)',\n",
              " 'def organization_memberships(self, user):\\n        \"\"\"\\n        Retrieve the organization memberships for this user.\\n\\n        :param user: User object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.organization_memberships, \\'organization_membership\\', id=user)',\n",
              " 'def permanently_delete(self, user):\\n        \"\"\"\\n        Permanently delete user. User should be softly deleted first.\\n        Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/users#permanently-delete-user>`__.\\n\\n        Note: This endpoint does not support multiple ids or list of `User` objects.\\n\\n        :param user: User object or id.\\n        :return: User object with `permanently_deleted` status\\n        \"\"\"\\n        url = self._build_url(self.endpoint.deleted(id=user))\\n        deleted_user = self._delete(url)\\n        self.cache.delete(deleted_user)\\n        return deleted_user',\n",
              " 'def skips(self, user):\\n        \"\"\"\\n        Skips for user. Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/ticket_skips>`__.\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.skips(id=user)))',\n",
              " 'def set_password(self, user, password):\\n        \"\"\"\\n        Sets the password for the passed user.\\n        Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/support/users#set-a-users-password>`__.\\n\\n        :param user: User object or id\\n        :param password: new password\\n        \"\"\"\\n        url = self._build_url(self.endpoint.set_password(id=user))\\n        return self._post(url, payload=dict(password=password))',\n",
              " 'def upload(self, fp, token=None, target_name=None, content_type=None):\\n        \"\"\"\\n        Upload a file to Zendesk.\\n\\n        :param fp: file object, StringIO instance, content, or file path to be\\n                   uploaded\\n        :param token: upload token for uploading multiple files\\n        :param target_name: name of the file inside Zendesk\\n        :return: :class:`Upload` object containing a token and other information see\\n            Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/attachments#uploading-files>`__.\\n        \"\"\"\\n        return UploadRequest(self).post(fp, token=token, target_name=target_name, content_type=content_type)',\n",
              " 'def download(self, attachment_id, destination):\\n        \"\"\"\\n        Download an attachment from Zendesk.\\n\\n        :param attachment_id: id of the attachment to download\\n        :param destination: destination path. If a directory, the file will be placed in the directory with\\n                            the filename from the Attachment object.\\n        :return: the path the file was written to\\n        \"\"\"\\n        attachment = self(id=attachment_id)\\n        if os.path.isdir(destination):\\n            destination = os.path.join(destination, attachment.file_name)\\n        return self._download_file(attachment.content_url, destination)',\n",
              " 'def organization_fields(self, organization):\\n        \"\"\"\\n        Retrieve the organization fields for this organization.\\n\\n        :param organization: Organization object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.organization_fields, \\'organization_field\\', id=organization)',\n",
              " 'def organization_memberships(self, organization):\\n        \"\"\"\\n        Retrieve tche organization fields for this organization.\\n\\n        :param organization: Organization object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.organization_memberships, \\'organization_membership\\', id=organization)',\n",
              " 'def external(self, external_id, include=None):\\n        \"\"\"\\n        Locate an Organization by it\\'s external_id attribute.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param external_id: external id of organization\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.external, \\'organization\\', id=external_id, include=include)',\n",
              " 'def apply(self, macro):\\n        \"\"\"\\n        Show what a macro would do\\n        Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/macros#show-changes-to-ticket>`__.\\n\\n        :param macro: Macro object or id.\\n        \"\"\"\\n\\n        return self._query_zendesk(self.endpoint.apply, \\'result\\', id=macro)',\n",
              " 'def organizations(self, organization, include=None):\\n        \"\"\"\\n        Retrieve the tickets for this organization.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs\\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param organization: Organization object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.organizations, \\'ticket\\', id=organization, include=include)',\n",
              " 'def recent(self, include=None):\\n        \"\"\"\\n        Retrieve the most recent tickets\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.recent, \\'ticket\\', id=None, include=include)',\n",
              " 'def comments(self, ticket, include_inline_images=False):\\n        \"\"\"\\n        Retrieve the comments for a ticket.\\n\\n        :param ticket: Ticket object or id\\n        :param include_inline_images: Boolean. If `True`, inline image attachments will be\\n            returned in each comments\\' `attachments` field alongside non-inline attachments\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.comments, \\'comment\\', id=ticket, include_inline_images=repr(include_inline_images).lower())',\n",
              " 'def permanently_delete(self, tickets):\\n        \"\"\"\\n        Permanently delete ticket. `See Zendesk API docs <https://developer.zendesk.com/rest_api/docs/support/tickets#delete-ticket-permanently>`_\\n\\n        Ticket should be softly deleted first with regular `delete` method.\\n\\n        :param tickets: Ticket object or list of tickets objects\\n        :return: JobStatus object\\n        \"\"\"\\n        endpoint_kwargs = dict()\\n        if isinstance(tickets, collections.Iterable):\\n            endpoint_kwargs[\\'destroy_ids\\'] = [i.id for i in tickets]\\n        else:\\n            endpoint_kwargs[\\'id\\'] = tickets.id\\n        url = self._build_url(self.endpoint.deleted(**endpoint_kwargs))\\n        deleted_ticket_job_id = self._delete(url)\\n        self.cache.delete(tickets)\\n        return deleted_ticket_job_id',\n",
              " 'def events(self, start_time, include=None):\\n        \"\"\"\\n        Retrieve TicketEvents\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param start_time: time to retrieve events from.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.events, \\'ticket_event\\', start_time=start_time, include=include)',\n",
              " 'def audits(self, ticket=None, include=None, **kwargs):\\n        \"\"\"\\n        Retrieve TicketAudits. If ticket is passed, return the tickets for a specific audit.\\n\\n        If ticket_id is None, a TicketAuditGenerator is returned to handle pagination. The way this generator\\n        works is a different to the other Zenpy generators as it is cursor based, allowing you to change the\\n        direction that you are consuming objects. This is done with the reversed() python method.\\n\\n        For example:\\n\\n        .. code-block:: python\\n\\n            for audit in reversed(zenpy_client.tickets.audits()):\\n                print(audit)\\n\\n        See the `Zendesk docs <https://developer.zendesk.com/rest_api/docs/core/ticket_audits#pagination>`__ for\\n        information on additional parameters.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param ticket: Ticket object or id\\n        \"\"\"\\n        if ticket is not None:\\n            return self._query_zendesk(self.endpoint.audits, \\'ticket_audit\\', id=ticket, include=include)\\n        else:\\n            return self._query_zendesk(self.endpoint.audits.cursor, \\'ticket_audit\\', include=include, **kwargs)',\n",
              " 'def metrics(self, ticket):\\n        \"\"\"\\n        Retrieve TicketMetric.\\n\\n        :param ticket: Ticket object or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.metrics, \\'ticket_metric\\', id=ticket)',\n",
              " 'def metrics_incremental(self, start_time):\\n        \"\"\"\\n        Retrieve TicketMetric incremental\\n\\n        :param start_time: time to retrieve events from.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.metrics.incremental, \\'ticket_metric_events\\', start_time=start_time)',\n",
              " 'def show_macro_effect(self, ticket, macro):\\n        \"\"\"\\n        Apply macro to ticket. Returns what it *would* do, does not alter the ticket.\\n\\n        :param ticket: Ticket or ticket id to target\\n        :param macro: Macro or macro id to use\\n        \"\"\"\\n\\n        url = self._build_url(self.endpoint.macro(ticket, macro))\\n        macro_effect = self._get(url)\\n        macro_effect._set_dirty()\\n        return macro_effect',\n",
              " 'def merge(self, target, source,\\n              target_comment=None, source_comment=None):\\n        \"\"\"\\n        Merge the ticket(s) or ticket ID(s) in source into the target ticket.\\n\\n        :param target: ticket id or object to merge tickets into\\n        :param source: ticket id, object or list of tickets or ids to merge into target\\n        :param source_comment: optional comment for the source ticket(s)\\n        :param target_comment: optional comment for the target ticket\\n\\n        :return: a JobStatus object\\n        \"\"\"\\n        return TicketMergeRequest(self).post(target, source,\\n                                             target_comment=target_comment,\\n                                             source_comment=source_comment)',\n",
              " 'def skips(self, ticket):\\n        \"\"\"\\n        Skips for ticket See Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/ticket_skips>`__.\\n        \"\"\"\\n\\n        return self._get(self._build_url(self.endpoint.skips(id=ticket)))',\n",
              " 'def show(self, ticket_field, custom_field_option):\\n        \"\"\"\\n        Return CustomFieldOption\\n\\n        :param ticket_field: TicketFieldOption or id\\n        :param custom_field_option: CustomFieldOption or id\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.show, \\'custom_field_option\\', ticket_field, custom_field_option)',\n",
              " 'def show(self, item, variant):\\n        \"\"\"\\n        Show a variant.\\n\\n        :param item: Item object or id\\n        :param variant: Variant object or id\\n        :return:\\n        \"\"\"\\n        url = self._build_url(self.endpoint.show(item, variant))\\n        return self._get(url)',\n",
              " 'def comments(self, request_id):\\n        \"\"\"\\n        Return comments for request\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.comments, \\'comment\\', id=request_id)',\n",
              " 'def search(self, *args, **kwargs):\\n        \"\"\"\\n        Search for requests. See the `Zendesk docs\\n        <https://developer.zendesk.com/rest_api/docs/core/requests#searching-requests>`__ for more information on the\\n        syntax.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.search, \\'request\\', *args, **kwargs)',\n",
              " 'def memberships(self, group, include=None):\\n        \"\"\"\\n        Return the GroupMemberships for this group.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param group: Group object or id\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.memberships(id=group, include=include)))',\n",
              " 'def memberships_assignable(self, group, include=None):\\n        \"\"\"\\n        Return memberships that are assignable for this group.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param group: Group object or id\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.memberships_assignable(id=group, include=include)))',\n",
              " 'def active(self, include=None):\\n        \"\"\"\\n        Return all active views.\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.active(include=include)))',\n",
              " 'def compact(self, include=None):\\n        \"\"\"\\n        Return compact views - See: Zendesk API `Reference\\n        <https://developer.zendesk.com/rest_api/docs/core/views#list-views---compact>`__\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.compact(include=include)))',\n",
              " 'def execute(self, view, include=None):\\n        \"\"\"\\n        Execute a view.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param view: View or view id\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.execute(id=view, include=include)))',\n",
              " 'def tickets(self, view, include=None):\\n        \"\"\"\\n        Return the tickets in a view.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param view: View or view id\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.tickets(id=view, include=include)))',\n",
              " 'def count(self, view, include=None):\\n        \"\"\"\\n        Return a ViewCount for a view.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param view: View or view id\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.count(id=view, include=include)))',\n",
              " 'def count_many(self, views, include=None):\\n        \"\"\"\\n        Return many ViewCounts.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n            <https://developer.zendesk.com/rest_api/docs/core/side_loading>`__.\\n        :param views: iterable of View or view ids\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint(count_many=views, include=include)))',\n",
              " 'def export(self, view, include=None):\\n        \"\"\"\\n        Export a view. Returns an Export object.\\n\\n        :param include: list of objects to sideload. `Side-loading API Docs \\n\\n        :param view: View or view id\\n        :return:\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.export(id=view, include=include)))',\n",
              " 'def search(self, *args, **kwargs):\\n        \"\"\"\\n        Search views. See Zendesk API `Reference <https://developer.zendesk.com/rest_api/docs/core/views#search-views>`__.\\n\\n        :param args: query is the only accepted arg.\\n        :param kwargs: search parameters\\n        \"\"\"\\n        return self._get(self._build_url(self.endpoint.search(*args, **kwargs)))',\n",
              " 'def make_default(self, user, group_membership):\\n        \"\"\"\\n        Set the passed GroupMembership as default for the specified user.\\n\\n        :param user: User object or id\\n        :param group_membership: GroupMembership object or id\\n        \"\"\"\\n        return self._put(self._build_url(self.endpoint.make_default(user, group_membership)), payload={})',\n",
              " 'def create(self, section, article):\\n        \"\"\"\\n        Create (POST) an Article - See: Zendesk API `Reference\\n        <https://developer.zendesk.com/rest_api/docs/help_center/articles#create-article>`__.\\n\\n        :param section: Section ID or object\\n        :param article: Article to create\\n        \"\"\"\\n        return CRUDRequest(self).post(article, create=True, id=section)',\n",
              " 'def comments(self, article):\\n        \"\"\"\\n        Retrieve comments for an article\\n\\n        :param article: Article ID or object\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.comments, object_type=\\'comment\\', id=article)',\n",
              " 'def inline(self, article):\\n        \"\"\"\\n        Returns all inline attachments associated with article_id where (Such attachments has ``inline=True`` flag).\\n\\n        Inline attachments and its url can be referenced in the HTML body of the article.\\n\\n        :param article: Numeric article id or :class:`Article` object.\\n        :return: Generator with all associated inline attachments.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.inline, \\'article_attachment\\', id=article)',\n",
              " 'def block(self, article):\\n        \"\"\"\\n        Returns all block attachments associated with article_id (Such attachments has ``inline=False``).\\n\\n        Block attachments are displayed as separated files attached to Article.\\n\\n        :param article: Numeric article id or :class:`Article` object.\\n        :return: Generator with all associated block attachments.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.block, \\'article_attachment\\', id=article)',\n",
              " 'def create(self, article, attachment, inline=False, file_name=None, content_type=None):\\n        \"\"\"\\n        This function creates attachment attached to article.\\n\\n        :param article: Numeric article id or :class:`Article` object.\\n        :param attachment: File object or os path to file\\n        :param inline: If true, the attached file is shown in the dedicated admin UI\\n            for inline attachments and its url can be referenced in the HTML body of\\n            the article. If false, the attachment is listed in the list of attachments.\\n            Default is `false`\\n        :param file_name: you can set filename on file upload.\\n        :param content_type: The content type of the file. `Example: image/png`, Zendesk can ignore it.\\n        :return: :class:`ArticleAttachment` object\\n        \"\"\"\\n        return HelpdeskAttachmentRequest(self).post(self.endpoint.create,\\n                                                    article=article,\\n                                                    attachments=attachment,\\n                                                    inline=inline,\\n                                                    file_name=file_name,\\n                                                    content_type=content_type)',\n",
              " 'def create_unassociated(self, attachment, inline=False, file_name=None, content_type=None):\\n        \"\"\"\\n        You can use this endpoint for bulk imports.\\n        It lets you upload a file without associating it to an article until later.\\n        Check Zendesk documentation `important notes\\n        <https://developer.zendesk.com/rest_api/docs/help_center/article_attachments#create-unassociated-attachment>\\n\\n        :param attachment: File object or os path to file\\n        :param inline: If true, the attached file is shown in the dedicated admin UI\\n            for inline attachments and its url can be referenced in the HTML body of\\n            the article. If false, the attachment is listed in the list of attachments.\\n            Default is `false`\\n        :param file_name: you can set filename on file upload.\\n        :param content_type: The content type of the file. `Example: image/png`, Zendesk can ignore it.\\n        :return: :class:`ArticleAttachment` object\\n        \"\"\"\\n        return HelpdeskAttachmentRequest(self).post(self.endpoint.create_unassociated,\\n                                                    attachments=attachment,\\n                                                    inline=inline,\\n                                                    file_name=file_name,\\n                                                    content_type=content_type)',\n",
              " 'def delete(self, article_attachment):\\n        \"\"\"\\n        This function completely wipes attachment from Zendesk Helpdesk article.\\n\\n        :param article_attachment: :class:`ArticleAttachment` object or numeric article attachment id.\\n        :return: status_code == 204 on success\\n        \"\"\"\\n        return HelpdeskAttachmentRequest(self).delete(self.endpoint.delete, article_attachment)',\n",
              " 'def bulk_attachments(self, article, attachments):\\n        \"\"\"\\n        This function implements associating attachments to an article after article creation (for\\n        unassociated attachments).\\n\\n        :param article: Article id or :class:`Article` object\\n        :param attachments: :class:`ArticleAttachment` object, or list of :class:`ArticleAttachment` objects,\\n        up to 20 supported. `Zendesk documentation.\\n        <https://developer.zendesk.com/rest_api/docs/help_center/articles#associate-attachments-in-bulk-to-article>`__\\n        :return:\\n        \"\"\"\\n        return HelpdeskAttachmentRequest(self).post(self.endpoint.bulk_attachments, article=article,\\n                                                    attachments=attachments)',\n",
              " 'def recipients_incremental(self, start_time):\\n        \"\"\"\\n        Retrieve NPS Recipients incremental\\n\\n        :param start_time: time to retrieve events from.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.recipients_incremental, \\'recipients\\', start_time=start_time)',\n",
              " 'def responses_incremental(self, start_time):\\n        \"\"\"\\n        Retrieve NPS Responses incremental\\n\\n        :param start_time: time to retrieve events from.\\n        \"\"\"\\n        return self._query_zendesk(self.endpoint.responses_incremental, \\'responses\\', start_time=start_time)',\n",
              " 'def _wrap_element(self, element):\\n        \"\"\"\\n        We want to know if an item is modified that is stored in this dict. If the element is a list or dict,\\n        we wrap it in a ProxyList or ProxyDict, and if it is modified execute a callback that updates this\\n        instance. If it is a ZenpyObject, then the callback updates the parent object.\\n        \"\"\"\\n\\n        def dirty_callback():\\n            self._set_dirty()\\n\\n        if isinstance(element, list):\\n            element = ProxyList(element, dirty_callback=dirty_callback)\\n        elif isinstance(element, dict):\\n            element = ProxyDict(element, dirty_callback=dirty_callback)\\n        # If it is a Zenpy object this will either return None or the previous wrapper.\\n        elif getattr(element, \\'_dirty_callback\\', self._sentinel) is not self._sentinel:\\n            # Don\\'t set callback if already set.\\n            if not callable(element._dirty_callback):\\n                element._dirty_callback = dirty_callback\\n        return element',\n",
              " 'def handle_pagination(self, page_num=None, page_size=None):\\n        \"\"\" Handle retrieving and processing the next page of results. \"\"\"\\n        self._response_json = self.get_next_page(page_num=page_num, page_size=page_size)\\n        self.update_attrs()\\n        self.position = 0\\n        self.values = self.process_page()',\n",
              " 'def update_attrs(self):\\n        \"\"\" Add attributes such as count/end_time that can be present \"\"\"\\n        for key, value in self._response_json.items():\\n            if key != \\'results\\' and type(value) not in (list, dict):\\n                setattr(self, key, value)',\n",
              " 'def get_next_page(self, page_num, page_size):\\n        \"\"\" Retrieve the next page of results. \"\"\"\\n        url = self._response_json.get(self.next_page_attr, None)\\n        if url is None:\\n            raise StopIteration()\\n        params, url = self.process_url(page_num, page_size, url)\\n        response = self.response_handler.api._get(url, raw_response=True, params=params)\\n        return response.json()',\n",
              " 'def process_url(self, page_num, page_size, url):\\n        \"\"\" When slicing, remove the per_page and page parameters and pass to requests in the params dict \"\"\"\\n        params = dict()\\n        if page_num is not None:\\n            url = re.sub(\\'page=\\\\d+\\', \\'\\', url)\\n            params[\\'page\\'] = page_num\\n        if page_size is not None:\\n            url = re.sub(\\'per_page=\\\\d+\\', \\'\\', url)\\n            params[\\'per_page\\'] = page_size\\n        return params, url',\n",
              " 'def author(self):\\n        \"\"\"\\n        |  Comment: The id of the user who wrote the article (set to the user who made the request on create by default)\\n        \"\"\"\\n        if self.api and self.author_id:\\n            return self.api._get_user(self.author_id)',\n",
              " 'def section(self):\\n        \"\"\"\\n        |  Comment: The id of the section to which this article belongs\\n        \"\"\"\\n        if self.api and self.section_id:\\n            return self.api._get_section(self.section_id)',\n",
              " 'def article(self):\\n        \"\"\"\\n        |  Comment: Id of the associated article, if present\\n        \"\"\"\\n        if self.api and self.article_id:\\n            return self.api._get_article(self.article_id)',\n",
              " 'def topic(self):\\n        \"\"\"\\n        |  Comment: The id of the topic that the post belongs to\\n        \"\"\"\\n        if self.api and self.topic_id:\\n            return self.api._get_topic(self.topic_id)',\n",
              " 'def category(self):\\n        \"\"\"\\n        |  Comment: The id of the category to which this section belongs\\n        \"\"\"\\n        if self.api and self.category_id:\\n            return self.api._get_category(self.category_id)',\n",
              " 'def user_segment(self):\\n        \"\"\"\\n        |  Comment: The id of the user segment to which this section belongs\\n        \"\"\"\\n        if self.api and self.user_segment_id:\\n            return self.api._get_user_segment(self.user_segment_id)',\n",
              " 'def user(self):\\n        \"\"\"\\n        |  Comment: The id of the user who has this subscription\\n        \"\"\"\\n        if self.api and self.user_id:\\n            return self.api._get_user(self.user_id)',\n",
              " 'def created_by(self):\\n        \"\"\"\\n        |  Comment: The id of the user who created the translation\\n        \"\"\"\\n        if self.api and self.created_by_id:\\n            return self.api._get_user(self.created_by_id)',\n",
              " 'def updated_by(self):\\n        \"\"\"\\n        |  Comment: The id of the user who last updated the translation\\n        \"\"\"\\n        if self.api and self.updated_by_id:\\n            return self.api._get_user(self.updated_by_id)',\n",
              " 'def organizations(self):\\n        \"\"\"\\n        |  Comment: The ids of the organizations that have access\\n        \"\"\"\\n        if self.api and self.organization_ids:\\n            return self.api._get_organizations(self.organization_ids)',\n",
              " 'def _clean_dirty(self, obj=None):\\n        \"\"\" Recursively clean self and all child objects. \"\"\"\\n        obj = obj or self\\n        obj.__dict__[\\'_dirty_attributes\\'].clear()\\n        obj._dirty = False\\n        for key, val in vars(obj).items():\\n            if isinstance(val, BaseObject):\\n                self._clean_dirty(val)\\n            else:\\n                func = getattr(val, \\'_clean_dirty\\', None)\\n                if callable(func):\\n                    func()',\n",
              " 'def _set_dirty(self, obj=None):\\n        \"\"\" Recursively set self and all child objects _dirty flag. \"\"\"\\n        obj = obj or self\\n        for key, value in vars(obj).items():\\n            if key not in (\\'api\\', \\'_dirty_attributes\\', \\'_always_dirty\\', \\'_dirty_callback\\', \\'_dirty\\'):\\n                setattr(obj, key, value)\\n                if isinstance(value, BaseObject):\\n                    self._set_dirty(value)',\n",
              " 'def to_json(self, indent=2):\\n        \"\"\" Return self formatted as JSON. \"\"\"\\n        return json.dumps(self, default=json_encode_for_printing, indent=indent)',\n",
              " 'def to_dict(self, serialize=False):\\n        \"\"\"\\n        This method returns the object as a Python dict. If serialize is passed, only those attributes\\n        that have been modified will be included in the result.\\n        :param serialize:\\n        :return:\\n        \"\"\"\\n        if serialize:\\n            encode_method = json_encode_for_zendesk\\n        else:\\n            encode_method = json_encode_for_printing\\n        return json.loads(json.dumps(self._to_dict(serialize=serialize), default=encode_method))',\n",
              " 'def _to_dict(self, serialize=False):\\n        \"\"\"\\n        This method works by copying self.__dict__, and removing everything that should not be serialized.\\n        \"\"\"\\n        copy_dict = self.__dict__.copy()\\n        for key, value in vars(self).items():\\n            # We want to send all ids to Zendesk always\\n            if serialize and key == \\'id\\':\\n                continue\\n\\n            # If this is a Zenpy object, convert it to a dict.\\n            if not serialize and isinstance(value, BaseObject):\\n                copy_dict[key] = copy_dict.pop(key).to_dict()\\n\\n            # This object has a flag indicating it has been dirtied, so we want to send it off.\\n            elif serialize and getattr(value, \\'_dirty\\', False):\\n                continue\\n\\n            # Here we have an attribute that should always be sent to Zendesk.\\n            elif serialize and key in self._always_dirty:\\n                continue\\n\\n            # These are for internal tracking, so just delete.\\n            elif key in (\\'api\\', \\'_dirty_attributes\\', \\'_always_dirty\\', \\'_dirty_callback\\', \\'_dirty\\'):\\n                del copy_dict[key]\\n\\n            # If the attribute has not been modified, do not send it.\\n            elif serialize and key not in self._dirty_attributes:\\n                del copy_dict[key]\\n\\n            # Some reserved words are prefixed with an underscore, remove it here.\\n            elif key.startswith(\\'_\\'):\\n                copy_dict[key[1:]] = copy_dict[key]\\n                del copy_dict[key]\\n        return copy_dict',\n",
              " 'def group(self):\\n        \"\"\"\\n        |  Comment: The id of a group\\n        \"\"\"\\n        if self.api and self.group_id:\\n            return self.api._get_group(self.group_id)',\n",
              " 'def organization(self):\\n        \"\"\"\\n        |  Comment: The ID of the organization associated with this user, in this membership\\n        \"\"\"\\n        if self.api and self.organization_id:\\n            return self.api._get_organization(self.organization_id)',\n",
              " 'def assignee(self):\\n        \"\"\"\\n        |  Comment: The id of the assignee if the field is visible to end users\\n        \"\"\"\\n        if self.api and self.assignee_id:\\n            return self.api._get_user(self.assignee_id)',\n",
              " 'def collaborators(self):\\n        \"\"\"\\n        |  Comment: Who are currently CC\\'ed on the ticket\\n        \"\"\"\\n        if self.api and self.collaborator_ids:\\n            return self.api._get_users(self.collaborator_ids)',\n",
              " 'def requester(self):\\n        \"\"\"\\n        |  Comment: The id of the requester\\n        \"\"\"\\n        if self.api and self.requester_id:\\n            return self.api._get_user(self.requester_id)',\n",
              " 'def forum_topic(self):\\n        \"\"\"\\n        |  Comment: The topic this ticket originated from, if any\\n        \"\"\"\\n        if self.api and self.forum_topic_id:\\n            return self.api._get_topic(self.forum_topic_id)',\n",
              " 'def problem(self):\\n        \"\"\"\\n        |  Comment: For tickets of type \"incident\", the ID of the problem the incident is linked to\\n        \"\"\"\\n        if self.api and self.problem_id:\\n            return self.api._get_problem(self.problem_id)',\n",
              " 'def sharing_agreements(self):\\n        \"\"\"\\n        |  Comment: The ids of the sharing agreements used for this ticket\\n        \"\"\"\\n        if self.api and self.sharing_agreement_ids:\\n            return self.api._get_sharing_agreements(self.sharing_agreement_ids)',\n",
              " 'def submitter(self):\\n        \"\"\"\\n        |  Comment: The user who submitted the ticket. The submitter always becomes the author of the first comment on the ticket\\n        \"\"\"\\n        if self.api and self.submitter_id:\\n            return self.api._get_user(self.submitter_id)',\n",
              " 'def restricted_brands(self):\\n        \"\"\"\\n        |  Comment: ids of all brands that this ticket form is restricted to\\n        \"\"\"\\n        if self.api and self.restricted_brand_ids:\\n            return self.api._get_restricted_brands(self.restricted_brand_ids)',\n",
              " 'def ticket_fields(self):\\n        \"\"\"\\n        |  Comment: ids of all ticket fields which are in this ticket form\\n        \"\"\"\\n        if self.api and self.ticket_field_ids:\\n            return self.api._get_ticket_fields(self.ticket_field_ids)',\n",
              " 'def custom_role(self):\\n        \"\"\"\\n        |  Comment: A custom role if the user is an agent on the Enterprise plan\\n        \"\"\"\\n        if self.api and self.custom_role_id:\\n            return self.api._get_custom_role(self.custom_role_id)',\n",
              " 'def deserialize(self, response_json):\\n        \"\"\"\\n        Locate and deserialize all objects in the returned JSON.\\n\\n        Return a dict keyed by object_type. If the key is plural, the value will be a list,\\n        if it is singular, the value will be an object of that type.\\n        :param response_json:\\n        \"\"\"\\n        response_objects = dict()\\n        if all((t in response_json for t in (\\'ticket\\', \\'audit\\'))):\\n            response_objects[\"ticket_audit\"] = self.object_mapping.object_from_json(\\n                \"ticket_audit\",\\n                response_json\\n            )\\n\\n        # Locate and store the single objects.\\n        for zenpy_object_name in self.object_mapping.class_mapping:\\n            if zenpy_object_name in response_json:\\n                zenpy_object = self.object_mapping.object_from_json(\\n                    zenpy_object_name,\\n                    response_json[zenpy_object_name]\\n                )\\n                response_objects[zenpy_object_name] = zenpy_object\\n\\n        # Locate and store the collections of objects.\\n        for key, value in response_json.items():\\n            if isinstance(value, list):\\n                zenpy_object_name = as_singular(key)\\n                if zenpy_object_name in self.object_mapping.class_mapping:\\n                    response_objects[key] = []\\n                    for object_json in response_json[key]:\\n                        zenpy_object = self.object_mapping.object_from_json(\\n                            zenpy_object_name,\\n                            object_json\\n                        )\\n                        response_objects[key].append(zenpy_object)\\n        return response_objects',\n",
              " 'def build(self, response):\\n        \"\"\"\\n        Deserialize the returned objects and return either a single Zenpy object, or a ResultGenerator in\\n        the case of multiple results.\\n\\n        :param response: the requests Response object.\\n        \"\"\"\\n        response_json = response.json()\\n\\n        # Special case for ticket audits.\\n        if get_endpoint_path(self.api, response).startswith(\\'/ticket_audits.json\\'):\\n            return TicketAuditGenerator(self, response_json)\\n\\n        zenpy_objects = self.deserialize(response_json)\\n\\n        # Collection of objects (eg, users/tickets)\\n        plural_object_type = as_plural(self.api.object_type)\\n        if plural_object_type in zenpy_objects:\\n            return ZendeskResultGenerator(self, response_json, response_objects=zenpy_objects[plural_object_type])\\n\\n        # Here the response matches the API object_type, seems legit.\\n        if self.api.object_type in zenpy_objects:\\n            return zenpy_objects[self.api.object_type]\\n\\n        # Could be anything, if we know of this object then return it.\\n        for zenpy_object_name in self.object_mapping.class_mapping:\\n            if zenpy_object_name in zenpy_objects:\\n                return zenpy_objects[zenpy_object_name]\\n\\n        # Maybe a collection of known objects?\\n        for zenpy_object_name in self.object_mapping.class_mapping:\\n            plural_zenpy_object_name = as_plural(zenpy_object_name)\\n            if plural_zenpy_object_name in zenpy_objects:\\n                return ZendeskResultGenerator(self, response_json, object_type=plural_zenpy_object_name)\\n\\n        # Bummer, bail out.\\n        raise ZenpyException(\"Unknown Response: \" + str(response_json))',\n",
              " 'def set_cache_impl(self, cache_impl, maxsize, **kwargs):\\n        \"\"\"\\n        Change cache implementation. The contents of the old cache will\\n        be transferred to the new one.\\n\\n        :param cache_impl: Name of cache implementation, must exist in AVAILABLE_CACHES\\n        \"\"\"\\n        new_cache = self._get_cache_impl(cache_impl, maxsize, **kwargs)\\n        self._populate_new_cache(new_cache)\\n        self.cache = new_cache',\n",
              " 'def set_maxsize(self, maxsize, **kwargs):\\n        \"\"\"\\n        Set maxsize. This involves creating a new cache and transferring the items.\\n        \"\"\"\\n        new_cache = self._get_cache_impl(self.impl_name, maxsize, **kwargs)\\n        self._populate_new_cache(new_cache)\\n        self.cache = new_cache',\n",
              " 'def add(self, zenpy_object):\\n        \"\"\" Add a Zenpy object to the relevant cache. If no cache exists for this object nothing is done. \"\"\"\\n        object_type = get_object_type(zenpy_object)\\n        if object_type not in self.mapping or self.disabled:\\n            return\\n        attr_name = self._cache_key_attribute(object_type)\\n        cache_key = getattr(zenpy_object, attr_name)\\n        log.debug(\"Caching: [{}({}={})]\".format(zenpy_object.__class__.__name__, attr_name, cache_key))\\n        self.mapping[object_type][cache_key] = zenpy_object',\n",
              " 'def delete(self, to_delete):\\n        \"\"\" Purge one or more items from the relevant caches \"\"\"\\n        if not isinstance(to_delete, list):\\n            to_delete = [to_delete]\\n        for zenpy_object in to_delete:\\n            object_type = get_object_type(zenpy_object)\\n            object_cache = self.mapping.get(object_type, None)\\n            if object_cache:\\n                removed_object = object_cache.pop(zenpy_object.id, None)\\n                if removed_object:\\n                    log.debug(\"Cache RM: [%s %s]\" % (object_type.capitalize(), zenpy_object.id))',\n",
              " 'def get(self, object_type, cache_key):\\n        \"\"\" Query the cache for a Zenpy object \"\"\"\\n        if object_type not in self.mapping or self.disabled:\\n            return None\\n        cache = self.mapping[object_type]\\n        if cache_key in cache:\\n            log.debug(\"Cache HIT: [%s %s]\" % (object_type.capitalize(), cache_key))\\n            return cache[cache_key]\\n        else:\\n            log.debug(\\'Cache MISS: [%s %s]\\' % (object_type.capitalize(), cache_key))',\n",
              " 'def query_cache_by_object(self, zenpy_object):\\n        \"\"\" Convenience method for testing. Given an object, return the cached version \"\"\"\\n        object_type = get_object_type(zenpy_object)\\n        cache_key = self._cache_key_attribute(object_type)\\n        return self.get(object_type, getattr(zenpy_object, cache_key))',\n",
              " 'def purge_cache(self, object_type):\\n        \"\"\" Purge the named cache of all values. If no cache exists for object_type, nothing is done \"\"\"\\n        if object_type in self.mapping:\\n            cache = self.mapping[object_type]\\n            log.debug(\"Purging [{}] cache of {} values.\".format(object_type, len(cache)))\\n            cache.purge()',\n",
              " 'def in_cache(self, zenpy_object):\\n        \"\"\" Determine whether or not this object is in the cache \"\"\"\\n        object_type = get_object_type(zenpy_object)\\n        cache_key_attr = self._cache_key_attribute(object_type)\\n        return self.get(object_type, getattr(zenpy_object, cache_key_attr)) is not None',\n",
              " 'def http_adapter_kwargs():\\n        \"\"\"\\n        Provides Zenpy\\'s default HTTPAdapter args for those users providing their own adapter.\\n        \"\"\"\\n\\n        return dict(\\n            # Transparently retry requests that are safe to retry, with the exception of 429. This is handled\\n            # in the Api._call_api() method.\\n            max_retries=Retry(\\n                total=3,\\n                status_forcelist=[r for r in Retry.RETRY_AFTER_STATUS_CODES if r != 429],\\n                respect_retry_after_header=False\\n            )\\n        )',\n",
              " 'def set_cache_max(self, cache_name, maxsize, **kwargs):\\n        \"\"\"\\n        Sets the maxsize attribute of the named cache\\n        \"\"\"\\n        cache = self._get_cache(cache_name)\\n        cache.set_maxsize(maxsize, **kwargs)',\n",
              " 'def set_cache_implementation(self, cache_name, impl_name, maxsize, **kwargs):\\n        \"\"\"\\n        Changes the cache implementation for the named cache\\n        \"\"\"\\n        self._get_cache(cache_name).set_cache_impl(impl_name, maxsize, **kwargs)',\n",
              " 'def add_cache(self, object_type, cache_impl_name, maxsize, **kwargs):\\n        \"\"\"\\n        Add a new cache for the named object type and cache implementation\\n        \"\"\"\\n        if object_type not in ZendeskObjectMapping.class_mapping:\\n            raise ZenpyException(\"No such object type: %s\" % object_type)\\n        self.cache.mapping[object_type] = ZenpyCache(cache_impl_name, maxsize, **kwargs)',\n",
              " 'def object_from_json(self, object_type, object_json, parent=None):\\n        \"\"\"\\n        Given a blob of JSON representing a Zenpy object, recursively deserialize it and\\n         any nested objects it contains. This method also adds the deserialized object\\n         to the relevant cache if applicable.\\n        \"\"\"\\n        if not isinstance(object_json, dict):\\n            return object_json\\n        obj = self.instantiate_object(object_type, parent)\\n        for key, value in object_json.items():\\n            if key not in self.skip_attrs:\\n                key, value = self._deserialize(key, obj, value)\\n            if isinstance(value, dict):\\n                value = ProxyDict(value, dirty_callback=getattr(\\n                    obj, \\'_dirty_callback\\', None))\\n            elif isinstance(value, list):\\n                value = ProxyList(value, dirty_callback=getattr(\\n                    obj, \\'_dirty_callback\\', None))\\n            setattr(obj, key, value)\\n        if hasattr(obj, \\'_clean_dirty\\'):\\n            obj._clean_dirty()\\n        self.api.cache.add(obj)\\n        return obj',\n",
              " 'def instantiate_object(self, object_type, parent):\\n        \"\"\"\\n        Instantiate a Zenpy object. If this object has a parent, add a callback to call the parent if it is modified.\\n        This is so the parent object is correctly marked as dirty when a child is modified, eg:\\n\\n            view.conditions.all.append(<something>)\\n\\n        Also, some attributes need to be sent together to Zendesk together if either is modified. For example,\\n        Condition objects need to send both \"all\" and \"any\", even if only one has changed. If we have such values\\n        configured, add them. They will be inspected in the objects to_dict method on serialization.\\n        \"\"\"\\n        ZenpyClass = self.class_for_type(object_type)\\n        obj = ZenpyClass(api=self.api)\\n        if parent:\\n            def dirty_callback():\\n                parent._dirty = True\\n                obj._dirty = True\\n\\n            obj._dirty_callback = dirty_callback\\n        obj._always_dirty.update(self.always_dirty.get(object_type, []))\\n        return obj',\n",
              " 'def class_for_type(self, object_type):\\n        \"\"\" Given an object_type return the class associated with it. \"\"\"\\n        if object_type not in self.class_mapping:\\n            raise ZenpyException(\"Unknown object_type: \" + str(object_type))\\n        else:\\n            return self.class_mapping[object_type]',\n",
              " 'def index_by(self, field):\\n        \"\"\"\\n        Returns a dict with a key for each value of `field` and the first record with that value as value.\\n        :param field: Name of the field to index by.\\n        :type field: string.\\n        \"\"\"\\n        values = self[field].unique()\\n        results = {}\\n        for value in values:\\n            results[value] = self.model_class(**self[self[field] == value].iloc[0])\\n        return results',\n",
              " 'def destroy(self, force=False):\\n        \"\"\"\\n        Deletes the record. If the model has ``soft_delete`` activated, the record will not actually be deleted.\\n\\n        :param force: forces the record to be actually deleted if ``soft_delete`` is activated.\\n        :type force: boolean\\n        \"\"\"\\n        if self.persisted:\\n            if self.soft_delete and not force:\\n                self.__class__.update(\\n                    values={\\n                        self.__class__.deleted_at_column(): datetime.utcnow()\\n                        },\\n                    where=self.where_self\\n                    )\\n            else:\\n                self.__class__.delete(\\n                    where=self.where_self,\\n                    skip_soft_delete=True\\n                    )\\n        else:\\n            raise RecordNotPersisted(\"Record\\'s primary key is None\")',\n",
              " 'def select(self, **kwargs):\\n        #select=\\'*\\', where=None, inner_joins=None, left_joins=None, \\n        #group=None, order=None, limit=None, db=None, role=\\'replica\\'):\\n        \"\"\"\\n        Perform a SELECT statement on the model\\'s table in the replica database.\\n\\n        :param select: Columns to return in the SELECT statement.\\n        :type select: string, array, dict\\n        :param where: WHERE clause of the SELECT statement. This can be a plain string, a dict or an array.\\n        :type where: string, dict, array\\n        :param inner_joins: Specifies an INNER JOIN clause. Can be a plain string (without the INNER JOIN part), an array of strings or an array of classes if the relationship was defined in the model.\\n        :type inner_joins: string, array\\n        :param left_joins: Specifies an LEFT JOIN clause. Can be a plain string (without the LEFT JOIN part), an array of strings or an array of classes if the relationship was defined in the model.\\n        :type left_joins: string, array\\n        :param group: Specifies a GROUP BY clause.\\n        :type group: string\\n        :param having: Specifies a HAVING clause.\\n        :type having: string\\n        :param order: ORDER BY clause.\\n        :type order: string\\n        :param limit: LIMIT clause.\\n        :type limit: integer\\n        :param db: Database name from your ``jardin_conf.py``, overrides the default database set in the model declaration.\\n        :type db: string\\n        :param role: One of ``(\\'master\\', \\'replica\\')`` to override the default.\\n        :type role: string\\n        :returns: ``jardin.Collection`` instance, which is a ``pandas.DataFrame``.\\n        \"\"\"\\n        db_adapter = self.db_adapter(\\n            db_name=kwargs.get(\\'db\\'),\\n            role=kwargs.get(\\'role\\', \\'replica\\')\\n            )\\n\\n        kwargs[\\'stack\\'] = self.stack_mark(\\n            inspect.stack(),\\n            db_conn=db_adapter.db\\n            )\\n\\n        return self.collection_instance(db_adapter.select(**kwargs))',\n",
              " 'def query(self, sql=None, filename=None, **kwargs):\\n        \"\"\" run raw sql from sql or file against.\\n\\n        :param sql: Raw SQL query to pass directly to the connection.\\n        :type sql: string\\n        :param filename: Path to a file containing a SQL query. The path should be relative to CWD.\\n        :type filename: string\\n        :param db: `optional` Database name from your ``jardin_conf.py``, overrides the default database set in the model declaration.\\n        :type db: string\\n        :param role: `optional` One of ``(\\'master\\', \\'replica\\')`` to override the default.\\n        :type role: string\\n        :returns: ``jardin.Collection`` collection, which is a ``pandas.DataFrame``.\\n        \"\"\"\\n        results = query(\\n            sql=sql,\\n            filename=filename,\\n            db=self.db_names[kwargs.get(\\'role\\', \\'replica\\')],\\n            **kwargs\\n            )\\n\\n        if results is None:\\n            return None\\n        else:\\n            return self.collection_instance(results)',\n",
              " 'def count(self, **kwargs):\\n        \"\"\"\\n        Performs a COUNT statement on the model\\'s table in the replica database.\\n\\n        :param select: Column to be counted.\\n        :type select: string\\n        :param where: WHERE clause of the SELECT statement. This can be a plain string, a dict or an array.\\n        :type where: string, dict, array\\n        :param db: Database name from your ``jardin_conf.py``, overrides the default database set in the model declaration.\\n        :type db: string\\n        :param role: One of ``(\\'master\\', \\'replica\\')`` to override the default.\\n        :type role: string\\n        :returns: integer\\n        \"\"\"\\n        if \\'select\\' in kwargs:\\n            kwargs[\\'select\\'] = {\\'cnt\\': \\'COUNT(%s)\\' % kwargs[\\'select\\']}\\n        else:\\n            kwargs[\\'select\\'] = {\\'cnt\\': \\'COUNT(*)\\'}\\n\\n        res = self.db_adapter(\\n            db_name=kwargs.get(\\'db\\'),\\n            role=kwargs.get(\\'role\\', \\'replica\\')\\n            ).select(**kwargs)\\n        return res.cnt[0]',\n",
              " 'def insert(self, **kwargs):\\n        \"\"\"\\n        Performs an INSERT statement on the model\\'s table in the master database.\\n\\n        :param values: A dictionary containing the values to be inserted. ``datetime``, ``dict`` and ``bool`` objects can be passed as is and will be correctly serialized by psycopg2.\\n        :type values: dict\\n        \"\"\"\\n        if len(kwargs[\\'values\\']) == 0:\\n            config.logger.warning(\\'No values to insert.\\')\\n            return\\n        values = kwargs[\\'values\\']\\n        if isinstance(values, self):\\n            values = values.attributes.copy()\\n        if isinstance(values, dict):\\n            for (k, v) in values.items():\\n                if v is None:\\n                    del kwargs[\\'values\\'][k]\\n        kwargs[\\'stack\\'] = self.stack_mark(inspect.stack())\\n        kwargs[\\'primary_key\\'] = self.primary_key\\n        column_names = self.table_schema().keys()\\n        now = datetime.utcnow()\\n        for field in (\\'created_at\\', \\'updated_at\\'):\\n            if field in column_names:\\n                kwargs[\\'values\\'][field] = now\\n        results = self.db_adapter(role=\\'master\\').insert(**kwargs)\\n        return self.record_or_model(results)',\n",
              " 'def update(self, **kwargs):\\n        \"\"\"\\n        Performs an UPDATE statement on the model\\'s table in the master database.\\n\\n        :param values: A dictionary of values to update. ``datetime``, ``dict`` and ``bool`` objects can be passed as is and will be correctly serialized by psycopg2.\\n        :type values: dict\\n        :param where: The WHERE clause. This can be a plain string, a dict or an array.\\n        :type where: string, dict, array\\n        \"\"\"\\n        kwargs[\\'stack\\'] = self.stack_mark(inspect.stack())\\n        kwargs[\\'primary_key\\'] = self.primary_key\\n        column_names = self.table_schema().keys()\\n        now = datetime.utcnow()\\n        if \\'updated_at\\' in column_names:\\n            kwargs[\\'values\\'][\\'updated_at\\'] = now\\n        results = self.db_adapter(role=\\'master\\').update(**kwargs)\\n        return self.record_or_model(results)',\n",
              " 'def delete(self, **kwargs):\\n        \"\"\"\\n        Performs a DELETE statement on the model\\'s table in the master database.\\n\\n        :param where: The WHERE clause. This can be a plain string, a dict or an array.\\n        :type where: string, dict, array\\n        \"\"\"\\n        kwargs[\\'stack\\'] = self.stack_mark(inspect.stack())\\n        \\n        return self.db_adapter(role=\\'master\\').delete(**kwargs)',\n",
              " 'def last(self, limit=1, **kwargs):\\n        \"\"\"\\n        Returns the last `limit` records inserted in the model\\'s table in the replica database. Rows are sorted by ``created_at``.\\n        \"\"\"\\n        return self.collection_instance(\\n            self.db_adapter(\\n                db_name=kwargs.get(\\'db\\'),\\n                role=kwargs.get(\\'role\\', \\'replica\\')\\n                ).select(\\n                    where=\\'created_at IS NOT NULL\\',\\n                    order=\\'created_at DESC\\',\\n                    limit=limit\\n                    )\\n                )',\n",
              " 'def find_by(self, values={}, **kwargs):\\n        \"\"\"\\n        Returns a single record matching the criteria in ``values`` found in the model\\'s table in the replica database.\\n\\n        :param values: Criteria to find the record.\\n        :type values: dict\\n        :returns: an instance of the model.\\n        \"\"\"\\n        try:\\n            return self(\\n                **self.select(\\n                    where=values,\\n                    limit=1,\\n                    **kwargs\\n                    ).to_dict(orient=\\'records\\')[0]\\n                )\\n        except IndexError:\\n            return None',\n",
              " 'def find(self, id, **kwargs):\\n        \"\"\"\\n        Finds a record by its id in the model\\'s table in the replica database.\\n        :returns: an instance of the model.\\n        \"\"\"\\n        return self.find_by(values={self.primary_key: id}, **kwargs)',\n",
              " 'def replica_lag(self, **kwargs):\\n        \"\"\"\\n        Returns the current replication lag in seconds between the master and replica databases.\\n\\n        :returns: float\\n        \"\"\"\\n        if not self._use_replica():\\n            return 0\\n        try:\\n            kwargs[\\'stack\\'] = self.stack_mark(inspect.stack())\\n            sql = \"select EXTRACT(EPOCH FROM NOW() - pg_last_xact_replay_timestamp()) AS replication_lag\"\\n            return self.collection_instance(\\n                self.db_adapter().raw_query(\\n                    sql=sql, **kwargs\\n                    )\\n                ).squeeze()\\n        except:\\n            return 0',\n",
              " 'def table_schema(self):\\n        \"\"\"\\n        Returns the table schema.\\n\\n        :returns: dict\\n        \"\"\"\\n        if self.__dict__.get(\\'_table_schema\\') is None:\\n            self._table_schema = None\\n            table_schema = {}\\n            for row in self.query_schema():\\n                name, default, dtype = self.db().lexicon.column_info(row)\\n                if isinstance(default, str):\\n                    json_matches = re.findall(r\"^\\\\\\'(.*)\\\\\\'::jsonb$\", default)\\n                    if len(json_matches) > 0:\\n                        default = json.loads(json_matches[0])\\n                if name == self.primary_key:\\n                    default = None\\n                table_schema[name] = {\\'default\\': default, \\'type\\': dtype}\\n            if len(table_schema):\\n                self._table_schema = table_schema\\n        return self._table_schema',\n",
              " 'def retry(ExceptionToCheck, tries=4, delay=3, backoff=2, logger=None):\\n    \"\"\"Retry calling the decorated function using an exponential backoff.\\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\\n\\n    :param ExceptionToCheck: the exception to check. may be a tuple of\\n        exceptions to check\\n    :type ExceptionToCheck: Exception or tuple\\n    :param tries: number of times to try (not retry) before giving up\\n    :type tries: int\\n    :param delay: initial delay between retries in seconds\\n    :type delay: int\\n    :param backoff: backoff multiplier e.g. value of 2 will double the delay\\n        each retry\\n    :type backoff: int\\n    :param logger: logger to use. If None, print\\n    :type logger: logging.Logger instance\\n    \"\"\"\\n    def deco_retry(f):\\n\\n        @wraps(f)\\n        def f_retry(*args, **kwargs):\\n            mtries, mdelay = tries, delay\\n            while mtries > 1:\\n                try:\\n                    return f(*args, **kwargs)\\n                except ExceptionToCheck as e:\\n                    msg = \"%s, Retrying in %d seconds...\" % (str(e), mdelay)\\n                    if logger:\\n                        logger.warning(msg)\\n                    else:\\n                        print(msg)\\n                    time.sleep(mdelay)\\n                    mtries -= 1\\n                    mdelay *= backoff\\n            return f(*args, **kwargs)\\n\\n        return f_retry  # true decorator\\n\\n    return deco_retry',\n",
              " 'def load_vertex_buffer(self, fd, material, length):\\n        \"\"\"\\n        Load vertex data from file. Can be overriden to reduce data copy\\n\\n        :param fd: file object\\n        :param material: The material these vertices belong to\\n        :param length: Byte length of the vertex data\\n        \"\"\"\\n        material.vertices = struct.unpack(\\'{}f\\'.format(length // 4), fd.read(length))',\n",
              " 'def _load_vertex_buffers(self):\\n        \"\"\"Load each vertex buffer into each material\"\"\"\\n        fd = gzip.open(cache_name(self.file_name), \\'rb\\')\\n\\n        for buff in self.meta.vertex_buffers:\\n\\n            mat = self.wavefront.materials.get(buff[\\'material\\'])\\n            if not mat:\\n                mat = Material(name=buff[\\'material\\'], is_default=True)\\n                self.wavefront.materials[mat.name] = mat\\n\\n            mat.vertex_format = buff[\\'vertex_format\\']\\n            self.load_vertex_buffer(fd, mat, buff[\\'byte_length\\'])\\n\\n        fd.close()',\n",
              " 'def _parse_mtllibs(self):\\n        \"\"\"Load mtl files\"\"\"\\n        for mtllib in self.meta.mtllibs:\\n            try:\\n                materials = self.material_parser_cls(\\n                    os.path.join(self.path, mtllib),\\n                    encoding=self.encoding,\\n                    strict=self.strict).materials\\n            except IOError:\\n                raise IOError(\"Failed to load mtl file:\".format(os.path.join(self.path, mtllib)))\\n\\n            for name, material in materials.items():\\n                self.wavefront.materials[name] = material',\n",
              " 'def add_vertex_buffer(self, material, vertex_format, byte_offset, byte_length):\\n        \"\"\"Add a vertex buffer\"\"\"\\n        self._vertex_buffers.append({\\n            \"material\": material,\\n            \"vertex_format\": vertex_format,\\n            \"byte_offset\": byte_offset,\\n            \"byte_length\": byte_length,\\n        })',\n",
              " 'def write(self, path):\\n        \"\"\"Save the metadata as json\"\"\"\\n        with open(path, \\'w\\') as fd:\\n            fd.write(json.dumps(\\n                {\\n                    \"created_at\": self._created_at,\\n                    \"version\": self._version,\\n                    \"mtllibs\": self._mtllibs,\\n                    \"vertex_buffers\": self._vertex_buffers,\\n                },\\n                indent=2,\\n            ))',\n",
              " 'def has_material(self, new_material):\\n        \"\"\"Determine whether we already have a material of this name.\"\"\"\\n        for material in self.materials:\\n            if material.name == new_material.name:\\n                return True\\n\\n        return False',\n",
              " 'def add_material(self, material):\\n        \"\"\"Add a material to the mesh, IF it\\'s not already present.\"\"\"\\n        if self.has_material(material):\\n            return\\n\\n        self.materials.append(material)',\n",
              " 'def auto_consume(func):\\n    \"\"\"Decorator for auto consuming lines when leaving the function\"\"\"\\n    def inner(*args, **kwargs):\\n        func(*args, **kwargs)\\n        args[0].consume_line()\\n    return inner',\n",
              " 'def create_line_generator(self):\\n        \"\"\"\\n        Creates a generator function yielding lines in the file\\n        Should only yield non-empty lines\\n        \"\"\"\\n\\n        if self.file_name.endswith(\".gz\"):\\n            if sys.version_info.major == 3:\\n                gz = gzip.open(self.file_name, mode=\\'rt\\', encoding=self.encoding)\\n            else:\\n                gz = gzip.open(self.file_name, mode=\\'rt\\')\\n\\n            for line in gz.readlines():\\n                yield line\\n\\n            gz.close()\\n        else:\\n            if sys.version_info.major == 3:\\n                # Python 3 native `open` is much faster\\n                file = open(self.file_name, mode=\\'r\\', encoding=self.encoding)\\n            else:\\n                # Python 2 needs the codecs package to deal with encoding\\n                file = codecs.open(self.file_name, mode=\\'r\\', encoding=self.encoding)\\n\\n            for line in file:\\n                yield line\\n\\n            file.close()',\n",
              " 'def next_line(self):\\n        \"\"\"Read the next line from the line generator and split it\"\"\"\\n        self.line = next(self.lines)  # Will raise StopIteration when there are no more lines\\n        self.values = self.line.split()',\n",
              " 'def parse(self):\\n        \"\"\"\\n        Parse all the lines in the obj file\\n        Determines what type of line we are and dispatch appropriately.\\n        \"\"\"\\n        try:\\n            # Continues until `next_line()` raises StopIteration\\n            # This can trigger here or in parse functions in the subclass\\n            while True:\\n                # Only advance the parser if the previous line was consumed.\\n                # Parse functions reading multiple lines can end up reading one line too far,\\n                # so they return without consuming the line and we pick it up here\\n                if not self.line:\\n                    self.next_line()\\n\\n                if self.line[0] == \\'#\\' or len(self.values) < 2:\\n                    self.consume_line()\\n                    continue\\n\\n                self.dispatcher.get(self.values[0], self.parse_fallback)()\\n        except StopIteration:\\n            pass\\n\\n        if self.auto_post_parse:\\n            self.post_parse()',\n",
              " 'def parse_fallback(self):\\n        \"\"\"Fallback method when parser doesn\\'t know the statement\"\"\"\\n        if self.strict:\\n            raise PywavefrontException(\"Unimplemented OBJ format statement \\'%s\\' on line \\'%s\\'\"\\n                                       % (self.values[0], self.line.rstrip()))\\n        else:\\n            logger.warning(\"Unimplemented OBJ format statement \\'%s\\' on line \\'%s\\'\"\\n                            % (self.values[0], self.line.rstrip()))',\n",
              " 'def _build_dispatch_map(self):\\n        \"\"\"\\n        Build a dispatch map: {func name\": func} dict\\n        This is to easily dispatch to each parse method.\\n\\n        Parse methods must start with `parse_` to be registered.\\n        The suffix should be the name of the obj statement\\n        such as `parse_v` for vertex statements.\\n        \"\"\"\\n        return {\"_\".join(a.split(\"_\")[1:]): getattr(self, a)\\n                for a in dir(self)\\n                if a.startswith(\"parse_\")}',\n",
              " 'def draw(instance):\\n    \"\"\"Generic draw function\"\"\"\\n    # Draw Wavefront instance\\n    if isinstance(instance, Wavefront):\\n        draw_materials(instance.materials)\\n    # Draw single material\\n    elif isinstance(instance, Material):\\n        draw_material(instance)\\n    # Draw dict of materials\\n    elif isinstance(instance, dict):\\n        draw_materials(instance)\\n    else:\\n        raise ValueError(\"Cannot figure out how to draw: {}\".format(instance))',\n",
              " 'def draw_material(material, face=GL_FRONT_AND_BACK):\\n    \"\"\"Draw a single material\"\"\"\\n    if material.gl_floats is None:\\n        material.gl_floats = (GLfloat * len(material.vertices))(*material.vertices)\\n        material.triangle_count = len(material.vertices) / material.vertex_size\\n\\n    vertex_format = VERTEX_FORMATS.get(material.vertex_format)\\n    if not vertex_format:\\n        raise ValueError(\"Vertex format {} not supported by pyglet\".format(material.vertex_format))\\n\\n    glPushClientAttrib(GL_CLIENT_VERTEX_ARRAY_BIT)\\n    glPushAttrib(GL_CURRENT_BIT | GL_ENABLE_BIT | GL_LIGHTING_BIT)\\n    glEnable(GL_CULL_FACE)\\n    glCullFace(GL_BACK)\\n\\n    # Fall back to ambient texture if no diffuse\\n    texture = material.texture or material.texture_ambient\\n    if texture and material.has_uvs:\\n        bind_texture(texture)\\n    else:\\n        glDisable(GL_TEXTURE_2D)\\n\\n    glMaterialfv(face, GL_DIFFUSE, gl_light(material.diffuse))\\n    glMaterialfv(face, GL_AMBIENT, gl_light(material.ambient))\\n    glMaterialfv(face, GL_SPECULAR, gl_light(material.specular))\\n    glMaterialfv(face, GL_EMISSION, gl_light(material.emissive))\\n    glMaterialf(face, GL_SHININESS, min(128.0, material.shininess))\\n    glEnable(GL_LIGHT0)\\n\\n    if material.has_normals:\\n        glEnable(GL_LIGHTING)\\n    else:\\n        glDisable(GL_LIGHTING)\\n\\n    glInterleavedArrays(vertex_format, 0, material.gl_floats)\\n    glDrawArrays(GL_TRIANGLES, 0, int(material.triangle_count))\\n\\n    glPopAttrib()\\n    glPopClientAttrib()',\n",
              " 'def bind_texture(texture):\\n    \"\"\"Draw a single texture\"\"\"\\n    if not getattr(texture, \\'image\\', None):\\n        texture.image = load_image(texture.path)\\n\\n    glEnable(texture.image.target)\\n    glBindTexture(texture.image.target, texture.image.id)\\n    gl.glTexParameterf(texture.image.target,\\n                       gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP_TO_EDGE)\\n    gl.glTexParameterf(texture.image.target,\\n                       gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP_TO_EDGE)',\n",
              " 'def load_image(name):\\n    \"\"\"Load an image\"\"\"\\n    image = pyglet.image.load(name).texture\\n    verify_dimensions(image)\\n    return image',\n",
              " 'def pad_light(self, values):\\n        \"\"\"Accept an array of up to 4 values, and return an array of 4 values.\\n        If the input array is less than length 4, pad it with zeroes until it\\n        is length 4. Also ensure each value is a float\"\"\"\\n        while len(values) < 4:\\n            values.append(0.)\\n\\n        return list(map(float, values))',\n",
              " 'def set_alpha(self, alpha):\\n        \"\"\"Set alpha/last value on all four lighting attributes.\"\"\"\\n        self.transparency = alpha\\n        self.diffuse[3] = alpha\\n        self.ambient[3] = alpha\\n        self.specular[3] = alpha\\n        self.emissive[3] = alpha',\n",
              " 'def parse_map_Kd(self):\\n        \"\"\"Diffuse map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture(Kd)',\n",
              " 'def parse_map_Ka(self):\\n        \"\"\"Ambient map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture_ambient(Kd)',\n",
              " 'def parse_map_Ks(self):\\n        \"\"\"Specular color map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture_specular_color(Kd)',\n",
              " 'def parse_map_Ns(self):\\n        \"\"\"Specular color map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture_specular_highlight(Kd)',\n",
              " 'def parse_map_d(self):\\n        \"\"\"Alpha map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture_alpha(Kd)',\n",
              " 'def parse_map_bump(self):\\n        \"\"\"Bump map\"\"\"\\n        Kd = os.path.join(self.dir, \" \".join(self.values[1:]))\\n        self.this_material.set_texture_bump(Kd)',\n",
              " 'def parse(self):\\n        \"\"\"Trigger cache load or call superclass parse()\"\"\"\\n        start = time.time()\\n\\n        if self.cache:\\n            self.load_cache()\\n\\n        if not self.cache_loaded:\\n            super(ObjParser, self).parse()\\n\\n        logger.info(\"%s: Load time: %s\", self.file_name, time.time() - start)',\n",
              " 'def load_cache(self):\\n        \"\"\"Loads the file using cached data\"\"\"\\n        self.cache_loaded = self.cache_loader_cls(\\n            self.file_name,\\n            self.wavefront,\\n            strict=self.strict,\\n            create_materials=self.create_materials,\\n            encoding=self.encoding,\\n            parse=self.parse,\\n        ).parse()',\n",
              " 'def post_parse(self):\\n        \"\"\"Called after parsing is done\"\"\"\\n        if self.cache and not self.cache_loaded:\\n            self.cache_writer_cls(self.file_name, self.wavefront).write()',\n",
              " 'def consume_vertices(self):\\n        \"\"\"\\n        Consumes all consecutive vertices.\\n        NOTE: There is no guarantee this will consume all vertices since other\\n        statements can also occur in the vertex list\\n        \"\"\"\\n        while True:\\n            # Vertex color\\n            if len(self.values) == 7:\\n                yield (\\n                    float(self.values[1]),\\n                    float(self.values[2]),\\n                    float(self.values[3]),\\n                    float(self.values[4]),\\n                    float(self.values[5]),\\n                    float(self.values[6]),\\n                )\\n            # Positions only\\n            else:\\n                yield (\\n                    float(self.values[1]),\\n                    float(self.values[2]),\\n                    float(self.values[3]),\\n                )\\n\\n            try:\\n                self.next_line()\\n            except StopIteration:\\n                break\\n\\n            if not self.values:\\n                break\\n\\n            if self.values[0] != \"v\":\\n                break',\n",
              " 'def consume_normals(self):\\n        \"\"\"Consumes all consecutive texture coordinate lines\"\"\"\\n        # The first iteration processes the current/first vn statement.\\n        # The loop continues until there are no more vn-statements or StopIteration is raised by generator\\n        while True:\\n            yield (\\n                float(self.values[1]),\\n                float(self.values[2]),\\n                float(self.values[3]),\\n            )\\n\\n            try:\\n                self.next_line()\\n            except StopIteration:\\n                break\\n\\n            if not self.values:\\n                break\\n\\n            if self.values[0] != \"vn\":\\n                break',\n",
              " 'def consume_texture_coordinates(self):\\n        \"\"\"Consume all consecutive texture coordinates\"\"\"\\n        # The first iteration processes the current/first vt statement.\\n        # The loop continues until there are no more vt-statements or StopIteration is raised by generator\\n        while True:\\n            yield (\\n                float(self.values[1]),\\n                float(self.values[2]),\\n            )\\n\\n            try:\\n                self.next_line()\\n            except StopIteration:\\n                break\\n\\n            if not self.values:\\n                break\\n\\n            if self.values[0] != \"vt\":\\n                break',\n",
              " 'def consume_faces(self, collected_faces = None):\\n        \"\"\"\\n        Consume all consecutive faces\\n\\n        If more than three vertices are specified, we triangulate by the following procedure:\\n\\n            Let the face have n vertices in the order v_1 v_2 v_3 ... v_n, n >= 3.\\n            We emit the first face as usual: (v_1, v_2, v_3). For each remaining vertex v_j,\\n            j > 3, we emit (v_j, v_1, v_{j - 1}), e.g. (v_4, v_1, v_3), (v_5, v_1, v_4).\\n\\n        In a perfect world we could consume all vertices straight forward and draw using\\n        GL_TRIANGLE_FAN (which exactly matches the procedure above).\\n        This is however rarely the case.\\n\\n        * If the face is co-planar but concave, then you need to triangulate the face.\\n        * If the face is not-coplanar, you are screwed, because OBJ doesn\\'t preserve enough information\\n          to know what tessellation was intended.\\n\\n        We always triangulate to make it simple.\\n\\n            :param collected_faces: A list into which all (possibly triangulated) faces will be written in the form\\n                                    of triples of the corresponding absolute vertex IDs. These IDs index the list\\n                                    self.wavefront.vertices.\\n                                    Specify None to prevent consuming faces (and thus saving memory usage).\\n        \"\"\"\\n\\n        # Helper tuple and function\\n        Vertex = namedtuple(\\'Vertex\\', \\'idx pos color uv normal\\')\\n        def emit_vertex(vertex):\\n            # Just yield all the values except for the index\\n            for v in vertex.uv:\\n                yield v\\n\\n            for v in vertex.color:\\n                yield v\\n\\n            for v in vertex.normal:\\n                yield v\\n\\n            for v in vertex.pos:\\n                yield v\\n\\n\\n        # Figure out the format of the first vertex\\n        # We raise an exception if any following vertex has a different format\\n        # NOTE: Order is always v/vt/vn where v is mandatory and vt and vn is optional\\n        has_vt = False\\n        has_vn = False\\n        has_colors = False\\n\\n        parts = self.values[1].split(\\'/\\')\\n        # We assume texture coordinates are present\\n        if len(parts) == 2:\\n            has_vt = True\\n\\n        # We have a vn, but not necessarily a vt\\n        elif len(parts) == 3:\\n            # Check for empty vt \"1//1\"\\n            if parts[1] != \\'\\':\\n                has_vt = True\\n            has_vn = True\\n\\n        # Are we referencing vertex with color info?\\n        vindex = int(parts[0])\\n        if vindex < 0:\\n            vindex += len(self.wavefront.vertices)\\n        else:\\n            vindex -= 1\\n\\n        vertex = self.wavefront.vertices[vindex]\\n        has_colors = len(vertex) == 6\\n\\n        # Prepare vertex format string\\n        vertex_format = \"_\".join(e[0] for e in [\\n            (\"T2F\", has_vt),\\n            (\"C3F\", has_colors),\\n            (\"N3F\", has_vn),\\n            (\"V3F\", True)\\n        ] if e[1])\\n\\n        # If the material already have vertex data, ensure the same format is used\\n        if self.material.vertex_format and self.material.vertex_format != vertex_format:\\n            raise ValueError((\\n                \"Trying to merge vertex data with different format: {}. \"\\n                \"Material {} has vertex format {}\"\\n            ).format(vertex_format, self.material.name, self.material.vertex_format))\\n\\n        self.material.vertex_format = vertex_format\\n\\n        # The first iteration processes the current/first f statement.\\n        # The loop continues until there are no more f-statements or StopIteration is raised by generator\\n        while True:\\n            # The very first vertex, the last encountered and the current one\\n            v1, vlast, vcurrent = None, None, None\\n\\n            for i, v in enumerate(self.values[1:]):\\n                parts = v.split(\\'/\\')\\n                v_index = (int(parts[0]) - 1)\\n                t_index = (int(parts[1]) - 1) if has_vt else None\\n                n_index = (int(parts[2]) - 1) if has_vn else None\\n\\n                # Resolve negative index lookups\\n                if v_index < 0:\\n                    v_index += len(self.wavefront.vertices) + 1\\n\\n                if has_vt and t_index < 0:\\n                    t_index += len(self.tex_coords) + 1\\n\\n                if has_vn and n_index < 0:\\n                    n_index += len(self.normals) + 1\\n\\n                vlast = vcurrent\\n                vcurrent = Vertex(\\n                    idx = v_index,\\n                    pos = self.wavefront.vertices[v_index][0:3] if has_colors else self.wavefront.vertices[v_index],\\n                    color = self.wavefront.vertices[v_index][3:] if has_colors else (),\\n                    uv = self.tex_coords[t_index] if has_vt and t_index < len(self.tex_coords) else (),\\n                    normal = self.normals[n_index] if has_vn and n_index < len(self.normals) else ()\\n                )\\n\\n                yield from emit_vertex(vcurrent)\\n\\n                # Triangulation when more than 3 elements are present\\n                if i >= 3:\\n                    # The current vertex has already been emitted.\\n                    # Now just emit the first and the third vertices from the face\\n                    yield from emit_vertex(v1)\\n                    yield from emit_vertex(vlast)\\n\\n                if i == 0:\\n                    # Store the first vertex\\n                    v1 = vcurrent\\n\\n                if (collected_faces is not None) and (i >= 2):\\n                    if i == 2:\\n                        # Append the first triangle face in usual order (i.e. as specified in the Wavefront file)\\n                        collected_faces.append([v1.idx, vlast.idx, vcurrent.idx])\\n                    if i >= 3:\\n                        # Triangulate the remaining part of the face by putting the current, the first\\n                        # and the last parsed vertex in that order as a new face.\\n                        # This order coincides deliberately with the order from vertex yielding above.\\n                        collected_faces.append([vcurrent.idx, v1.idx, vlast.idx])\\n\\n            # Break out of the loop when there are no more f statements\\n\\n            try:\\n                self.next_line()\\n            except StopIteration:\\n                break\\n\\n            if not self.values:\\n                break\\n\\n            if self.values[0] != \"f\":\\n                break',\n",
              " 'def check_error(code, context=\"client\"):\\n    \"\"\"\\n    check if the error code is set. If so, a Python log message is generated\\n    and an error is raised.\\n    \"\"\"\\n    if code:\\n        error = error_text(code, context)\\n        logger.error(error)\\n        raise Snap7Exception(error)',\n",
              " 'def error_text(error, context=\"client\"):\\n    \"\"\"Returns a textual explanation of a given error number\\n\\n    :param error: an error integer\\n    :param context: server, client or partner\\n    :returns: the error string\\n    \"\"\"\\n    assert context in (\"client\", \"server\", \"partner\")\\n    logger.debug(\"error text for %s\" % hex(error))\\n    len_ = 1024\\n    text_type = c_char * len_\\n    text = text_type()\\n    library = load_library()\\n    if context == \"client\":\\n        library.Cli_ErrorText(error, text, len_)\\n    elif context == \"server\":\\n        library.Srv_ErrorText(error, text, len_)\\n    elif context == \"partner\":\\n        library.Par_ErrorText(error, text, len_)\\n    return text.value',\n",
              " 'def event_text(self, event):\\n        \"\"\"Returns a textual explanation of a given event object\\n\\n        :param event: an PSrvEvent struct object\\n        :returns: the error string\\n        \"\"\"\\n        logger.debug(\"error text for %s\" % hex(event.EvtCode))\\n        len_ = 1024\\n        text_type = ctypes.c_char * len_\\n        text = text_type()\\n        error = self.library.Srv_EventText(ctypes.byref(event),\\n                                           ctypes.byref(text), len_)\\n        check_error(error)\\n        if six.PY2:\\n            return text.value\\n        else:\\n            return text.value.decode(\\'ascii\\')',\n",
              " 'def create(self):\\n        \"\"\"\\n        create the server.\\n        \"\"\"\\n        logger.info(\"creating server\")\\n        self.library.Srv_Create.restype = snap7.snap7types.S7Object\\n        self.pointer = snap7.snap7types.S7Object(self.library.Srv_Create())',\n",
              " 'def register_area(self, area_code, index, userdata):\\n        \"\"\"Shares a memory area with the server. That memory block will be\\n        visible by the clients.\\n        \"\"\"\\n        size = ctypes.sizeof(userdata)\\n        logger.info(\"registering area %s, index %s, size %s\" % (area_code,\\n                                                                index, size))\\n        size = ctypes.sizeof(userdata)\\n        return self.library.Srv_RegisterArea(self.pointer, area_code, index,\\n                                             ctypes.byref(userdata), size)',\n",
              " 'def set_events_callback(self, call_back):\\n        \"\"\"Sets the user callback that the Server object has to call when an\\n        event is created.\\n        \"\"\"\\n        logger.info(\"setting event callback\")\\n        callback_wrap = ctypes.CFUNCTYPE(None, ctypes.c_void_p,\\n                                         ctypes.POINTER(snap7.snap7types.SrvEvent),\\n                                         ctypes.c_int)\\n\\n        def wrapper(usrptr, pevent, size):\\n            \"\"\"\\n            Wraps python function into a ctypes function\\n\\n            :param usrptr: not used\\n            :param pevent: pointer to snap7 event struct\\n            :param size:\\n            :returns: should return an int\\n            \"\"\"\\n            logger.info(\"callback event: \" + self.event_text(pevent.contents))\\n            call_back(pevent.contents)\\n            return 0\\n\\n        self._callback = callback_wrap(wrapper)\\n        usrPtr = ctypes.c_void_p()\\n        return self.library.Srv_SetEventsCallback(self.pointer, self._callback, usrPtr)',\n",
              " 'def set_read_events_callback(self, call_back):\\n        \"\"\"\\n        Sets the user callback that the Server object has to call when a Read\\n        event is created.\\n\\n        :param call_back: a callback function that accepts a pevent argument.\\n        \"\"\"\\n        logger.info(\"setting read event callback\")\\n        callback_wrapper = ctypes.CFUNCTYPE(None, ctypes.c_void_p,\\n                                            ctypes.POINTER(snap7.snap7types.SrvEvent),\\n                                            ctypes.c_int)\\n\\n        def wrapper(usrptr, pevent, size):\\n            \"\"\"\\n            Wraps python function into a ctypes function\\n\\n            :param usrptr: not used\\n            :param pevent: pointer to snap7 event struct\\n            :param size:\\n            :returns: should return an int\\n            \"\"\"\\n            logger.info(\"callback event: \" + self.event_text(pevent.contents))\\n            call_back(pevent.contents)\\n            return 0\\n\\n        self._read_callback = callback_wrapper(wrapper)\\n        return self.library.Srv_SetReadEventsCallback(self.pointer,\\n                                                      self._read_callback)',\n",
              " 'def _set_log_callback(self):\\n        \"\"\"Sets a callback that logs the events\\n        \"\"\"\\n        logger.debug(\"setting up event logger\")\\n\\n        def log_callback(event):\\n            logger.info(\"callback event: \" + self.event_text(event))\\n\\n        self.set_events_callback(log_callback)',\n",
              " 'def start(self, tcpport=102):\\n        \"\"\"\\n        start the server.\\n        \"\"\"\\n        if tcpport != 102:\\n            logger.info(\"setting server TCP port to %s\" % tcpport)\\n            self.set_param(snap7.snap7types.LocalPort, tcpport)\\n        logger.info(\"starting server on 0.0.0.0:%s\" % tcpport)\\n        return self.library.Srv_Start(self.pointer)',\n",
              " 'def destroy(self):\\n        \"\"\"\\n        destroy the server.\\n        \"\"\"\\n        logger.info(\"destroying server\")\\n        if self.library:\\n            self.library.Srv_Destroy(ctypes.byref(self.pointer))',\n",
              " 'def get_status(self):\\n        \"\"\"Reads the server status, the Virtual CPU status and the number of\\n        the clients connected.\\n\\n        :returns: server status, cpu status, client count\\n        \"\"\"\\n        logger.debug(\"get server status\")\\n        server_status = ctypes.c_int()\\n        cpu_status = ctypes.c_int()\\n        clients_count = ctypes.c_int()\\n        error = self.library.Srv_GetStatus(self.pointer, ctypes.byref(server_status),\\n                                           ctypes.byref(cpu_status),\\n                                           ctypes.byref(clients_count))\\n        check_error(error)\\n        logger.debug(\"status server %s cpu %s clients %s\" %\\n                     (server_status.value, cpu_status.value,\\n                      clients_count.value))\\n        return snap7.snap7types.server_statuses[server_status.value], \\\\\\n               snap7.snap7types.cpu_statuses[cpu_status.value], \\\\\\n               clients_count.value',\n",
              " 'def unregister_area(self, area_code, index):\\n        \"\"\"\\'Unshares\\' a memory area previously shared with Srv_RegisterArea().\\n        That memory block will be no longer visible by the clients.\\n        \"\"\"\\n        return self.library.Srv_UnregisterArea(self.pointer, area_code, index)',\n",
              " 'def unlock_area(self, code, index):\\n        \"\"\"Unlocks a previously locked shared memory area.\\n        \"\"\"\\n        logger.debug(\"unlocking area code %s index %s\" % (code, index))\\n        return self.library.Srv_UnlockArea(self.pointer, code, index)',\n",
              " 'def lock_area(self, code, index):\\n        \"\"\"Locks a shared memory area.\\n        \"\"\"\\n        logger.debug(\"locking area code %s index %s\" % (code, index))\\n        return self.library.Srv_LockArea(self.pointer, code, index)',\n",
              " 'def start_to(self, ip, tcpport=102):\\n        \"\"\"\\n        start server on a specific interface.\\n        \"\"\"\\n        if tcpport != 102:\\n            logger.info(\"setting server TCP port to %s\" % tcpport)\\n            self.set_param(snap7.snap7types.LocalPort, tcpport)\\n        assert re.match(ipv4, ip), \\'%s is invalid ipv4\\' % ip\\n        logger.info(\"starting server to %s:102\" % ip)\\n        return self.library.Srv_Start(self.pointer, ip)',\n",
              " 'def set_param(self, number, value):\\n        \"\"\"Sets an internal Server object parameter.\\n        \"\"\"\\n        logger.debug(\"setting param number %s to %s\" % (number, value))\\n        return self.library.Srv_SetParam(self.pointer, number,\\n                                         ctypes.byref(ctypes.c_int(value)))',\n",
              " 'def set_mask(self, kind, mask):\\n        \"\"\"Writes the specified filter mask.\\n        \"\"\"\\n        logger.debug(\"setting mask kind %s to %s\" % (kind, mask))\\n        return self.library.Srv_SetMask(self.pointer, kind, mask)',\n",
              " 'def set_cpu_status(self, status):\\n        \"\"\"Sets the Virtual CPU status.\\n        \"\"\"\\n        assert status in snap7.snap7types.cpu_statuses, \\'unknown cpu state %s\\' % status\\n        logger.debug(\"setting cpu status to %s\" % status)\\n        return self.library.Srv_SetCpuStatus(self.pointer, status)',\n",
              " 'def pick_event(self):\\n        \"\"\"Extracts an event (if available) from the Events queue.\\n        \"\"\"\\n        logger.debug(\"checking event queue\")\\n        event = snap7.snap7types.SrvEvent()\\n        ready = ctypes.c_int32()\\n        code = self.library.Srv_PickEvent(self.pointer, ctypes.byref(event),\\n                                          ctypes.byref(ready))\\n        check_error(code)\\n        if ready:\\n            logger.debug(\"one event ready: %s\" % event)\\n            return event\\n        logger.debug(\"no events ready\")',\n",
              " 'def get_param(self, number):\\n        \"\"\"Reads an internal Server object parameter.\\n        \"\"\"\\n        logger.debug(\"retreiving param number %s\" % number)\\n        value = ctypes.c_int()\\n        code = self.library.Srv_GetParam(self.pointer, number,\\n                                         ctypes.byref(value))\\n        check_error(code)\\n        return value.value',\n",
              " 'def get_mask(self, kind):\\n        \"\"\"Reads the specified filter mask.\\n        \"\"\"\\n        logger.debug(\"retrieving mask kind %s\" % kind)\\n        mask = snap7.snap7types.longword()\\n        code = self.library.Srv_GetMask(self.pointer, kind, ctypes.byref(mask))\\n        check_error(code)\\n        return mask',\n",
              " 'def error_wrap(func):\\n    \"\"\"Parses a s7 error code returned the decorated function.\"\"\"\\n    def f(*args, **kw):\\n        code = func(*args, **kw)\\n        check_error(code, context=\"client\")\\n    return f',\n",
              " 'def create(self):\\n        \"\"\"\\n        create a SNAP7 client.\\n        \"\"\"\\n        logger.info(\"creating snap7 client\")\\n        self.library.Cli_Create.restype = c_void_p\\n        self.pointer = S7Object(self.library.Cli_Create())',\n",
              " 'def destroy(self):\\n        \"\"\"\\n        destroy a client.\\n        \"\"\"\\n        logger.info(\"destroying snap7 client\")\\n        if self.library:\\n            return self.library.Cli_Destroy(byref(self.pointer))',\n",
              " 'def get_cpu_state(self):\\n        \"\"\"\\n        Retrieves CPU state from client\\n        \"\"\"\\n        state = c_int(0)\\n        self.library.Cli_GetPlcStatus(self.pointer,byref(state))\\n        \\n        try:\\n            status_string = cpu_statuses[state.value]\\n        except KeyError:\\n            status_string = None\\n        \\n        if not status_string:\\n            raise Snap7Exception(\"The cpu state (%s) is invalid\" % state.value)\\n        \\n        logger.debug(\"CPU state is %s\" % status_string)\\n        return status_string',\n",
              " 'def get_cpu_info(self):\\n        \"\"\"\\n        Retrieves CPU info from client\\n        \"\"\"\\n        info = snap7.snap7types.S7CpuInfo()\\n        result = self.library.Cli_GetCpuInfo(self.pointer, byref(info))\\n        check_error(result, context=\"client\")\\n        return info',\n",
              " 'def connect(self, address, rack, slot, tcpport=102):\\n        \"\"\"\\n        Connect to a S7 server.\\n\\n        :param address: IP address of server\\n        :param rack: rack on server\\n        :param slot: slot on server.\\n        \"\"\"\\n        logger.info(\"connecting to %s:%s rack %s slot %s\" % (address, tcpport,\\n                                                             rack, slot))\\n\\n        self.set_param(snap7.snap7types.RemotePort, tcpport)\\n        return self.library.Cli_ConnectTo(\\n            self.pointer, c_char_p(six.b(address)),\\n            c_int(rack), c_int(slot))',\n",
              " 'def db_read(self, db_number, start, size):\\n        \"\"\"This is a lean function of Cli_ReadArea() to read PLC DB.\\n\\n        :returns: user buffer.\\n        \"\"\"\\n        logger.debug(\"db_read, db_number:%s, start:%s, size:%s\" %\\n                     (db_number, start, size))\\n\\n        type_ = snap7.snap7types.wordlen_to_ctypes[snap7.snap7types.S7WLByte]\\n        data = (type_ * size)()\\n        result = (self.library.Cli_DBRead(\\n            self.pointer, db_number, start, size,\\n            byref(data)))\\n        check_error(result, context=\"client\")\\n        return bytearray(data)',\n",
              " 'def delete(self, block_type, block_num):\\n        \"\"\"\\n        Deletes a block\\n        \\n        :param block_type: Type of block\\n        :param block_num: Bloc number\\n        \"\"\"\\n        logger.info(\"deleting block\")\\n        blocktype = snap7.snap7types.block_types[block_type]\\n        result = self.library.Cli_Delete(self.pointer, blocktype, block_num)\\n        return result',\n",
              " 'def full_upload(self, _type, block_num):\\n        \"\"\"\\n        Uploads a full block body from AG.\\n        The whole block (including header and footer) is copied into the user\\n        buffer.\\n\\n        :param block_num: Number of Block\\n        \"\"\"\\n        _buffer = buffer_type()\\n        size = c_int(sizeof(_buffer))\\n        block_type = snap7.snap7types.block_types[_type]\\n        result = self.library.Cli_FullUpload(self.pointer, block_type,\\n                                             block_num, byref(_buffer),\\n                                             byref(size))\\n        check_error(result, context=\"client\")\\n        return bytearray(_buffer), size.value',\n",
              " 'def upload(self, block_num):\\n        \"\"\"\\n        Uploads a block body from AG\\n\\n        :param data: bytearray\\n        \"\"\"\\n        logger.debug(\"db_upload block_num: %s\" % (block_num))\\n\\n        block_type = snap7.snap7types.block_types[\\'DB\\']\\n        _buffer = buffer_type()\\n        size = c_int(sizeof(_buffer))\\n\\n        result = self.library.Cli_Upload(self.pointer, block_type, block_num,\\n                                         byref(_buffer), byref(size))\\n\\n        check_error(result, context=\"client\")\\n        logger.info(\\'received %s bytes\\' % size)\\n        return bytearray(_buffer)',\n",
              " 'def download(self, data, block_num=-1):\\n        \"\"\"\\n        Downloads a DB data into the AG.\\n        A whole block (including header and footer) must be available into the\\n        user buffer.\\n\\n        :param block_num: New Block number (or -1)\\n        :param data: the user buffer\\n        \"\"\"\\n        type_ = c_byte\\n        size = len(data)\\n        cdata = (type_ * len(data)).from_buffer_copy(data)\\n        result = self.library.Cli_Download(self.pointer, block_num,\\n                                           byref(cdata), size)\\n        return result',\n",
              " 'def db_get(self, db_number):\\n        \"\"\"Uploads a DB from AG.\\n        \"\"\"\\n        logger.debug(\"db_get db_number: %s\" % db_number)\\n        _buffer = buffer_type()\\n        result = self.library.Cli_DBGet(\\n            self.pointer, db_number, byref(_buffer),\\n            byref(c_int(buffer_size)))\\n        check_error(result, context=\"client\")\\n        return bytearray(_buffer)',\n",
              " 'def read_area(self, area, dbnumber, start, size):\\n        \"\"\"This is the main function to read data from a PLC.\\n        With it you can read DB, Inputs, Outputs, Merkers, Timers and Counters.\\n\\n        :param dbnumber: The DB number, only used when area= S7AreaDB\\n        :param start: offset to start writing\\n        :param size: number of units to read\\n        \"\"\"\\n        assert area in snap7.snap7types.areas.values()\\n        wordlen = snap7.snap7types.S7WLByte\\n        type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        logger.debug(\"reading area: %s dbnumber: %s start: %s: amount %s: \"\\n                      \"wordlen: %s\" % (area, dbnumber, start, size, wordlen))\\n        data = (type_ * size)()\\n        result = self.library.Cli_ReadArea(self.pointer, area, dbnumber, start,\\n                                           size, wordlen, byref(data))\\n        check_error(result, context=\"client\")\\n        return bytearray(data)',\n",
              " 'def write_area(self, area, dbnumber, start, data):\\n        \"\"\"This is the main function to write data into a PLC. It\\'s the\\n        complementary function of Cli_ReadArea(), the parameters and their\\n        meanings are the same. The only difference is that the data is\\n        transferred from the buffer pointed by pUsrData into PLC.\\n\\n        :param dbnumber: The DB number, only used when area= S7AreaDB\\n        :param start: offset to start writing\\n        :param data: a bytearray containing the payload\\n        \"\"\"\\n        wordlen = snap7.snap7types.S7WLByte\\n        type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        size = len(data)\\n        logger.debug(\"writing area: %s dbnumber: %s start: %s: size %s: \"\\n                      \"type: %s\" % (area, dbnumber, start, size, type_))\\n        cdata = (type_ * len(data)).from_buffer_copy(data)\\n        return self.library.Cli_WriteArea(self.pointer, area, dbnumber, start,\\n                                          size, wordlen, byref(cdata))',\n",
              " 'def read_multi_vars(self, items):\\n        \"\"\"This function read multiple variables from the PLC.\\n\\n        :param items: list of S7DataItem objects\\n        :returns: a tuple with the return code and a list of data items\\n        \"\"\"\\n        result = self.library.Cli_ReadMultiVars(self.pointer, byref(items),\\n                                                c_int32(len(items)))\\n        check_error(result, context=\"client\")\\n        return result, items',\n",
              " 'def list_blocks(self):\\n        \"\"\"Returns the AG blocks amount divided by type.\\n\\n        :returns: a snap7.types.BlocksList object.\\n        \"\"\"\\n        logger.debug(\"listing blocks\")\\n        blocksList = BlocksList()\\n        result = self.library.Cli_ListBlocks(self.pointer, byref(blocksList))\\n        check_error(result, context=\"client\")\\n        logger.debug(\"blocks: %s\" % blocksList)\\n        return blocksList',\n",
              " 'def list_blocks_of_type(self, blocktype, size):\\n        \"\"\"This function returns the AG list of a specified block type.\"\"\"\\n\\n        blocktype = snap7.snap7types.block_types.get(blocktype)\\n\\n        if not blocktype:\\n            raise Snap7Exception(\"The blocktype parameter was invalid\")\\n\\n        logger.debug(\"listing blocks of type: %s size: %s\" %\\n                      (blocktype, size))\\n\\n        if (size == 0):\\n            return 0\\n\\t\\t\\n        data = (c_uint16 * size)()\\n        count = c_int(size)\\n        result = self.library.Cli_ListBlocksOfType(\\n            self.pointer, blocktype,\\n            byref(data),\\n            byref(count))\\n\\n        logger.debug(\"number of items found: %s\" % count)\\n\\n        check_error(result, context=\"client\")\\n        return data',\n",
              " 'def get_block_info(self, blocktype, db_number):\\n        \"\"\"Returns the block information for the specified block.\"\"\"\\n\\n        blocktype = snap7.snap7types.block_types.get(blocktype)\\n\\n        if not blocktype:\\n            raise Snap7Exception(\"The blocktype parameter was invalid\")\\n\\n        logger.debug(\"retrieving block info for block %s of type %s\" %\\n                      (db_number, blocktype))\\n\\n        data = TS7BlockInfo()\\n\\n        result = self.library.Cli_GetAgBlockInfo(\\n            self.pointer, blocktype,\\n            db_number, byref(data))\\n        check_error(result, context=\"client\")\\n        return data',\n",
              " 'def set_session_password(self, password):\\n        \"\"\"Send the password to the PLC to meet its security level.\"\"\"\\n        assert len(password) <= 8, \\'maximum password length is 8\\'\\n        return self.library.Cli_SetSessionPassword(self.pointer,\\n                                                   c_char_p(six.b(password)))',\n",
              " 'def set_connection_params(self, address, local_tsap, remote_tsap):\\n        \"\"\"\\n        Sets internally (IP, LocalTSAP, RemoteTSAP) Coordinates.\\n        This function must be called just before Cli_Connect().\\n\\n        :param address: PLC/Equipment IPV4 Address, for example \"192.168.1.12\"\\n        :param local_tsap: Local TSAP (PC TSAP)\\n        :param remote_tsap: Remote TSAP (PLC TSAP)\\n        \"\"\"\\n        assert re.match(ipv4, address), \\'%s is invalid ipv4\\' % address\\n        result = self.library.Cli_SetConnectionParams(self.pointer, address,\\n                                                      c_uint16(local_tsap),\\n                                                      c_uint16(remote_tsap))\\n        if result != 0:\\n            raise Snap7Exception(\"The parameter was invalid\")',\n",
              " 'def set_connection_type(self, connection_type):\\n        \"\"\"\\n        Sets the connection resource type, i.e the way in which the Clients\\n        connects to a PLC.\\n\\n        :param connection_type: 1 for PG, 2 for OP, 3 to 10 for S7 Basic\\n        \"\"\"\\n        result = self.library.Cli_SetConnectionType(self.pointer,\\n                                                    c_uint16(connection_type))\\n        if result != 0:\\n            raise Snap7Exception(\"The parameter was invalid\")',\n",
              " 'def get_connected(self):\\n        \"\"\"\\n        Returns the connection status\\n\\n        :returns: a boolean that indicates if connected.\\n        \"\"\"\\n        connected = c_int32()\\n        result = self.library.Cli_GetConnected(self.pointer, byref(connected))\\n        check_error(result, context=\"client\")\\n        return bool(connected)',\n",
              " 'def ab_read(self, start, size):\\n        \"\"\"\\n        This is a lean function of Cli_ReadArea() to read PLC process outputs.\\n        \"\"\"\\n        wordlen = snap7.snap7types.S7WLByte\\n        type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        data = (type_ * size)()\\n        logger.debug(\"ab_read: start: %s: size %s: \" % (start, size))\\n        result = self.library.Cli_ABRead(self.pointer, start, size,\\n                                         byref(data))\\n        check_error(result, context=\"client\")\\n        return bytearray(data)',\n",
              " 'def as_ab_write(self, start, data):\\n        \"\"\"\\n        This is the asynchronous counterpart of Cli_ABWrite.\\n        \"\"\"\\n        wordlen = snap7.snap7types.S7WLByte\\n        type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        size = len(data)\\n        cdata = (type_ * size).from_buffer_copy(data)\\n        logger.debug(\"ab write: start: %s: size: %s: \" % (start, size))\\n        return self.library.Cli_AsABWrite(\\n            self.pointer, start, size, byref(cdata))',\n",
              " 'def as_db_get(self, db_number):\\n        \"\"\"\\n        This is the asynchronous counterpart of Cli_DBGet.\\n        \"\"\"\\n        logger.debug(\"db_get db_number: %s\" % db_number)\\n        _buffer = buffer_type()\\n        result = self.library.Cli_AsDBGet(self.pointer, db_number,\\n                                          byref(_buffer),\\n                                          byref(c_int(buffer_size)))\\n        check_error(result, context=\"client\")\\n        return bytearray(_buffer)',\n",
              " 'def as_download(self, data, block_num=-1):\\n        \"\"\"\\n        Downloads a DB data into the AG asynchronously.\\n        A whole block (including header and footer) must be available into the\\n        user buffer.\\n\\n        :param block_num: New Block number (or -1)\\n        :param data: the user buffer\\n        \"\"\"\\n        size = len(data)\\n        type_ = c_byte * len(data)\\n        cdata = type_.from_buffer_copy(data)\\n        return self.library.Cli_AsDownload(self.pointer, block_num,\\n                                           byref(cdata), size)',\n",
              " 'def set_param(self, number, value):\\n        \"\"\"Sets an internal Server object parameter.\\n        \"\"\"\\n        logger.debug(\"setting param number %s to %s\" % (number, value))\\n        type_ = param_types[number]\\n        return self.library.Cli_SetParam(self.pointer, number,\\n                                         byref(type_(value)))',\n",
              " 'def get_param(self, number):\\n        \"\"\"Reads an internal Client object parameter.\\n        \"\"\"\\n        logger.debug(\"retreiving param number %s\" % number)\\n        type_ = param_types[number]\\n        value = type_()\\n        code = self.library.Cli_GetParam(self.pointer, c_int(number),\\n                                         byref(value))\\n        check_error(code)\\n        return value.value',\n",
              " 'def get_pdu_length(self):\\n        \"\"\"\\n        Returns info about the PDU length.\\n        \"\"\"\\n        logger.info(\"getting PDU length\")\\n        requested_ = c_uint16()\\n        negotiated_ = c_uint16()\\n        code = self.library.Cli_GetPduLength(self.pointer, byref(requested_), byref(negotiated_))\\n        check_error(code)\\n\\n        return negotiated_.value',\n",
              " 'def get_plc_datetime(self):\\n        \"\"\"\\n        Get date and time from PLC.\\n\\n        :return: date and time as datetime\\n        \"\"\"\\n        type_ = c_int32\\n        buffer = (type_ * 9)()\\n        result = self.library.Cli_GetPlcDateTime(self.pointer, byref(buffer))\\n        check_error(result, context=\"client\")\\n\\n        return datetime(\\n            year = buffer[5] + 1900,\\n            month = buffer[4] + 1,\\n            day = buffer[3],\\n            hour = buffer[2],\\n            minute = buffer[1],\\n            second = buffer[0]\\n        )',\n",
              " 'def set_plc_datetime(self, dt):\\n        \"\"\"\\n        Set date and time in PLC\\n\\n        :param dt: date and time as datetime\\n        \"\"\"\\n        type_ = c_int32\\n        buffer = (type_ * 9)()\\n        buffer[0] = dt.second\\n        buffer[1] = dt.minute\\n        buffer[2] = dt.hour\\n        buffer[3] = dt.day\\n        buffer[4] = dt.month - 1\\n        buffer[5] = dt.year - 1900\\n\\n        return self.library.Cli_SetPlcDateTime(self.pointer, byref(buffer))',\n",
              " 'def get_db1():\\n    \"\"\"\\n    Here we read out DB1, all data we is put in the all_data\\n    variable and is a bytearray with the raw plc data\\n    \"\"\"\\n    all_data = client.db_get(1)\\n\\n    for i in range(400):                 # items in db\\n        row_size = 130                   # size of item\\n        index = i * row_size\\n        offset = index + row_size        # end of row in db\\n        util.print_row(all_data[index:offset])',\n",
              " 'def get_db_row(db, start, size):\\n    \"\"\"\\n    Here you see and example of readying out a part of a DB\\n\\n    Args:\\n        db (int): The db to use\\n        start (int): The index of where to start in db data\\n        size (int): The size of the db data to read\\n    \"\"\"\\n    type_ = snap7.snap7types.wordlen_to_ctypes[snap7.snap7types.S7WLByte]\\n    data = client.db_read(db, start, type_, size)\\n    # print_row(data[:60])\\n    return data',\n",
              " 'def set_db_row(db, start, size, _bytearray):\\n    \"\"\"\\n    Here we replace a piece of data in a db block with new data\\n\\n    Args:\\n       db (int): The db to use\\n       start(int): The start within the db\\n       size(int): The size of the data in bytes\\n       _butearray (enumerable): The data to put in the db\\n    \"\"\"\\n    client.db_write(db, start, size, _bytearray)',\n",
              " 'def show_row(x):\\n    \"\"\"\\n    print data in DB of row/object X in\\n    \"\"\"\\n\\n    row_size = 126\\n\\n    while True:\\n        data = get_db_row(1, 4 + x * row_size, row_size)\\n        row = snap7.util.DB_Row(data, rc_if_db_1_layout,\\n                                layout_offset=4)\\n        print \\'name\\', row[\\'RC_IF_NAME\\']\\n        print row[\\'RC_IF_NAME\\']\\n        break',\n",
              " 'def set_row(x, row):\\n    \"\"\"\\n    We use db 1, use offset 4, we replace row x. To find the correct\\n    start_index we mulitpy by row_size by x and we put the\\n    byte array representation of row in the PLC\\n    \"\"\"\\n    row_size = 126\\n    set_db_row(1, 4 + x * row_size, row_size, row._bytearray)',\n",
              " 'def get_bool(_bytearray, byte_index, bool_index):\\n    \"\"\"\\n    Get the boolean value from location in bytearray\\n    \"\"\"\\n    index_value = 1 << bool_index\\n    byte_value = _bytearray[byte_index]\\n    current_value = byte_value & index_value\\n    return current_value == index_value',\n",
              " 'def set_bool(_bytearray, byte_index, bool_index, value):\\n    \"\"\"\\n    Set boolean value on location in bytearray\\n    \"\"\"\\n    assert value in [0, 1, True, False]\\n    current_value = get_bool(_bytearray, byte_index, bool_index)\\n    index_value = 1 << bool_index\\n\\n    # check if bool already has correct value\\n    if current_value == value:\\n        return\\n\\n    if value:\\n        # make sure index_v is IN current byte\\n        _bytearray[byte_index] += index_value\\n    else:\\n        # make sure index_v is NOT in current byte\\n        _bytearray[byte_index] -= index_value',\n",
              " 'def set_int(bytearray_, byte_index, _int):\\n    \"\"\"\\n    Set value in bytearray to int\\n    \"\"\"\\n    # make sure were dealing with an int\\n    _int = int(_int)\\n    _bytes = struct.unpack(\\'2B\\', struct.pack(\\'>h\\', _int))\\n    bytearray_[byte_index:byte_index + 2] = _bytes\\n    return bytearray_',\n",
              " 'def get_int(bytearray_, byte_index):\\n    \"\"\"\\n    Get int value from bytearray.\\n\\n    int are represented in two bytes\\n    \"\"\"\\n    data = bytearray_[byte_index:byte_index + 2]\\n    data[1] = data[1] & 0xff\\n    data[0] = data[0] & 0xff\\n    packed = struct.pack(\\'2B\\', *data)\\n    value = struct.unpack(\\'>h\\', packed)[0]\\n    return value',\n",
              " 'def set_real(_bytearray, byte_index, real):\\n    \"\"\"\\n    Set Real value\\n\\n    make 4 byte data from real\\n\\n    \"\"\"\\n    real = float(real)\\n    real = struct.pack(\\'>f\\', real)\\n    _bytes = struct.unpack(\\'4B\\', real)\\n    for i, b in enumerate(_bytes):\\n        _bytearray[byte_index + i] = b',\n",
              " 'def get_real(_bytearray, byte_index):\\n    \"\"\"\\n    Get real value. create float from 4 bytes\\n    \"\"\"\\n    x = _bytearray[byte_index:byte_index + 4]\\n    real = struct.unpack(\\'>f\\', struct.pack(\\'4B\\', *x))[0]\\n    return real',\n",
              " 'def set_string(_bytearray, byte_index, value, max_size):\\n    \"\"\"\\n    Set string value\\n\\n    :params value: string data\\n    :params max_size: max possible string size\\n    \"\"\"\\n    if six.PY2:\\n        assert isinstance(value, (str, unicode))\\n    else:\\n        assert isinstance(value, str)\\n\\n    size = len(value)\\n    # FAIL HARD WHEN trying to write too much data into PLC\\n    if size > max_size:\\n        raise ValueError(\\'size %s > max_size %s %s\\' % (size, max_size, value))\\n    # set len count on first position\\n    _bytearray[byte_index + 1] = len(value)\\n\\n    i = 0\\n    # fill array which chr integers\\n    for i, c in enumerate(value):\\n        _bytearray[byte_index + 2 + i] = ord(c)\\n\\n    # fill the rest with empty space\\n    for r in range(i + 1, _bytearray[byte_index]):\\n        _bytearray[byte_index + 2 + r] = ord(\\' \\')',\n",
              " 'def get_string(_bytearray, byte_index, max_size):\\n    \"\"\"\\n    parse string from bytearray\\n    \"\"\"\\n    size = _bytearray[byte_index + 1]\\n\\n    if max_size < size:\\n        logger.error(\"the string is to big for the size encountered in specification\")\\n        logger.error(\"WRONG SIZED STRING ENCOUNTERED\")\\n        size = max_size\\n\\n    data = map(chr, _bytearray[byte_index + 2:byte_index + 2 + size])\\n    return \"\".join(data)',\n",
              " 'def parse_specification(db_specification):\\n    \"\"\"\\n    Create a db specification derived from a\\n    dataview of a db in which the byte layout\\n    is specified\\n    \"\"\"\\n    parsed_db_specification = OrderedDict()\\n\\n    for line in db_specification.split(\\'\\\\n\\'):\\n        if line and not line.startswith(\\'#\\'):\\n            row = line.split(\\'#\\')[0]  # remove trailing comment\\n            index, var_name, _type = row.split()\\n            parsed_db_specification[var_name] = (index, _type)\\n\\n    return parsed_db_specification',\n",
              " 'def get_bytearray(self):\\n        \"\"\"\\n        return bytearray from self or DB parent\\n        \"\"\"\\n        if isinstance(self._bytearray, DB):\\n            return self._bytearray._bytearray\\n        return self._bytearray',\n",
              " 'def export(self):\\n        \"\"\"\\n        export dictionary with values\\n        \"\"\"\\n        data = {}\\n        for key in self._specification:\\n            data[key] = self[key]\\n        return data',\n",
              " 'def write(self, client):\\n        \"\"\"\\n        Write current data to db in plc\\n        \"\"\"\\n        assert(isinstance(self._bytearray, DB))\\n        assert(self.row_size >= 0)\\n\\n        db_nr = self._bytearray.db_number\\n        offset = self.db_offset\\n        data = self.get_bytearray()[offset:offset+self.row_size]\\n        db_offset = self.db_offset\\n\\n        # indicate start of write only area of row!\\n        if self.row_offset:\\n            data = data[self.row_offset:]\\n            db_offset += self.row_offset\\n\\n        client.db_write(db_nr, db_offset, data)',\n",
              " 'def read(self, client):\\n        \"\"\"\\n        read current data of db row from plc\\n        \"\"\"\\n        assert(isinstance(self._bytearray, DB))\\n        assert(self.row_size >= 0)\\n        db_nr = self._bytearray.db_number\\n        _bytearray = client.db_read(db_nr, self.db_offset, self.row_size)\\n\\n        data = self.get_bytearray()\\n        # replace data in bytearray\\n        for i, b in enumerate(_bytearray):\\n            data[i + self.db_offset] = b',\n",
              " 'def disconnect(self):\\n        \"\"\"\\n        disconnect a client.\\n        \"\"\"\\n        logger.info(\"disconnecting snap7 client\")\\n        result = self.library.Cli_Disconnect(self.pointer)\\n        check_error(result, context=\"client\") \\n        return result',\n",
              " 'def connect(self, ip_address, tsap_snap7, tsap_logo, tcpport=102):\\n        \"\"\"\\n        Connect to a Siemens LOGO server. Howto setup Logo communication configuration see: http://snap7.sourceforge.net/logo.html\\n\\n        :param ip_address: IP ip_address of server\\n        :param tsap_snap7: TSAP SNAP7 Client (e.g. 10.00 = 0x1000)\\n        :param tsap_logo: TSAP Logo Server (e.g. 20.00 = 0x2000)\\n        \"\"\"\\n        logger.info(\"connecting to %s:%s tsap_snap7 %s tsap_logo %s\" % (ip_address, tcpport,\\n                                                             tsap_snap7, tsap_logo))\\n        # special handling for Siemens Logo\\n        # 1st set connection params\\n        # 2nd connect without any parameters\\n        self.set_param(snap7.snap7types.RemotePort, tcpport)\\n        self.set_connection_params(ip_address, tsap_snap7, tsap_logo)\\n        result = self.library.Cli_Connect(self.pointer)\\n        check_error(result, context=\"client\") \\n        return result',\n",
              " 'def read(self, vm_address):\\n        \"\"\"\\n        Reads from VM addresses of Siemens Logo. Examples: read(\"V40\") / read(\"VW64\") / read(\"V10.2\") \\n        \\n        :param vm_address: of Logo memory (e.g. V30.1, VW32, V24)\\n        :returns: integer\\n        \"\"\"\\n        area = snap7types.S7AreaDB\\n        db_number = 1\\n        size = 1\\n        start = 0\\n        wordlen = 0\\n        logger.debug(\"read, vm_address:%s\" % (vm_address))\\n        if re.match(\"V[0-9]{1,4}\\\\.[0-7]{1}\", vm_address):\\n            ## bit value\\n            logger.info(\"read, Bit address: \" + vm_address)\\n            address = vm_address[1:].split(\".\")\\n            # transform string to int\\n            address_byte = int(address[0])\\n            address_bit = int(address[1])\\n            start = (address_byte*8)+address_bit\\n            wordlen = snap7types.S7WLBit\\n        elif re.match(\"V[0-9]+\", vm_address):\\n            ## byte value\\n            logger.info(\"Byte address: \" + vm_address)\\n            start = int(vm_address[1:])\\n            wordlen = snap7types.S7WLByte\\n        elif re.match(\"VW[0-9]+\", vm_address):\\n            ## byte value\\n            logger.info(\"Word address: \" + vm_address)\\n            start = int(vm_address[2:])\\n            wordlen = snap7types.S7WLWord\\n        elif re.match(\"VD[0-9]+\", vm_address):\\n            ## byte value\\n            logger.info(\"DWord address: \" + vm_address)\\n            start = int(vm_address[2:])\\n            wordlen = snap7types.S7WLDWord\\n        else:\\n            logger.info(\"Unknown address format\")\\n            return 0\\n             \\n        type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        data = (type_ * size)()\\n\\n        logger.debug(\"start:%s, wordlen:%s, data-length:%s\" % (start, wordlen, len(data)) )\\n\\n        result = self.library.Cli_ReadArea(self.pointer, area, db_number, start,\\n                                           size, wordlen, byref(data))\\n        check_error(result, context=\"client\")\\n        # transform result to int value\\n        if wordlen == snap7types.S7WLBit:\\n            return(data)[0]\\n        if wordlen == snap7types.S7WLByte:\\n            return struct.unpack_from(\">B\", data)[0]\\n        if wordlen == snap7types.S7WLWord:\\n            return struct.unpack_from(\">h\", data)[0]\\n        if wordlen == snap7types.S7WLDWord:\\n            return struct.unpack_from(\">l\", data)[0]',\n",
              " 'def write (self, vm_address, value):\\n        \"\"\"\\n        Writes to VM addresses of Siemens Logo.\\n        Example: write(\"VW10\", 200) or write(\"V10.3\", 1)\\n\\n        :param vm_address: write offset\\n        :param value: integer\\n        \"\"\"\\n        area = snap7types.S7AreaDB\\n        db_number = 1\\n        start = 0\\n        amount = 1\\n        wordlen = 0\\n        data = bytearray(0)\\n        logger.debug(\"write, vm_address:%s, value:%s\" %\\n                     (vm_address, value))\\n        if re.match(\"^V[0-9]{1,4}\\\\.[0-7]{1}$\", vm_address):\\n            ## bit value\\n            logger.info(\"read, Bit address: \" + vm_address)\\n            address = vm_address[1:].split(\".\")\\n            # transform string to int\\n            address_byte = int(address[0])\\n            address_bit = int(address[1])\\n            start = (address_byte*8)+address_bit\\n            wordlen = snap7types.S7WLBit\\n            if value > 0:\\n                data = bytearray([1])    \\n            else:\\n                data = bytearray([0])\\n        elif re.match(\"^V[0-9]+$\", vm_address):\\n            ## byte value\\n            logger.info(\"Byte address: \" + vm_address)\\n            start = int(vm_address[1:])\\n            wordlen = snap7types.S7WLByte\\n            data = bytearray(struct.pack(\">B\", value))\\n        elif re.match(\"^VW[0-9]+$\", vm_address):\\n            ## byte value\\n            logger.info(\"Word address: \" + vm_address)\\n            start = int(vm_address[2:])\\n            wordlen = snap7types.S7WLWord\\n            data = bytearray(struct.pack(\">h\", value))\\n        elif re.match(\"^VD[0-9]+$\", vm_address):\\n            ## byte value\\n            logger.info(\"DWord address: \" + vm_address)\\n            start = int(vm_address[2:])\\n            wordlen = snap7types.S7WLDWord\\n            data = bytearray(struct.pack(\">l\", value))\\n        else:\\n            logger.info(\"write, Unknown address format: \" + vm_address)\\n            return 1\\n        \\n        if wordlen == snap7types.S7WLBit:\\n            type_ = snap7.snap7types.wordlen_to_ctypes[snap7types.S7WLByte]\\n        else:\\n            type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\\n        \\n        cdata = (type_ * amount).from_buffer_copy(data)\\n\\n        logger.debug(\"write, vm_address:%s value:%s\" % (vm_address, value))\\n\\n        result = self.library.Cli_WriteArea(self.pointer, area, db_number, start,\\n                                          amount, wordlen, byref(cdata))\\n        check_error(result, context=\"client\")\\n        return result',\n",
              " 'def set_connection_params(self, ip_address, tsap_snap7, tsap_logo):\\n        \"\"\"\\n        Sets internally (IP, LocalTSAP, RemoteTSAP) Coordinates.\\n        This function must be called just before Cli_Connect().\\n\\n        :param ip_address: IP ip_address of server\\n        :param tsap_snap7: TSAP SNAP7 Client (e.g. 10.00 = 0x1000)\\n        :param tsap_logo: TSAP Logo Server (e.g. 20.00 = 0x2000)\\n        \"\"\"\\n        assert re.match(ipv4, ip_address), \\'%s is invalid ipv4\\' % ip_address\\n        result = self.library.Cli_SetConnectionParams(self.pointer, ip_address.encode(),\\n                                                      c_uint16(tsap_snap7),\\n                                                      c_uint16(tsap_logo))\\n        if result != 0:\\n            raise Snap7Exception(\"The parameter was invalid\")',\n",
              " 'def check_as_b_send_completion(self):\\n        \"\"\"\\n        Checks if the current asynchronous send job was completed and terminates\\n        immediately.\\n        \"\"\"\\n        op_result = ctypes.c_int32()\\n        result = self.library.Par_CheckAsBSendCompletion(self.pointer,\\n                                                 ctypes.byref(op_result))\\n        return_values = {\\n            0: \"job complete\",\\n            1: \"job in progress\",\\n            -2: \"invalid handled supplied\",\\n        }\\n\\n        if result == -2:\\n            raise Snap7Exception(\"The Client parameter was invalid\")\\n\\n        return return_values[result], op_result',\n",
              " 'def create(self, active=False):\\n        \"\"\"\\n        Creates a Partner and returns its handle, which is the reference that\\n        you have to use every time you refer to that Partner.\\n\\n        :param active: 0\\n        :returns: a pointer to the partner object\\n        \"\"\"\\n        self.library.Par_Create.restype = snap7.snap7types.S7Object\\n        self.pointer = snap7.snap7types.S7Object(self.library.Par_Create(int(active)))',\n",
              " 'def destroy(self):\\n        \"\"\"\\n        Destroy a Partner of given handle.\\n        Before destruction the Partner is stopped, all clients disconnected and\\n        all shared memory blocks released.\\n        \"\"\"\\n        if self.library:\\n            return self.library.Par_Destroy(ctypes.byref(self.pointer))',\n",
              " 'def get_last_error(self):\\n        \"\"\"\\n        Returns the last job result.\\n        \"\"\"\\n        error = ctypes.c_int32()\\n        result = self.library.Par_GetLastError(self.pointer, ctypes.byref(error))\\n        check_error(result, \"partner\")\\n        return error',\n",
              " 'def get_param(self, number):\\n        \"\"\"\\n        Reads an internal Partner object parameter.\\n        \"\"\"\\n        logger.debug(\"retreiving param number %s\" % number)\\n        type_ = snap7.snap7types.param_types[number]\\n        value = type_()\\n        code = self.library.Par_GetParam(self.pointer, ctypes.c_int(number),\\n                                         ctypes.byref(value))\\n        check_error(code)\\n        return value.value',\n",
              " 'def get_stats(self):\\n        \"\"\"\\n        Returns some statistics.\\n\\n        :returns: a tuple containing bytes send, received, send errors, recv errors\\n        \"\"\"\\n        sent = ctypes.c_uint32()\\n        recv = ctypes.c_uint32()\\n        send_errors = ctypes.c_uint32()\\n        recv_errors = ctypes.c_uint32()\\n        result = self.library.Par_GetStats(self.pointer, ctypes.byref(sent),\\n                                   ctypes.byref(recv),\\n                                   ctypes.byref(send_errors),\\n                                   ctypes.byref(recv_errors))\\n        check_error(result, \"partner\")\\n        return sent, recv, send_errors, recv_errors',\n",
              " 'def get_status(self):\\n        \"\"\"\\n        Returns the Partner status.\\n        \"\"\"\\n        status = ctypes.c_int32()\\n        result = self.library.Par_GetStatus(self.pointer, ctypes.byref(status))\\n        check_error(result, \"partner\")\\n        return status',\n",
              " 'def get_times(self):\\n        \"\"\"\\n        Returns the last send and recv jobs execution time in milliseconds.\\n        \"\"\"\\n        send_time = ctypes.c_int32()\\n        recv_time = ctypes.c_int32()\\n        result = self.library.Par_GetTimes(self.pointer, ctypes.byref(send_time),\\n                                   ctypes.byref(recv_time))\\n        check_error(result, \"partner\")\\n        return send_time, recv_time',\n",
              " 'def start_to(self, local_ip, remote_ip, local_tsap, remote_tsap):\\n        \"\"\"\\n        Starts the Partner and binds it to the specified IP address and the\\n        IsoTCP port.\\n\\n        :param local_ip: PC host IPV4 Address. \"0.0.0.0\" is the default adapter\\n        :param remote_ip: PLC IPV4 Address\\n        :param local_tsap: Local TSAP\\n        :param remote_tsap: PLC TSAP\\n        \"\"\"\\n        assert re.match(ipv4, local_ip), \\'%s is invalid ipv4\\' % local_ip\\n        assert re.match(ipv4, remote_ip), \\'%s is invalid ipv4\\' % remote_ip\\n        logger.info(\"starting partnering from %s to %s\" % (local_ip, remote_ip))\\n        return self.library.Par_StartTo(self.pointer, local_ip, remote_ip,\\n                                        ctypes.c_uint16(local_tsap),\\n                                        ctypes.c_uint16(remote_tsap))',\n",
              " 'def wait_socket(_socket, session, timeout=1):\\n    \"\"\"Helper function for testing non-blocking mode.\\n\\n    This function blocks the calling thread for <timeout> seconds -\\n    to be used only for testing purposes.\\n\\n    Also available at `ssh2.utils.wait_socket`\\n    \"\"\"\\n    directions = session.block_directions()\\n    if directions == 0:\\n        return 0\\n    readfds = [_socket] \\\\\\n        if (directions & LIBSSH2_SESSION_BLOCK_INBOUND) else ()\\n    writefds = [_socket] \\\\\\n        if (directions & LIBSSH2_SESSION_BLOCK_OUTBOUND) else ()\\n    return select(readfds, writefds, (), timeout)',\n",
              " 'def find_partition(graph, partition_type, initial_membership=None, weights=None, n_iterations=2, seed=None, **kwargs):\\n  \"\"\" Detect communities using the default settings.\\n\\n  This function detects communities given the specified method in the\\n  ``partition_type``. This should be type derived from\\n  :class:`VertexPartition.MutableVertexPartition`, e.g.\\n  :class:`ModularityVertexPartition` or :class:`CPMVertexPartition`. Optionally\\n  an initial membership and edge weights can be provided. Remaining\\n  ``**kwargs`` are passed on to the constructor of the ``partition_type``,\\n  including for example a ``resolution_parameter``.\\n\\n  Parameters\\n  ----------\\n  graph : :class:`ig.Graph`\\n    The graph for which to detect communities.\\n\\n  partition_type : type of :class:`\\n    The type of partition to use for optimisation.\\n\\n  initial_membership : list of int\\n    Initial membership for the partition. If :obj:`None` then defaults to a\\n    singleton partition.\\n\\n  weights : list of double, or edge attribute\\n    Weights of edges. Can be either an iterable or an edge attribute.\\n\\n  n_iterations : int\\n    Number of iterations to run the Leiden algorithm. By default, 2 iterations\\n    are run. If the number of iterations is negative, the Leiden algorithm is\\n    run until an iteration in which there was no improvement.\\n\\n  seed : int\\n    Seed for the random number generator. By default uses a random seed\\n    if nothing is specified.\\n\\n  **kwargs\\n    Remaining keyword arguments, passed on to constructor of\\n    ``partition_type``.\\n\\n  Returns\\n  -------\\n  partition\\n    The optimised partition.\\n\\n  See Also\\n  --------\\n  :func:`Optimiser.optimise_partition`\\n\\n  Examples\\n  --------\\n  >>> G = ig.Graph.Famous(\\'Zachary\\')\\n  >>> partition = la.find_partition(G, la.ModularityVertexPartition)\\n\\n  \"\"\"\\n  if not weights is None:\\n    kwargs[\\'weights\\'] = weights\\n  partition = partition_type(graph,\\n                             initial_membership=initial_membership,\\n                             **kwargs)\\n  optimiser = Optimiser()\\n\\n  if (not seed is None):\\n    optimiser.set_rng_seed(seed)\\n\\n  optimiser.optimise_partition(partition, n_iterations)\\n\\n  return partition',\n",
              " 'def time_slices_to_layers(graphs,\\n                          interslice_weight=1,\\n                          slice_attr=\\'slice\\',\\n                          vertex_id_attr=\\'id\\',\\n                          edge_type_attr=\\'type\\',\\n                          weight_attr=\\'weight\\'):\\n  \"\"\" Convert time slices to layer graphs.\\n\\n  Each graph is considered to represent a time slice. This function simply\\n  connects all the consecutive slices (i.e. the slice graph) with an\\n  ``interslice_weight``.  The further conversion is then delegated to\\n  :func:`slices_to_layers`, which also provides further details.\\n\\n  See Also\\n  --------\\n  :func:`find_partition_temporal`\\n\\n  :func:`slices_to_layers`\\n\\n  \"\"\"\\n  G_slices = _ig.Graph.Tree(len(graphs), 1, mode=_ig.TREE_UNDIRECTED)\\n  G_slices.es[weight_attr] = interslice_weight\\n  G_slices.vs[slice_attr] = graphs\\n  return slices_to_layers(G_slices,\\n                          slice_attr,\\n                          vertex_id_attr,\\n                          edge_type_attr,\\n                          weight_attr)',\n",
              " 'def slices_to_layers(G_coupling,\\n                     slice_attr=\\'slice\\',\\n                     vertex_id_attr=\\'id\\',\\n                     edge_type_attr=\\'type\\',\\n                     weight_attr=\\'weight\\'):\\n  \"\"\" Convert a coupling graph of slices to layers of graphs.\\n\\n  This function converts a graph of slices to layers so that they can be used\\n  with this package. This function assumes that the slices are represented by\\n  nodes in ``G_coupling``, and stored in the attribute ``slice_attr``. In other\\n  words, ``G_coupling.vs[slice_attr]`` should contain :class:`ig.Graph` s . The\\n  slices will be converted to layers, and nodes in different slices will be\\n  coupled if the two slices are connected in ``G_coupling``. Nodes in two\\n  connected slices are identified on the basis of the ``vertex_id_attr``, i.e.\\n  if two nodes in two connected slices have an identical value of the\\n  ``vertex_id_attr`` they will be coupled. The ``vertex_id_attr`` should hence\\n  be unique in each slice.  The weight of the coupling is determined by the\\n  weight of this link in ``G_coupling``, as determined by the ``weight_attr``.\\n\\n  Parameters\\n  ----------\\n  G_coupling : :class:`ig.Graph`\\n    The graph connecting the different slices.\\n\\n  slice_attr : string\\n    The vertex attribute which contains the slices.\\n\\n  edge_type_attr : string\\n    The edge attribute to use for indicating the type of link (``interslice``\\n    or ``intraslice``).\\n\\n  weight_attr : string\\n    The edge attribute used to indicate the (coupling) weight.\\n\\n  Returns\\n  -------\\n  G_layers : list of :class:`ig.Graph`\\n    A list of slices converted to layers.\\n\\n  G_interslice : :class:`ig.Graph`\\n    The interslice coupling layer.\\n\\n  G : :class:`ig.Graph`\\n    The complete graph containing all layers and interslice couplings.\\n\\n  Notes\\n  -----\\n  The distinction between slices and layers is not easy to grasp. Slices in\\n  this context refer to graphs that somehow represents different aspects of a\\n  network. The simplest example is probably slices that represents time: there\\n  are different snapshots network across time, and each snapshot is considered\\n  a slice. Some nodes may drop out of the network over time, while others enter\\n  the network. Edges may change over time, or the weight of the links may\\n  change over time. This is just the simplest example of a slice, and there may\\n  be different, more complex possibilities. Below an example with three time\\n  slices:\\n\\n  .. image:: figures/slices.png\\n\\n  Now in order to optimise partitions across these different slices, we\\n  represent them slightly differently, namely as layers. The idea of layers is\\n  that all graphs always are defined on the same set of nodes, and that only\\n  the links differ for different layers. We thus create new nodes as\\n  combinations of original nodes and slices. For example, if node 1 existed in\\n  both slice 1 and in slice 2, we will thus create two nodes to build the\\n  layers: a node 1-1 and a node 1-2. Additionally, if the slices are connected\\n  in the slice graph, the two nodes would also be connected, so there would be\\n  a linke between node 1-1 and 1-2. Different slices will then correspond to\\n  different layers: each layer only contains the link for that particular\\n  slice. In addition, for methods such as :class:`CPMVertexPartition`,\\n  so-called ``node_sizes`` are required, and for them to properly function,\\n  they should be set to 0 (which is handled appropriately in this function, and\\n  stored in the vertex attribute ``node_size``). We thus obtain equally many\\n  layers as we have slices, and we need one more layer for representing the\\n  interslice couplings.  For the example provided above, we thus obtain the\\n  following:\\n\\n  .. image:: figures/layers_separate.png\\n\\n  The idea of doing community detection with slices is further detailed in [1].\\n\\n  References\\n  ----------\\n  .. [1] Mucha, P. J., Richardson, T., Macon, K., Porter, M. A., & Onnela,\\n         J.-P. (2010).  Community structure in time-dependent, multiscale, and\\n         multiplex networks. Science, 328(5980), 876-8.\\n         `10.1126/science.1184819 <http://doi.org/10.1126/science.1184819>`_\\n  See Also\\n  --------\\n  :func:`find_partition_temporal`\\n\\n  :func:`time_slices_to_layers`\\n\\n  \"\"\"\\n  if not slice_attr in G_coupling.vertex_attributes():\\n    raise ValueError(\"Could not find the vertex attribute {0} in the coupling graph.\".format(slice_attr))\\n\\n  if not weight_attr in G_coupling.edge_attributes():\\n    raise ValueError(\"Could not find the edge attribute {0} in the coupling graph.\".format(weight_attr))\\n\\n  # Create disjoint union of the time graphs\\n  for v_slice in G_coupling.vs:\\n    H = v_slice[slice_attr]\\n    H.vs[slice_attr] = v_slice.index\\n    if not vertex_id_attr in H.vertex_attributes():\\n      raise ValueError(\"Could not find the vertex attribute {0} to identify nodes in different slices.\".format(vertex_id_attr ))\\n    if not weight_attr in H.edge_attributes():\\n      H.es[weight_attr] = 1\\n\\n  G = disjoint_union_attrs(G_coupling.vs[slice_attr])\\n  G.es[edge_type_attr] = \\'intraslice\\'\\n\\n  for v_slice in G_coupling.vs:\\n    for u_slice in v_slice.neighbors(mode=_ig.OUT):\\n      if v_slice.index < u_slice.index or G_coupling.is_directed():\\n        nodes_v = G.vs.select(lambda v: v[slice_attr]==v_slice.index)[vertex_id_attr]\\n        if len(set(nodes_v)) != len(nodes_v):\\n          err = \\'\\\\n\\'.join(\\n            [\\'\\\\t{0} {1} times\\'.format(item, count) for item, count in Counter(nodes_v).items() if count > 1]\\n            )\\n          raise ValueError(\\'No unique IDs for slice {0}, require unique IDs:\\\\n{1}\\'.format(v_slice.index, err))\\n        nodes_u = G.vs.select(lambda v: v[slice_attr]==u_slice.index)[vertex_id_attr]\\n        if len(set(nodes_u)) != len(nodes_u):\\n          err = \\'\\\\n\\'.join(\\n            [\\'\\\\t{0} {1} times\\'.format(item, count) for item, count in Counter(nodes_u).items() if count > 1]\\n            )\\n          raise ValueError(\\'No unique IDs for slice {0}, require unique IDs:\\\\n{1}\\'.format(u_slice.index, err))\\n        common_nodes = set(nodes_v).intersection(set(nodes_u))\\n        nodes_v = sorted([v for v in G.vs if v[slice_attr] == v_slice.index and v[vertex_id_attr] in common_nodes], key=lambda v: v[vertex_id_attr])\\n        nodes_u = sorted([v for v in G.vs if v[slice_attr] == u_slice.index and v[vertex_id_attr] in common_nodes], key=lambda v: v[vertex_id_attr])\\n        edges = zip(nodes_v, nodes_u)\\n        e_start = G.ecount()\\n        G.add_edges(edges)\\n        e_end = G.ecount()\\n        e_idx = range(e_start, e_end)\\n        interslice_weight = G_coupling.es[G_coupling.get_eid(v_slice, u_slice)][weight_attr]\\n        if not interslice_weight is None:\\n          G.es[e_idx][weight_attr] = interslice_weight\\n        G.es[e_idx][edge_type_attr] = \\'interslice\\'\\n\\n  # Convert aggregate graph to individual layers for each time slice.\\n  G_layers = [None]*G_coupling.vcount()\\n  for v_slice in G_coupling.vs:\\n    H = G.subgraph_edges(G.es.select(_within=[v.index for v in G.vs if v[slice_attr] == v_slice.index]), delete_vertices=False)\\n    H.vs[\\'node_size\\'] = [1 if v[slice_attr] == v_slice.index else 0 for v in H.vs]\\n    G_layers[v_slice.index] = H\\n\\n  # Create one graph for the interslice links.\\n  G_interslice = G.subgraph_edges(G.es.select(type_eq=\\'interslice\\'), delete_vertices=False)\\n  G_interslice.vs[\\'node_size\\'] = 0\\n\\n  return G_layers, G_interslice, G',\n",
              " 'def FromPartition(cls, partition, **kwargs):\\n    \"\"\" Create a new partition from an existing partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The :class:`~VertexPartition.MutableVertexPartition` to replicate.\\n\\n    **kwargs\\n      Any remaining keyword arguments will be passed on to the constructor of\\n      the new partition.\\n\\n    Notes\\n    -----\\n    This may for example come in handy when determining the quality of a\\n    partition using a different method. Suppose that we already have a\\n    partition ``p`` and that we want to determine the Significance of that\\n    partition. We can then simply use\\n\\n    >>> p = la.find_partition(ig.Graph.Famous(\\'Zachary\\'),\\n    ...                       la.ModularityVertexPartition)\\n    >>> sig = la.SignificanceVertexPartition.FromPartition(p).quality()\\n    \"\"\"\\n    new_partition = cls(partition.graph, partition.membership, **kwargs)\\n    return new_partition',\n",
              " 'def set_membership(self, membership):\\n    \"\"\" Set membership. \"\"\"\\n    _c_leiden._MutableVertexPartition_set_membership(self._partition, list(membership))\\n    self._update_internal_membership()',\n",
              " 'def diff_move(self,v,new_comm):\\n    \"\"\" Calculate the difference in the quality function if node ``v`` is\\n    moved to community ``new_comm``.\\n\\n    Parameters\\n    ----------\\n    v\\n      The node to move.\\n\\n    new_comm\\n      The community to move to.\\n\\n    Returns\\n    -------\\n    float\\n      Difference in quality function.\\n\\n    Notes\\n    -----\\n    The difference returned by diff_move should be equivalent to first\\n    determining the quality of the partition, then calling move_node, and then\\n    determining again the quality of the partition and looking at the\\n    difference. In other words\\n\\n    >>> partition = la.find_partition(ig.Graph.Famous(\\'Zachary\\'),\\n    ...                               la.ModularityVertexPartition)\\n    >>> diff = partition.diff_move(v=0, new_comm=0)\\n    >>> q1 = partition.quality()\\n    >>> partition.move_node(v=0, new_comm=0)\\n    >>> q2 = partition.quality()\\n    >>> round(diff, 10) == round(q2 - q1, 10)\\n    True\\n\\n    .. warning:: Only derived classes provide actual implementations, the base\\n                 class provides no implementation for this function.\\n\\n    \"\"\"\\n    return _c_leiden._MutableVertexPartition_diff_move(self._partition, v, new_comm)',\n",
              " 'def aggregate_partition(self, membership_partition=None):\\n    \"\"\" Aggregate the graph according to the current partition and provide a\\n    default partition for it.\\n\\n    The aggregated graph can then be found as a parameter of the partition\\n    ``partition.graph``.\\n\\n    Notes\\n    -----\\n    This function contrasts to the function ``cluster_graph`` in igraph itself,\\n    which also provides the aggregate graph, but we may require setting\\n    the appropriate ``resolution_parameter``, ``weights`` and ``node_sizes``.\\n    In particular, this function also ensures that the quality defined on the\\n    aggregate partition is identical to the quality defined on the original\\n    partition.\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> partition = la.find_partition(G, la.ModularityVertexPartition)\\n    >>> aggregate_partition = partition.aggregate_partition(partition)\\n    >>> aggregate_graph = aggregate_partition.graph\\n    >>> aggregate_partition.quality() == partition.quality()\\n    True\\n    \"\"\"\\n    partition_agg = self._FromCPartition(_c_leiden._MutableVertexPartition_aggregate_partition(self._partition))\\n\\n    if (not membership_partition is None):\\n      membership = partition_agg.membership\\n      for v in self.graph.vs:\\n        membership[self.membership[v.index]] = membership_partition.membership[v.index]\\n      partition_agg.set_membership(membership)\\n\\n    return partition_agg',\n",
              " 'def move_node(self,v,new_comm):\\n    \"\"\" Move node ``v`` to community ``new_comm``.\\n\\n    Parameters\\n    ----------\\n    v\\n      Node to move.\\n\\n    new_comm\\n      Community to move to.\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> partition.move_node(0, 1)\\n    \"\"\"\\n    _c_leiden._MutableVertexPartition_move_node(self._partition, v, new_comm)\\n    # Make sure this move is also reflected in the membership vector of the python object\\n    self._membership[v] = new_comm\\n    self._modularity_dirty = True',\n",
              " 'def from_coarse_partition(self, partition, coarse_node=None):\\n    \"\"\" Update current partition according to coarser partition.\\n\\n    Parameters\\n    ----------\\n    partition : :class:`~VertexPartition.MutableVertexPartition`\\n      The coarser partition used to update the current partition.\\n\\n    coarse_node : list of int\\n      The coarser node which represent the current node in the partition.\\n\\n    Notes\\n    -----\\n    This function is to be used to determine the correct partition for an\\n    aggregated graph. In particular, suppose we move nodes and then get an\\n    aggregate graph.\\n\\n    >>> diff = optimiser.move_nodes(partition)\\n    >>> aggregate_partition = partition.aggregate_partition()\\n\\n    Now we also move nodes in the aggregate partition\\n\\n    >>> diff = optimiser.move_nodes(aggregate_partition)\\n\\n    Now we improved the quality function of ``aggregate_partition``, but this\\n    is not yet reflected in the original ``partition``. We can thus call\\n\\n    >>> partition.from_coarse_partition(aggregate_partition)\\n\\n    so that ``partition`` now reflects the changes made to\\n    ``aggregate_partition``.\\n\\n    The ``coarse_node`` can be used it the ``aggregate_partition`` is not\\n    defined based on the membership of this partition. In particular the\\n    membership of this partition is defined as follows:\\n\\n    >>> for v in G.vs:\\n    ...   partition.membership[v] = aggregate_partition.membership[coarse_node[v]] # doctest: +SKIP\\n\\n    If ``coarse_node`` is :obj:`None` it is assumed the coarse node was defined\\n    based on the membership of the current partition, so that\\n\\n    >>> for v in G.vs:\\n    ...   partition.membership[v] = aggregate_partition.membership[partition.membership[v]] # doctest: +SKIP\\n\\n    This can be useful when the aggregate partition is defined on a more\\n    refined partition.\\n    \"\"\"\\n    # Read the coarser partition\\n    _c_leiden._MutableVertexPartition_from_coarse_partition(self._partition,\\n                                                             partition.membership, coarse_node)\\n    self._update_internal_membership()',\n",
              " 'def weight_to_comm(self, v, comm):\\n    \"\"\" The total number of edges (or sum of weights) from node ``v`` to\\n    community ``comm``.\\n\\n    See Also\\n    --------\\n    :func:`~VertexPartition.MutableVertexPartition.weight_from_comm`\\n    \"\"\"\\n    return _c_leiden._MutableVertexPartition_weight_to_comm(self._partition, v, comm)',\n",
              " 'def weight_from_comm(self, v, comm):\\n    \"\"\" The total number of edges (or sum of weights) to node ``v`` from\\n    community ``comm``.\\n\\n    See Also\\n    --------\\n    :func:`~VertexPartition.MutableVertexPartition.weight_to_comm`\\n    \"\"\"\\n    return _c_leiden._MutableVertexPartition_weight_from_comm(self._partition, v, comm)',\n",
              " 'def optimise_partition(self, partition, n_iterations=2):\\n    \"\"\" Optimise the given partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The :class:`~VertexPartition.MutableVertexPartition` to optimise.\\n\\n    n_iterations : int\\n      Number of iterations to run the Leiden algorithm. By default, 2 iterations\\n      are run. If the number of iterations is negative, the Leiden algorithm is\\n      run until an iteration in which there was no improvement.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality function.\\n\\n    Examples\\n    --------\\n\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.optimise_partition(partition)\\n\\n    \"\"\"\\n\\n    itr = 0\\n    diff = 0\\n    continue_iteration = itr < n_iterations or n_iterations < 0\\n    while continue_iteration:\\n      diff_inc = _c_leiden._Optimiser_optimise_partition(self._optimiser, partition._partition)\\n      diff += diff_inc\\n      itr += 1\\n      if n_iterations < 0:\\n        continue_iteration = (diff_inc > 0)\\n      else:\\n        continue_iteration = itr < n_iterations\\n\\n    partition._update_internal_membership()\\n    return diff',\n",
              " 'def optimise_partition_multiplex(self, partitions, layer_weights=None, n_iterations=2):\\n    \"\"\" Optimise the given partitions simultaneously.\\n\\n    Parameters\\n    ----------\\n    partitions\\n      List of :class:`~VertexPartition.MutableVertexPartition` layers to optimise.\\n\\n    layer_weights\\n      List of weights of layers.\\n\\n    n_iterations : int\\n      Number of iterations to run the Leiden algorithm. By default, 2 iterations\\n      are run. If the number of iterations is negative, the Leiden algorithm is\\n      run until an iteration in which there was no improvement.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality of combined partitions, see `Notes <#notes-multiplex>`_.\\n\\n\\n    .. _notes-multiplex:\\n\\n    Notes\\n    -----\\n\\n    This method assumes that the partitions are defined for graphs with the\\n    same vertices. The connections between the vertices may be different, but\\n    the vertices themselves should be identical. In other words, all vertices\\n    should have identical indices in all graphs (i.e. node `i` is assumed to be\\n    the same node in all graphs). The quality of the overall partition is\\n    simply the sum of the individual qualities for the various partitions,\\n    weighted by the layer_weight. If we denote by :math:`Q_k` the quality of\\n    layer :math:`k` and the weight by :math:`\\\\\\\\lambda_k`, the overall quality\\n    is then\\n\\n    .. math:: Q = \\\\sum_k \\\\\\\\lambda_k Q_k.\\n\\n    This is particularly useful for graphs containing negative links. When\\n    separating the graph in two graphs, the one containing only the positive\\n    links, and the other only the negative link, by supplying a negative weight\\n    to the latter layer, we try to find relatively many positive links within a\\n    community and relatively many negative links between communities. Note that\\n    in this case it may be better to assign a node to a community to which it\\n    is not connected so that :attr:`consider_comms` may be better set to\\n    :attr:`leidenalg.ALL_COMMS`.\\n\\n    Besides multiplex graphs where each node is assumed to have a single\\n    community, it is also useful in the case of for example multiple time\\n    slices, or in situations where nodes can have different communities in\\n    different slices. The package includes some special helper functions for\\n    using :func:`optimise_partition_multiplex` in such cases, where there is a\\n    conversion required from (time) slices to layers suitable for use in this\\n    function.\\n\\n    See Also\\n    --------\\n    :func:`slices_to_layers`\\n\\n    :func:`time_slices_to_layers`\\n\\n    :func:`find_partition_multiplex`\\n\\n    :func:`find_partition_temporal`\\n\\n    Examples\\n    --------\\n    >>> G_pos = ig.Graph.SBM(100, pref_matrix=[[0.5, 0.1], [0.1, 0.5]], block_sizes=[50, 50])\\n    >>> G_neg = ig.Graph.SBM(100, pref_matrix=[[0.1, 0.5], [0.5, 0.1]], block_sizes=[50, 50])\\n    >>> optimiser = la.Optimiser()\\n    >>> partition_pos = la.ModularityVertexPartition(G_pos)\\n    >>> partition_neg = la.ModularityVertexPartition(G_neg)\\n    >>> diff = optimiser.optimise_partition_multiplex(\\n    ...                     partitions=[partition_pos, partition_neg],\\n    ...                     layer_weights=[1,-1])\\n\\n    \"\"\"\\n    if not layer_weights:\\n      layer_weights = [1]*len(partitions)\\n\\n    itr = 0\\n    diff = 0\\n    continue_iteration = itr < n_iterations or n_iterations < 0\\n    while continue_iteration:\\n      diff_inc = _c_leiden._Optimiser_optimise_partition_multiplex(\\n        self._optimiser,\\n        [partition._partition for partition in partitions],\\n        layer_weights)\\n      diff += diff_inc\\n      itr += 1\\n      if n_iterations < 0:\\n        continue_iteration = (diff_inc > 0)\\n      else:\\n        continue_iteration = itr < n_iterations\\n\\n    for partition in partitions:\\n      partition._update_internal_membership()\\n    return diff',\n",
              " 'def move_nodes(self, partition, consider_comms=None):\\n    \"\"\" Move nodes to alternative communities for *optimising* the partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The partition for which to move nodes.\\n\\n    consider_comms\\n      If ``None`` uses :attr:`consider_comms`, but can be set to\\n      something else.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality function.\\n\\n    Notes\\n    -----\\n    When moving nodes, the function loops over nodes and considers moving the\\n    node to an alternative community. Which community depends on\\n    ``consider_comms``. The function terminates when no more nodes can be moved\\n    to an alternative community.\\n\\n    See Also\\n    --------\\n    :func:`Optimiser.move_nodes_constrained`\\n\\n    :func:`Optimiser.merge_nodes`\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.move_nodes(partition)\\n\\n    \"\"\"\\n    if (consider_comms is None):\\n      consider_comms = self.consider_comms\\n    diff =  _c_leiden._Optimiser_move_nodes(self._optimiser, partition._partition, consider_comms)\\n    partition._update_internal_membership()\\n    return diff',\n",
              " 'def move_nodes_constrained(self, partition, constrained_partition, consider_comms=None):\\n    \"\"\" Move nodes to alternative communities for *refining* the partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The partition for which to move nodes.\\n\\n    constrained_partition\\n      The partition within which we may move nodes.\\n\\n    consider_comms\\n      If ``None`` uses :attr:`refine_consider_comms`, but can be set\\n      to something else.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality function.\\n\\n    Notes\\n    -----\\n    The idea is constrain the movement of nodes to alternative communities to\\n    another partition. In other words, if there is a partition ``P`` which we\\n    want to refine, we can then initialize a new singleton partition, and move\\n    nodes in that partition constrained to ``P``.\\n\\n    See Also\\n    --------\\n    :func:`Optimiser.move_nodes`\\n\\n    :func:`Optimiser.merge_nodes_constrained`\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.optimise_partition(partition)\\n    >>> refine_partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.move_nodes_constrained(refine_partition, partition)\\n\\n    \"\"\"\\n    if (consider_comms is None):\\n      consider_comms = self.refine_consider_comms\\n    diff =  _c_leiden._Optimiser_move_nodes_constrained(self._optimiser, partition._partition, constrained_partition._partition, consider_comms)\\n    partition._update_internal_membership()\\n    return diff',\n",
              " 'def merge_nodes(self, partition, consider_comms=None):\\n    \"\"\" Merge nodes for *optimising* the partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The partition for which to merge nodes.\\n\\n    consider_comms\\n      If ``None`` uses :attr:`consider_comms`, but can be set to\\n      something else.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality function.\\n\\n    Notes\\n    -----\\n    This function loop over all nodes once and tries to merge them with another\\n    community.  Merging in this case implies that a node will never be removed\\n    from a community, only merged with other communities.\\n\\n    See Also\\n    --------\\n    :func:`Optimiser.move_nodes`\\n\\n    :func:`Optimiser.merge_nodes_constrained`\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.merge_nodes(partition)\\n\\n    \"\"\"\\n    if (consider_comms is None):\\n      consider_comms = self.consider_comms\\n    diff =  _c_leiden._Optimiser_merge_nodes(self._optimiser, partition._partition, consider_comms)\\n    partition._update_internal_membership()\\n    return diff',\n",
              " 'def merge_nodes_constrained(self, partition, constrained_partition, consider_comms=None):\\n    \"\"\" Merge nodes for *refining* the partition.\\n\\n    Parameters\\n    ----------\\n    partition\\n      The partition for which to merge nodes.\\n\\n    constrained_partition\\n      The partition within which we may merge nodes.\\n\\n    consider_comms\\n      If ``None`` uses :attr:`refine_consider_comms`, but can be set\\n      to something else.\\n\\n    Returns\\n    -------\\n    float\\n      Improvement in quality function.\\n\\n    Notes\\n    -----\\n    The idea is constrain the merging of nodes to another partition. In other\\n    words, if there is a partition ``P`` which we want to refine, we can then\\n    initialize a new singleton partition, and move nodes in that partition\\n    constrained to ``P``.\\n\\n    See Also\\n    --------\\n    :func:`Optimiser.move_nodes_constrained`\\n\\n    :func:`Optimiser.merge_nodes`\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.optimise_partition(partition)\\n    >>> refine_partition = la.ModularityVertexPartition(G)\\n    >>> diff = optimiser.move_nodes_constrained(refine_partition, partition)\\n\\n    \"\"\"\\n    if (consider_comms is None):\\n      consider_comms = self.refine_consider_comms\\n    diff =  _c_leiden._Optimiser_merge_nodes_constrained(self._optimiser, partition._partition, constrained_partition._partition, consider_comms)\\n    partition._update_internal_membership()\\n    return diff',\n",
              " 'def resolution_profile(self,\\n        graph,\\n        partition_type,\\n        resolution_range,\\n        weights=None,\\n        bisect_func=lambda p: p.bisect_value(),\\n        min_diff_bisect_value=1,\\n        min_diff_resolution=1e-3,\\n        linear_bisection=False,\\n        number_iterations=1,\\n        **kwargs\\n        ):\\n    \"\"\" Use bisectioning on the resolution parameter in order to construct a\\n    resolution profile.\\n\\n    Parameters\\n    ----------\\n    graph\\n      The graph for which to construct a resolution profile.\\n\\n    partition_type\\n      The type of :class:`~VertexPartition.MutableVertexPartition` used\\n      to find a partition (must support resolution parameters obviously).\\n\\n    resolution_range\\n      The range of resolution values that we would like to scan.\\n\\n    weights\\n      If provided, indicates the edge attribute to use as a weight.\\n\\n    Returns\\n    -------\\n    list of :class:`~VertexPartition.MutableVertexPartition`\\n      A list of partitions for different resolutions.\\n\\n    Other Parameters\\n    ----------------\\n    bisect_func\\n      The function used for bisectioning. For the methods currently\\n      implemented, this should usually not be altered.\\n\\n    min_diff_bisect_value\\n      The difference in the value returned by the bisect_func below which the\\n      bisectioning stops (i.e. by default, a difference of a single edge does\\n      not trigger further bisectioning).\\n\\n    min_diff_resolution\\n      The difference in resolution below which the bisectioning stops. For\\n      positive differences, the logarithmic difference is used by default, i.e.\\n      ``diff = log(res_1) - log(res_2) = log(res_1/res_2)``, for which ``diff >\\n      min_diff_resolution`` to continue bisectioning. Set the linear_bisection\\n      to true in order to use only linear bisectioning (in the case of negative\\n      resolution parameters for example, which can happen with negative\\n      weights).\\n\\n    linear_bisection\\n      Whether the bisectioning will be done on a linear or on a logarithmic\\n      basis (if possible).\\n\\n    number_iterations\\n      Indicates the number of iterations of the algorithm to run. If negative\\n      (or zero) the algorithm is run until a stable iteration.\\n\\n    Examples\\n    --------\\n    >>> G = ig.Graph.Famous(\\'Zachary\\')\\n    >>> optimiser = la.Optimiser()\\n    >>> profile = optimiser.resolution_profile(G, la.CPMVertexPartition,\\n    ...                                        resolution_range=(0,1))\\n    \"\"\"\\n\\n    # Helper function for cleaning values to be a stepwise function\\n    def clean_stepwise(bisect_values):\\n      # Check best partition for each resolution parameter\\n      for res, bisect in bisect_values.iteritems():\\n        best_bisect = bisect\\n        best_quality = bisect.partition.quality(res)\\n        for res2, bisect2 in bisect_values.iteritems():\\n          if bisect2.partition.quality(res) > best_quality:\\n            best_bisect = bisect2\\n            best_quality = bisect2.partition.quality(res)\\n        if best_bisect != bisect:\\n          bisect_values[res] = best_bisect\\n\\n      # We only need to keep the changes in the bisection values\\n      bisect_list = sorted([(res, part.bisect_value) for res, part in\\n        bisect_values.iteritems()], key=lambda x: x[0])\\n      for (res1, v1), (res2, v2) \\\\\\n          in zip(bisect_list,\\n                 bisect_list[1:]):\\n        # If two consecutive bisection values are the same, remove the second\\n        # resolution parameter\\n        if v1 == v2:\\n          del bisect_values[res2]\\n\\n      for res, bisect in bisect_values.iteritems():\\n        bisect.partition.resolution_parameter = res\\n\\n    # We assume here that the bisection values are\\n    # monotonically decreasing with increasing resolution\\n    # parameter values.\\n    def ensure_monotonicity(bisect_values, new_res):\\n      # First check if this partition improves on any other partition\\n      for res, bisect_part in bisect_values.iteritems():\\n        if bisect_values[new_res].partition.quality(res) > bisect_part.partition.quality(res):\\n          bisect_values[res] = bisect_values[new_res]\\n      # Then check what is best partition for the new_res\\n      current_quality = bisect_values[new_res].partition.quality(new_res)\\n      best_res = new_res\\n      for res, bisect_part in bisect_values.iteritems():\\n        if bisect_part.partition.quality(new_res) > current_quality:\\n          best_res = new_res\\n      bisect_values[new_res] = bisect_values[best_res]\\n\\n    def find_partition(self, graph, partition_type, weights=None, **kwargs):\\n      partition = partition_type(graph,\\n                             weights=weights,\\n                             **kwargs)\\n      n_itr = 0\\n      while self.optimise_partition(partition) > 0 and \\\\\\n        (n_itr < number_iterations or number_iterations <= 0):\\n        n_itr += 1\\n      return partition\\n\\n    assert issubclass(partition_type, LinearResolutionParameterVertexPartition), \"Bisectioning only works on partitions with a linear resolution parameter.\"\\n    # Start actual bisectioning\\n    bisect_values = {}\\n    stack_res_range = []\\n    # Push first range onto the stack\\n    stack_res_range.append(resolution_range)\\n    # Make sure the bisection values are calculated\\n    # The namedtuple we will use in the bisection function\\n    BisectPartition = namedtuple(\\'BisectPartition\\',\\n        [\\'partition\\', \\'bisect_value\\'])\\n    partition = find_partition(self, graph=graph, partition_type=partition_type,\\n        weights=weights,resolution_parameter=resolution_range[0],\\n        **kwargs)\\n    bisect_values[resolution_range[0]] = BisectPartition(partition=partition,\\n                                bisect_value=bisect_func(partition))\\n    partition = find_partition(self, graph=graph, partition_type=partition_type,\\n        weights=weights, resolution_parameter=resolution_range[1], **kwargs)\\n    bisect_values[resolution_range[1]] = BisectPartition(partition=partition,\\n                                bisect_value=bisect_func(partition))\\n    # While stack of ranges not yet empty\\n    while stack_res_range:\\n      # Get the current range from the stack\\n      current_range = stack_res_range.pop()\\n      # Get the difference in bisection values\\n      diff_bisect_value = abs(bisect_values[current_range[0]].bisect_value -\\n                              bisect_values[current_range[1]].bisect_value)\\n      # Get the difference in resolution parameter (in log space if 0 is not in\\n      # the interval (assuming only non-negative resolution parameters).\\n      if current_range[0] > 0 and current_range[1] > 0 and not linear_bisection:\\n        diff_resolution = log(current_range[1]/current_range[0])\\n      else:\\n        diff_resolution = abs(current_range[1] - current_range[0])\\n      # Check if we still want to scan a smaller interval\\n      # If we would like to bisect this interval\\n      if diff_bisect_value > min_diff_bisect_value and \\\\\\n         diff_resolution > min_diff_resolution:\\n        # Determine new resolution value\\n        if current_range[0] > 0 and current_range[1] > 0 and not linear_bisection:\\n          new_res = sqrt(current_range[1]*current_range[0])\\n        else:\\n          new_res = sum(current_range)/2.0\\n        # Bisect left (push on stack)\\n        stack_res_range.append((current_range[0], new_res))\\n        # Bisect right (push on stack)\\n        stack_res_range.append((new_res, current_range[1]))\\n        # If we haven\\'t scanned this resolution value yet,\\n        # do so now\\n        if not bisect_values.has_key(new_res):\\n          partition = find_partition(self, graph, partition_type=partition_type,\\n              weights=weights, resolution_parameter=new_res, **kwargs)\\n          bisect_values[new_res] = BisectPartition(partition=partition,\\n                                      bisect_value=bisect_func(partition))\\n          # Because of stochastic differences in different runs, the monotonicity\\n          # of the bisection values might be violated, so check for any\\n          # inconsistencies\\n          ensure_monotonicity(bisect_values, new_res)\\n\\n    # Ensure we only keep those resolution values for which\\n    # the bisection values actually changed, instead of all of them\\n    clean_stepwise(bisect_values)\\n    # Use an ordered dict so that when iterating over it, the results appear in\\n    # increasing order based on the resolution value.\\n    return sorted((bisect.partition for res, bisect in\\n      bisect_values.iteritems()), key=lambda x: x.resolution_parameter)',\n",
              " 'def cleanup_tmpdir(dirname):\\n    \"\"\"Removes the given temporary directory if it exists.\"\"\"\\n    if dirname is not None and os.path.exists(dirname):\\n        shutil.rmtree(dirname)',\n",
              " 'def create_dir_unless_exists(*args):\\n    \"\"\"Creates a directory unless it exists already.\"\"\"\\n    path = os.path.join(*args)\\n    if not os.path.isdir(path):\\n        os.makedirs(path)',\n",
              " 'def ensure_dir_does_not_exist(*args):\\n    \"\"\"Ensures that the given directory does not exist.\"\"\"\\n    path = os.path.join(*args)\\n    if os.path.isdir(path):\\n        shutil.rmtree(path)',\n",
              " 'def find_static_library(library_name, library_path):\\n    \"\"\"Given the raw name of a library in `library_name`, tries to find a\\n    static library with this name in the given `library_path`. `library_path`\\n    is automatically extended with common library directories on Linux and Mac\\n    OS X.\"\"\"\\n\\n    variants = [\"lib{0}.a\", \"{0}.a\", \"{0}.lib\", \"lib{0}.lib\"]\\n    if is_unix_like():\\n        extra_libdirs = [\"/usr/local/lib64\", \"/usr/local/lib\",\\n                \"/usr/lib64\", \"/usr/lib\", \"/lib64\", \"/lib\"]\\n    else:\\n        extra_libdirs = []\\n\\n    for path in extra_libdirs:\\n        if path not in library_path and os.path.isdir(path):\\n            library_path.append(path)\\n\\n    for path in library_path:\\n        for variant in variants:\\n            full_path = os.path.join(path, variant.format(library_name))\\n            if os.path.isfile(full_path):\\n                return full_path',\n",
              " 'def get_output(command):\\n    \"\"\"Returns the output of a command returning a single line of output.\"\"\"\\n    p = Popen(command, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n    p.stdin.close()\\n    p.stderr.close()\\n    line=p.stdout.readline().strip()\\n    p.wait()\\n    if type(line).__name__ == \"bytes\":\\n        line = str(line, encoding=\"utf-8\")\\n    return line, p.returncode',\n",
              " 'def http_url_exists(url):\\n    \"\"\"Returns whether the given HTTP URL \\'exists\\' in the sense that it is returning\\n    an HTTP error code or not. A URL is considered to exist if it does not return\\n    an HTTP error code.\"\"\"\\n    class HEADRequest(Request):\\n        def get_method(self):\\n            return \"HEAD\"\\n    try:\\n        response = urlopen(HEADRequest(url))\\n        return True\\n    except URLError:\\n        return False',\n",
              " 'def is_unix_like(platform=None):\\n    \"\"\"Returns whether the given platform is a Unix-like platform with the usual\\n    Unix filesystem. When the parameter is omitted, it defaults to ``sys.platform``\\n    \"\"\"\\n    platform = platform or sys.platform\\n    platform = platform.lower()\\n    return platform.startswith(\"linux\") or platform.startswith(\"darwin\") or \\\\\\n            platform.startswith(\"cygwin\")',\n",
              " 'def preprocess_fallback_config():\\n    \"\"\"Preprocesses the fallback include and library paths depending on the\\n    platform.\"\"\"\\n    global LIBIGRAPH_FALLBACK_INCLUDE_DIRS\\n    global LIBIGRAPH_FALLBACK_LIBRARY_DIRS\\n    global LIBIGRAPH_FALLBACK_LIBRARIES\\n    \\n    if os.name == \\'nt\\' and distutils.ccompiler.get_default_compiler() == \\'msvc\\':\\n        # if this setup is run in the source checkout *and* the igraph msvc was build,\\n        # this code adds the right library and include dir\\n        version = \\'\\';\\n        if sys.version_info >= (2, 7) and sys.version_info < (3, 0):\\n          version = \\'27\\';\\n        elif sys.version_info >= (3, 4) and sys.version_info < (3, 5):\\n          version =\\'34\\';\\n        elif sys.version_info >= (3, 5):\\n          version =\\'35\\';\\n        all_msvc_dirs = glob.glob(os.path.join(\\'..\\', \\'igraph\\', \\'igraph-*-msvc-py{0}\\'.format(version)))\\n        if len(all_msvc_dirs) > 0:\\n            if len(all_msvc_dirs) > 1:\\n                print(\"More than one MSVC build directory (igraph-*-msvc-py{0}) found!\".format(version))\\n                print(\"It could happen that setup.py uses the wrong one! Please remove all but the right one!\\\\n\\\\n\")\\n\\n            msvc_builddir = all_msvc_dirs[-1]\\n            if not os.path.exists(os.path.join(msvc_builddir, \"Release\")):\\n                print(\"There is no \\'Release\\' dir in the MSVC build directory\\\\n(%s)\" % msvc_builddir)\\n                print(\"Please build the MSVC build first!\\\\n\")\\n            else:\\n                print(\"Using MSVC build dir as a fallback: %s\\\\n\\\\n\" % msvc_builddir)\\n\\n                LIBIGRAPH_FALLBACK_INCLUDE_DIRS = [os.path.join(msvc_builddir, \"include\")]\\n\\n                is_64bits = sys.maxsize > 2**32\\n                LIBIGRAPH_FALLBACK_LIBRARY_DIRS = [os.path.join(msvc_builddir, \"Release\", \"x64\" if is_64bits else \"win32\")]',\n",
              " 'def version_variants(version):\\n    \"\"\"Given an igraph version number, returns a list of possible version\\n    number variants to try when looking for a suitable nightly build of the\\n    C core to download from igraph.org.\"\"\"\\n\\n    result = [version]\\n\\n    # Add trailing \".0\" as needed to ensure that we have at least\\n    # major.minor.patch\\n    parts = version.split(\".\")\\n    while len(parts) < 3:\\n        parts.append(\"0\")\\n        result.append(\".\".join(parts))\\n\\n    return result',\n",
              " 'def tmpdir(self):\\n        \"\"\"The temporary directory in which igraph is downloaded and extracted.\"\"\"\\n        if self._tmpdir is None:\\n            self._tmpdir = tempfile.mkdtemp(prefix=\"igraph.\")\\n            atexit.register(cleanup_tmpdir, self._tmpdir)\\n        return self._tmpdir',\n",
              " 'def download_and_compile(self):\\n        \"\"\"Downloads and compiles the C core of igraph.\"\"\"\\n\\n        def _progress_hook(count, block_size, total_size):\\n            if total_size < 0:\\n                sys.stdout.write(\"\\\\rDownloading %s... please wait.\" % local_file)\\n            else:\\n                percentage = count * block_size * 100.0 / total_size\\n                percentage = min(percentage, 100.0)\\n                sys.stdout.write(\"\\\\rDownloading %s... %.2f%%\" % (local_file, percentage))\\n            sys.stdout.flush()\\n\\n        # Determine the remote URL if needed\\n        if self.remote_url is None:\\n            self.version, remote_url = self.find_first_version()\\n            if not self.version:\\n                print(\"Version %s of the C core of igraph is not found among the \"\\n                        \"nightly builds.\" % self.versions_to_try[0])\\n                print(\"Use the --c-core-version switch to try a different version.\")\\n                print(\"\")\\n                return False\\n            local_file = \"igraph-%s.tar.gz\" % self.version\\n        else:\\n            remote_url = self.remote_url\\n            local_file = remote_url.rsplit(\"/\", 1)[1]\\n\\n        # Now determine the full path where the C core will be downloaded\\n        local_file_full_path = os.path.join(self.tmpdir, local_file)\\n\\n        # Download the C core\\n        if self.show_progress_bar:\\n            urlretrieve(remote_url, local_file_full_path, reporthook=_progress_hook)\\n            print(\"\")\\n        else:\\n            print(\"Downloading %s... \" % local_file)\\n            urlretrieve(remote_url, local_file_full_path)\\n\\n        # Extract it in the temporary directory\\n        print(\"Extracting %s...\" % local_file)\\n        archive = tarfile.open(local_file_full_path, \"r:gz\")\\n        archive.extractall(self.tmpdir)\\n\\n        # Determine the name of the build directory\\n        self.builddir = None\\n        for name in os.listdir(self.tmpdir):\\n            full_path = os.path.join(self.tmpdir, name)\\n            if name.startswith(\"igraph\") and os.path.isdir(full_path):\\n                self.builddir = full_path\\n                break\\n\\n        if not self.builddir:\\n            print(\"Downloaded tarball did not contain a directory whose name \"\\n                    \"started with igraph; giving up build.\")\\n            return False\\n\\n        # Try to compile\\n        cwd = os.getcwd()\\n        try:\\n            print(\"Configuring igraph...\")\\n            os.chdir(self.builddir)\\n            retcode = subprocess.call(\"CFLAGS=-fPIC CXXFLAGS=-fPIC ./configure --disable-tls --disable-gmp\",\\n                    shell=True)\\n            if retcode:\\n                return False\\n\\n            retcode = subprocess.call(\"make\", shell=True)\\n            if retcode:\\n                return False\\n\\n            libraries = []\\n            for line in open(os.path.join(self.builddir, \"igraph.pc\")):\\n                if line.startswith(\"Libs: \") or line.startswith(\"Libs.private: \"):\\n                    words = line.strip().split()\\n                    libraries.extend(word[2:] for word in words if word.startswith(\"-l\"))\\n\\n            if not libraries:\\n                # Educated guess\\n                libraries = [\"igraph\"]\\n\\n        finally:\\n            os.chdir(cwd)\\n\\n        # Compilation succeeded; copy everything into igraphcore\\n        create_dir_unless_exists(\"igraphcore\")\\n        ensure_dir_does_not_exist(\"igraphcore\", \"include\")\\n        ensure_dir_does_not_exist(\"igraphcore\", \"lib\")\\n        shutil.copytree(os.path.join(self.builddir, \"include\"),\\n                os.path.join(\"igraphcore\", \"include\"))\\n        shutil.copytree(os.path.join(self.builddir, \"src\", \".libs\"),\\n                os.path.join(\"igraphcore\", \"lib\"))\\n        f = open(os.path.join(\"igraphcore\", \"build.cfg\"), \"w\")\\n        f.write(repr(libraries))\\n        f.close()\\n\\n        return True',\n",
              " 'def find_first_version(self):\\n        \"\"\"Finds the first version of igraph that exists in the nightly build\\n        repo from the version numbers provided in ``self.versions_to_try``.\"\"\"\\n        for version in self.versions_to_try:\\n            remote_url = self.get_download_url(version=version)\\n            if http_url_exists(remote_url):\\n                return version, remote_url\\n        return None, None',\n",
              " 'def has_pkgconfig(self):\\n        \"\"\"Returns whether ``pkg-config`` is available on the current system\\n        and it knows about igraph or not.\"\"\"\\n        if self._has_pkgconfig is None:\\n            if self.use_pkgconfig:\\n                line, exit_code = get_output(\"pkg-config igraph\")\\n                self._has_pkgconfig = (exit_code == 0)\\n            else:\\n                self._has_pkgconfig = False\\n        return self._has_pkgconfig',\n",
              " 'def configure(self, ext):\\n        \"\"\"Configures the given Extension object using this build configuration.\"\"\"\\n        ext.include_dirs += self.include_dirs\\n        ext.library_dirs += self.library_dirs\\n        ext.libraries += self.libraries\\n        ext.extra_compile_args += self.extra_compile_args\\n        ext.extra_link_args += self.extra_link_args\\n        ext.extra_objects += self.extra_objects',\n",
              " 'def detect_from_pkgconfig(self):\\n        \"\"\"Detects the igraph include directory, library directory and the\\n        list of libraries to link to using ``pkg-config``.\"\"\"\\n        if not buildcfg.has_pkgconfig:\\n            print(\"Cannot find the C core of igraph on this system using pkg-config.\")\\n            return False\\n\\n        cmd = \"pkg-config igraph --cflags --libs\"\\n        if self.static_extension:\\n            cmd += \" --static\"\\n        line, exit_code = get_output(cmd)\\n        if exit_code > 0 or len(line) == 0:\\n            return False\\n\\n        opts = line.strip().split()\\n        self.libraries = [opt[2:] for opt in opts if opt.startswith(\"-l\")]\\n        self.library_dirs = [opt[2:] for opt in opts if opt.startswith(\"-L\")]\\n        self.include_dirs = [opt[2:] for opt in opts if opt.startswith(\"-I\")]\\n        return True',\n",
              " 'def download_and_compile_igraph(self):\\n        \"\"\"Downloads and compiles the C core of igraph.\"\"\"\\n        print(\"We will now try to download and compile the C core from scratch.\")\\n        print(\"Version number of the C core: %s\" % self.c_core_versions[0])\\n        if len(self.c_core_versions) > 1:\\n            print(\"We will also try: %s\" % \", \".join(self.c_core_versions[1:]))\\n        print(\"\")\\n\\n        igraph_builder = IgraphCCoreBuilder(self.c_core_versions, self.c_core_url,\\n                show_progress_bar=self.show_progress_bar)\\n        if not igraph_builder.run():\\n            print(\"Could not download and compile the C core of igraph.\")\\n            print(\"\")\\n            return False\\n        else:\\n            return True',\n",
              " 'def print_build_info(self):\\n        \"\"\"Prints the include and library path being used for debugging purposes.\"\"\"\\n        if self.static_extension:\\n            build_type = \"static extension\"\\n        else:\\n            build_type = \"dynamic extension\"\\n        print(\"Build type: %s\" % build_type)\\n        print(\"Include path: %s\" % \" \".join(self.include_dirs))\\n        print(\"Library path: %s\" % \" \".join(self.library_dirs))\\n        print(\"Linked dynamic libraries: %s\" % \" \".join(self.libraries))\\n        print(\"Linked static libraries: %s\" % \" \".join(self.extra_objects))\\n        print(\"Extra compiler options: %s\" % \" \".join(self.extra_compile_args))\\n        print(\"Extra linker options: %s\" % \" \".join(self.extra_link_args))',\n",
              " 'def process_args_from_command_line(self):\\n        \"\"\"Preprocesses the command line options before they are passed to\\n        setup.py and sets up the build configuration.\"\"\"\\n        # Yes, this is ugly, but we don\\'t want to interfere with setup.py\\'s own\\n        # option handling\\n        opts_to_remove = []\\n        for idx, option in enumerate(sys.argv):\\n            if not option.startswith(\"--\"):\\n                continue\\n            if option == \"--static\":\\n                opts_to_remove.append(idx)\\n                self.static_extension = True\\n            elif option == \"--no-download\":\\n                opts_to_remove.append(idx)\\n                self.download_igraph_if_needed = False\\n            elif option == \"--no-pkg-config\":\\n                opts_to_remove.append(idx)\\n                self.use_pkgconfig = False\\n            elif option == \"--no-progress-bar\":\\n                opts_to_remove.append(idx)\\n                self.show_progress_bar = False\\n            elif option == \"--no-wait\":\\n                opts_to_remove.append(idx)\\n                self.wait = False                \\n            elif option.startswith(\"--c-core-version\"):\\n                opts_to_remove.append(idx)\\n                if option == \"--c-core-version\":\\n                    value = sys.argv[idx+1]\\n                    opts_to_remove.append(idx+1)\\n                else:\\n                    value = option.split(\"=\", 1)[1]\\n                self.c_core_versions = [value]\\n            elif option.startswith(\"--c-core-url\"):\\n                opts_to_remove.append(idx)\\n                if option == \"--c-core-url\":\\n                    value = sys.argv[idx+1]\\n                    opts_to_remove.append(idx+1)\\n                else:\\n                    value = option.split(\"=\", 1)[1]\\n                self.c_core_url = value\\n\\n        for idx in reversed(opts_to_remove):\\n            sys.argv[idx:(idx+1)] = []',\n",
              " 'def replace_static_libraries(self, exclusions=None):\\n        \"\"\"Replaces references to libraries with full paths to their static\\n        versions if the static version is to be found on the library path.\"\"\"\\n        if \"stdc++\" not in self.libraries:\\n            self.libraries.append(\"stdc++\")\\n\\n        if exclusions is None:\\n            exclusions = []\\n\\n        for library_name in set(self.libraries) - set(exclusions):\\n            static_lib = find_static_library(library_name, self.library_dirs)\\n            if static_lib:\\n                self.libraries.remove(library_name)\\n                self.extra_objects.append(static_lib)',\n",
              " 'def use_built_igraph(self):\\n        \"\"\"Assumes that igraph is built already in ``igraphcore`` and sets up\\n        the include and library paths and the library names accordingly.\"\"\"\\n        buildcfg.include_dirs = [os.path.join(\"igraphcore\", \"include\")]\\n        buildcfg.library_dirs = [os.path.join(\"igraphcore\", \"lib\")]\\n        buildcfg.static_extension = True\\n\\n        buildcfg_file = os.path.join(\"igraphcore\", \"build.cfg\")\\n        if os.path.exists(buildcfg_file):\\n            buildcfg.libraries = eval(open(buildcfg_file).read())',\n",
              " 'def use_educated_guess(self):\\n        \"\"\"Tries to guess the proper library names, include and library paths\\n        if everything else failed.\"\"\"\\n\\n        preprocess_fallback_config()\\n\\n        global LIBIGRAPH_FALLBACK_LIBRARIES\\n        global LIBIGRAPH_FALLBACK_INCLUDE_DIRS\\n        global LIBIGRAPH_FALLBACK_LIBRARY_DIRS\\n\\n        print(\"WARNING: we were not able to detect where igraph is installed on\")\\n        print(\"your machine (if it is installed at all). We will use the fallback\")\\n        print(\"library and include paths hardcoded in setup.py and hope that the\")\\n        print(\"C core of igraph is installed there.\")\\n        print(\"\")\\n        print(\"If the compilation fails and you are sure that igraph is installed\")\\n        print(\"on your machine, adjust the following two variables in setup.py\")\\n        print(\"accordingly and try again:\")\\n        print(\"\")\\n        print(\"- LIBIGRAPH_FALLBACK_INCLUDE_DIRS\",\\n            LIBIGRAPH_FALLBACK_INCLUDE_DIRS)\\n        print(\"- LIBIGRAPH_FALLBACK_LIBRARY_DIRS\",\\n            LIBIGRAPH_FALLBACK_LIBRARY_DIRS)\\n        print(\"\")\\n\\n        seconds_remaining = 10 if self.wait else 0\\n        while seconds_remaining > 0:\\n            if seconds_remaining > 1:\\n                plural = \"s\"\\n            else:\\n                plural = \"\"\\n\\n            sys.stdout.write(\"\\\\rContinuing in %2d second%s; press Enter to continue \"\\n                    \"immediately. \" % (seconds_remaining, plural))\\n            sys.stdout.flush()\\n\\n            if os.name == \\'nt\\':\\n              if msvcrt.kbhit():\\n                  if msvcrt.getch() == b\\'\\\\r\\': # not \\'\\\\n\\'\\n                      break\\n              time.sleep(1)\\n            else:\\n              rlist, _, _ = select([sys.stdin], [], [], 1)\\n              if rlist:\\n                  sys.stdin.readline()\\n                  break\\n\\n            seconds_remaining -= 1\\n        sys.stdout.write(\"\\\\r\" + \" \"*65 + \"\\\\r\")\\n\\n        self.libraries = LIBIGRAPH_FALLBACK_LIBRARIES[:]\\n        if self.static_extension:\\n            self.libraries.extend([\"xml2\", \"z\", \"m\", \"stdc++\"])\\n        self.include_dirs = LIBIGRAPH_FALLBACK_INCLUDE_DIRS[:]\\n        self.library_dirs = LIBIGRAPH_FALLBACK_LIBRARY_DIRS[:]',\n",
              " 'def main(*args):\\n    \"\"\"Contains flow control\"\"\"\\n    options, args, parser = parse_options(args)\\n\\n    if options.regex and options.write_changes:\\n        print(\\'ERROR: --write-changes cannot be used together with \\'\\n              \\'--regex\\')\\n        parser.print_help()\\n        return 1\\n    word_regex = options.regex or word_regex_def\\n    try:\\n        word_regex = re.compile(word_regex)\\n    except re.error as err:\\n        print(\\'ERROR: invalid regular expression \"%s\" (%s)\\' %\\n              (word_regex, err), file=sys.stderr)\\n        parser.print_help()\\n        return 1\\n\\n    ignore_words_files = options.ignore_words or []\\n    ignore_words = set()\\n    for ignore_words_file in ignore_words_files:\\n        if not os.path.exists(ignore_words_file):\\n            print(\\'ERROR: cannot find ignore-words file: %s\\' %\\n                  ignore_words_file, file=sys.stderr)\\n            parser.print_help()\\n            return 1\\n        build_ignore_words(ignore_words_file, ignore_words)\\n\\n    ignore_words_list = options.ignore_words_list or []\\n    for comma_separated_words in ignore_words_list:\\n        for word in comma_separated_words.split(\\',\\'):\\n            ignore_words.add(word.strip())\\n\\n    dictionaries = options.dictionary or [default_dictionary]\\n    misspellings = dict()\\n    for dictionary in dictionaries:\\n        if dictionary == \"-\":\\n            dictionary = default_dictionary\\n        if not os.path.exists(dictionary):\\n            print(\\'ERROR: cannot find dictionary file: %s\\' % dictionary,\\n                  file=sys.stderr)\\n            parser.print_help()\\n            return 1\\n        build_dict(dictionary, misspellings, ignore_words)\\n    colors = TermColors()\\n    if not options.colors or sys.platform == \\'win32\\':\\n        colors.disable()\\n\\n    if options.summary:\\n        summary = Summary()\\n    else:\\n        summary = None\\n\\n    context = None\\n    if options.context is not None:\\n        if (options.before_context is not None) or \\\\\\n                (options.after_context is not None):\\n            print(\\'ERROR: --context/-C cannot be used together with \\'\\n                  \\'--context-before/-B or --context-after/-A\\')\\n            parser.print_help()\\n            return 1\\n        context_both = max(0, options.context)\\n        context = (context_both, context_both)\\n    elif (options.before_context is not None) or \\\\\\n            (options.after_context is not None):\\n        context_before = 0\\n        context_after = 0\\n        if options.before_context is not None:\\n            context_before = max(0, options.before_context)\\n        if options.after_context is not None:\\n            context_after = max(0, options.after_context)\\n        context = (context_before, context_after)\\n\\n    exclude_lines = set()\\n    if options.exclude_file:\\n        build_exclude_hashes(options.exclude_file, exclude_lines)\\n\\n    file_opener = FileOpener(options.hard_encoding_detection,\\n                             options.quiet_level)\\n    glob_match = GlobMatch(options.skip)\\n\\n    bad_count = 0\\n    for filename in args:\\n        # ignore hidden files\\n        if is_hidden(filename, options.check_hidden):\\n            continue\\n\\n        if os.path.isdir(filename):\\n            for root, dirs, files in os.walk(filename):\\n                if glob_match.match(root):  # skip (absolute) directories\\n                    del dirs[:]\\n                    continue\\n                for file_ in files:\\n                    if glob_match.match(file_):  # skip files\\n                        continue\\n                    fname = os.path.join(root, file_)\\n                    if glob_match.match(fname):  # skip paths\\n                        continue\\n                    if not os.path.isfile(fname) or not os.path.getsize(fname):\\n                        continue\\n                    bad_count += parse_file(\\n                        fname, colors, summary, misspellings, exclude_lines,\\n                        file_opener, word_regex, context, options)\\n\\n                # skip (relative) directories\\n                dirs[:] = [dir_ for dir_ in dirs if not glob_match.match(dir_)]\\n\\n        else:\\n            bad_count += parse_file(\\n                filename, colors, summary, misspellings, exclude_lines,\\n                file_opener, word_regex, context, options)\\n\\n    if summary:\\n        print(\"\\\\n-------8<-------\\\\nSUMMARY:\")\\n        print(summary)\\n    return bad_count',\n",
              " 'def capture(self, data_buffer = None, log_time = False, debug_print = False, retry_reset = True):\\n    \"\"\"Capture a frame of data.\\n\\n    Captures 80x60 uint16 array of non-normalized (raw 12-bit) data. Returns that frame and a frame_id (which\\n    is currently just the sum of all pixels). The Lepton will return multiple, identical frames at a rate of up\\n    to ~27 Hz, with unique frames at only ~9 Hz, so the frame_id can help you from doing additional work\\n    processing duplicate frames.\\n\\n    Args:\\n      data_buffer (numpy.ndarray): Optional. If specified, should be ``(60,80,1)`` with `dtype`=``numpy.uint16``.\\n\\n    Returns:\\n      tuple consisting of (data_buffer, frame_id)\\n    \"\"\"\\n\\n    start = time.time()\\n\\n    if data_buffer is None:\\n      data_buffer = np.ndarray((Lepton.ROWS, Lepton.COLS, 1), dtype=np.uint16)\\n    elif data_buffer.ndim < 2 or data_buffer.shape[0] < Lepton.ROWS or data_buffer.shape[1] < Lepton.COLS or data_buffer.itemsize < 2:\\n      raise Exception(\"Provided input array not large enough\")\\n\\n    while True:\\n      Lepton.capture_segment(self.__handle, self.__xmit_buf, self.__msg_size, self.__capture_buf[0])\\n      if retry_reset and (self.__capture_buf[20, 0] & 0xFF0F) != 0x1400: # make sure that this is a well-formed frame, should find line 20 here\\n        # Leave chip select deasserted for at least 185 ms to reset\\n        if debug_print:\\n          print(\"Garbage frame number reset waiting...\")\\n        time.sleep(0.185)\\n      else:\\n        break\\n\\n    self.__capture_buf.byteswap(True)\\n    data_buffer[:,:] = self.__capture_buf[:,2:]\\n\\n    end = time.time()\\n\\n    if debug_print:\\n      print(\"---\")\\n      for i in range(Lepton.ROWS):\\n        fid = self.__capture_buf[i, 0, 0]\\n        crc = self.__capture_buf[i, 1, 0]\\n        fnum = fid & 0xFFF\\n        print(\"0x{0:04x} 0x{1:04x} : Row {2:2} : crc={1}\".format(fid, crc, fnum))\\n      print(\"---\")\\n\\n    if log_time:\\n      print(\"frame processed int {0}s, {1}hz\".format(end-start, 1.0/(end-start)))\\n\\n    # TODO: turn on telemetry to get real frame id, sum on this array is fast enough though (< 500us)\\n    return data_buffer, data_buffer.sum()',\n",
              " 'def disambiguate(self, word):\\n        \"\"\"Disambiguate Prefix Rule 24\\n        Rule 24 : perCAerV -> per-CAerV where C != \\'r\\'\\n        \"\"\"\\n        matches = re.match(r\\'^per([bcdfghjklmnpqrstvwxyz])([a-z])er([aiueo])(.*)$\\', word)\\n        if matches:\\n            if matches.group(1) == \\'r\\':\\n                return\\n            return matches.group(1) + matches.group(2) + \\'er\\' + matches.group(3) + matches.group(4)',\n",
              " 'def stem(self, text):\\n        \"\"\"Stem a text string to its common stem form.\"\"\"\\n        normalizedText = TextNormalizer.normalize_text(text)\\n\\n        words = normalizedText.split(\\' \\')\\n        stems = []\\n\\n        for word in words:\\n            stems.append(self.stem_word(word))\\n\\n        return \\' \\'.join(stems)',\n",
              " 'def stem_word(self, word):\\n        \"\"\"Stem a word to its common stem form.\"\"\"\\n        if self.is_plural(word):\\n            return self.stem_plural_word(word)\\n        else:\\n            return self.stem_singular_word(word)',\n",
              " 'def stem_plural_word(self, plural):\\n        \"\"\"Stem a plural word to its common stem form.\\n        Asian J. (2007) \"Effective Techniques for Indonesian Text Retrieval\" page 76-77.\\n\\n        @link   http://researchbank.rmit.edu.au/eserv/rmit:6312/Asian.pdf\\n        \"\"\"\\n        matches = re.match(r\\'^(.*)-(.*)$\\', plural)\\n        #translated from PHP conditional check:\\n        #if (!isset($words[1]) || !isset($words[2]))\\n        if not matches:\\n            return plural\\n        words = [matches.group(1), matches.group(2)]\\n\\n        #malaikat-malaikat-nya -> malaikat malaikat-nya\\n        suffix = words[1]\\n        suffixes = [\\'ku\\', \\'mu\\', \\'nya\\', \\'lah\\', \\'kah\\', \\'tah\\', \\'pun\\']\\n        matches = re.match(r\\'^(.*)-(.*)$\\', words[0])\\n        if suffix in suffixes and matches:\\n            words[0] = matches.group(1)\\n            words[1] = matches.group(2) + \\'-\\' + suffix\\n\\n        #berbalas-balasan -> balas\\n        rootWord1 = self.stem_singular_word(words[0])\\n        rootWord2 = self.stem_singular_word(words[1])\\n\\n        #meniru-nirukan -> tiru\\n        if not self.dictionary.contains(words[1]) and rootWord2 == words[1]:\\n            rootWord2 = self.stem_singular_word(\\'me\\' + words[1])\\n\\n        if rootWord1 == rootWord2:\\n            return rootWord1\\n        else:\\n            return plural',\n",
              " 'def stem_singular_word(self, word):\\n        \"\"\"Stem a singular word to its common stem form.\"\"\"\\n        context = Context(word, self.dictionary, self.visitor_provider)\\n        context.execute()\\n\\n        return context.result',\n",
              " 'def execute(self):\\n        \"\"\"Execute stemming process; the result can be retrieved with result\"\"\"\\n\\n        #step 1 - 5\\n        self.start_stemming_process()\\n\\n        #step 6\\n        if self.dictionary.contains(self.current_word):\\n            self.result = self.current_word\\n        else:\\n            self.result = self.original_word',\n",
              " 'def loop_pengembalian_akhiran(self):\\n        \"\"\"ECS Loop Pengembalian Akhiran\"\"\"\\n        self.restore_prefix()\\n\\n        removals = self.removals\\n        reversed_removals = reversed(removals)\\n        current_word = self.current_word\\n\\n        for removal in reversed_removals:\\n            if not self.is_suffix_removal(removal):\\n                continue\\n            if removal.get_removed_part() == \\'kan\\':\\n                self.current_word = removal.result + \\'k\\'\\n\\n                #step 4,5\\n                self.remove_prefixes()\\n                if self.dictionary.contains(self.current_word):\\n                    return\\n                self.current_word = removal.result + \\'kan\\'\\n            else:\\n                self.current_word = removal.get_subject()\\n\\n            #step 4,5\\n            self.remove_prefixes()\\n            if self.dictionary.contains(self.current_word):\\n                return\\n\\n            self.removals = removals\\n            self.current_word = current_word',\n",
              " 'def restore_prefix(self):\\n        \"\"\"Restore prefix to proceed with ECS loop pengembalian akhiran\"\"\"\\n        for removal in self.removals:\\n            #return the word before precoding (the subject of first prefix removal)\\n            self.current_word = removal.get_subject()\\n            break\\n\\n        for removal in self.removals:\\n            if removal.get_affix_type() == \\'DP\\':\\n                self.removals.remove(removal)',\n",
              " 'def remove(self, text):\\n        \"\"\"Remove stop words.\"\"\"\\n        words = text.split(\\' \\')\\n        stopped_words = [word for word in words if not self.dictionary.contains(word)]\\n\\n        return \\' \\'.join(stopped_words)',\n",
              " 'def create_stemmer(self, isDev=False):\\n        \"\"\" Returns Stemmer instance \"\"\"\\n\\n        words = self.get_words(isDev)\\n        dictionary = ArrayDictionary(words)\\n        stemmer = Stemmer(dictionary)\\n\\n        resultCache = ArrayCache()\\n        cachedStemmer = CachedStemmer(resultCache, stemmer)\\n\\n        return cachedStemmer',\n",
              " 'def add(self, word):\\n        \"\"\"Add a word to the dictionary\"\"\"\\n        if not word or word.strip() == \\'\\':\\n            return\\n        self.words[word]=word',\n",
              " 'def truth(f):\\n    \"\"\"Convenience decorator to convert truth functions into validators.\\n\\n        >>> @truth\\n        ... def isdir(v):\\n        ...   return os.path.isdir(v)\\n        >>> validate = Schema(isdir)\\n        >>> validate(\\'/\\')\\n        \\'/\\'\\n        >>> with raises(MultipleInvalid, \\'not a valid value\\'):\\n        ...   validate(\\'/notavaliddir\\')\\n    \"\"\"\\n\\n    @wraps(f)\\n    def check(v):\\n        t = f(v)\\n        if not t:\\n            raise ValueError\\n        return v\\n\\n    return check',\n",
              " 'def Boolean(v):\\n    \"\"\"Convert human-readable boolean values to a bool.\\n\\n    Accepted values are 1, true, yes, on, enable, and their negatives.\\n    Non-string values are cast to bool.\\n\\n    >>> validate = Schema(Boolean())\\n    >>> validate(True)\\n    True\\n    >>> validate(\"1\")\\n    True\\n    >>> validate(\"0\")\\n    False\\n    >>> with raises(MultipleInvalid, \"expected boolean\"):\\n    ...   validate(\\'moo\\')\\n    >>> try:\\n    ...  validate(\\'moo\\')\\n    ... except MultipleInvalid as e:\\n    ...   assert isinstance(e.errors[0], BooleanInvalid)\\n    \"\"\"\\n    if isinstance(v, basestring):\\n        v = v.lower()\\n        if v in (\\'1\\', \\'true\\', \\'yes\\', \\'on\\', \\'enable\\'):\\n            return True\\n        if v in (\\'0\\', \\'false\\', \\'no\\', \\'off\\', \\'disable\\'):\\n            return False\\n        raise ValueError\\n    return bool(v)',\n",
              " 'def Email(v):\\n    \"\"\"Verify that the value is an Email or not.\\n\\n    >>> s = Schema(Email())\\n    >>> with raises(MultipleInvalid, \\'expected an Email\\'):\\n    ...   s(\"a.com\")\\n    >>> with raises(MultipleInvalid, \\'expected an Email\\'):\\n    ...   s(\"a@.com\")\\n    >>> with raises(MultipleInvalid, \\'expected an Email\\'):\\n    ...   s(\"a@.com\")\\n    >>> s(\\'t@x.com\\')\\n    \\'t@x.com\\'\\n    \"\"\"\\n    try:\\n        if not v or \"@\" not in v:\\n            raise EmailInvalid(\"Invalid Email\")\\n        user_part, domain_part = v.rsplit(\\'@\\', 1)\\n\\n        if not (USER_REGEX.match(user_part) and DOMAIN_REGEX.match(domain_part)):\\n            raise EmailInvalid(\"Invalid Email\")\\n        return v\\n    except:\\n        raise ValueError',\n",
              " 'def FqdnUrl(v):\\n    \"\"\"Verify that the value is a Fully qualified domain name URL.\\n\\n    >>> s = Schema(FqdnUrl())\\n    >>> with raises(MultipleInvalid, \\'expected a Fully qualified domain name URL\\'):\\n    ...   s(\"http://localhost/\")\\n    >>> s(\\'http://w3.org\\')\\n    \\'http://w3.org\\'\\n    \"\"\"\\n    try:\\n        parsed_url = _url_validation(v)\\n        if \".\" not in parsed_url.netloc:\\n            raise UrlInvalid(\"must have a domain name in URL\")\\n        return v\\n    except:\\n        raise ValueError',\n",
              " 'def IsFile(v):\\n    \"\"\"Verify the file exists.\\n\\n    >>> os.path.basename(IsFile()(__file__)).startswith(\\'validators.py\\')\\n    True\\n    >>> with raises(FileInvalid, \\'not a file\\'):\\n    ...   IsFile()(\"random_filename_goes_here.py\")\\n    >>> with raises(FileInvalid, \\'Not a file\\'):\\n    ...   IsFile()(None)\\n    \"\"\"\\n    try:\\n        if v:\\n            v = str(v)\\n            return os.path.isfile(v)\\n        else:\\n            raise FileInvalid(\\'Not a file\\')\\n    except TypeError:\\n        raise FileInvalid(\\'Not a file\\')',\n",
              " 'def IsDir(v):\\n    \"\"\"Verify the directory exists.\\n\\n    >>> IsDir()(\\'/\\')\\n    \\'/\\'\\n    >>> with raises(DirInvalid, \\'Not a directory\\'):\\n    ...   IsDir()(None)\\n    \"\"\"\\n    try:\\n        if v:\\n            v = str(v)\\n            return os.path.isdir(v)\\n        else:\\n            raise DirInvalid(\"Not a directory\")\\n    except TypeError:\\n        raise DirInvalid(\"Not a directory\")',\n",
              " 'def PathExists(v):\\n    \"\"\"Verify the path exists, regardless of its type.\\n\\n    >>> os.path.basename(PathExists()(__file__)).startswith(\\'validators.py\\')\\n    True\\n    >>> with raises(Invalid, \\'path does not exist\\'):\\n    ...   PathExists()(\"random_filename_goes_here.py\")\\n    >>> with raises(PathInvalid, \\'Not a Path\\'):\\n    ...   PathExists()(None)\\n    \"\"\"\\n    try:\\n        if v:\\n            v = str(v)\\n            return os.path.exists(v)\\n        else:\\n            raise PathInvalid(\"Not a Path\")\\n    except TypeError:\\n        raise PathInvalid(\"Not a Path\")',\n",
              " 'def _get_precision_scale(self, number):\\n        \"\"\"\\n        :param number:\\n        :return: tuple(precision, scale, decimal_number)\\n        \"\"\"\\n        try:\\n            decimal_num = Decimal(number)\\n        except InvalidOperation:\\n            raise Invalid(self.msg or \\'Value must be a number enclosed with string\\')\\n\\n        return (len(decimal_num.as_tuple().digits), -(decimal_num.as_tuple().exponent), decimal_num)',\n",
              " 'def humanize_error(data, validation_error, max_sub_error_length=MAX_VALIDATION_ERROR_ITEM_LENGTH):\\n    \"\"\" Provide a more helpful + complete validation error message than that provided automatically\\n    Invalid and MultipleInvalid do not include the offending value in error messages,\\n    and MultipleInvalid.__str__ only provides the first error.\\n    \"\"\"\\n    if isinstance(validation_error, MultipleInvalid):\\n        return \\'\\\\n\\'.join(sorted(\\n            humanize_error(data, sub_error, max_sub_error_length)\\n            for sub_error in validation_error.errors\\n        ))\\n    else:\\n        offending_item_summary = repr(_nested_getitem(data, validation_error.path))\\n        if len(offending_item_summary) > max_sub_error_length:\\n            offending_item_summary = offending_item_summary[:max_sub_error_length - 3] + \\'...\\'\\n        return \\'%s. Got %s\\' % (validation_error, offending_item_summary)',\n",
              " 'def _compile_scalar(schema):\\n    \"\"\"A scalar value.\\n\\n    The schema can either be a value or a type.\\n\\n    >>> _compile_scalar(int)([], 1)\\n    1\\n    >>> with raises(er.Invalid, \\'expected float\\'):\\n    ...   _compile_scalar(float)([], \\'1\\')\\n\\n    Callables have\\n    >>> _compile_scalar(lambda v: float(v))([], \\'1\\')\\n    1.0\\n\\n    As a convenience, ValueError\\'s are trapped:\\n\\n    >>> with raises(er.Invalid, \\'not a valid value\\'):\\n    ...   _compile_scalar(lambda v: float(v))([], \\'a\\')\\n    \"\"\"\\n    if inspect.isclass(schema):\\n        def validate_instance(path, data):\\n            if isinstance(data, schema):\\n                return data\\n            else:\\n                msg = \\'expected %s\\' % schema.__name__\\n                raise er.TypeInvalid(msg, path)\\n\\n        return validate_instance\\n\\n    if callable(schema):\\n        def validate_callable(path, data):\\n            try:\\n                return schema(data)\\n            except ValueError as e:\\n                raise er.ValueInvalid(\\'not a valid value\\', path)\\n            except er.Invalid as e:\\n                e.prepend(path)\\n                raise\\n\\n        return validate_callable\\n\\n    def validate_value(path, data):\\n        if data != schema:\\n            raise er.ScalarInvalid(\\'not a valid value\\', path)\\n        return data\\n\\n    return validate_value',\n",
              " \"def _compile_itemsort():\\n    '''return sort function of mappings'''\\n\\n    def is_extra(key_):\\n        return key_ is Extra\\n\\n    def is_remove(key_):\\n        return isinstance(key_, Remove)\\n\\n    def is_marker(key_):\\n        return isinstance(key_, Marker)\\n\\n    def is_type(key_):\\n        return inspect.isclass(key_)\\n\\n    def is_callable(key_):\\n        return callable(key_)\\n\\n    # priority list for map sorting (in order of checking)\\n    # We want Extra to match last, because it's a catch-all. On the other hand,\\n    # Remove markers should match first (since invalid values will not\\n    # raise an Error, instead the validator will check if other schemas match\\n    # the same value).\\n    priority = [(1, is_remove),  # Remove highest priority after values\\n                (2, is_marker),  # then other Markers\\n                (4, is_type),  # types/classes lowest before Extra\\n                (3, is_callable),  # callables after markers\\n                (5, is_extra)]  # Extra lowest priority\\n\\n    def item_priority(item_):\\n        key_ = item_[0]\\n        for i, check_ in priority:\\n            if check_(key_):\\n                return i\\n        # values have hightest priorities\\n        return 0\\n\\n    return item_priority\",\n",
              " 'def _iterate_object(obj):\\n    \"\"\"Return iterator over object attributes. Respect objects with\\n    defined __slots__.\\n\\n    \"\"\"\\n    d = {}\\n    try:\\n        d = vars(obj)\\n    except TypeError:\\n        # maybe we have named tuple here?\\n        if hasattr(obj, \\'_asdict\\'):\\n            d = obj._asdict()\\n    for item in iteritems(d):\\n        yield item\\n    try:\\n        slots = obj.__slots__\\n    except AttributeError:\\n        pass\\n    else:\\n        for key in slots:\\n            if key != \\'__dict__\\':\\n                yield (key, getattr(obj, key))',\n",
              " 'def message(default=None, cls=None):\\n    \"\"\"Convenience decorator to allow functions to provide a message.\\n\\n    Set a default message:\\n\\n        >>> @message(\\'not an integer\\')\\n        ... def isint(v):\\n        ...   return int(v)\\n\\n        >>> validate = Schema(isint())\\n        >>> with raises(er.MultipleInvalid, \\'not an integer\\'):\\n        ...   validate(\\'a\\')\\n\\n    The message can be overridden on a per validator basis:\\n\\n        >>> validate = Schema(isint(\\'bad\\'))\\n        >>> with raises(er.MultipleInvalid, \\'bad\\'):\\n        ...   validate(\\'a\\')\\n\\n    The class thrown too:\\n\\n        >>> class IntegerInvalid(er.Invalid): pass\\n        >>> validate = Schema(isint(\\'bad\\', clsoverride=IntegerInvalid))\\n        >>> try:\\n        ...  validate(\\'a\\')\\n        ... except er.MultipleInvalid as e:\\n        ...   assert isinstance(e.errors[0], IntegerInvalid)\\n    \"\"\"\\n    if cls and not issubclass(cls, er.Invalid):\\n        raise er.SchemaError(\"message can only use subclases of Invalid as custom class\")\\n\\n    def decorator(f):\\n        @wraps(f)\\n        def check(msg=None, clsoverride=None):\\n            @wraps(f)\\n            def wrapper(*args, **kwargs):\\n                try:\\n                    return f(*args, **kwargs)\\n                except ValueError:\\n                    raise (clsoverride or cls or er.ValueInvalid)(msg or default or \\'invalid value\\')\\n\\n            return wrapper\\n\\n        return check\\n\\n    return decorator',\n",
              " 'def _args_to_dict(func, args):\\n    \"\"\"Returns argument names as values as key-value pairs.\"\"\"\\n    if sys.version_info >= (3, 0):\\n        arg_count = func.__code__.co_argcount\\n        arg_names = func.__code__.co_varnames[:arg_count]\\n    else:\\n        arg_count = func.func_code.co_argcount\\n        arg_names = func.func_code.co_varnames[:arg_count]\\n\\n    arg_value_list = list(args)\\n    arguments = dict((arg_name, arg_value_list[i])\\n                     for i, arg_name in enumerate(arg_names)\\n                     if i < len(arg_value_list))\\n    return arguments',\n",
              " 'def _merge_args_with_kwargs(args_dict, kwargs_dict):\\n    \"\"\"Merge args with kwargs.\"\"\"\\n    ret = args_dict.copy()\\n    ret.update(kwargs_dict)\\n    return ret',\n",
              " 'def validate(*a, **kw):\\n    \"\"\"Decorator for validating arguments of a function against a given schema.\\n\\n    Set restrictions for arguments:\\n\\n        >>> @validate(arg1=int, arg2=int)\\n        ... def foo(arg1, arg2):\\n        ...   return arg1 * arg2\\n\\n    Set restriction for returned value:\\n\\n        >>> @validate(arg=int, __return__=int)\\n        ... def bar(arg1):\\n        ...   return arg1 * 2\\n\\n    \"\"\"\\n    RETURNS_KEY = \\'__return__\\'\\n\\n    def validate_schema_decorator(func):\\n\\n        returns_defined = False\\n        returns = None\\n\\n        schema_args_dict = _args_to_dict(func, a)\\n        schema_arguments = _merge_args_with_kwargs(schema_args_dict, kw)\\n\\n        if RETURNS_KEY in schema_arguments:\\n            returns_defined = True\\n            returns = schema_arguments[RETURNS_KEY]\\n            del schema_arguments[RETURNS_KEY]\\n\\n        input_schema = (Schema(schema_arguments, extra=ALLOW_EXTRA)\\n                        if len(schema_arguments) != 0 else lambda x: x)\\n        output_schema = Schema(returns) if returns_defined else lambda x: x\\n\\n        @wraps(func)\\n        def func_wrapper(*args, **kwargs):\\n            args_dict = _args_to_dict(func, args)\\n            arguments = _merge_args_with_kwargs(args_dict, kwargs)\\n            validated_arguments = input_schema(arguments)\\n            output = func(**validated_arguments)\\n            return output_schema(output)\\n\\n        return func_wrapper\\n\\n    return validate_schema_decorator',\n",
              " 'def infer(cls, data, **kwargs):\\n        \"\"\"Create a Schema from concrete data (e.g. an API response).\\n\\n        For example, this will take a dict like:\\n\\n        {\\n            \\'foo\\': 1,\\n            \\'bar\\': {\\n                \\'a\\': True,\\n                \\'b\\': False\\n            },\\n            \\'baz\\': [\\'purple\\', \\'monkey\\', \\'dishwasher\\']\\n        }\\n\\n        And return a Schema:\\n\\n        {\\n            \\'foo\\': int,\\n            \\'bar\\': {\\n                \\'a\\': bool,\\n                \\'b\\': bool\\n            },\\n            \\'baz\\': [str]\\n        }\\n\\n        Note: only very basic inference is supported.\\n        \"\"\"\\n        def value_to_schema_type(value):\\n            if isinstance(value, dict):\\n                if len(value) == 0:\\n                    return dict\\n                return {k: value_to_schema_type(v)\\n                        for k, v in iteritems(value)}\\n            if isinstance(value, list):\\n                if len(value) == 0:\\n                    return list\\n                else:\\n                    return [value_to_schema_type(v)\\n                            for v in value]\\n            return type(value)\\n\\n        return cls(value_to_schema_type(data), **kwargs)',\n",
              " 'def _compile_mapping(self, schema, invalid_msg=None):\\n        \"\"\"Create validator for given mapping.\"\"\"\\n        invalid_msg = invalid_msg or \\'mapping value\\'\\n\\n        # Keys that may be required\\n        all_required_keys = set(key for key in schema\\n                                if key is not Extra and\\n                                ((self.required and not isinstance(key, (Optional, Remove))) or\\n                                 isinstance(key, Required)))\\n\\n        # Keys that may have defaults\\n        all_default_keys = set(key for key in schema\\n                               if isinstance(key, Required) or\\n                               isinstance(key, Optional))\\n\\n        _compiled_schema = {}\\n        for skey, svalue in iteritems(schema):\\n            new_key = self._compile(skey)\\n            new_value = self._compile(svalue)\\n            _compiled_schema[skey] = (new_key, new_value)\\n\\n        candidates = list(_iterate_mapping_candidates(_compiled_schema))\\n\\n        # After we have the list of candidates in the correct order, we want to apply some optimization so that each\\n        # key in the data being validated will be matched against the relevant schema keys only.\\n        # No point in matching against different keys\\n        additional_candidates = []\\n        candidates_by_key = {}\\n        for skey, (ckey, cvalue) in candidates:\\n            if type(skey) in primitive_types:\\n                candidates_by_key.setdefault(skey, []).append((skey, (ckey, cvalue)))\\n            elif isinstance(skey, Marker) and type(skey.schema) in primitive_types:\\n                candidates_by_key.setdefault(skey.schema, []).append((skey, (ckey, cvalue)))\\n            else:\\n                # These are wildcards such as \\'int\\', \\'str\\', \\'Remove\\' and others which should be applied to all keys\\n                additional_candidates.append((skey, (ckey, cvalue)))\\n\\n        def validate_mapping(path, iterable, out):\\n            required_keys = all_required_keys.copy()\\n\\n            # Build a map of all provided key-value pairs.\\n            # The type(out) is used to retain ordering in case a ordered\\n            # map type is provided as input.\\n            key_value_map = type(out)()\\n            for key, value in iterable:\\n                key_value_map[key] = value\\n\\n            # Insert default values for non-existing keys.\\n            for key in all_default_keys:\\n                if not isinstance(key.default, Undefined) and \\\\\\n                   key.schema not in key_value_map:\\n                    # A default value has been specified for this missing\\n                    # key, insert it.\\n                    key_value_map[key.schema] = key.default()\\n\\n            error = None\\n            errors = []\\n            for key, value in key_value_map.items():\\n                key_path = path + [key]\\n                remove_key = False\\n\\n                # Optimization. Validate against the matching key first, then fallback to the rest\\n                relevant_candidates = itertools.chain(candidates_by_key.get(key, []), additional_candidates)\\n\\n                # compare each given key/value against all compiled key/values\\n                # schema key, (compiled key, compiled value)\\n                for skey, (ckey, cvalue) in relevant_candidates:\\n                    try:\\n                        new_key = ckey(key_path, key)\\n                    except er.Invalid as e:\\n                        if len(e.path) > len(key_path):\\n                            raise\\n                        if not error or len(e.path) > len(error.path):\\n                            error = e\\n                        continue\\n                    # Backtracking is not performed once a key is selected, so if\\n                    # the value is invalid we immediately throw an exception.\\n                    exception_errors = []\\n                    # check if the key is marked for removal\\n                    is_remove = new_key is Remove\\n                    try:\\n                        cval = cvalue(key_path, value)\\n                        # include if it\\'s not marked for removal\\n                        if not is_remove:\\n                            out[new_key] = cval\\n                        else:\\n                            remove_key = True\\n                            continue\\n                    except er.MultipleInvalid as e:\\n                        exception_errors.extend(e.errors)\\n                    except er.Invalid as e:\\n                        exception_errors.append(e)\\n\\n                    if exception_errors:\\n                        if is_remove or remove_key:\\n                            continue\\n                        for err in exception_errors:\\n                            if len(err.path) <= len(key_path):\\n                                err.error_type = invalid_msg\\n                            errors.append(err)\\n                        # If there is a validation error for a required\\n                        # key, this means that the key was provided.\\n                        # Discard the required key so it does not\\n                        # create an additional, noisy exception.\\n                        required_keys.discard(skey)\\n                        break\\n\\n                    # Key and value okay, mark as found in case it was\\n                    # a Required() field.\\n                    required_keys.discard(skey)\\n\\n                    break\\n                else:\\n                    if remove_key:\\n                        # remove key\\n                        continue\\n                    elif self.extra == ALLOW_EXTRA:\\n                        out[key] = value\\n                    elif self.extra != REMOVE_EXTRA:\\n                        errors.append(er.Invalid(\\'extra keys not allowed\\', key_path))\\n                        # else REMOVE_EXTRA: ignore the key so it\\'s removed from output\\n\\n            # for any required keys left that weren\\'t found and don\\'t have defaults:\\n            for key in required_keys:\\n                msg = key.msg if hasattr(key, \\'msg\\') and key.msg else \\'required key not provided\\'\\n                errors.append(er.RequiredFieldInvalid(msg, path + [key]))\\n            if errors:\\n                raise er.MultipleInvalid(errors)\\n\\n            return out\\n\\n        return validate_mapping',\n",
              " 'def _compile_object(self, schema):\\n        \"\"\"Validate an object.\\n\\n        Has the same behavior as dictionary validator but work with object\\n        attributes.\\n\\n        For example:\\n\\n            >>> class Structure(object):\\n            ...     def __init__(self, one=None, three=None):\\n            ...         self.one = one\\n            ...         self.three = three\\n            ...\\n            >>> validate = Schema(Object({\\'one\\': \\'two\\', \\'three\\': \\'four\\'}, cls=Structure))\\n            >>> with raises(er.MultipleInvalid, \"not a valid value for object value @ data[\\'one\\']\"):\\n            ...   validate(Structure(one=\\'three\\'))\\n\\n        \"\"\"\\n        base_validate = self._compile_mapping(\\n            schema, invalid_msg=\\'object value\\')\\n\\n        def validate_object(path, data):\\n            if schema.cls is not UNDEFINED and not isinstance(data, schema.cls):\\n                raise er.ObjectInvalid(\\'expected a {0!r}\\'.format(schema.cls), path)\\n            iterable = _iterate_object(data)\\n            iterable = ifilter(lambda item: item[1] is not None, iterable)\\n            out = base_validate(path, iterable, {})\\n            return type(data)(**out)\\n\\n        return validate_object',\n",
              " 'def _compile_dict(self, schema):\\n        \"\"\"Validate a dictionary.\\n\\n        A dictionary schema can contain a set of values, or at most one\\n        validator function/type.\\n\\n        A dictionary schema will only validate a dictionary:\\n\\n            >>> validate = Schema({})\\n            >>> with raises(er.MultipleInvalid, \\'expected a dictionary\\'):\\n            ...   validate([])\\n\\n        An invalid dictionary value:\\n\\n            >>> validate = Schema({\\'one\\': \\'two\\', \\'three\\': \\'four\\'})\\n            >>> with raises(er.MultipleInvalid, \"not a valid value for dictionary value @ data[\\'one\\']\"):\\n            ...   validate({\\'one\\': \\'three\\'})\\n\\n        An invalid key:\\n\\n            >>> with raises(er.MultipleInvalid, \"extra keys not allowed @ data[\\'two\\']\"):\\n            ...   validate({\\'two\\': \\'three\\'})\\n\\n\\n        Validation function, in this case the \"int\" type:\\n\\n            >>> validate = Schema({\\'one\\': \\'two\\', \\'three\\': \\'four\\', int: str})\\n\\n        Valid integer input:\\n\\n            >>> validate({10: \\'twenty\\'})\\n            {10: \\'twenty\\'}\\n\\n        By default, a \"type\" in the schema (in this case \"int\") will be used\\n        purely to validate that the corresponding value is of that type. It\\n        will not Coerce the value:\\n\\n            >>> with raises(er.MultipleInvalid, \"extra keys not allowed @ data[\\'10\\']\"):\\n            ...   validate({\\'10\\': \\'twenty\\'})\\n\\n        Wrap them in the Coerce() function to achieve this:\\n            >>> from voluptuous import Coerce\\n            >>> validate = Schema({\\'one\\': \\'two\\', \\'three\\': \\'four\\',\\n            ...                    Coerce(int): str})\\n            >>> validate({\\'10\\': \\'twenty\\'})\\n            {10: \\'twenty\\'}\\n\\n        Custom message for required key\\n\\n            >>> validate = Schema({Required(\\'one\\', \\'required\\'): \\'two\\'})\\n            >>> with raises(er.MultipleInvalid, \"required @ data[\\'one\\']\"):\\n            ...   validate({})\\n\\n        (This is to avoid unexpected surprises.)\\n\\n        Multiple errors for nested field in a dict:\\n\\n        >>> validate = Schema({\\n        ...     \\'adict\\': {\\n        ...         \\'strfield\\': str,\\n        ...         \\'intfield\\': int\\n        ...     }\\n        ... })\\n        >>> try:\\n        ...     validate({\\n        ...         \\'adict\\': {\\n        ...             \\'strfield\\': 123,\\n        ...             \\'intfield\\': \\'one\\'\\n        ...         }\\n        ...     })\\n        ... except er.MultipleInvalid as e:\\n        ...     print(sorted(str(i) for i in e.errors)) # doctest: +NORMALIZE_WHITESPACE\\n        [\"expected int for dictionary value @ data[\\'adict\\'][\\'intfield\\']\",\\n         \"expected str for dictionary value @ data[\\'adict\\'][\\'strfield\\']\"]\\n\\n        \"\"\"\\n        base_validate = self._compile_mapping(\\n            schema, invalid_msg=\\'dictionary value\\')\\n\\n        groups_of_exclusion = {}\\n        groups_of_inclusion = {}\\n        for node in schema:\\n            if isinstance(node, Exclusive):\\n                g = groups_of_exclusion.setdefault(node.group_of_exclusion, [])\\n                g.append(node)\\n            elif isinstance(node, Inclusive):\\n                g = groups_of_inclusion.setdefault(node.group_of_inclusion, [])\\n                g.append(node)\\n\\n        def validate_dict(path, data):\\n            if not isinstance(data, dict):\\n                raise er.DictInvalid(\\'expected a dictionary\\', path)\\n\\n            errors = []\\n            for label, group in groups_of_exclusion.items():\\n                exists = False\\n                for exclusive in group:\\n                    if exclusive.schema in data:\\n                        if exists:\\n                            msg = exclusive.msg if hasattr(exclusive, \\'msg\\') and exclusive.msg else \\\\\\n                                \"two or more values in the same group of exclusion \\'%s\\'\" % label\\n                            next_path = path + [VirtualPathComponent(label)]\\n                            errors.append(er.ExclusiveInvalid(msg, next_path))\\n                            break\\n                        exists = True\\n\\n            if errors:\\n                raise er.MultipleInvalid(errors)\\n\\n            for label, group in groups_of_inclusion.items():\\n                included = [node.schema in data for node in group]\\n                if any(included) and not all(included):\\n                    msg = \"some but not all values in the same group of inclusion \\'%s\\'\" % label\\n                    for g in group:\\n                        if hasattr(g, \\'msg\\') and g.msg:\\n                            msg = g.msg\\n                            break\\n                    next_path = path + [VirtualPathComponent(label)]\\n                    errors.append(er.InclusiveInvalid(msg, next_path))\\n                    break\\n\\n            if errors:\\n                raise er.MultipleInvalid(errors)\\n\\n            out = data.__class__()\\n            return base_validate(path, iteritems(data), out)\\n\\n        return validate_dict',\n",
              " 'def _compile_sequence(self, schema, seq_type):\\n        \"\"\"Validate a sequence type.\\n\\n        This is a sequence of valid values or validators tried in order.\\n\\n        >>> validator = Schema([\\'one\\', \\'two\\', int])\\n        >>> validator([\\'one\\'])\\n        [\\'one\\']\\n        >>> with raises(er.MultipleInvalid, \\'expected int @ data[0]\\'):\\n        ...   validator([3.5])\\n        >>> validator([1])\\n        [1]\\n        \"\"\"\\n        _compiled = [self._compile(s) for s in schema]\\n        seq_type_name = seq_type.__name__\\n\\n        def validate_sequence(path, data):\\n            if not isinstance(data, seq_type):\\n                raise er.SequenceTypeInvalid(\\'expected a %s\\' % seq_type_name, path)\\n\\n            # Empty seq schema, allow any data.\\n            if not schema:\\n                if data:\\n                    raise er.MultipleInvalid([\\n                        er.ValueInvalid(\\'not a valid value\\', [value]) for value in data\\n                    ])\\n                return data\\n\\n            out = []\\n            invalid = None\\n            errors = []\\n            index_path = UNDEFINED\\n            for i, value in enumerate(data):\\n                index_path = path + [i]\\n                invalid = None\\n                for validate in _compiled:\\n                    try:\\n                        cval = validate(index_path, value)\\n                        if cval is not Remove:  # do not include Remove values\\n                            out.append(cval)\\n                        break\\n                    except er.Invalid as e:\\n                        if len(e.path) > len(index_path):\\n                            raise\\n                        invalid = e\\n                else:\\n                    errors.append(invalid)\\n            if errors:\\n                raise er.MultipleInvalid(errors)\\n\\n            if _isnamedtuple(data):\\n                return type(data)(*out)\\n            else:\\n                return type(data)(out)\\n\\n        return validate_sequence',\n",
              " 'def _compile_set(self, schema):\\n        \"\"\"Validate a set.\\n\\n        A set is an unordered collection of unique elements.\\n\\n        >>> validator = Schema({int})\\n        >>> validator(set([42])) == set([42])\\n        True\\n        >>> with raises(er.Invalid, \\'expected a set\\'):\\n        ...   validator(42)\\n        >>> with raises(er.MultipleInvalid, \\'invalid value in set\\'):\\n        ...   validator(set([\\'a\\']))\\n        \"\"\"\\n        type_ = type(schema)\\n        type_name = type_.__name__\\n\\n        def validate_set(path, data):\\n            if not isinstance(data, type_):\\n                raise er.Invalid(\\'expected a %s\\' % type_name, path)\\n\\n            _compiled = [self._compile(s) for s in schema]\\n            errors = []\\n            for value in data:\\n                for validate in _compiled:\\n                    try:\\n                        validate(path, value)\\n                        break\\n                    except er.Invalid:\\n                        pass\\n                else:\\n                    invalid = er.Invalid(\\'invalid value in %s\\' % type_name, path)\\n                    errors.append(invalid)\\n\\n            if errors:\\n                raise er.MultipleInvalid(errors)\\n\\n            return data\\n\\n        return validate_set',\n",
              " 'def extend(self, schema, required=None, extra=None):\\n        \"\"\"Create a new `Schema` by merging this and the provided `schema`.\\n\\n        Neither this `Schema` nor the provided `schema` are modified. The\\n        resulting `Schema` inherits the `required` and `extra` parameters of\\n        this, unless overridden.\\n\\n        Both schemas must be dictionary-based.\\n\\n        :param schema: dictionary to extend this `Schema` with\\n        :param required: if set, overrides `required` of this `Schema`\\n        :param extra: if set, overrides `extra` of this `Schema`\\n        \"\"\"\\n\\n        assert type(self.schema) == dict and type(schema) == dict, \\'Both schemas must be dictionary-based\\'\\n\\n        result = self.schema.copy()\\n\\n        # returns the key that may have been passed as arugment to Marker constructor\\n        def key_literal(key):\\n            return (key.schema if isinstance(key, Marker) else key)\\n\\n        # build a map that takes the key literals to the needed objects\\n        # literal -> Required|Optional|literal\\n        result_key_map = dict((key_literal(key), key) for key in result)\\n\\n        # for each item in the extension schema, replace duplicates\\n        # or add new keys\\n        for key, value in iteritems(schema):\\n\\n            # if the key is already in the dictionary, we need to replace it\\n            # transform key to literal before checking presence\\n            if key_literal(key) in result_key_map:\\n\\n                result_key = result_key_map[key_literal(key)]\\n                result_value = result[result_key]\\n\\n                # if both are dictionaries, we need to extend recursively\\n                # create the new extended sub schema, then remove the old key and add the new one\\n                if type(result_value) == dict and type(value) == dict:\\n                    new_value = Schema(result_value).extend(value).schema\\n                    del result[result_key]\\n                    result[key] = new_value\\n                # one or the other or both are not sub-schemas, simple replacement is fine\\n                # remove old key and add new one\\n                else:\\n                    del result[result_key]\\n                    result[key] = value\\n\\n            # key is new and can simply be added\\n            else:\\n                result[key] = value\\n\\n        # recompile and send old object\\n        result_cls = type(self)\\n        result_required = (required if required is not None else self.required)\\n        result_extra = (extra if extra is not None else self.extra)\\n        return result_cls(result, required=result_required, extra=result_extra)',\n",
              " 'def get_upload_path(instance, filename):\\n    \"\"\"Overriding to store the original filename\"\"\"\\n    if not instance.name:\\n        instance.name = filename  # set original filename\\n    date = timezone.now().date()\\n    filename = \\'{name}.{ext}\\'.format(name=uuid4().hex,\\n                                     ext=filename.split(\\'.\\')[-1])\\n\\n    return os.path.join(\\'post_office_attachments\\', str(date.year),\\n                        str(date.month), str(date.day), filename)',\n",
              " 'def get_prep_value(self, value):\\n        \"\"\"\\n        We need to accomodate queries where a single email,\\n        or list of email addresses is supplied as arguments. For example:\\n\\n        - Email.objects.filter(to=\\'mail@example.com\\')\\n        - Email.objects.filter(to=[\\'one@example.com\\', \\'two@example.com\\'])\\n        \"\"\"\\n        if isinstance(value, six.string_types):\\n            return value\\n        else:\\n            return \\', \\'.join(map(lambda s: s.strip(), value))',\n",
              " 'def create(sender, recipients=None, cc=None, bcc=None, subject=\\'\\', message=\\'\\',\\n           html_message=\\'\\', context=None, scheduled_time=None, headers=None,\\n           template=None, priority=None, render_on_delivery=False, commit=True,\\n           backend=\\'\\'):\\n    \"\"\"\\n    Creates an email from supplied keyword arguments. If template is\\n    specified, email subject and content will be rendered during delivery.\\n    \"\"\"\\n    priority = parse_priority(priority)\\n    status = None if priority == PRIORITY.now else STATUS.queued\\n\\n    if recipients is None:\\n        recipients = []\\n    if cc is None:\\n        cc = []\\n    if bcc is None:\\n        bcc = []\\n    if context is None:\\n        context = \\'\\'\\n\\n    # If email is to be rendered during delivery, save all necessary\\n    # information\\n    if render_on_delivery:\\n        email = Email(\\n            from_email=sender,\\n            to=recipients,\\n            cc=cc,\\n            bcc=bcc,\\n            scheduled_time=scheduled_time,\\n            headers=headers, priority=priority, status=status,\\n            context=context, template=template, backend_alias=backend\\n        )\\n\\n    else:\\n\\n        if template:\\n            subject = template.subject\\n            message = template.content\\n            html_message = template.html_content\\n\\n        _context = Context(context or {})\\n        subject = Template(subject).render(_context)\\n        message = Template(message).render(_context)\\n        html_message = Template(html_message).render(_context)\\n\\n        email = Email(\\n            from_email=sender,\\n            to=recipients,\\n            cc=cc,\\n            bcc=bcc,\\n            subject=subject,\\n            message=message,\\n            html_message=html_message,\\n            scheduled_time=scheduled_time,\\n            headers=headers, priority=priority, status=status,\\n            backend_alias=backend\\n        )\\n\\n    if commit:\\n        email.save()\\n\\n    return email',\n",
              " 'def send_many(kwargs_list):\\n    \"\"\"\\n    Similar to mail.send(), but this function accepts a list of kwargs.\\n    Internally, it uses Django\\'s bulk_create command for efficiency reasons.\\n    Currently send_many() can\\'t be used to send emails with priority = \\'now\\'.\\n    \"\"\"\\n    emails = []\\n    for kwargs in kwargs_list:\\n        emails.append(send(commit=False, **kwargs))\\n    Email.objects.bulk_create(emails)',\n",
              " 'def get_queued():\\n    \"\"\"\\n    Returns a list of emails that should be sent:\\n     - Status is queued\\n     - Has scheduled_time lower than the current time or None\\n    \"\"\"\\n    return Email.objects.filter(status=STATUS.queued) \\\\\\n        .select_related(\\'template\\') \\\\\\n        .filter(Q(scheduled_time__lte=now()) | Q(scheduled_time=None)) \\\\\\n        .order_by(*get_sending_order()).prefetch_related(\\'attachments\\')[:get_batch_size()]',\n",
              " 'def send_queued(processes=1, log_level=None):\\n    \"\"\"\\n    Sends out all queued mails that has scheduled_time less than now or None\\n    \"\"\"\\n    queued_emails = get_queued()\\n    total_sent, total_failed = 0, 0\\n    total_email = len(queued_emails)\\n\\n    logger.info(\\'Started sending %s emails with %s processes.\\' %\\n                (total_email, processes))\\n\\n    if log_level is None:\\n        log_level = get_log_level()\\n\\n    if queued_emails:\\n\\n        # Don\\'t use more processes than number of emails\\n        if total_email < processes:\\n            processes = total_email\\n\\n        if processes == 1:\\n            total_sent, total_failed = _send_bulk(queued_emails,\\n                                                  uses_multiprocessing=False,\\n                                                  log_level=log_level)\\n        else:\\n            email_lists = split_emails(queued_emails, processes)\\n\\n            pool = Pool(processes)\\n            results = pool.map(_send_bulk, email_lists)\\n            pool.terminate()\\n\\n            total_sent = sum([result[0] for result in results])\\n            total_failed = sum([result[1] for result in results])\\n    message = \\'%s emails attempted, %s sent, %s failed\\' % (\\n        total_email,\\n        total_sent,\\n        total_failed\\n    )\\n    logger.info(message)\\n    return (total_sent, total_failed)',\n",
              " 'def send_messages(self, email_messages):\\n        \"\"\"\\n        Queue one or more EmailMessage objects and returns the number of\\n        email messages sent.\\n        \"\"\"\\n        from .mail import create\\n        from .utils import create_attachments\\n\\n        if not email_messages:\\n            return\\n\\n        for email_message in email_messages:\\n            subject = email_message.subject\\n            from_email = email_message.from_email\\n            message = email_message.body\\n            headers = email_message.extra_headers\\n\\n            # Check whether email has \\'text/html\\' alternative\\n            alternatives = getattr(email_message, \\'alternatives\\', ())\\n            for alternative in alternatives:\\n                if alternative[1].startswith(\\'text/html\\'):\\n                    html_message = alternative[0]\\n                    break\\n            else:\\n                html_message = \\'\\'\\n\\n            attachment_files = {}\\n            for attachment in email_message.attachments:\\n                if isinstance(attachment, MIMEBase):\\n                    attachment_files[attachment.get_filename()] = {\\n                        \\'file\\': ContentFile(attachment.get_payload()),\\n                        \\'mimetype\\': attachment.get_content_type(),\\n                        \\'headers\\': OrderedDict(attachment.items()),\\n                    }\\n                else:\\n                    attachment_files[attachment[0]] = ContentFile(attachment[1])\\n\\n            email = create(sender=from_email,\\n                           recipients=email_message.to, cc=email_message.cc,\\n                           bcc=email_message.bcc, subject=subject,\\n                           message=message, html_message=html_message,\\n                           headers=headers)\\n\\n            if attachment_files:\\n                attachments = create_attachments(attachment_files)\\n\\n                email.attachments.add(*attachments)\\n\\n            if get_default_priority() == \\'now\\':\\n                email.dispatch()',\n",
              " 'def valid_lock(self):\\n        \"\"\"\\n        See if the lock exists and is left over from an old process.\\n        \"\"\"\\n\\n        lock_pid = self.get_lock_pid()\\n\\n        # If we\\'re unable to get lock_pid\\n        if lock_pid is None:\\n            return False\\n\\n        # this is our process\\n        if self._pid == lock_pid:\\n            return True\\n\\n        # it is/was another process\\n        # see if it is running\\n        try:\\n            os.kill(lock_pid, 0)\\n        except OSError:\\n            self.release()\\n            return False\\n\\n        # it is running\\n        return True',\n",
              " 'def acquire(self):\\n        \"\"\"Create a pid filename and create a symlink (the actual lock file)\\n        across platforms that points to it. Symlink is used because it\\'s an\\n        atomic operation across platforms.\\n        \"\"\"\\n\\n        pid_file = os.open(self.pid_filename, os.O_CREAT | os.O_EXCL | os.O_RDWR)\\n        os.write(pid_file, str(os.getpid()).encode(\\'utf-8\\'))\\n        os.close(pid_file)\\n\\n        if hasattr(os, \\'symlink\\') and platform.system() != \\'Windows\\':\\n            os.symlink(self.pid_filename, self.lock_filename)\\n        else:\\n            # Windows platforms doesn\\'t support symlinks, at least not through the os API\\n            self.lock_filename = self.pid_filename',\n",
              " 'def release(self):\\n        \"\"\"Try to delete the lock files. Doesn\\'t matter if we fail\"\"\"\\n        if self.lock_filename != self.pid_filename:\\n            try:\\n                os.unlink(self.lock_filename)\\n            except OSError:\\n                pass\\n\\n        try:\\n            os.remove(self.pid_filename)\\n        except OSError:\\n            pass',\n",
              " 'def validate_email_with_name(value):\\n    \"\"\"\\n    Validate email address.\\n\\n    Both \"Recipient Name <email@example.com>\" and \"email@example.com\" are valid.\\n    \"\"\"\\n    value = force_text(value)\\n\\n    recipient = value\\n    if \\'<\\' and \\'>\\' in value:\\n        start = value.find(\\'<\\') + 1\\n        end = value.find(\\'>\\')\\n        if start < end:\\n            recipient = value[start:end]\\n\\n    validate_email(recipient)',\n",
              " 'def validate_comma_separated_emails(value):\\n    \"\"\"\\n    Validate every email address in a comma separated list of emails.\\n    \"\"\"\\n    if not isinstance(value, (tuple, list)):\\n        raise ValidationError(\\'Email list must be a list/tuple.\\')\\n\\n    for email in value:\\n        try:\\n            validate_email_with_name(email)\\n        except ValidationError:\\n            raise ValidationError(\\'Invalid email: %s\\' % email, code=\\'invalid\\')',\n",
              " 'def validate_template_syntax(source):\\n    \"\"\"\\n    Basic Django Template syntax validation. This allows for robuster template\\n    authoring.\\n    \"\"\"\\n    try:\\n        Template(source)\\n    except (TemplateSyntaxError, TemplateDoesNotExist) as err:\\n        raise ValidationError(text_type(err))',\n",
              " 'def get_available_backends():\\n    \"\"\" Returns a dictionary of defined backend classes. For example:\\n    {\\n        \\'default\\': \\'django.core.mail.backends.smtp.EmailBackend\\',\\n        \\'locmem\\': \\'django.core.mail.backends.locmem.EmailBackend\\',\\n    }\\n    \"\"\"\\n    backends = get_config().get(\\'BACKENDS\\', {})\\n\\n    if backends:\\n        return backends\\n\\n    # Try to get backend settings from old style\\n    # POST_OFFICE = {\\n    #     \\'EMAIL_BACKEND\\': \\'mybackend\\'\\n    # }\\n    backend = get_config().get(\\'EMAIL_BACKEND\\')\\n    if backend:\\n        warnings.warn(\\'Please use the new POST_OFFICE[\"BACKENDS\"] settings\\',\\n                      DeprecationWarning)\\n\\n        backends[\\'default\\'] = backend\\n        return backends\\n\\n    # Fall back to Django\\'s EMAIL_BACKEND definition\\n    backends[\\'default\\'] = getattr(\\n        settings, \\'EMAIL_BACKEND\\',\\n        \\'django.core.mail.backends.smtp.EmailBackend\\')\\n\\n    # If EMAIL_BACKEND is set to use PostOfficeBackend\\n    # and POST_OFFICE_BACKEND is not set, fall back to SMTP\\n    if \\'post_office.EmailBackend\\' in backends[\\'default\\']:\\n        backends[\\'default\\'] = \\'django.core.mail.backends.smtp.EmailBackend\\'\\n\\n    return backends',\n",
              " 'def send_mail(subject, message, from_email, recipient_list, html_message=\\'\\',\\n              scheduled_time=None, headers=None, priority=PRIORITY.medium):\\n    \"\"\"\\n    Add a new message to the mail queue. This is a replacement for Django\\'s\\n    ``send_mail`` core email method.\\n    \"\"\"\\n\\n    subject = force_text(subject)\\n    status = None if priority == PRIORITY.now else STATUS.queued\\n    emails = []\\n    for address in recipient_list:\\n        emails.append(\\n            Email.objects.create(\\n                from_email=from_email, to=address, subject=subject,\\n                message=message, html_message=html_message, status=status,\\n                headers=headers, priority=priority, scheduled_time=scheduled_time\\n            )\\n        )\\n    if priority == PRIORITY.now:\\n        for email in emails:\\n            email.dispatch()\\n    return emails',\n",
              " 'def get_email_template(name, language=\\'\\'):\\n    \"\"\"\\n    Function that returns an email template instance, from cache or DB.\\n    \"\"\"\\n    use_cache = getattr(settings, \\'POST_OFFICE_CACHE\\', True)\\n    if use_cache:\\n        use_cache = getattr(settings, \\'POST_OFFICE_TEMPLATE_CACHE\\', True)\\n    if not use_cache:\\n        return EmailTemplate.objects.get(name=name, language=language)\\n    else:\\n        composite_name = \\'%s:%s\\' % (name, language)\\n        email_template = cache.get(composite_name)\\n        if email_template is not None:\\n            return email_template\\n        else:\\n            email_template = EmailTemplate.objects.get(name=name,\\n                                                       language=language)\\n            cache.set(composite_name, email_template)\\n            return email_template',\n",
              " 'def create_attachments(attachment_files):\\n    \"\"\"\\n    Create Attachment instances from files\\n\\n    attachment_files is a dict of:\\n        * Key - the filename to be used for the attachment.\\n        * Value - file-like object, or a filename to open OR a dict of {\\'file\\': file-like-object, \\'mimetype\\': string}\\n\\n    Returns a list of Attachment objects\\n    \"\"\"\\n    attachments = []\\n    for filename, filedata in attachment_files.items():\\n\\n        if isinstance(filedata, dict):\\n            content = filedata.get(\\'file\\', None)\\n            mimetype = filedata.get(\\'mimetype\\', None)\\n            headers = filedata.get(\\'headers\\', None)\\n        else:\\n            content = filedata\\n            mimetype = None\\n            headers = None\\n\\n        opened_file = None\\n\\n        if isinstance(content, string_types):\\n            # `content` is a filename - try to open the file\\n            opened_file = open(content, \\'rb\\')\\n            content = File(opened_file)\\n\\n        attachment = Attachment()\\n        if mimetype:\\n            attachment.mimetype = mimetype\\n        attachment.headers = headers\\n        attachment.file.save(filename, content=content, save=True)\\n\\n        attachments.append(attachment)\\n\\n        if opened_file is not None:\\n            opened_file.close()\\n\\n    return attachments',\n",
              " 'def parse_emails(emails):\\n    \"\"\"\\n    A function that returns a list of valid email addresses.\\n    This function will also convert a single email address into\\n    a list of email addresses.\\n    None value is also converted into an empty list.\\n    \"\"\"\\n\\n    if isinstance(emails, string_types):\\n        emails = [emails]\\n    elif emails is None:\\n        emails = []\\n\\n    for email in emails:\\n        try:\\n            validate_email_with_name(email)\\n        except ValidationError:\\n            raise ValidationError(\\'%s is not a valid email address\\' % email)\\n\\n    return emails',\n",
              " 'def VERSION(self):\\n        \"\"\"TAN mechanism version\"\"\"\\n        return int(re.match(r\\'^(\\\\D+)(\\\\d+)$\\', self.__class__.__name__).group(2))',\n",
              " 'def parse_message(self, data: bytes) -> SegmentSequence:\\n        \"\"\"Takes a FinTS 3.0 message as byte array, and returns a parsed segment sequence\"\"\"\\n        if isinstance(data, bytes):\\n            data = self.explode_segments(data)\\n\\n        message = SegmentSequence()\\n        for segment in data:\\n            seg = self.parse_segment(segment)\\n            message.segments.append(seg)\\n        return message',\n",
              " 'def serialize_message(self, message: SegmentSequence) -> bytes:\\n        \"\"\"Serialize a message (as SegmentSequence, list of FinTS3Segment, or FinTS3Segment) into a byte array\"\"\"\\n        if isinstance(message, FinTS3Segment):\\n            message = SegmentSequence([message])\\n        if isinstance(message, (list, tuple, Iterable)):\\n            message = SegmentSequence(list(message))\\n\\n        result = []\\n\\n        for segment in message.segments:\\n            result.append(self.serialize_segment(segment))\\n\\n        return self.implode_segments(result)',\n",
              " 'def terminal_flicker_unix(code, field_width=3, space_width=3, height=1, clear=False, wait=0.05):\\n    \"\"\"\\n    Re-encodes a flicker code and prints it on a unix terminal.\\n\\n    :param code: Challenge value\\n    :param field_width: Width of fields in characters (default: 3).\\n    :param space_width: Width of spaces in characters (default: 3).\\n    :param height: Height of fields in characters (default: 1).\\n    :param clear: Clear terminal after every line (default: ``False``).\\n    :param wait: Waiting interval between lines (default: 0.05).\\n    \"\"\"\\n    # Inspired by Andreas Schiermeier\\n    # https://git.ccc-ffm.de/?p=smartkram.git;a=blob_plain;f=chiptan/flicker/flicker.sh;h\\n    # =7066293b4e790c2c4c1f6cbdab703ed9976ffe1f;hb=refs/heads/master\\n    code = parse(code).render()\\n    data = swap_bytes(code)\\n    high = \\'\\\\033[48;05;15m\\'\\n    low = \\'\\\\033[48;05;0m\\'\\n    std = \\'\\\\033[0m\\'\\n    stream = [\\'10000\\', \\'00000\\', \\'11111\\', \\'01111\\', \\'11111\\', \\'01111\\', \\'11111\\']\\n    for c in data:\\n        v = int(c, 16)\\n        stream.append(\\'1\\' + str(v & 1) + str((v & 2) >> 1) + str((v & 4) >> 2) + str((v & 8) >> 3))\\n        stream.append(\\'0\\' + str(v & 1) + str((v & 2) >> 1) + str((v & 4) >> 2) + str((v & 8) >> 3))\\n\\n    while True:\\n        for frame in stream:\\n            if clear:\\n                print(\\'\\\\033c\\', end=\\'\\')\\n\\n            for i in range(height):\\n                for c in frame:\\n                    print(low + \\' \\' * space_width, end=\\'\\')\\n                    if c == \\'1\\':\\n                        print(high + \\' \\' * field_width, end=\\'\\')\\n                    else:\\n                        print(low+ \\' \\' * field_width, end=\\'\\')\\n                print(low + \\' \\' * space_width + std)\\n\\n            time.sleep(wait)',\n",
              " 'def find_segments(self, query=None, version=None, callback=None, recurse=True, throw=False):\\n        \"\"\"Yields an iterable of all matching segments.\\n\\n        :param query: Either a str or class specifying a segment type (such as \\'HNHBK\\', or :class:`~fints.segments.message.HNHBK3`), or a list or tuple of strings or classes.\\n                     If a list/tuple is specified, segments returning any matching type will be returned.\\n        :param version: Either an int specifying a segment version, or a list or tuple of ints.\\n                        If a list/tuple is specified, segments returning any matching version will be returned.\\n        :param callback: A callable that will be given the segment as its sole argument and must return a boolean indicating whether to return this segment.\\n        :param recurse: If True (the default), recurse into SegmentSequenceField values, otherwise only look at segments in this SegmentSequence.\\n        :param throw: If True, a FinTSNoResponseError is thrown if no result is found. Defaults to False.\\n\\n        The match results of all given parameters will be AND-combined.\\n        \"\"\"\\n        found_something = False\\n\\n        if query is None:\\n            query = []\\n        elif isinstance(query, str) or not isinstance(query, (list, tuple, Iterable)):\\n            query = [query]\\n\\n        if version is None:\\n            version = []\\n        elif not isinstance(version, (list, tuple, Iterable)):\\n            version = [version]\\n\\n        if callback is None:\\n            callback = lambda s: True\\n\\n        for s in self.segments:\\n            if ((not query) or any((isinstance(s, t) if isinstance(t, type) else s.header.type == t) for t in query)) and \\\\\\n                    ((not version) or any(s.header.version == v for v in version)) and \\\\\\n                    callback(s):\\n                yield s\\n                found_something = True\\n\\n            if recurse:\\n                for name, field in s._fields.items():\\n                    val = getattr(s, name)\\n                    if val and hasattr(val, \\'find_segments\\'):\\n                        for v in val.find_segments(query=query, version=version, callback=callback, recurse=recurse):\\n                            yield v\\n                            found_something = True\\n\\n        if throw and not found_something:\\n            raise FinTSNoResponseError(\\n                \\'The bank\\\\\\'s response did not contain a response to your request, please inspect debug log.\\'\\n            )',\n",
              " 'def find_segment_first(self, *args, **kwargs):\\n        \"\"\"Finds the first matching segment.\\n\\n        Same parameters as find_segments(), but only returns the first match, or None if no match is found.\"\"\"\\n\\n        for m in self.find_segments(*args, **kwargs):\\n            return m\\n\\n        return None',\n",
              " 'def find_segment_highest_version(self, query=None, version=None, callback=None, recurse=True, default=None):\\n        \"\"\"Finds the highest matching segment.\\n\\n        Same parameters as find_segments(), but returns the match with the highest version, or default if no match is found.\"\"\"\\n        # FIXME Test\\n\\n        retval = None\\n\\n        for s in self.find_segments(query=query, version=version, callback=callback, recurse=recurse):\\n            if not retval or s.header.version > retval.header.version:\\n                retval = s\\n\\n        if retval is None:\\n            return default\\n\\n        return retval',\n",
              " 'def print_nested(self, stream=None, level=0, indent=\"    \", prefix=\"\", first_level_indent=True, trailer=\"\", print_doc=True, first_line_suffix=\"\"):\\n        \"\"\"Structured nested print of the object to the given stream.\\n\\n        The print-out is eval()able to reconstruct the object.\"\"\"\\n        import sys\\n        stream = stream or sys.stdout\\n\\n        stream.write(\\n            ((prefix + level * indent) if first_level_indent else \"\")\\n            + \"{}.{}(\".format(self.__class__.__module__, self.__class__.__name__)\\n            + first_line_suffix\\n            + \"\\\\n\"\\n        )\\n        for name, value in self._repr_items:\\n            val = getattr(self, name)\\n            if print_doc and not name.startswith(\"_\"):\\n                docstring = self._fields[name]._inline_doc_comment(val)\\n            else:\\n                docstring = \"\"\\n            if not hasattr(getattr(val, \\'print_nested\\', None), \\'__call__\\'):\\n                stream.write(\\n                    (prefix + (level + 1) * indent) + \"{} = {!r},{}\\\\n\".format(name, val, docstring)\\n                )\\n            else:\\n                stream.write(\\n                    (prefix + (level + 1) * indent) + \"{} = \".format(name)\\n                )\\n                val.print_nested(stream=stream, level=level + 2, indent=indent, prefix=prefix, first_level_indent=False, trailer=\",\", print_doc=print_doc,\\n                                 first_line_suffix=docstring)\\n        stream.write((prefix + level * indent) + \"){}\\\\n\".format(trailer))',\n",
              " 'def from_data(cls, blob):\\n        \"\"\"Restore an object instance from a compressed datablob.\\n\\n        Returns an instance of a concrete subclass.\"\"\"\\n        version, data = decompress_datablob(DATA_BLOB_MAGIC_RETRY, blob)\\n\\n        if version == 1:\\n            for clazz in cls._all_subclasses():\\n                if clazz.__name__ == data[\"_class_name\"]:\\n                    return clazz._from_data_v1(data)\\n\\n        raise Exception(\"Invalid data blob data or version\")',\n",
              " 'def deconstruct(self, including_private: bool=False) -> bytes:\\n        \"\"\"Return state of this FinTSClient instance as an opaque datablob. You should not\\n        use this object after calling this method.\\n\\n        Information about the connection is implicitly retrieved from the bank and\\n        cached in the FinTSClient. This includes: system identifier, bank parameter\\n        data, user parameter data. It\\'s not strictly required to retain this information\\n        across sessions, but beneficial. If possible, an API user SHOULD use this method\\n        to serialize the client instance before destroying it, and provide the serialized\\n        data next time an instance is constructed.\\n\\n        Parameter `including_private` should be set to True, if the storage is sufficiently\\n        secure (with regards to confidentiality) to include private data, specifically,\\n        account numbers and names. Most often this is the case.\\n\\n        Note: No connection information is stored in the datablob, neither is the PIN.\\n        \"\"\"\\n        data = self._deconstruct_v1(including_private=including_private)\\n        return compress_datablob(DATA_BLOB_MAGIC, 1, data)',\n",
              " 'def get_information(self):\\n        \"\"\"\\n        Return information about the connected bank.\\n\\n        Note: Can only be filled after the first communication with the bank.\\n        If in doubt, use a construction like::\\n        \\n            f = FinTS3Client(...)\\n            with f:\\n                info = f.get_information()\\n\\n        Returns a nested dictionary::\\n\\n            bank:\\n                name: Bank Name\\n                supported_operations: dict(FinTSOperations -> boolean)\\n            accounts:\\n                - iban: IBAN\\n                  account_number: Account Number\\n                  subaccount_number: Sub-Account Number\\n                  bank_identifier: fints.formals.BankIdentifier(...)\\n                  customer_id: Customer ID\\n                  type: Account type\\n                  currency: Currency\\n                  owner_name: [\\'Owner Name 1\\', \\'Owner Name 2 (optional)\\']\\n                  product_name: Account product name\\n                  supported_operations: dict(FinTSOperations -> boolean)\\n                - ...\\n\\n        \"\"\"\\n        retval = {\\n            \\'bank\\': {},\\n            \\'accounts\\': [],\\n            \\'auth\\': {},\\n        }\\n        if self.bpa:\\n            retval[\\'bank\\'][\\'name\\'] = self.bpa.bank_name\\n        if self.bpd.segments:\\n            retval[\\'bank\\'][\\'supported_operations\\'] = {\\n                op: any(self.bpd.find_segment_first(cmd[0]+\\'I\\'+cmd[2:]+\\'S\\') for cmd in op.value)\\n                for op in FinTSOperations\\n            }\\n            hispas = self.bpd.find_segment_first(\\'HISPAS\\')\\n            if hispas:\\n                retval[\\'bank\\'][\\'supported_sepa_formats\\'] = list(hispas.parameter.supported_sepa_formats)\\n            else:\\n                retval[\\'bank\\'][\\'supported_sepa_formats\\'] = []\\n        if self.upd.segments:\\n            for upd in self.upd.find_segments(\\'HIUPD\\'):\\n                acc = {}\\n                acc[\\'iban\\'] = upd.iban\\n                acc[\\'account_number\\'] = upd.account_information.account_number\\n                acc[\\'subaccount_number\\'] = upd.account_information.subaccount_number\\n                acc[\\'bank_identifier\\'] = upd.account_information.bank_identifier\\n                acc[\\'customer_id\\'] = upd.customer_id\\n                acc[\\'type\\'] = upd.account_type\\n                acc[\\'currency\\'] = upd.account_currency\\n                acc[\\'owner_name\\'] = []\\n                if upd.name_account_owner_1:\\n                    acc[\\'owner_name\\'].append(upd.name_account_owner_1)\\n                if upd.name_account_owner_2:\\n                    acc[\\'owner_name\\'].append(upd.name_account_owner_2)\\n                acc[\\'product_name\\'] = upd.account_product_name\\n                acc[\\'supported_operations\\'] = {\\n                    op: any(allowed_transaction.transaction in op.value for allowed_transaction in upd.allowed_transactions)\\n                    for op in FinTSOperations\\n                }\\n                retval[\\'accounts\\'].append(acc)\\n        return retval',\n",
              " 'def get_sepa_accounts(self):\\n        \"\"\"\\n        Returns a list of SEPA accounts\\n\\n        :return: List of SEPAAccount objects.\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            response = dialog.send(HKSPA1())\\n            \\n        self.accounts = []\\n        for seg in response.find_segments(HISPA1, throw=True):\\n            self.accounts.extend(seg.accounts)\\n\\n        return [a for a in [acc.as_sepa_account() for acc in self.accounts] if a]',\n",
              " 'def _fetch_with_touchdowns(self, dialog, segment_factory, *args, **kwargs):\\n        \"\"\"Execute a sequence of fetch commands on dialog.\\n        segment_factory must be a callable with one argument touchdown. Will be None for the\\n        first call and contains the institute\\'s touchdown point on subsequent calls.\\n        segment_factory must return a command segment.\\n        Extra arguments will be passed to FinTSMessage.response_segments.\\n        Return value is a concatenated list of the return values of FinTSMessage.response_segments().\\n        \"\"\"\\n        responses = []\\n        touchdown_counter = 1\\n        touchdown = None\\n\\n        while touchdown or touchdown_counter == 1:\\n            seg = segment_factory(touchdown)\\n\\n            rm = dialog.send(seg)\\n\\n            for resp in rm.response_segments(seg, *args, **kwargs):\\n                responses.append(resp)\\n\\n            touchdown = None\\n            for response in rm.responses(seg, \\'3040\\'):\\n                touchdown = response.parameters[0]\\n                break\\n\\n            if touchdown:\\n                logger.info(\\'Fetching more results ({})...\\'.format(touchdown_counter))\\n\\n            touchdown_counter += 1\\n\\n        return responses',\n",
              " 'def _find_highest_supported_command(self, *segment_classes, **kwargs):\\n        \"\"\"Search the BPD for the highest supported version of a segment.\"\"\"\\n        return_parameter_segment = kwargs.get(\"return_parameter_segment\", False)\\n\\n        parameter_segment_name = \"{}I{}S\".format(segment_classes[0].TYPE[0], segment_classes[0].TYPE[2:])\\n        version_map = dict((clazz.VERSION, clazz) for clazz in segment_classes)\\n        max_version = self.bpd.find_segment_highest_version(parameter_segment_name, version_map.keys())\\n        if not max_version:\\n            raise FinTSUnsupportedOperation(\\'No supported {} version found. I support {}, bank supports {}.\\'.format(\\n                parameter_segment_name,\\n                tuple(version_map.keys()),\\n                tuple(v.header.version for v in self.bpd.find_segments(parameter_segment_name))\\n            ))\\n\\n        if return_parameter_segment:\\n            return max_version, version_map.get(max_version.header.version)\\n        else:\\n            return version_map.get(max_version.header.version)',\n",
              " 'def get_transactions(self, account: SEPAAccount, start_date: datetime.date = None, end_date: datetime.date = None):\\n        \"\"\"\\n        Fetches the list of transactions of a bank account in a certain timeframe.\\n\\n        :param account: SEPA\\n        :param start_date: First day to fetch\\n        :param end_date: Last day to fetch\\n        :return: A list of mt940.models.Transaction objects\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            hkkaz = self._find_highest_supported_command(HKKAZ5, HKKAZ6, HKKAZ7)\\n\\n            logger.info(\\'Start fetching from {} to {}\\'.format(start_date, end_date))\\n            responses = self._fetch_with_touchdowns(\\n                dialog,\\n                lambda touchdown: hkkaz(\\n                    account=hkkaz._fields[\\'account\\'].type.from_sepa_account(account),\\n                    all_accounts=False,\\n                    date_start=start_date,\\n                    date_end=end_date,\\n                    touchdown_point=touchdown,\\n                ),\\n                \\'HIKAZ\\'\\n            )\\n            logger.info(\\'Fetching done.\\')\\n\\n        statement = []\\n        for seg in responses:\\n            # Note: MT940 messages are encoded in the S.W.I.F.T character set,\\n            # which is a subset of ISO 8859. There are no character in it that\\n            # differ between ISO 8859 variants, so we\\'ll arbitrarily chose 8859-1.\\n            statement += mt940_to_array(seg.statement_booked.decode(\\'iso-8859-1\\'))\\n\\n        logger.debug(\\'Statement: {}\\'.format(statement))\\n\\n        return statement',\n",
              " 'def get_transactions_xml(self, account: SEPAAccount, start_date: datetime.date = None,\\n                             end_date: datetime.date = None) -> list:\\n        \"\"\"\\n        Fetches the list of transactions of a bank account in a certain timeframe as camt.052.001.02 XML files.\\n\\n        :param account: SEPA\\n        :param start_date: First day to fetch\\n        :param end_date: Last day to fetch\\n        :return: A list of bytestrings containing XML documents\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            hkcaz = self._find_highest_supported_command(HKCAZ1)\\n\\n            logger.info(\\'Start fetching from {} to {}\\'.format(start_date, end_date))\\n            responses = self._fetch_with_touchdowns(\\n                dialog,\\n                lambda touchdown: hkcaz(\\n                    account=hkcaz._fields[\\'account\\'].type.from_sepa_account(account),\\n                    all_accounts=False,\\n                    date_start=start_date,\\n                    date_end=end_date,\\n                    touchdown_point=touchdown,\\n                    supported_camt_messages=SupportedMessageTypes(\\'urn:iso:std:iso:20022:tech:xsd:camt.052.001.02\\'),\\n                ),\\n                \\'HICAZ\\'\\n            )\\n            logger.info(\\'Fetching done.\\')\\n\\n        xml_streams = []\\n        for seg in responses:\\n            xml_streams.append(seg.statement_booked)\\n        return xml_streams',\n",
              " 'def get_balance(self, account: SEPAAccount):\\n        \"\"\"\\n        Fetches an accounts current balance.\\n\\n        :param account: SEPA account to fetch the balance\\n        :return: A mt940.models.Balance object\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            hksal = self._find_highest_supported_command(HKSAL5, HKSAL6, HKSAL7)\\n\\n            seg = hksal(\\n                account=hksal._fields[\\'account\\'].type.from_sepa_account(account),\\n                all_accounts=False,\\n            )\\n\\n            response = dialog.send(seg)\\n\\n            for resp in response.response_segments(seg, \\'HISAL\\'):\\n                return resp.balance_booked.as_mt940_Balance()',\n",
              " 'def get_holdings(self, account: SEPAAccount):\\n        \"\"\"\\n        Retrieve holdings of an account.\\n\\n        :param account: SEPAAccount to retrieve holdings for.\\n        :return: List of Holding objects\\n        \"\"\"\\n        # init dialog\\n        with self._get_dialog() as dialog:\\n            hkwpd = self._find_highest_supported_command(HKWPD5, HKWPD6)\\n\\n            responses = self._fetch_with_touchdowns(\\n                dialog,\\n                lambda touchdown: hkwpd(\\n                    account=hkwpd._fields[\\'account\\'].type.from_sepa_account(account),\\n                    touchdown_point=touchdown,\\n                ),\\n                \\'HIWPD\\'\\n            )\\n\\n        holdings = []\\n        for resp in responses:\\n            if type(resp.holdings) == bytes:\\n                holding_str = resp.holdings.decode()\\n            else:\\n                holding_str = resp.holdings\\n\\n            mt535_lines = str.splitlines(holding_str)\\n            # The first line is empty - drop it.\\n            del mt535_lines[0]\\n            mt535 = MT535_Miniparser()\\n            holdings.extend(mt535.parse(mt535_lines))\\n\\n        if not holdings:\\n            logger.debug(\\'No HIWPD response segment found - maybe account has no holdings?\\')\\n        return holdings',\n",
              " 'def simple_sepa_transfer(self, account: SEPAAccount, iban: str, bic: str,\\n                             recipient_name: str, amount: Decimal, account_name: str, reason: str,\\n                             endtoend_id=\\'NOTPROVIDED\\'):\\n        \"\"\"\\n        Simple SEPA transfer.\\n\\n        :param account: SEPAAccount to start the transfer from.\\n        :param iban: Recipient\\'s IBAN\\n        :param bic: Recipient\\'s BIC\\n        :param recipient_name: Recipient name\\n        :param amount: Amount as a ``Decimal``\\n        :param account_name: Sender account name\\n        :param reason: Transfer reason\\n        :param endtoend_id: End-to-end-Id (defaults to ``NOTPROVIDED``)\\n        :return: Returns either a NeedRetryResponse or TransactionResponse\\n        \"\"\"\\n        config = {\\n            \"name\": account_name,\\n            \"IBAN\": account.iban,\\n            \"BIC\": account.bic,\\n            \"batch\": False,\\n            \"currency\": \"EUR\",\\n        }\\n        sepa = SepaTransfer(config, \\'pain.001.001.03\\')\\n        payment = {\\n            \"name\": recipient_name,\\n            \"IBAN\": iban,\\n            \"BIC\": bic,\\n            \"amount\": round(Decimal(amount) * 100),  # in cents\\n            \"execution_date\": datetime.date(1999, 1, 1),\\n            \"description\": reason,\\n            \"endtoend_id\": endtoend_id,\\n        }\\n        sepa.add_payment(payment)\\n        xml = sepa.export().decode()\\n        return self.sepa_transfer(account, xml)',\n",
              " 'def sepa_transfer(self, account: SEPAAccount, pain_message: str, multiple=False,\\n                      control_sum=None, currency=\\'EUR\\', book_as_single=False,\\n                      pain_descriptor=\\'urn:iso:std:iso:20022:tech:xsd:pain.001.001.03\\'):\\n        \"\"\"\\n        Custom SEPA transfer.\\n\\n        :param account: SEPAAccount to send the transfer from.\\n        :param pain_message: SEPA PAIN message containing the transfer details.\\n        :param multiple: Whether this message contains multiple transfers.\\n        :param control_sum: Sum of all transfers (required if there are multiple)\\n        :param currency: Transfer currency\\n        :param book_as_single: Kindly ask the bank to put multiple transactions as separate lines on the bank statement (defaults to ``False``)\\n        :param pain_descriptor: URN of the PAIN message schema used.\\n        :return: Returns either a NeedRetryResponse or TransactionResponse\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            if multiple:\\n                command_class = HKCCM1\\n            else:\\n                command_class = HKCCS1\\n\\n            hiccxs, hkccx = self._find_highest_supported_command(\\n                command_class,\\n                return_parameter_segment=True\\n            )\\n\\n            seg = hkccx(\\n                account=hkccx._fields[\\'account\\'].type.from_sepa_account(account),\\n                sepa_descriptor=pain_descriptor,\\n                sepa_pain_message=pain_message.encode(),\\n            )\\n\\n            if multiple:\\n                if hiccxs.parameter.sum_amount_required and control_sum is None:\\n                    raise ValueError(\"Control sum required.\")\\n                if book_as_single and not hiccxs.parameter.single_booking_allowed:\\n                    raise FinTSUnsupportedOperation(\"Single booking not allowed by bank.\")\\n\\n                if control_sum:\\n                    seg.sum_amount.amount = control_sum\\n                    seg.sum_amount.currency = currency\\n\\n                if book_as_single:\\n                    seg.request_single_booking = True\\n\\n            return self._send_with_possible_retry(dialog, seg, self._continue_sepa_transfer)',\n",
              " 'def sepa_debit(self, account: SEPAAccount, pain_message: str, multiple=False, cor1=False,\\n                   control_sum=None, currency=\\'EUR\\', book_as_single=False,\\n                   pain_descriptor=\\'urn:iso:std:iso:20022:tech:xsd:pain.008.003.01\\'):\\n        \"\"\"\\n        Custom SEPA debit.\\n\\n        :param account: SEPAAccount to send the debit from.\\n        :param pain_message: SEPA PAIN message containing the debit details.\\n        :param multiple: Whether this message contains multiple debits.\\n        :param cor1: Whether to use COR1 debit (lead time reduced to 1 day)\\n        :param control_sum: Sum of all debits (required if there are multiple)\\n        :param currency: Debit currency\\n        :param book_as_single: Kindly ask the bank to put multiple transactions as separate lines on the bank statement (defaults to ``False``)\\n        :param pain_descriptor: URN of the PAIN message schema used. Defaults to ``urn:iso:std:iso:20022:tech:xsd:pain.008.003.01``.\\n        :return: Returns either a NeedRetryResponse or TransactionResponse (with data[\\'task_id\\'] set, if available)\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            if multiple:\\n                if cor1:\\n                    command_candidates = (HKDMC1, )\\n                else:\\n                    command_candidates = (HKDME1, HKDME2)\\n            else:\\n                if cor1:\\n                    command_candidates = (HKDSC1, )\\n                else:\\n                    command_candidates = (HKDSE1, HKDSE2)\\n\\n            hidxxs, hkdxx = self._find_highest_supported_command(\\n                *command_candidates,\\n                return_parameter_segment=True\\n            )\\n\\n            seg = hkdxx(\\n                account=hkdxx._fields[\\'account\\'].type.from_sepa_account(account),\\n                sepa_descriptor=pain_descriptor,\\n                sepa_pain_message=pain_message.encode(),\\n            )\\n\\n            if multiple:\\n                if hidxxs.parameter.sum_amount_required and control_sum is None:\\n                    raise ValueError(\"Control sum required.\")\\n                if book_as_single and not hidxxs.parameter.single_booking_allowed:\\n                    raise FinTSUnsupportedOperation(\"Single booking not allowed by bank.\")\\n\\n                if control_sum:\\n                    seg.sum_amount.amount = control_sum\\n                    seg.sum_amount.currency = currency\\n\\n                if book_as_single:\\n                    seg.request_single_booking = True\\n\\n            return self._send_with_possible_retry(dialog, seg, self._continue_sepa_debit)',\n",
              " 'def set_product(self, product_name, product_version):\\n        \"\"\"Set the product name and version that is transmitted as part of our identification\\n        \\n        According to \\'FinTS Financial Transaction Services, Schnittstellenspezifikation, Formals\\',\\n        version 3.0, section C.3.1.3, you should fill this with useful information about the\\n        end-user product, *NOT* the FinTS library.\"\"\"\\n\\n        self.product_name = product_name\\n        self.product_version = product_version',\n",
              " 'def get_data(self) -> bytes:\\n        \"\"\"Return a compressed datablob representing this object.\\n        \\n        To restore the object, use :func:`fints.client.NeedRetryResponse.from_data`.\\n        \"\"\"\\n        data = {\\n            \"_class_name\": self.__class__.__name__,\\n            \"version\": 1,\\n            \"segments_bin\": SegmentSequence([self.command_seg, self.tan_request]).render_bytes(),\\n            \"resume_method\": self.resume_method,\\n            \"tan_request_structured\": self.tan_request_structured,\\n        }\\n        return compress_datablob(DATA_BLOB_MAGIC_RETRY, 1, data)',\n",
              " 'def send_tan(self, challenge: NeedTANResponse, tan: str):\\n        \"\"\"\\n        Sends a TAN to confirm a pending operation.\\n\\n        :param challenge: NeedTANResponse to respond to\\n        :param tan: TAN value\\n        :return: Currently no response\\n        \"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            tan_seg = self._get_tan_segment(challenge.command_seg, \\'2\\', challenge.tan_request)\\n            self._pending_tan = tan\\n\\n            response = dialog.send(tan_seg)\\n\\n            resume_func = getattr(self, challenge.resume_method)\\n            return resume_func(challenge.command_seg, response)',\n",
              " 'def get_tan_mechanisms(self):\\n        \"\"\"\\n        Get the available TAN mechanisms.\\n\\n        Note: Only checks for HITANS versions listed in IMPLEMENTED_HKTAN_VERSIONS.\\n\\n        :return: Dictionary of security_function: TwoStepParameters objects.\\n        \"\"\"\\n\\n        retval = OrderedDict()\\n\\n        for version in sorted(IMPLEMENTED_HKTAN_VERSIONS.keys()):\\n            for seg in self.bpd.find_segments(\\'HITANS\\', version):\\n                for parameter in seg.parameter.twostep_parameters:\\n                    if parameter.security_function in self.allowed_security_functions:\\n                        retval[parameter.security_function] = parameter\\n\\n        return retval',\n",
              " 'def get_tan_media(self, media_type = TANMediaType2.ALL, media_class = TANMediaClass4.ALL):\\n        \"\"\"Get information about TAN lists/generators.\\n\\n        Returns tuple of fints.formals.TANUsageOption and a list of fints.formals.TANMedia4 or fints.formals.TANMedia5 objects.\"\"\"\\n\\n        with self._get_dialog() as dialog:\\n            hktab = self._find_highest_supported_command(HKTAB4, HKTAB5)\\n\\n            seg = hktab(\\n                tan_media_type = media_type,\\n                tan_media_class = str(media_class),\\n            )\\n\\n            response = dialog.send(seg)\\n\\n            for resp in response.response_segments(seg, \\'HITAB\\'):\\n                return resp.tan_usage_option, list(resp.tan_media_list)',\n",
              " 'def _generate_MAC(segments=6, segment_length=2, delimiter=\":\", charset=\"0123456789abcdef\"):\\n        \"\"\"generate a non-guaranteed-unique mac address\"\"\"\\n        addr = []\\n        for _ in range(segments):\\n            sub = \\'\\'.join(random.choice(charset) for _ in range(segment_length))\\n            addr.append(sub)\\n        return delimiter.join(addr)',\n",
              " 'def run(self):\\n        \"\"\"runloop that gets triggered by node.start()\\n        reads new packets off the link and feeds them to recv()\\n        \"\"\"\\n        if self.program:\\n            self.program.start()\\n        while self.keep_listening:\\n            for interface in self.interfaces:\\n                packet = interface.recv(self.mac_addr if not self.promiscuous else \"00:00:00:00:00:00\")\\n                if packet:\\n                    self.recv(packet, interface)\\n                time.sleep(0.01)\\n        self.log(\"Stopped listening.\")',\n",
              " 'def recv(self, packet, interface):\\n        \"\"\"run incoming packet through the filters, then place it in its inq\"\"\"\\n        # the packet is piped into the first filter, then the result of that into the second filter, etc.\\n        for f in self.filters:\\n            if not packet:\\n                break\\n            packet = f.tr(packet, interface)\\n        if packet:\\n            # if the packet wasn\\'t dropped by a filter, log the recv and place it in the interface\\'s inq\\n            # self.log(\"IN      \", str(interface).ljust(30), packet.decode())\\n            self.inq[interface].put(packet)',\n",
              " 'def send(self, packet, interfaces=None):\\n        \"\"\"write packet to given interfaces, default is broadcast to all interfaces\"\"\"\\n        interfaces = interfaces or self.interfaces  # default to all interfaces\\n        interfaces = interfaces if hasattr(interfaces, \\'__iter__\\') else [interfaces]\\n\\n        for interface in interfaces:\\n            for f in self.filters:\\n                packet = f.tx(packet, interface)  # run outgoing packet through the filters\\n            if packet:\\n                # if not dropped, log the transmit and pass it to the interface\\'s send method\\n                # self.log(\"OUT     \", (\"<\"+\",\".join(i.name for i in interfaces)+\">\").ljust(30), packet.decode())\\n                interface.send(packet)',\n",
              " 'def chunk(iterable, chunk_size=20):\\n    \"\"\"chunk an iterable [1,2,3,4,5,6,7,8] -> ([1,2,3], [4,5,6], [7,8])\"\"\"\\n    items = []\\n    for value in iterable:\\n        items.append(value)\\n        if len(items) == chunk_size:\\n            yield items\\n            items = []\\n    if items:\\n        yield items',\n",
              " 'def match(cls, pattern, inverse=False):\\n        \"\"\"Factory method to create a StringFilter which filters with the given pattern.\"\"\"\\n        string_pattern = pattern\\n        invert_search = inverse\\n\\n        class DefinedStringFilter(cls):\\n            pattern = string_pattern\\n            inverse = invert_search\\n        return DefinedStringFilter',\n",
              " 'def run_cmd(command, verbose=True, shell=\\'/bin/bash\\'):\\n    \"\"\"internal helper function to run shell commands and get output\"\"\"\\n    process = Popen(command, shell=True, stdout=PIPE, stderr=STDOUT, executable=shell)\\n    output = process.stdout.read().decode().strip().split(\\'\\\\n\\')\\n    if verbose:\\n        # return full output including empty lines\\n        return output\\n    return [line for line in output if line.strip()]',\n",
              " 'def run_python(cmd, timeout=60):\\n    \"\"\"interactively interpret recieved python code\"\"\"\\n    try:\\n        try:\\n            buffer = StringIO()\\n            sys.stdout = buffer\\n            exec(cmd)\\n            sys.stdout = sys.__stdout__\\n            out = buffer.getvalue()\\n        except Exception as error:\\n            out = error\\n\\n        out = str(out).strip()\\n\\n        if len(out) < 1:\\n            try:\\n                out = \"[eval]: \"+str(eval(cmd))\\n            except Exception as error:\\n                out = \"[eval]: \"+str(error)\\n        else:\\n            out = \"[exec]: \"+out\\n\\n    except Exception as python_exception:\\n        out = \"[X]: %s\" % python_exception\\n\\n    return out.strip()',\n",
              " 'def run_shell(cmd, timeout=60, verbose=False):\\n    \"\"\"run a shell command and return the output, verbose enables live command output via yield\"\"\"\\n    retcode = None\\n    try:\\n        p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT, executable=\\'/bin/bash\\')\\n        continue_running = True\\n    except Exception as e:\\n        yield(\"Failed: %s\" % e)\\n        continue_running = False\\n\\n    while continue_running:\\n        try:\\n            line = p.stdout.readline()\\n            if verbose and line:\\n                yield(line)\\n            elif line.strip():\\n                yield(line.strip())\\n        except Exception:\\n            pass\\n\\n        try:\\n            data = irc.recv(4096)\\n        except Exception as e:\\n            data = \"\"\\n            retcode = p.poll()  # returns None while subprocess is running\\n\\n        if \\'!cancel\\' in data:\\n            retcode = \"Cancelled live output reading. You have to kill the process manually.\"\\n            yield \"[X]: %s\" % retcode\\n            break\\n\\n        elif retcode is not None:\\n            try:\\n                line = p.stdout.read()\\n            except:\\n                retcode = \"Too much output, read timed out. Process is still running in background.\"\\n\\n            if verbose and line:\\n                yield line\\n\\n            if retcode != 0:\\n                yield \"[X]: %s\" % retcode\\n            elif retcode == 0 and verbose:\\n                yield \"[√]\"\\n\\n            break',\n",
              " 'def get_platform():\\n    \"\"\"get Mac OS X version or kernel version if mac version is not found\"\"\"\\n    mac_version = str(platform.mac_ver()[0]).strip()    # e.g. 10.11.2\\n    if mac_version:\\n        return \\'OS X %s\\' % mac_version\\n    return platform.platform().strip()',\n",
              " 'def run(self):\\n        \"\"\"runloop that reads packets off the node\\'s incoming packet buffer (node.inq)\"\"\"\\n        while self.keep_listening:\\n            for interface in self.node.interfaces:\\n                try:\\n                    self.recv(self.node.inq[interface].get(timeout=0), interface)\\n                except Empty:\\n                    sleep(0.01)',\n",
              " 'def email(to=\\'medusa@sweeting.me\\', _from=default_from, subject=\\'BOT MSG\\', message=\"Info email\", attachments=None):\\n    \"\"\"function to send mail to a specified address with the given attachments\"\"\"\\n    for attachment in attachments or []:\\n        filename = attachment.strip()\\n        try:\\n            result = run_cmd(\\'uuencode %s %s | mailx -s \"%s\" %s\\' % (filename, filename, subject, to))[0]\\n            return \"Sending email From: %s; To: %s; Subject: %s; Attachment: %s (%s)\" % (_from, to, subject, filename, result or \\'Succeded\\')\\n        except Exception as error:\\n            return str(error)\\n\\n    if not attachments:\\n        p = os.popen(\"/usr/sbin/sendmail -t\", \"w\")\\n        p.write(\"From: %s\\\\n\" % _from)\\n        p.write(\"To: %s\\\\n\" % to)\\n        p.write(\"Subject: %s\\\\n\" % subject)\\n        p.write(\"\\\\n\")   # blank line separating headers from body\\n        p.write(\\'%s\\\\n\\' % message)\\n        result = p.close()\\n\\n    if not result:\\n        return \"Sent email From: %s; To: %s; Subject: %s; Attachments: %s)\" % (_from, to, subject, \\',\\'.join(attachments or []))\\n    else:\\n        return \"Error: %s. Please fix Postfix:\\\\n %s\" % (result, help_str)',\n",
              " 'def log(self, *args):\\n        \"\"\"stdout and stderr for the link\"\"\"\\n        print(\"%s %s\" % (str(self).ljust(8), \" \".join([str(x) for x in args])))',\n",
              " 'def stop(self):\\n        \"\"\"all links also need stop() to stop their runloops\"\"\"\\n        self.keep_listening = False\\n        # if threaded, kill threads before going down\\n        if hasattr(self, \\'join\\'):\\n            self.join()\\n        self.log(\"Went down.\")\\n        return True',\n",
              " 'def recv(self, mac_addr=broadcast_addr, timeout=0):\\n        \"\"\"read packet off the recv queue for a given address, optional timeout to block and wait for packet\"\"\"\\n        # recv on the broadcast address \"00:..:00\" will give you all packets (for promiscuous mode)\\n        if self.keep_listening:\\n            try:\\n                return self.inq[str(mac_addr)].get(timeout=timeout)\\n            except Empty:\\n                return \"\"\\n        else:\\n            self.log(\"is down.\")',\n",
              " 'def send(self, packet, mac_addr=broadcast_addr):\\n        \"\"\"place sent packets directly into the reciever\\'s queues (as if they are connected by wire)\"\"\"\\n        if self.keep_listening:\\n            if mac_addr == self.broadcast_addr:\\n                for addr, recv_queue in self.inq.items():\\n                    recv_queue.put(packet)\\n            else:\\n                self.inq[mac_addr].put(packet)\\n                self.inq[self.broadcast_addr].put(packet)\\n        else:\\n            self.log(\"is down.\")',\n",
              " 'def _initsocket(self):\\n        \"\"\"bind to the datagram socket (UDP), and enable BROADCAST mode\"\"\"\\n        self.send_socket = socket(AF_INET, SOCK_DGRAM)\\n        self.send_socket.setblocking(0)\\n        self.send_socket.setsockopt(SOL_SOCKET, SO_BROADCAST, 1)\\n\\n        self.recv_socket = socket(AF_INET, SOCK_DGRAM)\\n        self.recv_socket.setblocking(0)\\n        if IS_BSD:\\n            self.recv_socket.setsockopt(SOL_SOCKET, SO_REUSEPORT, 1)  # requires sudo\\n        self.recv_socket.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)  # allows multiple UDPLinks to all listen for UDP packets\\n        self.recv_socket.bind((\\'\\', self.port))',\n",
              " 'def run(self):\\n        \"\"\"runloop that reads incoming packets off the interface into the inq buffer\"\"\"\\n        # self.log(\"ready to receive.\")\\n        # we use a runloop instead of synchronous recv so stopping the node mid-recv is possible\\n        read_ready = None\\n\\n        while self.keep_listening:\\n            try:\\n                read_ready, w, x = select.select([self.recv_socket], [], [], 0.01)\\n            except Exception:\\n                # catch timeouts\\n                pass\\n\\n            if read_ready:\\n                packet, addr = read_ready[0].recvfrom(4096)\\n                if addr[1] == self.port:\\n                    # for each address listening to this link\\n                    for mac_addr, recv_queue in self.inq.items():\\n                        recv_queue.put(packet)  # put packet in node\\'s recv queue\\n                else:\\n                    pass',\n",
              " 'def send(self, packet, retry=True):\\n        \"\"\"send a packet down the line to the inteface\"\"\"\\n        addr = (\\'255.255.255.255\\', self.port)  # 255. is the broadcast IP for UDP\\n        try:\\n            self.send_socket.sendto(packet, addr)\\n        except Exception as e:\\n            self.log(\"Link failed to send packet over socket %s\" % e)\\n            sleep(0.2)\\n            if retry:\\n                self.send(packet, retry=False)',\n",
              " 'def run(self):\\n        \"\"\"runloop that reads incoming packets off the interface into the inq buffer\"\"\"\\n        self.log(\"ready to receive.\")\\n        # we use a runloop instead of synchronous recv so stopping the connection mid-recv is possible\\n        self.net_socket.settimeout(0.05)\\n        while self.keep_listening:\\n            try:\\n                packet = self.net_socket.recv(4096)\\n            except:\\n                packet = None\\n            if packet:\\n                packet, source = self._parse_msg(packet)\\n                if packet == \"PING\":\\n                    self.net_socket.send(b\\'PONG \\' + source + b\\'\\\\r\\')\\n                elif packet:\\n                    for mac_addr, recv_queue in self.inq.items():\\n                        # put the packet in that mac_addr recv queue\\n                        recv_queue.put(packet)\\n        self.log(\\'is down.\\')',\n",
              " 'def send(self, packet, retry=True):\\n        \"\"\"send a packet down the line to the inteface\"\"\"\\n        if not self.keep_listening:\\n            self.log(\\'is down.\\')\\n            return\\n\\n        try:\\n            # (because the IRC server sees this link as 1 connection no matter how many nodes use it, it wont send enough copies of the packet back)\\n            # for each node listening to this link object locally\\n            for mac_addr, recv_queue in self.inq.items():\\n                recv_queue.put(packet) # put the packet directly in their in queue\\n            # then send it down the wire to the IRC channel\\n            self.net_socket.send((\\'PRIVMSG %s :%s\\\\r\\\\n\\' % (self.channel, packet.decode())).encode(\\'utf-8\\'))\\n        except Exception as e:\\n            self.log(\"Link failed to send packet over socket %s\" % e)\\n            sleep(0.2)\\n            if retry:\\n                self.send(packet, retry=False)',\n",
              " 'def hops(node1, node2):\\n    \"\"\"returns # of hops it takes to get from node1 to node2, 1 means they\\'re on the same link\"\"\"\\n    if node1 == node2:\\n        return 0\\n    elif set(node1.interfaces) & set(node2.interfaces):\\n        # they share a common interface\\n        return 1\\n    else:\\n        # Not implemented yet, graphsearch to find min hops between two nodes\\n        return 0',\n",
              " 'def eigenvalue(nodes, node=None):\\n    \"\"\"\\n    calculate the eigenvalue (number of connections) for a given node in an array of nodes connected by an array of links\\n    if no node is given, return the minimum eigenvalue in the whole network\\n    \"\"\"\\n    if node is None:\\n        return sorted([eigenvalue(nodes, n) for n in nodes])[0]  # return lowest eigenvalue\\n    else:\\n        return len([1 for n in nodes if hops(node, n)])',\n",
              " 'def register_on_network_adapter_changed(self, callback):\\n        \"\"\"Set the callback function to consume on network adapter changed\\n        events.\\n\\n        Callback receives a INetworkAdapterChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_network_adapter_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_serial_port_changed(self, callback):\\n        \"\"\"Set the callback function to consume on serial port changed events.\\n\\n        Callback receives a ISerialPortChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_serial_port_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_parallel_port_changed(self, callback):\\n        \"\"\"Set the callback function to consume on serial port changed events.\\n\\n        Callback receives a IParallelPortChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_parallel_port_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_medium_changed(self, callback):\\n        \"\"\"Set the callback function to consume on medium changed events.\\n\\n        Callback receives a IMediumChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_medium_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_clipboard_mode_changed(self, callback):\\n        \"\"\"Set the callback function to consume on clipboard mode changed\\n        events.\\n\\n        Callback receives a IClipboardModeChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_clipboard_mode_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_drag_and_drop_mode_changed(self, callback):\\n        \"\"\"Set the callback function to consume on drag and drop mode changed\\n        events.\\n\\n        Callback receives a IDragAndDropModeChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_drag_and_drop_mode_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_vrde_server_changed(self, callback):\\n        \"\"\"Set the callback function to consume on VirtualBox Remote Desktop\\n        Extension (VRDE) changed events.\\n\\n        Callback receives a IVRDEServerChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_vrde_server_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_shared_folder_changed(self, callback):\\n        \"\"\"Set the callback function to consume on shared folder changed events.\\n\\n        Callback receives a ISharedFolderChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_shared_folder_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_additions_state_changed(self, callback):\\n        \"\"\"Set the callback function to consume on additions state changed\\n        events.\\n\\n        Callback receives a IAdditionsStateChangedEvent object.\\n\\n        Note: Interested callees should query IGuest attributes to find out\\n              what has changed.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_additions_state_change\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_state_changed(self, callback):\\n        \"\"\"Set the callback function to consume on state changed events\\n        which are generated when the state of the machine changes.\\n\\n        Callback receives a IStateChangeEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_state_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_event_source_changed(self, callback):\\n        \"\"\"Set the callback function to consume on event source changed\\n        events.  This occurs when a listener is added or removed.\\n\\n        Callback receives a IEventStateChangedEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_event_source_changed\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_can_show_window(self, callback):\\n        \"\"\"Set the callback function to consume on can show window events.\\n        This occurs when the console window is to be activated and brought to\\n        the foreground of the desktop of the host PC.  If this behaviour is\\n        not desired a call to event.add_veto will stop this from happening.\\n\\n        Callback receives a ICanShowWindowEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_can_show_window\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def register_on_show_window(self, callback):\\n        \"\"\"Set the callback function to consume on show window events.\\n        This occurs when the console window is to be activated and brought to\\n        the foreground of the desktop of the host PC.\\n\\n        Callback receives a IShowWindowEvent object.\\n\\n        Returns the callback_id\\n        \"\"\"\\n        event_type = library.VBoxEventType.on_show_window\\n        return self.event_source.register_callback(callback, event_type)',\n",
              " 'def import_vboxapi():\\n    \"\"\"This import is designed to help when loading vboxapi inside of\\n    alternative Python environments (virtualenvs etc).\\n\\n    :rtype: vboxapi module\\n    \"\"\"\\n    try:\\n        import vboxapi\\n    except ImportError:\\n        system = platform.system()\\n        py_mm_ver = sys.version_info[:2]\\n        py_major = sys.version_info[0]\\n        packages = [\\'vboxapi\\']\\n\\n        if system == \\'Windows\\':\\n            packages.extend([\\'win32com\\', \\'win32\\', \\'win32api\\', \\'pywintypes\\', \\'win32comext\\'])\\n            search = [\\'C:\\\\\\\\Python%s%s\\\\\\\\Lib\\\\\\\\site-packages\\' % py_mm_ver,\\n                      \\'C:\\\\\\\\Python%s%s\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\win32\\' % py_mm_ver,\\n                      \\'C:\\\\\\\\Python%s%s\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib\\' % py_mm_ver,\\n                      \\'C:\\\\\\\\Program Files\\\\\\\\Oracle\\\\\\\\VirtualBox\\\\\\\\sdk\\\\\\\\install\\',\\n                      \\'C:\\\\\\\\Program Files (x86)\\\\\\\\Oracle\\\\\\\\VirtualBox\\\\\\\\sdk\\\\\\\\install\\']\\n\\n            for x in [\\'\\', py_major]:\\n                search.extend([\\'C:\\\\\\\\Anaconda%s\\\\\\\\Lib\\\\\\\\site-packages\\' % x,\\n                               \\'C:\\\\\\\\Anaconda%s\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\win32\\' % x,\\n                               \\'C:\\\\\\\\Anaconda%s\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib\\' % x])\\n\\n        elif system == \\'Linux\\':\\n            search = [\\'/usr/lib/python%s.%s/dist-packages\\' % py_mm_ver,\\n                      \\'/usr/lib/python%s.%s/site-packages\\' % py_mm_ver,\\n                      \\'/usr/share/pyshared\\']\\n\\n        elif system == \\'Darwin\\':\\n            search = [\\'/Library/Python/%s.%s/site-packages\\' % py_mm_ver]\\n        else:\\n            # No idea where to look...\\n            search = []\\n\\n        # Generates a common prefix from sys.executable in the\\n        # case that vboxapi is installed in a virtualenv.\\n        # This will also help with when we don\\'t know where\\n        # to search because of an unknown platform.\\n        # These paths also help if the system Python is installed\\n        # in a non-standard location.\\n        #\\n        # NOTE: We don\\'t have to worry if these directories don\\'t\\n        # exist as they\\'re checked below.\\n        prefix = os.path.dirname(os.path.dirname(sys.executable))\\n        search.extend([os.path.join(prefix, \\'Lib\\', \\'site-packages\\'),\\n                       os.path.join(prefix, \\'Lib\\', \\'site-packages\\', \\'win32\\'),\\n                       os.path.join(prefix, \\'Lib\\', \\'site-packages\\', \\'win32\\', \\'lib\\'),\\n                       os.path.join(prefix, \\'lib\\', \\'site-packages\\'),\\n                       os.path.join(prefix, \\'lib\\', \\'dist-packages\\')])\\n\\n        packages = set(packages)\\n        original_path = copy.copy(sys.path)\\n        for path in search:\\n            if not os.path.isdir(path):\\n                continue\\n            listing = set([os.path.splitext(f)[0] for f in os.listdir(path)])\\n            if packages.intersection(listing):\\n                sys.path.append(path)\\n            packages -= listing\\n            if not packages:\\n                break\\n        else:\\n            # After search each path we still failed to find\\n            # the required set of packages.\\n            raise\\n        import vboxapi\\n        try:\\n            yield vboxapi\\n        finally:\\n            sys.path = original_path\\n    else:\\n        yield vboxapi',\n",
              " 'def manager(self, value):\\n        \"Set the manager object in the global _managers dict.\"\\n        pid = current_process().ident\\n        if _managers is None:\\n            raise RuntimeError(\"Can not set the manager following a system exit.\")\\n        if pid not in _managers:\\n            _managers[pid] = value\\n        else:\\n            raise Exception(\"Manager already set for pid %s\" % pid)',\n",
              " 'def get_session(self):\\n        \"\"\"Return a Session interface\\n\\n        :rtype: library.ISession\\n        \"\"\"\\n        # The inconsistent vboxapi implementation makes this annoying...\\n        if hasattr(self.manager, \\'mgr\\'):\\n            manager = getattr(self.manager, \\'mgr\\')\\n        else:\\n            manager = self.manager\\n        return Session(interface=manager.getSessionObject(None))',\n",
              " 'def cast_object(self, interface_object, interface_class):\\n        \"\"\"Cast the obj to the interface class\\n\\n        :rtype: interface_class(interface_object)\\n        \"\"\"\\n        name = interface_class.__name__\\n        i = self.manager.queryInterface(interface_object._i, name)\\n        return interface_class(interface=i)',\n",
              " 'def _lock(self, timeout_ms=-1):\\n        \"\"\"Exclusive lock over root machine\"\"\"\\n        vbox = VirtualBox()\\n        machine = vbox.find_machine(self.machine_name)\\n        wait_time = 0\\n        while True:\\n            session = Session()\\n            try:\\n                machine.lock_machine(session, LockType.write)\\n            except Exception as exc:\\n                if timeout_ms != -1 and wait_time > timeout_ms:\\n                    raise ValueError(\"Failed to acquire lock - %s\" % exc)\\n                time.sleep(1)\\n                wait_time += 1000\\n            else:\\n                try:\\n                    yield session\\n                finally:\\n                    session.unlock_machine()\\n                break',\n",
              " 'def _clones(self):\\n        \"\"\"Yield all machines under this pool\"\"\"\\n        vbox = VirtualBox()\\n        machines = []\\n        for machine in vbox.machines:\\n            if machine.name == self.machine_name:\\n                continue\\n            if machine.name.startswith(self.machine_name):\\n                machines.append(machine)\\n        return machines',\n",
              " 'def acquire(self, username, password, frontend=\\'headless\\'):\\n        \"\"\"Acquire a Machine resource.\"\"\"\\n        with self._lock() as root_session:\\n            for clone in self._clones:\\n                # Search for a free clone\\n                session = Session()\\n                try:\\n                    clone.lock_machine(session, LockType.write)\\n                except Exception:\\n                    continue\\n                else:\\n                    try:\\n                        p = session.machine.restore_snapshot()\\n                        p.wait_for_completion(60 * 1000)\\n                    except Exception:\\n                        pass\\n                    session.unlock_machine()\\n                    break\\n            else:\\n                # Build a new clone\\n                machine = root_session.machine\\n                clone = machine.clone(name=\"%s Pool\" % self.machine_name)\\n                p = clone.launch_vm_process(type_p=frontend)\\n                p.wait_for_completion(60 * 1000)\\n                session = clone.create_session()\\n                console = session.console\\n                guest = console.guest\\n                try:\\n                    guest_session = guest.create_session(username, password,\\n                                                         timeout_ms=300 * 1000)\\n                    idle_count = 0\\n                    timeout = 60\\n                    while idle_count < 5 and timeout > 0:\\n                        act = console.get_device_activity([DeviceType.hard_disk])\\n                        if act[0] == DeviceActivity.idle:\\n                            idle_count += 1\\n                        time.sleep(0.5)\\n                        timeout -= 0.5\\n                    guest_session.close()\\n                    console.pause()\\n                    p, id_p = console.machine.take_snapshot(\\'initialised\\',\\n                                                            \\'machine pool\\',\\n                                                            True)\\n                    p.wait_for_completion(60 * 1000)\\n                    self._power_down(session)\\n                finally:\\n                    if session.state == SessionState.locked:\\n                        session.unlock_machine()\\n\\n            # Launch our clone\\n            p = clone.launch_vm_process(type_p=frontend)\\n            p.wait_for_completion(60 * 1000)\\n            session = clone.create_session()\\n            return session',\n",
              " 'def release(self, session):\\n        \"\"\"Release a machine session resource.\"\"\"\\n        if session.state != SessionState.locked:\\n            return\\n        with self._lock():\\n            return self._power_down(session)',\n",
              " 'def add_port_forward_rule(self, is_ipv6, rule_name, proto, host_ip, host_port, guest_ip, guest_port):\\n        \"\"\"Protocol handled with the rule.\\n\\n        in is_ipv6 of type bool\\n\\n        in rule_name of type str\\n\\n        in proto of type :class:`NATProtocol`\\n            Protocol handled with the rule.\\n\\n        in host_ip of type str\\n            IP of the host interface to which the rule should apply.\\n            An empty ip address is acceptable, in which case the NAT engine\\n            binds the handling socket to any interface.\\n\\n        in host_port of type int\\n            The port number to listen on.\\n\\n        in guest_ip of type str\\n            The IP address of the guest which the NAT engine will forward\\n            matching packets to. An empty IP address is not acceptable.\\n\\n        in guest_port of type int\\n            The port number to forward.\\n\\n        \"\"\"\\n        if not isinstance(is_ipv6, bool):\\n            raise TypeError(\"is_ipv6 can only be an instance of type bool\")\\n        if not isinstance(rule_name, basestring):\\n            raise TypeError(\"rule_name can only be an instance of type basestring\")\\n        if not isinstance(proto, NATProtocol):\\n            raise TypeError(\"proto can only be an instance of type NATProtocol\")\\n        if not isinstance(host_ip, basestring):\\n            raise TypeError(\"host_ip can only be an instance of type basestring\")\\n        if not isinstance(host_port, baseinteger):\\n            raise TypeError(\"host_port can only be an instance of type baseinteger\")\\n        if not isinstance(guest_ip, basestring):\\n            raise TypeError(\"guest_ip can only be an instance of type basestring\")\\n        if not isinstance(guest_port, baseinteger):\\n            raise TypeError(\"guest_port can only be an instance of type baseinteger\")\\n        self._call(\"addPortForwardRule\",\\n                     in_p=[is_ipv6, rule_name, proto, host_ip, host_port, guest_ip, guest_port])',\n",
              " 'def start(self, trunk_type):\\n        \"\"\"Type of internal network trunk.\\n\\n        in trunk_type of type str\\n            Type of internal network trunk.\\n\\n        \"\"\"\\n        if not isinstance(trunk_type, basestring):\\n            raise TypeError(\"trunk_type can only be an instance of type basestring\")\\n        self._call(\"start\",\\n                     in_p=[trunk_type])',\n",
              " 'def remove_global_option(self, option):\\n        \"\"\"removes the specified option\\n\\n        in option of type :class:`DhcpOpt`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            invalid option id supplied\\n        \\n        \"\"\"\\n        if not isinstance(option, DhcpOpt):\\n            raise TypeError(\"option can only be an instance of type DhcpOpt\")\\n        self._call(\"removeGlobalOption\",\\n                     in_p=[option])',\n",
              " 'def remove_vm_slot_option(self, vmname, slot, option):\\n        \"\"\"removes the specified option\\n\\n        in vmname of type str\\n\\n        in slot of type int\\n\\n        in option of type :class:`DhcpOpt`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            invalid VM, slot, or option id supplied\\n        \\n        \"\"\"\\n        if not isinstance(vmname, basestring):\\n            raise TypeError(\"vmname can only be an instance of type basestring\")\\n        if not isinstance(slot, baseinteger):\\n            raise TypeError(\"slot can only be an instance of type baseinteger\")\\n        if not isinstance(option, DhcpOpt):\\n            raise TypeError(\"option can only be an instance of type DhcpOpt\")\\n        self._call(\"removeVmSlotOption\",\\n                     in_p=[vmname, slot, option])',\n",
              " 'def remove_vm_slot_options(self, vmname, slot):\\n        \"\"\"removes all option for the specified adapter\\n\\n        in vmname of type str\\n\\n        in slot of type int\\n\\n        raises :class:`OleErrorInvalidarg`\\n            invalid VM or slot supplied\\n        \\n        \"\"\"\\n        if not isinstance(vmname, basestring):\\n            raise TypeError(\"vmname can only be an instance of type basestring\")\\n        if not isinstance(slot, baseinteger):\\n            raise TypeError(\"slot can only be an instance of type baseinteger\")\\n        self._call(\"removeVmSlotOptions\",\\n                     in_p=[vmname, slot])',\n",
              " 'def set_configuration(self, ip_address, network_mask, from_ip_address, to_ip_address):\\n        \"\"\"configures the server\\n\\n        in ip_address of type str\\n            server IP address\\n\\n        in network_mask of type str\\n            server network mask\\n\\n        in from_ip_address of type str\\n            server From IP address for address range\\n\\n        in to_ip_address of type str\\n            server To IP address for address range\\n\\n        raises :class:`OleErrorInvalidarg`\\n            invalid configuration supplied\\n        \\n        \"\"\"\\n        if not isinstance(ip_address, basestring):\\n            raise TypeError(\"ip_address can only be an instance of type basestring\")\\n        if not isinstance(network_mask, basestring):\\n            raise TypeError(\"network_mask can only be an instance of type basestring\")\\n        if not isinstance(from_ip_address, basestring):\\n            raise TypeError(\"from_ip_address can only be an instance of type basestring\")\\n        if not isinstance(to_ip_address, basestring):\\n            raise TypeError(\"to_ip_address can only be an instance of type basestring\")\\n        self._call(\"setConfiguration\",\\n                     in_p=[ip_address, network_mask, from_ip_address, to_ip_address])',\n",
              " 'def start(self, network_name, trunk_name, trunk_type):\\n        \"\"\"Starts DHCP server process.\\n\\n        in network_name of type str\\n            Name of internal network DHCP server should attach to.\\n\\n        in trunk_name of type str\\n            Name of internal network trunk.\\n\\n        in trunk_type of type str\\n            Type of internal network trunk.\\n\\n        raises :class:`OleErrorFail`\\n            Failed to start the process.\\n        \\n        \"\"\"\\n        if not isinstance(network_name, basestring):\\n            raise TypeError(\"network_name can only be an instance of type basestring\")\\n        if not isinstance(trunk_name, basestring):\\n            raise TypeError(\"trunk_name can only be an instance of type basestring\")\\n        if not isinstance(trunk_type, basestring):\\n            raise TypeError(\"trunk_type can only be an instance of type basestring\")\\n        self._call(\"start\",\\n                     in_p=[network_name, trunk_name, trunk_type])',\n",
              " 'def compose_machine_filename(self, name, group, create_flags, base_folder):\\n        \"\"\"Returns a recommended full path of the settings file name for a new virtual\\n        machine.\\n        \\n        This API serves two purposes:\\n        \\n        \\n        It gets called by :py:func:`create_machine`  if @c null or\\n        empty string (which is recommended) is specified for the\\n        @a settingsFile argument there, which means that API should use\\n        a recommended default file name.\\n        \\n        It can be called manually by a client software before creating a machine,\\n        e.g. if that client wants to pre-create the machine directory to create\\n        virtual hard disks in that directory together with the new machine\\n        settings file. In that case, the file name should be stripped from the\\n        full settings file path returned by this function to obtain the\\n        machine directory.\\n        \\n        \\n        See :py:func:`IMachine.name`  and :py:func:`create_machine`  for more\\n        details about the machine name.\\n        \\n        @a groupName defines which additional subdirectory levels should be\\n        included. It must be either a valid group name or @c null or empty\\n        string which designates that the machine will not be related to a\\n        machine group.\\n        \\n        If @a baseFolder is a @c null or empty string (which is recommended), the\\n        default machine settings folder\\n        (see :py:func:`ISystemProperties.default_machine_folder` ) will be used as\\n        a base folder for the created machine, resulting in a file name like\\n        \"/home/user/VirtualBox VMs/name/name.vbox\". Otherwise the given base folder\\n        will be used.\\n        \\n        This method does not access the host disks. In particular, it does not check\\n        for whether a machine with this name already exists.\\n\\n        in name of type str\\n            Suggested machine name.\\n\\n        in group of type str\\n            Machine group name for the new machine or machine group. It is\\n            used to determine the right subdirectory.\\n\\n        in create_flags of type str\\n            Machine creation flags, see :py:func:`create_machine`  (optional).\\n\\n        in base_folder of type str\\n            Base machine folder (optional).\\n\\n        return file_p of type str\\n            Fully qualified path where the machine would be created.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(group, basestring):\\n            raise TypeError(\"group can only be an instance of type basestring\")\\n        if not isinstance(create_flags, basestring):\\n            raise TypeError(\"create_flags can only be an instance of type basestring\")\\n        if not isinstance(base_folder, basestring):\\n            raise TypeError(\"base_folder can only be an instance of type basestring\")\\n        file_p = self._call(\"composeMachineFilename\",\\n                     in_p=[name, group, create_flags, base_folder])\\n        return file_p',\n",
              " 'def create_machine(self, settings_file, name, groups, os_type_id, flags):\\n        \"\"\"Creates a new virtual machine by creating a machine settings file at\\n        the given location.\\n        \\n        VirtualBox machine settings files use a custom XML dialect. Starting\\n        with VirtualBox 4.0, a \".vbox\" extension is recommended, but not enforced,\\n        and machine files can be created at arbitrary locations.\\n        \\n        However, it is recommended that machines are created in the default\\n        machine folder (e.g. \"/home/user/VirtualBox VMs/name/name.vbox\"; see\\n        :py:func:`ISystemProperties.default_machine_folder` ). If you specify\\n        @c null or empty string (which is recommended) for the @a settingsFile\\n        argument, :py:func:`compose_machine_filename`  is called automatically\\n        to have such a recommended name composed based on the machine name\\n        given in the @a name argument and the primary group.\\n        \\n        If the resulting settings file already exists, this method will fail,\\n        unless the forceOverwrite flag is set.\\n        \\n        The new machine is created unregistered, with the initial configuration\\n        set according to the specified guest OS type. A typical sequence of\\n        actions to create a new virtual machine is as follows:\\n        \\n        \\n        \\n        Call this method to have a new machine created. The returned machine\\n        object will be \"mutable\" allowing to change any machine property.\\n        \\n        \\n        \\n        Configure the machine using the appropriate attributes and methods.\\n        \\n        \\n        \\n        Call :py:func:`IMachine.save_settings`  to write the settings\\n        to the machine\\'s XML settings file. The configuration of the newly\\n        created machine will not be saved to disk until this method is\\n        called.\\n        \\n        \\n        \\n        Call :py:func:`register_machine`  to add the machine to the list\\n        of machines known to VirtualBox.\\n        \\n        \\n        \\n        The specified guest OS type identifier must match an ID of one of known\\n        guest OS types listed in the :py:func:`IVirtualBox.guest_os_types` \\n        array.\\n        \\n        \\n        :py:func:`IMachine.settings_modified`  will return\\n        @c false for the created machine, until any of machine settings\\n        are changed.\\n        \\n        \\n        \\n        There is no way to change the name of the settings file or\\n        subfolder of the created machine directly.\\n\\n        in settings_file of type str\\n            Fully qualified path where the settings file should be created,\\n            empty string or @c null for a default folder and file based on the\\n            @a name argument and the primary group.\\n            (see :py:func:`compose_machine_filename` ).\\n\\n        in name of type str\\n            Machine name.\\n\\n        in groups of type str\\n            Array of group names. @c null or an empty array have the same\\n            meaning as an array with just the empty string or \"/\", i.e.\\n            create a machine without group association.\\n\\n        in os_type_id of type str\\n            Guest OS Type ID.\\n\\n        in flags of type str\\n            Additional property parameters, passed as a comma-separated list of\\n            \"name=value\" type entries. The following ones are recognized:\\n            forceOverwrite=1 to overwrite an existing machine settings\\n            file, UUID=<uuid> to specify a machine UUID and\\n            directoryIncludesUUID=1 to switch to a special VM directory\\n            naming scheme which should not be used unless necessary.\\n\\n        return machine of type :class:`IMachine`\\n            Created machine object.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            @a osTypeId is invalid.\\n        \\n        raises :class:`VBoxErrorFileError`\\n            Resulting settings file name is invalid or the settings file already\\nexists or could not be created due to an I/O error.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            @a name is empty or @c null.\\n        \\n        \"\"\"\\n        if not isinstance(settings_file, basestring):\\n            raise TypeError(\"settings_file can only be an instance of type basestring\")\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(groups, list):\\n            raise TypeError(\"groups can only be an instance of type list\")\\n        for a in groups[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(os_type_id, basestring):\\n            raise TypeError(\"os_type_id can only be an instance of type basestring\")\\n        if not isinstance(flags, basestring):\\n            raise TypeError(\"flags can only be an instance of type basestring\")\\n        machine = self._call(\"createMachine\",\\n                     in_p=[settings_file, name, groups, os_type_id, flags])\\n        machine = IMachine(machine)\\n        return machine',\n",
              " 'def open_machine(self, settings_file):\\n        \"\"\"Opens a virtual machine from the existing settings file.\\n        The opened machine remains unregistered until you call\\n        :py:func:`register_machine` .\\n        \\n        The specified settings file name must be fully qualified.\\n        The file must exist and be a valid machine XML settings file\\n        whose contents will be used to construct the machine object.\\n        \\n        \\n        :py:func:`IMachine.settings_modified`  will return\\n        @c false for the opened machine, until any of machine settings\\n        are changed.\\n\\n        in settings_file of type str\\n            Name of the machine settings file.\\n\\n        return machine of type :class:`IMachine`\\n            Opened machine object.\\n\\n        raises :class:`VBoxErrorFileError`\\n            Settings file name invalid, not found or sharing violation.\\n        \\n        \"\"\"\\n        if not isinstance(settings_file, basestring):\\n            raise TypeError(\"settings_file can only be an instance of type basestring\")\\n        machine = self._call(\"openMachine\",\\n                     in_p=[settings_file])\\n        machine = IMachine(machine)\\n        return machine',\n",
              " 'def register_machine(self, machine):\\n        \"\"\"Registers the machine previously created using\\n        :py:func:`create_machine`  or opened using\\n        :py:func:`open_machine`  within this VirtualBox installation. After\\n        successful method invocation, the\\n        :py:class:`IMachineRegisteredEvent`  event is fired.\\n        \\n        \\n        This method implicitly calls :py:func:`IMachine.save_settings` \\n        to save all current machine settings before registering it.\\n\\n        in machine of type :class:`IMachine`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            No matching virtual machine found.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Virtual machine was not created within this VirtualBox instance.\\n        \\n        \"\"\"\\n        if not isinstance(machine, IMachine):\\n            raise TypeError(\"machine can only be an instance of type IMachine\")\\n        self._call(\"registerMachine\",\\n                     in_p=[machine])',\n",
              " 'def find_machine(self, name_or_id):\\n        \"\"\"Attempts to find a virtual machine given its name or UUID.\\n        \\n        Inaccessible machines cannot be found by name, only by UUID, because their name\\n        cannot safely be determined.\\n\\n        in name_or_id of type str\\n            What to search for. This can either be the UUID or the name of a virtual machine.\\n\\n        return machine of type :class:`IMachine`\\n            Machine object, if found.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Could not find registered machine matching @a nameOrId.\\n        \\n        \"\"\"\\n        if not isinstance(name_or_id, basestring):\\n            raise TypeError(\"name_or_id can only be an instance of type basestring\")\\n        machine = self._call(\"findMachine\",\\n                     in_p=[name_or_id])\\n        machine = IMachine(machine)\\n        return machine',\n",
              " 'def get_machines_by_groups(self, groups):\\n        \"\"\"Gets all machine references which are in one of the specified groups.\\n\\n        in groups of type str\\n            What groups to match. The usual group list rules apply, i.e.\\n            passing an empty list will match VMs in the toplevel group, likewise\\n            the empty string.\\n\\n        return machines of type :class:`IMachine`\\n            All machines which matched.\\n\\n        \"\"\"\\n        if not isinstance(groups, list):\\n            raise TypeError(\"groups can only be an instance of type list\")\\n        for a in groups[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        machines = self._call(\"getMachinesByGroups\",\\n                     in_p=[groups])\\n        machines = [IMachine(a) for a in machines]\\n        return machines',\n",
              " 'def get_machine_states(self, machines):\\n        \"\"\"Gets the state of several machines in a single operation.\\n\\n        in machines of type :class:`IMachine`\\n            Array with the machine references.\\n\\n        return states of type :class:`MachineState`\\n            Machine states, corresponding to the machines.\\n\\n        \"\"\"\\n        if not isinstance(machines, list):\\n            raise TypeError(\"machines can only be an instance of type list\")\\n        for a in machines[:10]:\\n            if not isinstance(a, IMachine):\\n                raise TypeError(\\n                        \"array can only contain objects of type IMachine\")\\n        states = self._call(\"getMachineStates\",\\n                     in_p=[machines])\\n        states = [MachineState(a) for a in states]\\n        return states',\n",
              " 'def create_medium(self, format_p, location, access_mode, a_device_type_type):\\n        \"\"\"Creates a new base medium object that will use the given storage\\n        format and location for medium data.\\n        \\n        The actual storage unit is not created by this method. In order to\\n        do it, and before you are able to attach the created medium to\\n        virtual machines, you must call one of the following methods to\\n        allocate a format-specific storage unit at the specified location:\\n        \\n        :py:func:`IMedium.create_base_storage` \\n        :py:func:`IMedium.create_diff_storage` \\n        \\n        \\n        Some medium attributes, such as :py:func:`IMedium.id_p` , may\\n        remain uninitialized until the medium storage unit is successfully\\n        created by one of the above methods.\\n        \\n        Depending on the given device type, the file at the storage location\\n        must be in one of the media formats understood by VirtualBox:\\n        \\n        \\n        With a \"HardDisk\" device type, the file must be a hard disk image\\n        in one of the formats supported by VirtualBox (see\\n        :py:func:`ISystemProperties.medium_formats` ).\\n        After the storage unit is successfully created and this method succeeds,\\n        if the medium is a base medium, it\\n        will be added to the :py:func:`hard_disks`  array attribute.\\n        With a \"DVD\" device type, the file must be an ISO 9960 CD/DVD image.\\n        After this method succeeds, the medium will be added to the\\n        :py:func:`dvd_images`  array attribute.\\n        With a \"Floppy\" device type, the file must be an RAW floppy image.\\n        After this method succeeds, the medium will be added to the\\n        :py:func:`floppy_images`  array attribute.\\n        \\n        \\n        The list of all storage formats supported by this VirtualBox\\n        installation can be obtained using\\n        :py:func:`ISystemProperties.medium_formats` . If the @a format\\n        attribute is empty or @c null then the default storage format\\n        specified by :py:func:`ISystemProperties.default_hard_disk_format`  will\\n        be used for disks r creating a storage unit of the medium.\\n        \\n        Note that the format of the location string is storage format specific.\\n        See :py:func:`IMedium.location`  and IMedium for more details.\\n\\n        in format_p of type str\\n            Identifier of the storage format to use for the new medium.\\n\\n        in location of type str\\n            Location of the storage unit for the new medium.\\n\\n        in access_mode of type :class:`AccessMode`\\n            Whether to open the image in read/write or read-only mode. For\\n            a \"DVD\" device type, this is ignored and read-only mode is always assumed.\\n\\n        in a_device_type_type of type :class:`DeviceType`\\n            Must be one of \"HardDisk\", \"DVD\" or \"Floppy\".\\n\\n        return medium of type :class:`IMedium`\\n            Created medium object.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            @a format identifier is invalid. See\\n        \\n        raises :class:`VBoxErrorFileError`\\n            @a location is a not valid file name (for file-based formats only).\\n        \\n        \"\"\"\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        if not isinstance(location, basestring):\\n            raise TypeError(\"location can only be an instance of type basestring\")\\n        if not isinstance(access_mode, AccessMode):\\n            raise TypeError(\"access_mode can only be an instance of type AccessMode\")\\n        if not isinstance(a_device_type_type, DeviceType):\\n            raise TypeError(\"a_device_type_type can only be an instance of type DeviceType\")\\n        medium = self._call(\"createMedium\",\\n                     in_p=[format_p, location, access_mode, a_device_type_type])\\n        medium = IMedium(medium)\\n        return medium',\n",
              " 'def open_medium(self, location, device_type, access_mode, force_new_uuid):\\n        \"\"\"Finds existing media or opens a medium from an existing storage location.\\n        \\n        Once a medium has been opened, it can be passed to other VirtualBox\\n        methods, in particular to :py:func:`IMachine.attach_device` .\\n        \\n        Depending on the given device type, the file at the storage location\\n        must be in one of the media formats understood by VirtualBox:\\n        \\n        \\n        With a \"HardDisk\" device type, the file must be a hard disk image\\n        in one of the formats supported by VirtualBox (see\\n        :py:func:`ISystemProperties.medium_formats` ).\\n        After this method succeeds, if the medium is a base medium, it\\n        will be added to the :py:func:`hard_disks`  array attribute.\\n        With a \"DVD\" device type, the file must be an ISO 9960 CD/DVD image.\\n        After this method succeeds, the medium will be added to the\\n        :py:func:`dvd_images`  array attribute.\\n        With a \"Floppy\" device type, the file must be an RAW floppy image.\\n        After this method succeeds, the medium will be added to the\\n        :py:func:`floppy_images`  array attribute.\\n        \\n        \\n        After having been opened, the medium can be re-found by this method\\n        and can be attached to virtual machines. See :py:class:`IMedium`  for\\n        more details.\\n        \\n        The UUID of the newly opened medium will either be retrieved from the\\n        storage location, if the format supports it (e.g. for hard disk images),\\n        or a new UUID will be randomly generated (e.g. for ISO and RAW files).\\n        If for some reason you need to change the medium\\'s UUID, use\\n        :py:func:`IMedium.set_ids` .\\n        \\n        If a differencing hard disk medium is to be opened by this method, the\\n        operation will succeed only if its parent medium and all ancestors,\\n        if any, are already known to this VirtualBox installation (for example,\\n        were opened by this method before).\\n        \\n        This method attempts to guess the storage format of the specified medium\\n        by reading medium data at the specified location.\\n        \\n        If @a accessMode is ReadWrite (which it should be for hard disks and floppies),\\n        the image is opened for read/write access and must have according permissions,\\n        as VirtualBox may actually write status information into the disk\\'s metadata\\n        sections.\\n        \\n        Note that write access is required for all typical hard disk usage in VirtualBox,\\n        since VirtualBox may need to write metadata such as a UUID into the image.\\n        The only exception is opening a source image temporarily for copying and\\n        cloning (see :py:func:`IMedium.clone_to`  when the image will be closed\\n        again soon.\\n        \\n        The format of the location string is storage format specific. See\\n        :py:func:`IMedium.location`  and IMedium for more details.\\n\\n        in location of type str\\n            Location of the storage unit that contains medium data in one of\\n            the supported storage formats.\\n\\n        in device_type of type :class:`DeviceType`\\n            Must be one of \"HardDisk\", \"DVD\" or \"Floppy\".\\n\\n        in access_mode of type :class:`AccessMode`\\n            Whether to open the image in read/write or read-only mode. For\\n            a \"DVD\" device type, this is ignored and read-only mode is always assumed.\\n\\n        in force_new_uuid of type bool\\n            Allows the caller to request a completely new medium UUID for\\n            the image which is to be opened. Useful if one intends to open an exact\\n            copy of a previously opened image, as this would normally fail due to\\n            the duplicate UUID.\\n\\n        return medium of type :class:`IMedium`\\n            Opened medium object.\\n\\n        raises :class:`VBoxErrorFileError`\\n            Invalid medium storage file location or could not find the medium\\nat the specified location.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not get medium storage format.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid medium storage format.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Medium has already been added to a media registry.\\n        \\n        \"\"\"\\n        if not isinstance(location, basestring):\\n            raise TypeError(\"location can only be an instance of type basestring\")\\n        if not isinstance(device_type, DeviceType):\\n            raise TypeError(\"device_type can only be an instance of type DeviceType\")\\n        if not isinstance(access_mode, AccessMode):\\n            raise TypeError(\"access_mode can only be an instance of type AccessMode\")\\n        if not isinstance(force_new_uuid, bool):\\n            raise TypeError(\"force_new_uuid can only be an instance of type bool\")\\n        medium = self._call(\"openMedium\",\\n                     in_p=[location, device_type, access_mode, force_new_uuid])\\n        medium = IMedium(medium)\\n        return medium',\n",
              " 'def get_guest_os_type(self, id_p):\\n        \"\"\"Returns an object describing the specified guest OS type.\\n        \\n        The requested guest OS type is specified using a string which is a\\n        mnemonic identifier of the guest operating system, such as\\n        \"win31\" or \"ubuntu\". The guest OS type ID of a\\n        particular virtual machine can be read or set using the\\n        :py:func:`IMachine.os_type_id`  attribute.\\n        \\n        The :py:func:`IVirtualBox.guest_os_types`  collection contains all\\n        available guest OS type objects. Each object has an\\n        :py:func:`IGuestOSType.id_p`  attribute which contains an identifier of\\n        the guest OS this object describes.\\n        \\n        While this function returns an error for unknown guest OS types, they\\n        can be still used without serious problems (if one accepts the fact\\n        that there is no default VM config information).\\n\\n        in id_p of type str\\n            Guest OS type ID string.\\n\\n        return type_p of type :class:`IGuestOSType`\\n            Guest OS type object.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            @a id is not a valid Guest OS type.\\n        \\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        type_p = self._call(\"getGuestOSType\",\\n                     in_p=[id_p])\\n        type_p = IGuestOSType(type_p)\\n        return type_p',\n",
              " 'def create_shared_folder(self, name, host_path, writable, automount, auto_mount_point):\\n        \"\"\"Creates a new global shared folder by associating the given logical\\n        name with the given host path, adds it to the collection of shared\\n        folders and starts sharing it. Refer to the description of\\n        :py:class:`ISharedFolder`  to read more about logical names.\\n        \\n        In the current implementation, this operation is not\\n        implemented.\\n\\n        in name of type str\\n            Unique logical name of the shared folder.\\n\\n        in host_path of type str\\n            Full path to the shared folder in the host file system.\\n\\n        in writable of type bool\\n            Whether the share is writable or readonly\\n\\n        in automount of type bool\\n            Whether the share gets automatically mounted by the guest\\n            or not.\\n\\n        in auto_mount_point of type str\\n            Where the guest should automatically mount the folder, if possible.\\n            For Windows and OS/2 guests this should be a drive letter, while other\\n            guests it should be a absolute directory.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(host_path, basestring):\\n            raise TypeError(\"host_path can only be an instance of type basestring\")\\n        if not isinstance(writable, bool):\\n            raise TypeError(\"writable can only be an instance of type bool\")\\n        if not isinstance(automount, bool):\\n            raise TypeError(\"automount can only be an instance of type bool\")\\n        if not isinstance(auto_mount_point, basestring):\\n            raise TypeError(\"auto_mount_point can only be an instance of type basestring\")\\n        self._call(\"createSharedFolder\",\\n                     in_p=[name, host_path, writable, automount, auto_mount_point])',\n",
              " 'def remove_shared_folder(self, name):\\n        \"\"\"Removes the global shared folder with the given name previously\\n        created by :py:func:`create_shared_folder`  from the collection of\\n        shared folders and stops sharing it.\\n        \\n        In the current implementation, this operation is not\\n        implemented.\\n\\n        in name of type str\\n            Logical name of the shared folder to remove.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"removeSharedFolder\",\\n                     in_p=[name])',\n",
              " 'def set_settings_secret(self, password):\\n        \"\"\"Unlocks the secret data by passing the unlock password to the\\n        server. The server will cache the password for that machine.\\n\\n        in password of type str\\n            The cipher key.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine is not mutable.\\n        \\n        \"\"\"\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        self._call(\"setSettingsSecret\",\\n                     in_p=[password])',\n",
              " 'def create_dhcp_server(self, name):\\n        \"\"\"Creates a DHCP server settings to be used for the given internal network name\\n\\n        in name of type str\\n            server name\\n\\n        return server of type :class:`IDHCPServer`\\n            DHCP server settings\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Host network interface @a name already exists.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        server = self._call(\"createDHCPServer\",\\n                     in_p=[name])\\n        server = IDHCPServer(server)\\n        return server',\n",
              " 'def remove_dhcp_server(self, server):\\n        \"\"\"Removes the DHCP server settings\\n\\n        in server of type :class:`IDHCPServer`\\n            DHCP server settings to be removed\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Host network interface @a name already exists.\\n        \\n        \"\"\"\\n        if not isinstance(server, IDHCPServer):\\n            raise TypeError(\"server can only be an instance of type IDHCPServer\")\\n        self._call(\"removeDHCPServer\",\\n                     in_p=[server])',\n",
              " 'def check_firmware_present(self, firmware_type, version):\\n        \"\"\"Check if this VirtualBox installation has a firmware\\n        of the given type available, either system-wide or per-user.\\n        Optionally, this may return a hint where this firmware can be\\n        downloaded from.\\n\\n        in firmware_type of type :class:`FirmwareType`\\n            Type of firmware to check.\\n\\n        in version of type str\\n            Expected version number, usually empty string (presently ignored).\\n\\n        out url of type str\\n            Suggested URL to download this firmware from.\\n\\n        out file_p of type str\\n            Filename of firmware, only valid if result == TRUE.\\n\\n        return result of type bool\\n            If firmware of this type and version is available.\\n\\n        \"\"\"\\n        if not isinstance(firmware_type, FirmwareType):\\n            raise TypeError(\"firmware_type can only be an instance of type FirmwareType\")\\n        if not isinstance(version, basestring):\\n            raise TypeError(\"version can only be an instance of type basestring\")\\n        (result, url, file_p) = self._call(\"checkFirmwarePresent\",\\n                     in_p=[firmware_type, version])\\n        return (result, url, file_p)',\n",
              " 'def cd(self, dir_p):\\n        \"\"\"Change the current directory level.\\n\\n        in dir_p of type str\\n            The name of the directory to go in.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(dir_p, basestring):\\n            raise TypeError(\"dir_p can only be an instance of type basestring\")\\n        progress = self._call(\"cd\",\\n                     in_p=[dir_p])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def entry_list(self):\\n        \"\"\"Returns a list of files/directories after a call to :py:func:`update` . The user is responsible for keeping this internal\\n        list up do date.\\n\\n        out names of type str\\n            The list of names for the entries.\\n\\n        out types of type int\\n            The list of types for the entries. :py:class:`FsObjType` \\n\\n        out sizes of type int\\n            The list of sizes (in bytes) for the entries.\\n\\n        out modes of type int\\n            The list of file modes (in octal form) for the entries.\\n\\n        \"\"\"\\n        (names, types, sizes, modes) = self._call(\"entryList\")\\n        return (names, types, sizes, modes)',\n",
              " 'def exists(self, names):\\n        \"\"\"Checks if the given file list exists in the current directory\\n        level.\\n\\n        in names of type str\\n            The names to check.\\n\\n        return exists of type str\\n            The names which exist.\\n\\n        \"\"\"\\n        if not isinstance(names, list):\\n            raise TypeError(\"names can only be an instance of type list\")\\n        for a in names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        exists = self._call(\"exists\",\\n                     in_p=[names])\\n        return exists',\n",
              " 'def remove(self, names):\\n        \"\"\"Deletes the given files in the current directory level.\\n\\n        in names of type str\\n            The names to remove.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(names, list):\\n            raise TypeError(\"names can only be an instance of type list\")\\n        for a in names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        progress = self._call(\"remove\",\\n                     in_p=[names])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def query_info(self, what):\\n        \"\"\"Way to extend the interface.\\n\\n        in what of type int\\n\\n        return result of type str\\n\\n        \"\"\"\\n        if not isinstance(what, baseinteger):\\n            raise TypeError(\"what can only be an instance of type baseinteger\")\\n        result = self._call(\"queryInfo\",\\n                     in_p=[what])\\n        return result',\n",
              " 'def read(self, file_p):\\n        \"\"\"Reads an OVF file into the appliance object.\\n        \\n        This method succeeds if the OVF is syntactically valid and, by itself, without errors. The\\n        mere fact that this method returns successfully does not mean that VirtualBox supports all\\n        features requested by the appliance; this can only be examined after a call to :py:func:`interpret` .\\n\\n        in file_p of type str\\n            Name of appliance file to open (either with an .ovf or .ova extension, depending\\n            on whether the appliance is distributed as a set of files or as a single file, respectively).\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(file_p, basestring):\\n            raise TypeError(\"file_p can only be an instance of type basestring\")\\n        progress = self._call(\"read\",\\n                     in_p=[file_p])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def import_machines(self, options):\\n        \"\"\"Imports the appliance into VirtualBox by creating instances of :py:class:`IMachine` \\n        and other interfaces that match the information contained in the appliance as\\n        closely as possible, as represented by the import instructions in the\\n        :py:func:`virtual_system_descriptions`  array.\\n        \\n        Calling this method is the final step of importing an appliance into VirtualBox;\\n        see :py:class:`IAppliance`  for an overview.\\n        \\n        Since importing the appliance will most probably involve copying and converting\\n        disk images, which can take a long time, this method operates asynchronously and\\n        returns an IProgress object to allow the caller to monitor the progress.\\n        \\n        After the import succeeded, the UUIDs of the IMachine instances created can be\\n        retrieved from the :py:func:`machines`  array attribute.\\n\\n        in options of type :class:`ImportOptions`\\n            Options for the importing operation.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(options, list):\\n            raise TypeError(\"options can only be an instance of type list\")\\n        for a in options[:10]:\\n            if not isinstance(a, ImportOptions):\\n                raise TypeError(\\n                        \"array can only contain objects of type ImportOptions\")\\n        progress = self._call(\"importMachines\",\\n                     in_p=[options])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def create_vfs_explorer(self, uri):\\n        \"\"\"Returns a :py:class:`IVFSExplorer`  object for the given URI.\\n\\n        in uri of type str\\n            The URI describing the file system to use.\\n\\n        return explorer of type :class:`IVFSExplorer`\\n\\n        \"\"\"\\n        if not isinstance(uri, basestring):\\n            raise TypeError(\"uri can only be an instance of type basestring\")\\n        explorer = self._call(\"createVFSExplorer\",\\n                     in_p=[uri])\\n        explorer = IVFSExplorer(explorer)\\n        return explorer',\n",
              " 'def write(self, format_p, options, path):\\n        \"\"\"Writes the contents of the appliance exports into a new OVF file.\\n        \\n        Calling this method is the final step of exporting an appliance from VirtualBox;\\n        see :py:class:`IAppliance`  for an overview.\\n        \\n        Since exporting the appliance will most probably involve copying and converting\\n        disk images, which can take a long time, this method operates asynchronously and\\n        returns an IProgress object to allow the caller to monitor the progress.\\n\\n        in format_p of type str\\n            Output format, as a string. Currently supported formats are \"ovf-0.9\", \"ovf-1.0\",\\n            \"ovf-2.0\" and \"opc-1.0\"; future versions of VirtualBox may support additional formats.\\n            The \"opc-1.0\" format is for creating tarballs for the Oracle Public Cloud.\\n\\n        in options of type :class:`ExportOptions`\\n            Options for the exporting operation.\\n\\n        in path of type str\\n            Name of appliance file to create.  There are certain restrictions with regard\\n            to the file name suffix.  If the format parameter is \"opc-1.0\" a .tar.gz\\n            suffix is required.  Otherwise the suffix must either be .ovf or\\n            .ova, depending on whether the appliance is distributed as a set of\\n            files or as a single file, respectively.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        if not isinstance(options, list):\\n            raise TypeError(\"options can only be an instance of type list\")\\n        for a in options[:10]:\\n            if not isinstance(a, ExportOptions):\\n                raise TypeError(\\n                        \"array can only contain objects of type ExportOptions\")\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        progress = self._call(\"write\",\\n                     in_p=[format_p, options, path])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def get_medium_ids_for_password_id(self, password_id):\\n        \"\"\"Returns a list of medium identifiers which use the given password identifier.\\n\\n        in password_id of type str\\n            The password identifier to get the medium identifiers for.\\n\\n        return identifiers of type str\\n            The list of medium identifiers returned on success.\\n\\n        \"\"\"\\n        if not isinstance(password_id, basestring):\\n            raise TypeError(\"password_id can only be an instance of type basestring\")\\n        identifiers = self._call(\"getMediumIdsForPasswordId\",\\n                     in_p=[password_id])\\n        return identifiers',\n",
              " 'def add_passwords(self, identifiers, passwords):\\n        \"\"\"Adds a list of passwords required to import or export encrypted virtual\\n        machines.\\n\\n        in identifiers of type str\\n            List of identifiers.\\n\\n        in passwords of type str\\n            List of matching passwords.\\n\\n        \"\"\"\\n        if not isinstance(identifiers, list):\\n            raise TypeError(\"identifiers can only be an instance of type list\")\\n        for a in identifiers[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(passwords, list):\\n            raise TypeError(\"passwords can only be an instance of type list\")\\n        for a in passwords[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"addPasswords\",\\n                     in_p=[identifiers, passwords])',\n",
              " 'def get_description(self):\\n        \"\"\"Returns information about the virtual system as arrays of instruction items. In each array, the\\n        items with the same indices correspond and jointly represent an import instruction for VirtualBox.\\n        \\n        The list below identifies the value sets that are possible depending on the\\n        :py:class:`VirtualSystemDescriptionType`  enum value in the array item in @a aTypes[]. In each case,\\n        the array item with the same index in @a OVFValues[] will contain the original value as contained\\n        in the OVF file (just for informational purposes), and the corresponding item in @a aVBoxValues[]\\n        will contain a suggested value to be used for VirtualBox. Depending on the description type,\\n        the @a aExtraConfigValues[] array item may also be used.\\n        \\n        \\n        \\n        \"OS\": the guest operating system type. There must be exactly one such array item on import. The\\n        corresponding item in @a aVBoxValues[] contains the suggested guest operating system for VirtualBox.\\n        This will be one of the values listed in :py:func:`IVirtualBox.guest_os_types` . The corresponding\\n        item in @a OVFValues[] will contain a numerical value that described the operating system in the OVF.\\n        \\n        \\n        \"Name\": the name to give to the new virtual machine. There can be at most one such array item;\\n        if none is present on import, then an automatic name will be created from the operating system\\n        type. The corresponding item im @a OVFValues[] will contain the suggested virtual machine name\\n        from the OVF file, and @a aVBoxValues[] will contain a suggestion for a unique VirtualBox\\n        :py:class:`IMachine`  name that does not exist yet.\\n        \\n        \\n        \"Description\": an arbitrary description.\\n        \\n        \\n        \"License\": the EULA section from the OVF, if present. It is the responsibility of the calling\\n        code to display such a license for agreement; the Main API does not enforce any such policy.\\n        \\n        \\n        Miscellaneous: reserved for future use.\\n        \\n        \\n        \"CPU\": the number of CPUs. There can be at most one such item, which will presently be ignored.\\n        \\n        \\n        \"Memory\": the amount of guest RAM, in bytes. There can be at most one such array item; if none\\n        is present on import, then VirtualBox will set a meaningful default based on the operating system\\n        type.\\n        \\n        \\n        \"HardDiskControllerIDE\": an IDE hard disk controller. There can be at most two such items.\\n        An optional value in @a OVFValues[] and @a aVBoxValues[] can be \"PIIX3\" or \"PIIX4\" to specify\\n        the type of IDE controller; this corresponds to the ResourceSubType element which VirtualBox\\n        writes into the OVF.\\n        The matching item in the @a aRefs[] array will contain an integer that items of the \"Harddisk\"\\n        type can use to specify which hard disk controller a virtual disk should be connected to.\\n        Note that in OVF, an IDE controller has two channels, corresponding to \"master\" and \"slave\"\\n        in traditional terminology, whereas the IDE storage controller that VirtualBox supports in\\n        its virtual machines supports four channels (primary master, primary slave, secondary master,\\n        secondary slave) and thus maps to two IDE controllers in the OVF sense.\\n        \\n        \\n        \"HardDiskControllerSATA\": an SATA hard disk controller. There can be at most one such item. This\\n        has no value in @a OVFValues[] or @a aVBoxValues[].\\n        The matching item in the @a aRefs[] array will be used as with IDE controllers (see above).\\n        \\n        \\n        \"HardDiskControllerSCSI\": a SCSI hard disk controller. There can be at most one such item.\\n        The items in @a OVFValues[] and @a aVBoxValues[] will either be \"LsiLogic\", \"BusLogic\" or\\n        \"LsiLogicSas\". (Note that in OVF, the LsiLogicSas controller is treated as a SCSI controller\\n        whereas VirtualBox considers it a class of storage controllers of its own; see\\n        :py:class:`StorageControllerType` ).\\n        The matching item in the @a aRefs[] array will be used as with IDE controllers (see above).\\n        \\n        \\n        \"HardDiskImage\": a virtual hard disk, most probably as a reference to an image file. There can be an\\n        arbitrary number of these items, one for each virtual disk image that accompanies the OVF.\\n        \\n        The array item in @a OVFValues[] will contain the file specification from the OVF file (without\\n        a path since the image file should be in the same location as the OVF file itself), whereas the\\n        item in @a aVBoxValues[] will contain a qualified path specification to where VirtualBox uses the\\n        hard disk image. This means that on import the image will be copied and converted from the\\n        \"ovf\" location to the \"vbox\" location; on export, this will be handled the other way round.\\n        \\n        The matching item in the @a aExtraConfigValues[] array must contain a string of the following\\n        format: \"controller=<index>;channel=<c>\"\\n        In this string, <index> must be an integer specifying the hard disk controller to connect\\n        the image to. That number must be the index of an array item with one of the hard disk controller\\n        types (HardDiskControllerSCSI, HardDiskControllerSATA, HardDiskControllerIDE).\\n        In addition, <c> must specify the channel to use on that controller. For IDE controllers,\\n        this can be 0 or 1 for master or slave, respectively. For compatibility with VirtualBox versions\\n        before 3.2, the values 2 and 3 (for secondary master and secondary slave) are also supported, but\\n        no longer exported. For SATA and SCSI controllers, the channel can range from 0-29.\\n        \\n        \\n        \"CDROM\": a virtual CD-ROM drive. The matching item in @a aExtraConfigValue[] contains the same\\n        attachment information as with \"HardDiskImage\" items.\\n        \\n        \\n        \"CDROM\": a virtual floppy drive. The matching item in @a aExtraConfigValue[] contains the same\\n        attachment information as with \"HardDiskImage\" items.\\n        \\n        \\n        \"NetworkAdapter\": a network adapter. The array item in @a aVBoxValues[] will specify the hardware\\n        for the network adapter, whereas the array item in @a aExtraConfigValues[] will have a string\\n        of the \"type=<X>\" format, where <X> must be either \"NAT\" or \"Bridged\".\\n        \\n        \\n        \"USBController\": a USB controller. There can be at most one such item. If, and only if, such an\\n        item is present, USB support will be enabled for the new virtual machine.\\n        \\n        \\n        \"SoundCard\": a sound card. There can be at most one such item. If and only if such an item is\\n        present, sound support will be enabled for the new virtual machine. Note that the virtual\\n        machine in VirtualBox will always be presented with the standard VirtualBox soundcard, which\\n        may be different from the virtual soundcard expected by the appliance.\\n\\n        out types of type :class:`VirtualSystemDescriptionType`\\n\\n        out refs of type str\\n\\n        out ovf_values of type str\\n\\n        out v_box_values of type str\\n\\n        out extra_config_values of type str\\n\\n        \"\"\"\\n        (types, refs, ovf_values, v_box_values, extra_config_values) = self._call(\"getDescription\")\\n        types = [VirtualSystemDescriptionType(a) for a in types]\\n        return (types, refs, ovf_values, v_box_values, extra_config_values)',\n",
              " 'def get_description_by_type(self, type_p):\\n        \"\"\"This is the same as :py:func:`get_description`  except that you can specify which types\\n        should be returned.\\n\\n        in type_p of type :class:`VirtualSystemDescriptionType`\\n\\n        out types of type :class:`VirtualSystemDescriptionType`\\n\\n        out refs of type str\\n\\n        out ovf_values of type str\\n\\n        out v_box_values of type str\\n\\n        out extra_config_values of type str\\n\\n        \"\"\"\\n        if not isinstance(type_p, VirtualSystemDescriptionType):\\n            raise TypeError(\"type_p can only be an instance of type VirtualSystemDescriptionType\")\\n        (types, refs, ovf_values, v_box_values, extra_config_values) = self._call(\"getDescriptionByType\",\\n                     in_p=[type_p])\\n        types = [VirtualSystemDescriptionType(a) for a in types]\\n        return (types, refs, ovf_values, v_box_values, extra_config_values)',\n",
              " 'def remove_description_by_type(self, type_p):\\n        \"\"\"Delete all records which are equal to the passed type from the list\\n\\n        in type_p of type :class:`VirtualSystemDescriptionType`\\n\\n        \"\"\"\\n        if not isinstance(type_p, VirtualSystemDescriptionType):\\n            raise TypeError(\"type_p can only be an instance of type VirtualSystemDescriptionType\")\\n        self._call(\"removeDescriptionByType\",\\n                     in_p=[type_p])',\n",
              " 'def get_values_by_type(self, type_p, which):\\n        \"\"\"This is the same as :py:func:`get_description_by_type`  except that you can specify which\\n        value types should be returned. See :py:class:`VirtualSystemDescriptionValueType`  for possible\\n        values.\\n\\n        in type_p of type :class:`VirtualSystemDescriptionType`\\n\\n        in which of type :class:`VirtualSystemDescriptionValueType`\\n\\n        return values of type str\\n\\n        \"\"\"\\n        if not isinstance(type_p, VirtualSystemDescriptionType):\\n            raise TypeError(\"type_p can only be an instance of type VirtualSystemDescriptionType\")\\n        if not isinstance(which, VirtualSystemDescriptionValueType):\\n            raise TypeError(\"which can only be an instance of type VirtualSystemDescriptionValueType\")\\n        values = self._call(\"getValuesByType\",\\n                     in_p=[type_p, which])\\n        return values',\n",
              " 'def set_final_values(self, enabled, v_box_values, extra_config_values):\\n        \"\"\"This method allows the appliance\\'s user to change the configuration for the virtual\\n        system descriptions. For each array item returned from :py:func:`get_description` ,\\n        you must pass in one boolean value and one configuration value.\\n        \\n        Each item in the boolean array determines whether the particular configuration item\\n        should be enabled.\\n        You can only disable items of the types HardDiskControllerIDE, HardDiskControllerSATA,\\n        HardDiskControllerSCSI, HardDiskImage, CDROM, Floppy, NetworkAdapter, USBController\\n        and SoundCard.\\n        \\n        For the \"vbox\" and \"extra configuration\" values, if you pass in the same arrays\\n        as returned in the aVBoxValues and aExtraConfigValues arrays from :py:func:`get_description` ,\\n        the configuration remains unchanged. Please see the documentation for :py:func:`get_description` \\n        for valid configuration values for the individual array item types. If the\\n        corresponding item in the aEnabled array is @c false, the configuration value is ignored.\\n\\n        in enabled of type bool\\n\\n        in v_box_values of type str\\n\\n        in extra_config_values of type str\\n\\n        \"\"\"\\n        if not isinstance(enabled, list):\\n            raise TypeError(\"enabled can only be an instance of type list\")\\n        for a in enabled[:10]:\\n            if not isinstance(a, bool):\\n                raise TypeError(\\n                        \"array can only contain objects of type bool\")\\n        if not isinstance(v_box_values, list):\\n            raise TypeError(\"v_box_values can only be an instance of type list\")\\n        for a in v_box_values[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(extra_config_values, list):\\n            raise TypeError(\"extra_config_values can only be an instance of type list\")\\n        for a in extra_config_values[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"setFinalValues\",\\n                     in_p=[enabled, v_box_values, extra_config_values])',\n",
              " 'def add_description(self, type_p, v_box_value, extra_config_value):\\n        \"\"\"This method adds an additional description entry to the stack of already\\n        available descriptions for this virtual system. This is handy for writing\\n        values which aren\\'t directly supported by VirtualBox. One example would\\n        be the License type of :py:class:`VirtualSystemDescriptionType` .\\n\\n        in type_p of type :class:`VirtualSystemDescriptionType`\\n\\n        in v_box_value of type str\\n\\n        in extra_config_value of type str\\n\\n        \"\"\"\\n        if not isinstance(type_p, VirtualSystemDescriptionType):\\n            raise TypeError(\"type_p can only be an instance of type VirtualSystemDescriptionType\")\\n        if not isinstance(v_box_value, basestring):\\n            raise TypeError(\"v_box_value can only be an instance of type basestring\")\\n        if not isinstance(extra_config_value, basestring):\\n            raise TypeError(\"extra_config_value can only be an instance of type basestring\")\\n        self._call(\"addDescription\",\\n                     in_p=[type_p, v_box_value, extra_config_value])',\n",
              " 'def update_state(self, state):\\n        \"\"\"Updates the VM state.\\n        \\n        This operation will also update the settings file with the correct\\n        information about the saved state file and delete this file from disk\\n        when appropriate.\\n\\n        in state of type :class:`MachineState`\\n\\n        \"\"\"\\n        if not isinstance(state, MachineState):\\n            raise TypeError(\"state can only be an instance of type MachineState\")\\n        self._call(\"updateState\",\\n                     in_p=[state])',\n",
              " 'def begin_power_up(self, progress):\\n        \"\"\"Tells VBoxSVC that :py:func:`IConsole.power_up`  is under ways and\\n        gives it the progress object that should be part of any pending\\n        :py:func:`IMachine.launch_vm_process`  operations. The progress\\n        object may be called back to reflect an early cancelation, so some care\\n        have to be taken with respect to any cancelation callbacks. The console\\n        object will call :py:func:`IInternalMachineControl.end_power_up` \\n        to signal the completion of the progress object.\\n\\n        in progress of type :class:`IProgress`\\n\\n        \"\"\"\\n        if not isinstance(progress, IProgress):\\n            raise TypeError(\"progress can only be an instance of type IProgress\")\\n        self._call(\"beginPowerUp\",\\n                     in_p=[progress])',\n",
              " 'def end_power_up(self, result):\\n        \"\"\"Tells VBoxSVC that :py:func:`IConsole.power_up`  has completed.\\n        This method may query status information from the progress object it\\n        received in :py:func:`IInternalMachineControl.begin_power_up`  and copy\\n        it over to any in-progress :py:func:`IMachine.launch_vm_process` \\n        call in order to complete that progress object.\\n\\n        in result of type int\\n\\n        \"\"\"\\n        if not isinstance(result, baseinteger):\\n            raise TypeError(\"result can only be an instance of type baseinteger\")\\n        self._call(\"endPowerUp\",\\n                     in_p=[result])',\n",
              " 'def end_powering_down(self, result, err_msg):\\n        \"\"\"Called by the VM process to inform the server that powering\\n        down previously requested by #beginPoweringDown is either\\n        successfully finished or there was a failure.\\n\\n        in result of type int\\n            @c S_OK to indicate success.\\n\\n        in err_msg of type str\\n            @c human readable error message in case of failure.\\n\\n        raises :class:`VBoxErrorFileError`\\n            Settings file not accessible.\\n        \\n        raises :class:`VBoxErrorXmlError`\\n            Could not parse the settings file.\\n        \\n        \"\"\"\\n        if not isinstance(result, baseinteger):\\n            raise TypeError(\"result can only be an instance of type baseinteger\")\\n        if not isinstance(err_msg, basestring):\\n            raise TypeError(\"err_msg can only be an instance of type basestring\")\\n        self._call(\"endPoweringDown\",\\n                     in_p=[result, err_msg])',\n",
              " 'def run_usb_device_filters(self, device):\\n        \"\"\"Asks the server to run USB devices filters of the associated\\n        machine against the given USB device and tell if there is\\n        a match.\\n        \\n        Intended to be used only for remote USB devices. Local\\n        ones don\\'t require to call this method (this is done\\n        implicitly by the Host and USBProxyService).\\n\\n        in device of type :class:`IUSBDevice`\\n\\n        out matched of type bool\\n\\n        out masked_interfaces of type int\\n\\n        \"\"\"\\n        if not isinstance(device, IUSBDevice):\\n            raise TypeError(\"device can only be an instance of type IUSBDevice\")\\n        (matched, masked_interfaces) = self._call(\"runUSBDeviceFilters\",\\n                     in_p=[device])\\n        return (matched, masked_interfaces)',\n",
              " 'def capture_usb_device(self, id_p, capture_filename):\\n        \"\"\"Requests a capture of the given host USB device.\\n        When the request is completed, the VM process will\\n        get a :py:func:`IInternalSessionControl.on_usb_device_attach` \\n        notification.\\n\\n        in id_p of type str\\n\\n        in capture_filename of type str\\n\\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        if not isinstance(capture_filename, basestring):\\n            raise TypeError(\"capture_filename can only be an instance of type basestring\")\\n        self._call(\"captureUSBDevice\",\\n                     in_p=[id_p, capture_filename])',\n",
              " 'def detach_usb_device(self, id_p, done):\\n        \"\"\"Notification that a VM is going to detach (@a done = @c false) or has\\n        already detached (@a done = @c true) the given USB device.\\n        When the @a done = @c true request is completed, the VM process will\\n        get a :py:func:`IInternalSessionControl.on_usb_device_detach` \\n        notification.\\n        \\n        In the @a done = @c true case, the server must run its own filters\\n        and filters of all VMs but this one on the detached device\\n        as if it were just attached to the host computer.\\n\\n        in id_p of type str\\n\\n        in done of type bool\\n\\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        if not isinstance(done, bool):\\n            raise TypeError(\"done can only be an instance of type bool\")\\n        self._call(\"detachUSBDevice\",\\n                     in_p=[id_p, done])',\n",
              " 'def detach_all_usb_devices(self, done):\\n        \"\"\"Notification that a VM that is being powered down. The done\\n        parameter indicates whether which stage of the power down\\n        we\\'re at. When @a done = @c false the VM is announcing its\\n        intentions, while when @a done = @c true the VM is reporting\\n        what it has done.\\n        \\n        In the @a done = @c true case, the server must run its own filters\\n        and filters of all VMs but this one on all detach devices as\\n        if they were just attached to the host computer.\\n\\n        in done of type bool\\n\\n        \"\"\"\\n        if not isinstance(done, bool):\\n            raise TypeError(\"done can only be an instance of type bool\")\\n        self._call(\"detachAllUSBDevices\",\\n                     in_p=[done])',\n",
              " 'def on_session_end(self, session):\\n        \"\"\"Triggered by the given session object when the session is about\\n        to close normally.\\n\\n        in session of type :class:`ISession`\\n            Session that is being closed\\n\\n        return progress of type :class:`IProgress`\\n            Used to wait until the corresponding machine is actually\\n            dissociated from the given session on the server.\\n            Returned only when this session is a direct one.\\n\\n        \"\"\"\\n        if not isinstance(session, ISession):\\n            raise TypeError(\"session can only be an instance of type ISession\")\\n        progress = self._call(\"onSessionEnd\",\\n                     in_p=[session])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def pull_guest_properties(self):\\n        \"\"\"Get the list of the guest properties matching a set of patterns along\\n        with their values, timestamps and flags and give responsibility for\\n        managing properties to the console.\\n\\n        out names of type str\\n            The names of the properties returned.\\n\\n        out values of type str\\n            The values of the properties returned. The array entries match the\\n            corresponding entries in the @a name array.\\n\\n        out timestamps of type int\\n            The timestamps of the properties returned. The array entries match\\n            the corresponding entries in the @a name array.\\n\\n        out flags of type str\\n            The flags of the properties returned. The array entries match the\\n            corresponding entries in the @a name array.\\n\\n        \"\"\"\\n        (names, values, timestamps, flags) = self._call(\"pullGuestProperties\")\\n        return (names, values, timestamps, flags)',\n",
              " 'def push_guest_property(self, name, value, timestamp, flags):\\n        \"\"\"Update a single guest property in IMachine.\\n\\n        in name of type str\\n            The name of the property to be updated.\\n\\n        in value of type str\\n            The value of the property.\\n\\n        in timestamp of type int\\n            The timestamp of the property.\\n\\n        in flags of type str\\n            The flags of the property.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(value, basestring):\\n            raise TypeError(\"value can only be an instance of type basestring\")\\n        if not isinstance(timestamp, baseinteger):\\n            raise TypeError(\"timestamp can only be an instance of type baseinteger\")\\n        if not isinstance(flags, basestring):\\n            raise TypeError(\"flags can only be an instance of type basestring\")\\n        self._call(\"pushGuestProperty\",\\n                     in_p=[name, value, timestamp, flags])',\n",
              " 'def eject_medium(self, attachment):\\n        \"\"\"Tells VBoxSVC that the guest has ejected the medium associated with\\n        the medium attachment.\\n\\n        in attachment of type :class:`IMediumAttachment`\\n            The medium attachment where the eject happened.\\n\\n        return new_attachment of type :class:`IMediumAttachment`\\n            A new reference to the medium attachment, as the config change can\\n            result in the creation of a new instance.\\n\\n        \"\"\"\\n        if not isinstance(attachment, IMediumAttachment):\\n            raise TypeError(\"attachment can only be an instance of type IMediumAttachment\")\\n        new_attachment = self._call(\"ejectMedium\",\\n                     in_p=[attachment])\\n        new_attachment = IMediumAttachment(new_attachment)\\n        return new_attachment',\n",
              " 'def report_vm_statistics(self, valid_stats, cpu_user, cpu_kernel, cpu_idle, mem_total, mem_free, mem_balloon, mem_shared, mem_cache, paged_total, mem_alloc_total, mem_free_total, mem_balloon_total, mem_shared_total, vm_net_rx, vm_net_tx):\\n        \"\"\"Passes statistics collected by VM (including guest statistics) to VBoxSVC.\\n\\n        in valid_stats of type int\\n            Mask defining which parameters are valid. For example: 0x11 means\\n            that cpuIdle and XXX are valid. Other parameters should be ignored.\\n\\n        in cpu_user of type int\\n            Percentage of processor time spent in user mode as seen by the guest.\\n\\n        in cpu_kernel of type int\\n            Percentage of processor time spent in kernel mode as seen by the guest.\\n\\n        in cpu_idle of type int\\n            Percentage of processor time spent idling as seen by the guest.\\n\\n        in mem_total of type int\\n            Total amount of physical guest RAM.\\n\\n        in mem_free of type int\\n            Free amount of physical guest RAM.\\n\\n        in mem_balloon of type int\\n            Amount of ballooned physical guest RAM.\\n\\n        in mem_shared of type int\\n            Amount of shared physical guest RAM.\\n\\n        in mem_cache of type int\\n            Total amount of guest (disk) cache memory.\\n\\n        in paged_total of type int\\n            Total amount of space in the page file.\\n\\n        in mem_alloc_total of type int\\n            Total amount of memory allocated by the hypervisor.\\n\\n        in mem_free_total of type int\\n            Total amount of free memory available in the hypervisor.\\n\\n        in mem_balloon_total of type int\\n            Total amount of memory ballooned by the hypervisor.\\n\\n        in mem_shared_total of type int\\n            Total amount of shared memory in the hypervisor.\\n\\n        in vm_net_rx of type int\\n            Network receive rate for VM.\\n\\n        in vm_net_tx of type int\\n            Network transmit rate for VM.\\n\\n        \"\"\"\\n        if not isinstance(valid_stats, baseinteger):\\n            raise TypeError(\"valid_stats can only be an instance of type baseinteger\")\\n        if not isinstance(cpu_user, baseinteger):\\n            raise TypeError(\"cpu_user can only be an instance of type baseinteger\")\\n        if not isinstance(cpu_kernel, baseinteger):\\n            raise TypeError(\"cpu_kernel can only be an instance of type baseinteger\")\\n        if not isinstance(cpu_idle, baseinteger):\\n            raise TypeError(\"cpu_idle can only be an instance of type baseinteger\")\\n        if not isinstance(mem_total, baseinteger):\\n            raise TypeError(\"mem_total can only be an instance of type baseinteger\")\\n        if not isinstance(mem_free, baseinteger):\\n            raise TypeError(\"mem_free can only be an instance of type baseinteger\")\\n        if not isinstance(mem_balloon, baseinteger):\\n            raise TypeError(\"mem_balloon can only be an instance of type baseinteger\")\\n        if not isinstance(mem_shared, baseinteger):\\n            raise TypeError(\"mem_shared can only be an instance of type baseinteger\")\\n        if not isinstance(mem_cache, baseinteger):\\n            raise TypeError(\"mem_cache can only be an instance of type baseinteger\")\\n        if not isinstance(paged_total, baseinteger):\\n            raise TypeError(\"paged_total can only be an instance of type baseinteger\")\\n        if not isinstance(mem_alloc_total, baseinteger):\\n            raise TypeError(\"mem_alloc_total can only be an instance of type baseinteger\")\\n        if not isinstance(mem_free_total, baseinteger):\\n            raise TypeError(\"mem_free_total can only be an instance of type baseinteger\")\\n        if not isinstance(mem_balloon_total, baseinteger):\\n            raise TypeError(\"mem_balloon_total can only be an instance of type baseinteger\")\\n        if not isinstance(mem_shared_total, baseinteger):\\n            raise TypeError(\"mem_shared_total can only be an instance of type baseinteger\")\\n        if not isinstance(vm_net_rx, baseinteger):\\n            raise TypeError(\"vm_net_rx can only be an instance of type baseinteger\")\\n        if not isinstance(vm_net_tx, baseinteger):\\n            raise TypeError(\"vm_net_tx can only be an instance of type baseinteger\")\\n        self._call(\"reportVmStatistics\",\\n                     in_p=[valid_stats, cpu_user, cpu_kernel, cpu_idle, mem_total, mem_free, mem_balloon, mem_shared, mem_cache, paged_total, mem_alloc_total, mem_free_total, mem_balloon_total, mem_shared_total, vm_net_rx, vm_net_tx])',\n",
              " 'def authenticate_external(self, auth_params):\\n        \"\"\"Verify credentials using the external auth library.\\n\\n        in auth_params of type str\\n            The auth parameters, credentials, etc.\\n\\n        out result of type str\\n            The authentification result.\\n\\n        \"\"\"\\n        if not isinstance(auth_params, list):\\n            raise TypeError(\"auth_params can only be an instance of type list\")\\n        for a in auth_params[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        result = self._call(\"authenticateExternal\",\\n                     in_p=[auth_params])\\n        return result',\n",
              " 'def is_feature_enabled(self, feature):\\n        \"\"\"Returns whether a particular recording feature is enabled for this\\n        screen or not.\\n\\n        in feature of type :class:`RecordingFeature`\\n            Feature to check for.\\n\\n        return enabled of type bool\\n            @c true if the feature is enabled, @c false if not.\\n\\n        \"\"\"\\n        if not isinstance(feature, RecordingFeature):\\n            raise TypeError(\"feature can only be an instance of type RecordingFeature\")\\n        enabled = self._call(\"isFeatureEnabled\",\\n                     in_p=[feature])\\n        return enabled',\n",
              " 'def get_screen_settings(self, screen_id):\\n        \"\"\"Returns the recording settings for a particular screen.\\n\\n        in screen_id of type int\\n            Screen ID to retrieve recording screen settings for.\\n\\n        return record_screen_settings of type :class:`IRecordingScreenSettings`\\n            Recording screen settings for the requested screen.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        record_screen_settings = self._call(\"getScreenSettings\",\\n                     in_p=[screen_id])\\n        record_screen_settings = IRecordingScreenSettings(record_screen_settings)\\n        return record_screen_settings',\n",
              " 'def from_long(self, number):\\n        \"\"\"Make PCI address from long.\\n\\n        in number of type int\\n\\n        \"\"\"\\n        if not isinstance(number, baseinteger):\\n            raise TypeError(\"number can only be an instance of type baseinteger\")\\n        self._call(\"fromLong\",\\n                     in_p=[number])',\n",
              " 'def lock_machine(self, session, lock_type):\\n        \"\"\"Locks the machine for the given session to enable the caller\\n        to make changes to the machine or start the VM or control\\n        VM execution.\\n        \\n        There are two ways to lock a machine for such uses:\\n        \\n        \\n        If you want to make changes to the machine settings,\\n        you must obtain an exclusive write lock on the machine\\n        by setting @a lockType to @c Write.\\n        \\n        This will only succeed if no other process has locked\\n        the machine to prevent conflicting changes. Only after\\n        an exclusive write lock has been obtained using this method, one\\n        can change all VM settings or execute the VM in the process\\n        space of the session object. (Note that the latter is only of\\n        interest if you actually want to write a new front-end for\\n        virtual machines; but this API gets called internally by\\n        the existing front-ends such as VBoxHeadless and the VirtualBox\\n        GUI to acquire a write lock on the machine that they are running.)\\n        \\n        On success, write-locking the machine for a session creates\\n        a second copy of the IMachine object. It is this second object\\n        upon which changes can be made; in VirtualBox terminology, the\\n        second copy is \"mutable\". It is only this second, mutable machine\\n        object upon which you can call methods that change the\\n        machine state. After having called this method, you can\\n        obtain this second, mutable machine object using the\\n        :py:func:`ISession.machine`  attribute.\\n        \\n        If you only want to check the machine state or control\\n        machine execution without actually changing machine\\n        settings (e.g. to get access to VM statistics or take\\n        a snapshot or save the machine state), then set the\\n        @a lockType argument to @c Shared.\\n        \\n        If no other session has obtained a lock, you will obtain an\\n        exclusive write lock as described above. However, if another\\n        session has already obtained such a lock, then a link to that\\n        existing session will be established which allows you\\n        to control that existing session.\\n        \\n        To find out which type of lock was obtained, you can\\n        inspect :py:func:`ISession.type_p` , which will have been\\n        set to either @c WriteLock or @c Shared.\\n        \\n        \\n        \\n        In either case, you can get access to the :py:class:`IConsole` \\n        object which controls VM execution.\\n        \\n        Also in all of the above cases, one must always call\\n        :py:func:`ISession.unlock_machine`  to release the lock on the machine, or\\n        the machine\\'s state will eventually be set to \"Aborted\".\\n        \\n        To change settings on a machine, the following sequence is typically\\n        performed:\\n        \\n        \\n        Call this method to obtain an exclusive write lock for the current session.\\n        \\n        Obtain a mutable IMachine object from :py:func:`ISession.machine` .\\n        \\n        Change the settings of the machine by invoking IMachine methods.\\n        \\n        Call :py:func:`IMachine.save_settings` .\\n        \\n        Release the write lock by calling :py:func:`ISession.unlock_machine` .\\n\\n        in session of type :class:`ISession`\\n            Session object for which the machine will be locked.\\n\\n        in lock_type of type :class:`LockType`\\n            If set to @c Write, then attempt to acquire an exclusive write lock or fail.\\n            If set to @c Shared, then either acquire an exclusive write lock or establish\\n            a link to an existing session.\\n\\n        raises :class:`OleErrorUnexpected`\\n            Virtual machine not registered.\\n        \\n        raises :class:`OleErrorAccessdenied`\\n            Process not started by\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session already open or being opened.\\n        \\n        raises :class:`VBoxErrorVmError`\\n            Failed to assign machine to session.\\n        \\n        \"\"\"\\n        if not isinstance(session, ISession):\\n            raise TypeError(\"session can only be an instance of type ISession\")\\n        if not isinstance(lock_type, LockType):\\n            raise TypeError(\"lock_type can only be an instance of type LockType\")\\n        self._call(\"lockMachine\",\\n                     in_p=[session, lock_type])',\n",
              " 'def launch_vm_process(self, session, name, environment):\\n        \"\"\"Spawns a new process that will execute the virtual machine and obtains a shared\\n        lock on the machine for the calling session.\\n        \\n        If launching the VM succeeds, the new VM process will create its own session\\n        and write-lock the machine for it, preventing conflicting changes from other\\n        processes. If the machine is already locked (because it is already running or\\n        because another session has a write lock), launching the VM process will therefore\\n        fail. Reversely, future attempts to obtain a write lock will also fail while the\\n        machine is running.\\n        \\n        The caller\\'s session object remains separate from the session opened by the new\\n        VM process. It receives its own :py:class:`IConsole`  object which can be used\\n        to control machine execution, but it cannot be used to change all VM settings\\n        which would be available after a :py:func:`lock_machine`  call.\\n        \\n        The caller must eventually release the session\\'s shared lock by calling\\n        :py:func:`ISession.unlock_machine`  on the local session object once this call\\n        has returned. However, the session\\'s state (see :py:func:`ISession.state` )\\n        will not return to \"Unlocked\" until the remote session has also unlocked\\n        the machine (i.e. the machine has stopped running).\\n        \\n        Launching a VM process can take some time (a new VM is started in a new process,\\n        for which memory and other resources need to be set up). Because of this,\\n        an :py:class:`IProgress`  object is returned to allow the caller to wait\\n        for this asynchronous operation to be completed. Until then, the caller\\'s\\n        session object remains in the \"Unlocked\" state, and its :py:func:`ISession.machine` \\n        and :py:func:`ISession.console`  attributes cannot be accessed.\\n        It is recommended to use :py:func:`IProgress.wait_for_completion`  or\\n        similar calls to wait for completion. Completion is signalled when the VM\\n        is powered on. If launching the VM fails, error messages can be queried\\n        via the progress object, if available.\\n        \\n        The progress object will have at least 2 sub-operations. The first\\n        operation covers the period up to the new VM process calls powerUp.\\n        The subsequent operations mirror the :py:func:`IConsole.power_up` \\n        progress object. Because :py:func:`IConsole.power_up`  may require\\n        some extra sub-operations, the :py:func:`IProgress.operation_count` \\n        may change at the completion of operation.\\n        \\n        For details on the teleportation progress operation, see\\n        :py:func:`IConsole.power_up` .\\n        \\n        <!-- TODO/r=bird: What about making @a environment into a smart array?  Guess\\n        this predates our safe array support by a year or so... Dmitry wrote the text here, right?\\n        Just rename it to @a environmentChanges and shorten the documentation to say the string\\n        are applied onto the server environment putenv style, i.e. \"VAR=VALUE\" for setting/replacing\\n        and \"VAR\" for unsetting. -->\\n        The @a environment argument is a string containing definitions of\\n        environment variables in the following format:\\n        \\n        ::\\n\\n             NAME[=VALUE]\\\\n\\n             NAME[=VALUE]\\\\n\\n             ...\\n\\n\\n        where \\\\\\\\n is the new line character. These environment\\n        variables will be appended to the environment of the VirtualBox server\\n        process. If an environment variable exists both in the server process\\n        and in this list, the value from this list takes precedence over the\\n        server\\'s variable. If the value of the environment variable is\\n        omitted, this variable will be removed from the resulting environment.\\n        If the environment string is @c null or empty, the server environment\\n        is inherited by the started process as is.\\n\\n        in session of type :class:`ISession`\\n            Client session object to which the VM process will be connected (this\\n            must be in \"Unlocked\" state).\\n\\n        in name of type str\\n            Front-end to use for the new VM process. The following are currently supported:\\n            \\n            \"gui\": VirtualBox Qt GUI front-end\\n            \"headless\": VBoxHeadless (VRDE Server) front-end\\n            \"sdl\": VirtualBox SDL front-end\\n            \"emergencystop\": reserved value, used for aborting\\n            the currently running VM or session owner. In this case the\\n            @a session parameter may be @c null (if it is non-null it isn\\'t\\n            used in any way), and the @a progress return value will be always\\n            @c null. The operation completes immediately.\\n            \"\": use the per-VM default frontend if set, otherwise\\n            the global default defined in the system properties. If neither\\n            are set, the API will launch a \"gui\" session, which may\\n            fail if there is no windowing environment available. See\\n            :py:func:`IMachine.default_frontend`  and\\n            :py:func:`ISystemProperties.default_frontend` .\\n\\n        in environment of type str\\n            Environment to pass to the VM process.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorUnexpected`\\n            Virtual machine not registered.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid session type @a type.\\n        \\n        raises :class:`VBoxErrorObjectNotFound`\\n            No machine matching @a machineId found.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session already open or being opened.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Launching process for machine failed.\\n        \\n        raises :class:`VBoxErrorVmError`\\n            Failed to assign machine to session.\\n        \\n        \"\"\"\\n        if not isinstance(session, ISession):\\n            raise TypeError(\"session can only be an instance of type ISession\")\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(environment, basestring):\\n            raise TypeError(\"environment can only be an instance of type basestring\")\\n        progress = self._call(\"launchVMProcess\",\\n                     in_p=[session, name, environment])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def set_boot_order(self, position, device):\\n        \"\"\"Puts the given device to the specified position in\\n        the boot order.\\n        \\n        To indicate that no device is associated with the given position,\\n        :py:attr:`DeviceType.null`  should be used.\\n        \\n        @todo setHardDiskBootOrder(), setNetworkBootOrder()\\n\\n        in position of type int\\n            Position in the boot order (@c 1 to the total number of\\n            devices the machine can boot from, as returned by\\n            :py:func:`ISystemProperties.max_boot_position` ).\\n\\n        in device of type :class:`DeviceType`\\n            The type of the device used to boot at the given position.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Boot @a position out of range.\\n        \\n        raises :class:`OleErrorNotimpl`\\n            Booting from USB @a device currently not supported.\\n        \\n        \"\"\"\\n        if not isinstance(position, baseinteger):\\n            raise TypeError(\"position can only be an instance of type baseinteger\")\\n        if not isinstance(device, DeviceType):\\n            raise TypeError(\"device can only be an instance of type DeviceType\")\\n        self._call(\"setBootOrder\",\\n                     in_p=[position, device])',\n",
              " 'def attach_device(self, name, controller_port, device, type_p, medium):\\n        \"\"\"Attaches a device and optionally mounts a medium to the given storage\\n        controller (:py:class:`IStorageController` , identified by @a name),\\n        at the indicated port and device.\\n        \\n        This method is intended for managing storage devices in general while a\\n        machine is powered off. It can be used to attach and detach fixed\\n        and removable media. The following kind of media can be attached\\n        to a machine:\\n        \\n        \\n        For fixed and removable media, you can pass in a medium that was\\n        previously opened using :py:func:`IVirtualBox.open_medium` .\\n        \\n        \\n        Only for storage devices supporting removable media (such as\\n        DVDs and floppies), you can also specify a null pointer to\\n        indicate an empty drive or one of the medium objects listed\\n        in the :py:func:`IHost.dvd_drives`  and :py:func:`IHost.floppy_drives` \\n        arrays to indicate a host drive.\\n        For removable devices, you can also use :py:func:`IMachine.mount_medium` \\n        to change the media while the machine is running.\\n        \\n        \\n        \\n        In a VM\\'s default configuration of virtual machines, the secondary\\n        master of the IDE controller is used for a CD/DVD drive.\\n        \\n        After calling this returns successfully, a new instance of\\n        :py:class:`IMediumAttachment`  will appear in the machine\\'s list of medium\\n        attachments (see :py:func:`IMachine.medium_attachments` ).\\n        \\n        See :py:class:`IMedium`  and :py:class:`IMediumAttachment`  for more\\n        information about attaching media.\\n        \\n        The specified device slot must not have a device attached to it,\\n        or this method will fail.\\n        \\n        \\n        You cannot attach a device to a newly created machine until\\n        this machine\\'s settings are saved to disk using\\n        :py:func:`save_settings` .\\n        \\n        \\n        If the medium is being attached indirectly, a new differencing medium\\n        will implicitly be created for it and attached instead. If the\\n        changes made to the machine settings (including this indirect\\n        attachment) are later cancelled using :py:func:`discard_settings` ,\\n        this implicitly created differencing medium will implicitly\\n        be deleted.\\n\\n        in name of type str\\n            Name of the storage controller to attach the device to.\\n\\n        in controller_port of type int\\n            Port to attach the device to. For an IDE controller, 0 specifies\\n            the primary controller and 1 specifies the secondary controller.\\n            For a SCSI controller, this must range from 0 to 15; for a SATA controller,\\n            from 0 to 29; for an SAS controller, from 0 to 7.\\n\\n        in device of type int\\n            Device slot in the given port to attach the device to. This is only\\n            relevant for IDE controllers, for which 0 specifies the master device and\\n            1 specifies the slave device. For all other controller types, this must\\n            be 0.\\n\\n        in type_p of type :class:`DeviceType`\\n            Device type of the attached device. For media opened by\\n            :py:func:`IVirtualBox.open_medium` , this must match the device type\\n            specified there.\\n\\n        in medium of type :class:`IMedium`\\n            Medium to mount or @c null for an empty drive.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range, or\\nfile or UUID not found.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Machine must be registered before media can be attached.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        raises :class:`VBoxErrorObjectInUse`\\n            A medium is already attached to this or another virtual machine.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(type_p, DeviceType):\\n            raise TypeError(\"type_p can only be an instance of type DeviceType\")\\n        if not isinstance(medium, IMedium):\\n            raise TypeError(\"medium can only be an instance of type IMedium\")\\n        self._call(\"attachDevice\",\\n                     in_p=[name, controller_port, device, type_p, medium])',\n",
              " 'def attach_device_without_medium(self, name, controller_port, device, type_p):\\n        \"\"\"Attaches a device and optionally mounts a medium to the given storage\\n        controller (:py:class:`IStorageController` , identified by @a name),\\n        at the indicated port and device.\\n        \\n        This method is intended for managing storage devices in general while a\\n        machine is powered off. It can be used to attach and detach fixed\\n        and removable media. The following kind of media can be attached\\n        to a machine:\\n        \\n        \\n        For fixed and removable media, you can pass in a medium that was\\n        previously opened using :py:func:`IVirtualBox.open_medium` .\\n        \\n        \\n        Only for storage devices supporting removable media (such as\\n        DVDs and floppies) with an empty drive or one of the medium objects listed\\n        in the :py:func:`IHost.dvd_drives`  and :py:func:`IHost.floppy_drives` \\n        arrays to indicate a host drive.\\n        For removable devices, you can also use :py:func:`IMachine.mount_medium` \\n        to change the media while the machine is running.\\n        \\n        \\n        \\n        In a VM\\'s default configuration of virtual machines, the secondary\\n        master of the IDE controller is used for a CD/DVD drive.\\n        :py:class:`IMediumAttachment`  will appear in the machine\\'s list of medium\\n        attachments (see :py:func:`IMachine.medium_attachments` ).\\n        \\n        See :py:class:`IMedium`  and :py:class:`IMediumAttachment`  for more\\n        information about attaching media.\\n        \\n        The specified device slot must not have a device attached to it,\\n        or this method will fail.\\n        \\n        You cannot attach a device to a newly created machine until\\n        this machine\\'s settings are saved to disk using\\n        :py:func:`save_settings` .\\n        \\n        \\n        If the medium is being attached indirectly, a new differencing medium\\n        will implicitly be created for it and attached instead. If the\\n        changes made to the machine settings (including this indirect\\n        attachment) are later cancelled using :py:func:`discard_settings` ,\\n        this implicitly created differencing medium will implicitly\\n        be deleted.\\n\\n        in name of type str\\n            Name of the storage controller to attach the device to.\\n\\n        in controller_port of type int\\n            Port to attach the device to. For an IDE controller, 0 specifies\\n            the primary controller and 1 specifies the secondary controller.\\n            For a SCSI controller, this must range from 0 to 15; for a SATA controller,\\n            from 0 to 29; for an SAS controller, from 0 to 7.\\n\\n        in device of type int\\n            Device slot in the given port to attach the device to. This is only\\n            relevant for IDE controllers, for which 0 specifies the master device and\\n            1 specifies the slave device. For all other controller types, this must\\n            be 0.\\n\\n        in type_p of type :class:`DeviceType`\\n            Device type of the attached device. For media opened by\\n            :py:func:`IVirtualBox.open_medium` , this must match the device type\\n            specified there.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range, or\\nfile or UUID not found.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Machine must be registered before media can be attached.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        raises :class:`VBoxErrorObjectInUse`\\n            A medium is already attached to this or another virtual machine.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(type_p, DeviceType):\\n            raise TypeError(\"type_p can only be an instance of type DeviceType\")\\n        self._call(\"attachDeviceWithoutMedium\",\\n                     in_p=[name, controller_port, device, type_p])',\n",
              " 'def passthrough_device(self, name, controller_port, device, passthrough):\\n        \"\"\"Sets the passthrough mode of an existing DVD device. Changing the\\n        setting while the VM is running is forbidden. The setting is only used\\n        if at VM start the device is configured as a host DVD drive, in all\\n        other cases it is ignored. The device must already exist; see\\n        :py:func:`IMachine.attach_device`  for how to attach a new device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in passthrough of type bool\\n            New value for the passthrough setting.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(passthrough, bool):\\n            raise TypeError(\"passthrough can only be an instance of type bool\")\\n        self._call(\"passthroughDevice\",\\n                     in_p=[name, controller_port, device, passthrough])',\n",
              " 'def temporary_eject_device(self, name, controller_port, device, temporary_eject):\\n        \"\"\"Sets the behavior for guest-triggered medium eject. In some situations\\n        it is desirable that such ejects update the VM configuration, and in\\n        others the eject should keep the VM configuration. The device must\\n        already exist; see :py:func:`IMachine.attach_device`  for how to\\n        attach a new device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in temporary_eject of type bool\\n            New value for the eject behavior.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(temporary_eject, bool):\\n            raise TypeError(\"temporary_eject can only be an instance of type bool\")\\n        self._call(\"temporaryEjectDevice\",\\n                     in_p=[name, controller_port, device, temporary_eject])',\n",
              " 'def non_rotational_device(self, name, controller_port, device, non_rotational):\\n        \"\"\"Sets a flag in the device information which indicates that the medium\\n        is not based on rotational technology, i.e. that the access times are\\n        more or less independent of the position on the medium. This may or may\\n        not be supported by a particular drive, and is silently ignored in the\\n        latter case. At the moment only hard disks (which is a misnomer in this\\n        context) accept this setting. Changing the setting while the VM is\\n        running is forbidden. The device must already exist; see\\n        :py:func:`IMachine.attach_device`  for how to attach a new device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in non_rotational of type bool\\n            New value for the non-rotational device flag.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(non_rotational, bool):\\n            raise TypeError(\"non_rotational can only be an instance of type bool\")\\n        self._call(\"nonRotationalDevice\",\\n                     in_p=[name, controller_port, device, non_rotational])',\n",
              " 'def set_auto_discard_for_device(self, name, controller_port, device, discard):\\n        \"\"\"Sets a flag in the device information which indicates that the medium\\n        supports discarding unused blocks (called trimming for SATA or unmap\\n        for SCSI devices) .This may or may not be supported by a particular drive,\\n        and is silently ignored in the latter case. At the moment only hard disks\\n        (which is a misnomer in this context) accept this setting. Changing the\\n        setting while the VM is running is forbidden. The device must already\\n        exist; see :py:func:`IMachine.attach_device`  for how to attach a new\\n        device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in discard of type bool\\n            New value for the discard device flag.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, SCSI port out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(discard, bool):\\n            raise TypeError(\"discard can only be an instance of type bool\")\\n        self._call(\"setAutoDiscardForDevice\",\\n                     in_p=[name, controller_port, device, discard])',\n",
              " 'def set_hot_pluggable_for_device(self, name, controller_port, device, hot_pluggable):\\n        \"\"\"Sets a flag in the device information which indicates that the attached\\n        device is hot pluggable or not. This may or may not be supported by a\\n        particular controller and/or drive, and is silently ignored in the\\n        latter case. Changing the setting while the VM is running is forbidden.\\n        The device must already exist; see :py:func:`IMachine.attach_device` \\n        for how to attach a new device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in hot_pluggable of type bool\\n            New value for the hot-pluggable device flag.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Controller doesn\\'t support hot plugging.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(hot_pluggable, bool):\\n            raise TypeError(\"hot_pluggable can only be an instance of type bool\")\\n        self._call(\"setHotPluggableForDevice\",\\n                     in_p=[name, controller_port, device, hot_pluggable])',\n",
              " 'def set_bandwidth_group_for_device(self, name, controller_port, device, bandwidth_group):\\n        \"\"\"Sets the bandwidth group of an existing storage device.\\n        The device must already exist; see :py:func:`IMachine.attach_device` \\n        for how to attach a new device.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        in bandwidth_group of type :class:`IBandwidthGroup`\\n            New value for the bandwidth group or @c null for no group.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(bandwidth_group, IBandwidthGroup):\\n            raise TypeError(\"bandwidth_group can only be an instance of type IBandwidthGroup\")\\n        self._call(\"setBandwidthGroupForDevice\",\\n                     in_p=[name, controller_port, device, bandwidth_group])',\n",
              " 'def set_no_bandwidth_group_for_device(self, name, controller_port, device):\\n        \"\"\"Sets no bandwidth group for an existing storage device.\\n        The device must already exist; see :py:func:`IMachine.attach_device` \\n        for how to attach a new device.\\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n\\n        in name of type str\\n            Name of the storage controller.\\n\\n        in controller_port of type int\\n            Storage controller port.\\n\\n        in device of type int\\n            Device slot in the given port.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to modify an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        self._call(\"setNoBandwidthGroupForDevice\",\\n                     in_p=[name, controller_port, device])',\n",
              " 'def unmount_medium(self, name, controller_port, device, force):\\n        \"\"\"Unmounts any currently mounted medium (:py:class:`IMedium` ,\\n        identified by the given UUID @a id) to the given storage controller\\n        (:py:class:`IStorageController` , identified by @a name),\\n        at the indicated port and device. The device must already exist;\\n        \\n        This method is intended only for managing removable media, where the\\n        device is fixed but media is changeable at runtime (such as DVDs\\n        and floppies). It cannot be used for fixed media such as hard disks.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot\\n        and have have the same meaning as with\\n        :py:func:`IMachine.attach_device` .\\n        \\n        The specified device slot must have a medium mounted, which will be\\n        unmounted. If there is no mounted medium it will do nothing.\\n        See :py:class:`IMedium`  for more detailed information about\\n        attaching/unmounting media.\\n\\n        in name of type str\\n            Name of the storage controller to unmount the medium from.\\n\\n        in controller_port of type int\\n            Port to unmount the medium from.\\n\\n        in device of type int\\n            Device slot in the given port to unmount the medium from.\\n\\n        in force of type bool\\n            Allows to force unmount of a medium which is locked by\\n            the device slot in the given port medium is attached to.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to unmount medium that is not removable - not DVD or floppy.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        raises :class:`VBoxErrorObjectInUse`\\n            Medium already attached to this or another virtual machine.\\n        \\n        raises :class:`VBoxErrorObjectNotFound`\\n            Medium not attached to specified port, device, controller.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(force, bool):\\n            raise TypeError(\"force can only be an instance of type bool\")\\n        self._call(\"unmountMedium\",\\n                     in_p=[name, controller_port, device, force])',\n",
              " 'def mount_medium(self, name, controller_port, device, medium, force):\\n        \"\"\"Mounts a medium (:py:class:`IMedium` , identified\\n        by the given UUID @a id) to the given storage controller\\n        (:py:class:`IStorageController` , identified by @a name),\\n        at the indicated port and device. The device must already exist;\\n        see :py:func:`IMachine.attach_device`  for how to attach a new device.\\n        \\n        This method is intended only for managing removable media, where the\\n        device is fixed but media is changeable at runtime (such as DVDs\\n        and floppies). It cannot be used for fixed media such as hard disks.\\n        \\n        The @a controllerPort and @a device parameters specify the device slot and\\n        have have the same meaning as with :py:func:`IMachine.attach_device` .\\n        \\n        The specified device slot can have a medium mounted, which will be\\n        unmounted first. Specifying a zero UUID (or an empty string) for\\n        @a medium does just an unmount.\\n        \\n        See :py:class:`IMedium`  for more detailed information about\\n        attaching media.\\n\\n        in name of type str\\n            Name of the storage controller to attach the medium to.\\n\\n        in controller_port of type int\\n            Port to attach the medium to.\\n\\n        in device of type int\\n            Device slot in the given port to attach the medium to.\\n\\n        in medium of type :class:`IMedium`\\n            Medium to mount or @c null for an empty drive.\\n\\n        in force of type bool\\n            Allows to force unmount/mount of a medium which is locked by\\n            the device slot in the given port to attach the medium to.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            SATA device, SATA port, IDE port or IDE slot out of range.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Attempt to attach medium to an unregistered virtual machine.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Invalid machine state.\\n        \\n        raises :class:`VBoxErrorObjectInUse`\\n            Medium already attached to this or another virtual machine.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        if not isinstance(medium, IMedium):\\n            raise TypeError(\"medium can only be an instance of type IMedium\")\\n        if not isinstance(force, bool):\\n            raise TypeError(\"force can only be an instance of type bool\")\\n        self._call(\"mountMedium\",\\n                     in_p=[name, controller_port, device, medium, force])',\n",
              " 'def get_medium(self, name, controller_port, device):\\n        \"\"\"Returns the virtual medium attached to a device slot of the specified\\n        bus.\\n        \\n        Note that if the medium was indirectly attached by\\n        :py:func:`mount_medium`  to the given device slot then this\\n        method will return not the same object as passed to the\\n        :py:func:`mount_medium`  call. See :py:class:`IMedium`  for\\n        more detailed information about mounting a medium.\\n\\n        in name of type str\\n            Name of the storage controller the medium is attached to.\\n\\n        in controller_port of type int\\n            Port to query.\\n\\n        in device of type int\\n            Device slot in the given port to query.\\n\\n        return medium of type :class:`IMedium`\\n            Attached medium object.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            No medium attached to given slot/bus.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        medium = self._call(\"getMedium\",\\n                     in_p=[name, controller_port, device])\\n        medium = IMedium(medium)\\n        return medium',\n",
              " 'def get_medium_attachments_of_controller(self, name):\\n        \"\"\"Returns an array of medium attachments which are attached to the\\n        the controller with the given name.\\n\\n        in name of type str\\n\\n        return medium_attachments of type :class:`IMediumAttachment`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A storage controller with given name doesn\\'t exist.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        medium_attachments = self._call(\"getMediumAttachmentsOfController\",\\n                     in_p=[name])\\n        medium_attachments = [IMediumAttachment(a) for a in medium_attachments]\\n        return medium_attachments',\n",
              " 'def get_medium_attachment(self, name, controller_port, device):\\n        \"\"\"Returns a medium attachment which corresponds to the controller with\\n        the given name, on the given port and device slot.\\n\\n        in name of type str\\n\\n        in controller_port of type int\\n\\n        in device of type int\\n\\n        return attachment of type :class:`IMediumAttachment`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            No attachment exists for the given controller/port/device combination.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(controller_port, baseinteger):\\n            raise TypeError(\"controller_port can only be an instance of type baseinteger\")\\n        if not isinstance(device, baseinteger):\\n            raise TypeError(\"device can only be an instance of type baseinteger\")\\n        attachment = self._call(\"getMediumAttachment\",\\n                     in_p=[name, controller_port, device])\\n        attachment = IMediumAttachment(attachment)\\n        return attachment',\n",
              " 'def attach_host_pci_device(self, host_address, desired_guest_address, try_to_unbind):\\n        \"\"\"Attaches host PCI device with the given (host) PCI address to the\\n        PCI bus of the virtual machine. Please note, that this operation\\n        is two phase, as real attachment will happen when VM will start,\\n        and most information will be delivered as IHostPCIDevicePlugEvent\\n        on IVirtualBox event source.\\n        \\n        :py:class:`IHostPCIDevicePlugEvent` \\n\\n        in host_address of type int\\n            Address of the host PCI device.\\n\\n        in desired_guest_address of type int\\n            Desired position of this device on guest PCI bus.\\n\\n        in try_to_unbind of type bool\\n            If VMM shall try to unbind existing drivers from the\\n            device before attaching it to the guest.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine state is not stopped (PCI hotplug not yet implemented).\\n        \\n        raises :class:`VBoxErrorPdmError`\\n            Virtual machine does not have a PCI controller allowing attachment of physical devices.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Hardware or host OS doesn\\'t allow PCI device passthrough.\\n        \\n        \"\"\"\\n        if not isinstance(host_address, baseinteger):\\n            raise TypeError(\"host_address can only be an instance of type baseinteger\")\\n        if not isinstance(desired_guest_address, baseinteger):\\n            raise TypeError(\"desired_guest_address can only be an instance of type baseinteger\")\\n        if not isinstance(try_to_unbind, bool):\\n            raise TypeError(\"try_to_unbind can only be an instance of type bool\")\\n        self._call(\"attachHostPCIDevice\",\\n                     in_p=[host_address, desired_guest_address, try_to_unbind])',\n",
              " 'def detach_host_pci_device(self, host_address):\\n        \"\"\"Detach host PCI device from the virtual machine.\\n        Also HostPCIDevicePlugEvent on IVirtualBox event source\\n        will be delivered. As currently we don\\'t support hot device\\n        unplug, IHostPCIDevicePlugEvent event is delivered immediately.\\n        \\n        :py:class:`IHostPCIDevicePlugEvent` \\n\\n        in host_address of type int\\n            Address of the host PCI device.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine state is not stopped (PCI hotplug not yet implemented).\\n        \\n        raises :class:`VBoxErrorObjectNotFound`\\n            This host device is not attached to this machine.\\n        \\n        raises :class:`VBoxErrorPdmError`\\n            Virtual machine does not have a PCI controller allowing attachment of physical devices.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Hardware or host OS doesn\\'t allow PCI device passthrough.\\n        \\n        \"\"\"\\n        if not isinstance(host_address, baseinteger):\\n            raise TypeError(\"host_address can only be an instance of type baseinteger\")\\n        self._call(\"detachHostPCIDevice\",\\n                     in_p=[host_address])',\n",
              " 'def get_network_adapter(self, slot):\\n        \"\"\"Returns the network adapter associated with the given slot.\\n        Slots are numbered sequentially, starting with zero. The total\\n        number of adapters per machine is defined by the\\n        :py:func:`ISystemProperties.get_max_network_adapters`  property,\\n        so the maximum slot number is one less than that property\\'s value.\\n\\n        in slot of type int\\n\\n        return adapter of type :class:`INetworkAdapter`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a slot number.\\n        \\n        \"\"\"\\n        if not isinstance(slot, baseinteger):\\n            raise TypeError(\"slot can only be an instance of type baseinteger\")\\n        adapter = self._call(\"getNetworkAdapter\",\\n                     in_p=[slot])\\n        adapter = INetworkAdapter(adapter)\\n        return adapter',\n",
              " 'def add_storage_controller(self, name, connection_type):\\n        \"\"\"Adds a new storage controller (SCSI, SAS or SATA controller) to the\\n        machine and returns it as an instance of\\n        :py:class:`IStorageController` .\\n        \\n        @a name identifies the controller for subsequent calls such as\\n        :py:func:`get_storage_controller_by_name` ,\\n        :py:func:`get_storage_controller_by_instance` ,\\n        :py:func:`remove_storage_controller` ,\\n        :py:func:`attach_device`  or :py:func:`mount_medium` .\\n        \\n        After the controller has been added, you can set its exact\\n        type by setting the :py:func:`IStorageController.controller_type` .\\n\\n        in name of type str\\n\\n        in connection_type of type :class:`StorageBus`\\n\\n        return controller of type :class:`IStorageController`\\n\\n        raises :class:`VBoxErrorObjectInUse`\\n            A storage controller with given name exists already.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a controllerType.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(connection_type, StorageBus):\\n            raise TypeError(\"connection_type can only be an instance of type StorageBus\")\\n        controller = self._call(\"addStorageController\",\\n                     in_p=[name, connection_type])\\n        controller = IStorageController(controller)\\n        return controller',\n",
              " 'def get_storage_controller_by_name(self, name):\\n        \"\"\"Returns a storage controller with the given name.\\n\\n        in name of type str\\n\\n        return storage_controller of type :class:`IStorageController`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A storage controller with given name doesn\\'t exist.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        storage_controller = self._call(\"getStorageControllerByName\",\\n                     in_p=[name])\\n        storage_controller = IStorageController(storage_controller)\\n        return storage_controller',\n",
              " 'def get_storage_controller_by_instance(self, connection_type, instance):\\n        \"\"\"Returns a storage controller of a specific storage bus\\n        with the given instance number.\\n\\n        in connection_type of type :class:`StorageBus`\\n\\n        in instance of type int\\n\\n        return storage_controller of type :class:`IStorageController`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A storage controller with given instance number doesn\\'t exist.\\n        \\n        \"\"\"\\n        if not isinstance(connection_type, StorageBus):\\n            raise TypeError(\"connection_type can only be an instance of type StorageBus\")\\n        if not isinstance(instance, baseinteger):\\n            raise TypeError(\"instance can only be an instance of type baseinteger\")\\n        storage_controller = self._call(\"getStorageControllerByInstance\",\\n                     in_p=[connection_type, instance])\\n        storage_controller = IStorageController(storage_controller)\\n        return storage_controller',\n",
              " 'def remove_storage_controller(self, name):\\n        \"\"\"Removes a storage controller from the machine with all devices attached to it.\\n\\n        in name of type str\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A storage controller with given name doesn\\'t exist.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Medium format does not support storage deletion (only for implicitly\\ncreated differencing media, should not happen).\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"removeStorageController\",\\n                     in_p=[name])',\n",
              " 'def set_storage_controller_bootable(self, name, bootable):\\n        \"\"\"Sets the bootable flag of the storage controller with the given name.\\n\\n        in name of type str\\n\\n        in bootable of type bool\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A storage controller with given name doesn\\'t exist.\\n        \\n        raises :class:`VBoxErrorObjectInUse`\\n            Another storage controller is marked as bootable already.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(bootable, bool):\\n            raise TypeError(\"bootable can only be an instance of type bool\")\\n        self._call(\"setStorageControllerBootable\",\\n                     in_p=[name, bootable])',\n",
              " 'def add_usb_controller(self, name, type_p):\\n        \"\"\"Adds a new USB controller to the machine and returns it as an instance of\\n        :py:class:`IUSBController` .\\n\\n        in name of type str\\n\\n        in type_p of type :class:`USBControllerType`\\n\\n        return controller of type :class:`IUSBController`\\n\\n        raises :class:`VBoxErrorObjectInUse`\\n            A USB controller with given type exists already.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a controllerType.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(type_p, USBControllerType):\\n            raise TypeError(\"type_p can only be an instance of type USBControllerType\")\\n        controller = self._call(\"addUSBController\",\\n                     in_p=[name, type_p])\\n        controller = IUSBController(controller)\\n        return controller',\n",
              " 'def remove_usb_controller(self, name):\\n        \"\"\"Removes a USB controller from the machine.\\n\\n        in name of type str\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A USB controller with given type doesn\\'t exist.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"removeUSBController\",\\n                     in_p=[name])',\n",
              " 'def get_usb_controller_by_name(self, name):\\n        \"\"\"Returns a USB controller with the given type.\\n\\n        in name of type str\\n\\n        return controller of type :class:`IUSBController`\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            A USB controller with given name doesn\\'t exist.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        controller = self._call(\"getUSBControllerByName\",\\n                     in_p=[name])\\n        controller = IUSBController(controller)\\n        return controller',\n",
              " 'def get_usb_controller_count_by_type(self, type_p):\\n        \"\"\"Returns the number of USB controllers of the given type attached to the VM.\\n\\n        in type_p of type :class:`USBControllerType`\\n\\n        return controllers of type int\\n\\n        \"\"\"\\n        if not isinstance(type_p, USBControllerType):\\n            raise TypeError(\"type_p can only be an instance of type USBControllerType\")\\n        controllers = self._call(\"getUSBControllerCountByType\",\\n                     in_p=[type_p])\\n        return controllers',\n",
              " 'def get_serial_port(self, slot):\\n        \"\"\"Returns the serial port associated with the given slot.\\n        Slots are numbered sequentially, starting with zero. The total\\n        number of serial ports per machine is defined by the\\n        :py:func:`ISystemProperties.serial_port_count`  property,\\n        so the maximum slot number is one less than that property\\'s value.\\n\\n        in slot of type int\\n\\n        return port of type :class:`ISerialPort`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a slot number.\\n        \\n        \"\"\"\\n        if not isinstance(slot, baseinteger):\\n            raise TypeError(\"slot can only be an instance of type baseinteger\")\\n        port = self._call(\"getSerialPort\",\\n                     in_p=[slot])\\n        port = ISerialPort(port)\\n        return port',\n",
              " 'def get_parallel_port(self, slot):\\n        \"\"\"Returns the parallel port associated with the given slot.\\n        Slots are numbered sequentially, starting with zero. The total\\n        number of parallel ports per machine is defined by the\\n        :py:func:`ISystemProperties.parallel_port_count`  property,\\n        so the maximum slot number is one less than that property\\'s value.\\n\\n        in slot of type int\\n\\n        return port of type :class:`IParallelPort`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a slot number.\\n        \\n        \"\"\"\\n        if not isinstance(slot, baseinteger):\\n            raise TypeError(\"slot can only be an instance of type baseinteger\")\\n        port = self._call(\"getParallelPort\",\\n                     in_p=[slot])\\n        port = IParallelPort(port)\\n        return port',\n",
              " 'def get_cpu_property(self, property_p):\\n        \"\"\"Returns the virtual CPU boolean value of the specified property.\\n\\n        in property_p of type :class:`CPUPropertyType`\\n            Property type to query.\\n\\n        return value of type bool\\n            Property value.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid property.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, CPUPropertyType):\\n            raise TypeError(\"property_p can only be an instance of type CPUPropertyType\")\\n        value = self._call(\"getCPUProperty\",\\n                     in_p=[property_p])\\n        return value',\n",
              " 'def set_cpu_property(self, property_p, value):\\n        \"\"\"Sets the virtual CPU boolean value of the specified property.\\n\\n        in property_p of type :class:`CPUPropertyType`\\n            Property type to query.\\n\\n        in value of type bool\\n            Property value.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid property.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, CPUPropertyType):\\n            raise TypeError(\"property_p can only be an instance of type CPUPropertyType\")\\n        if not isinstance(value, bool):\\n            raise TypeError(\"value can only be an instance of type bool\")\\n        self._call(\"setCPUProperty\",\\n                     in_p=[property_p, value])',\n",
              " 'def get_cpuid_leaf_by_ordinal(self, ordinal):\\n        \"\"\"Used to enumerate CPUID information override values.\\n\\n        in ordinal of type int\\n            The ordinal number of the leaf to get.\\n\\n        out idx of type int\\n            CPUID leaf index.\\n\\n        out idx_sub of type int\\n            CPUID leaf sub-index.\\n\\n        out val_eax of type int\\n            CPUID leaf value for register eax.\\n\\n        out val_ebx of type int\\n            CPUID leaf value for register ebx.\\n\\n        out val_ecx of type int\\n            CPUID leaf value for register ecx.\\n\\n        out val_edx of type int\\n            CPUID leaf value for register edx.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid ordinal number is out of range.\\n        \\n        \"\"\"\\n        if not isinstance(ordinal, baseinteger):\\n            raise TypeError(\"ordinal can only be an instance of type baseinteger\")\\n        (idx, idx_sub, val_eax, val_ebx, val_ecx, val_edx) = self._call(\"getCPUIDLeafByOrdinal\",\\n                     in_p=[ordinal])\\n        return (idx, idx_sub, val_eax, val_ebx, val_ecx, val_edx)',\n",
              " 'def get_cpuid_leaf(self, idx, idx_sub):\\n        \"\"\"Returns the virtual CPU cpuid information for the specified leaf.\\n        \\n        Currently supported index values for cpuid:\\n        Standard CPUID leaves: 0 - 0x1f\\n        Extended CPUID leaves: 0x80000000 - 0x8000001f\\n        VIA CPUID leaves:      0xc0000000 - 0xc000000f\\n        \\n        See the Intel, AMD and VIA programmer\\'s manuals for detailed information\\n        about the CPUID instruction and its leaves.\\n\\n        in idx of type int\\n            CPUID leaf index.\\n\\n        in idx_sub of type int\\n            CPUID leaf sub-index (ECX).  Set to 0xffffffff (or 0) if not applicable.\\n\\n        out val_eax of type int\\n            CPUID leaf value for register eax.\\n\\n        out val_ebx of type int\\n            CPUID leaf value for register ebx.\\n\\n        out val_ecx of type int\\n            CPUID leaf value for register ecx.\\n\\n        out val_edx of type int\\n            CPUID leaf value for register edx.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid index.\\n        \\n        \"\"\"\\n        if not isinstance(idx, baseinteger):\\n            raise TypeError(\"idx can only be an instance of type baseinteger\")\\n        if not isinstance(idx_sub, baseinteger):\\n            raise TypeError(\"idx_sub can only be an instance of type baseinteger\")\\n        (val_eax, val_ebx, val_ecx, val_edx) = self._call(\"getCPUIDLeaf\",\\n                     in_p=[idx, idx_sub])\\n        return (val_eax, val_ebx, val_ecx, val_edx)',\n",
              " 'def set_cpuid_leaf(self, idx, idx_sub, val_eax, val_ebx, val_ecx, val_edx):\\n        \"\"\"Sets the virtual CPU cpuid information for the specified leaf. Note that these values\\n        are not passed unmodified. VirtualBox clears features that it doesn\\'t support.\\n        \\n        Currently supported index values for cpuid:\\n        Standard CPUID leaves: 0 - 0x1f\\n        Extended CPUID leaves: 0x80000000 - 0x8000001f\\n        VIA CPUID leaves:      0xc0000000 - 0xc000000f\\n        \\n        The subleaf index is only applicable to certain leaves (see manuals as this is\\n        subject to change).\\n        \\n        See the Intel, AMD and VIA programmer\\'s manuals for detailed information\\n        about the cpuid instruction and its leaves.\\n        \\n        Do not use this method unless you know exactly what you\\'re doing. Misuse can lead to\\n        random crashes inside VMs.\\n\\n        in idx of type int\\n            CPUID leaf index.\\n\\n        in idx_sub of type int\\n            CPUID leaf sub-index (ECX).  Set to 0xffffffff (or 0) if not applicable.\\n            The 0xffffffff causes it to remove all other subleaves before adding one\\n            with sub-index 0.\\n\\n        in val_eax of type int\\n            CPUID leaf value for register eax.\\n\\n        in val_ebx of type int\\n            CPUID leaf value for register ebx.\\n\\n        in val_ecx of type int\\n            CPUID leaf value for register ecx.\\n\\n        in val_edx of type int\\n            CPUID leaf value for register edx.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid index.\\n        \\n        \"\"\"\\n        if not isinstance(idx, baseinteger):\\n            raise TypeError(\"idx can only be an instance of type baseinteger\")\\n        if not isinstance(idx_sub, baseinteger):\\n            raise TypeError(\"idx_sub can only be an instance of type baseinteger\")\\n        if not isinstance(val_eax, baseinteger):\\n            raise TypeError(\"val_eax can only be an instance of type baseinteger\")\\n        if not isinstance(val_ebx, baseinteger):\\n            raise TypeError(\"val_ebx can only be an instance of type baseinteger\")\\n        if not isinstance(val_ecx, baseinteger):\\n            raise TypeError(\"val_ecx can only be an instance of type baseinteger\")\\n        if not isinstance(val_edx, baseinteger):\\n            raise TypeError(\"val_edx can only be an instance of type baseinteger\")\\n        self._call(\"setCPUIDLeaf\",\\n                     in_p=[idx, idx_sub, val_eax, val_ebx, val_ecx, val_edx])',\n",
              " 'def remove_cpuid_leaf(self, idx, idx_sub):\\n        \"\"\"Removes the virtual CPU cpuid leaf for the specified index\\n\\n        in idx of type int\\n            CPUID leaf index.\\n\\n        in idx_sub of type int\\n            CPUID leaf sub-index (ECX).  Set to 0xffffffff (or 0) if not applicable.\\n            The 0xffffffff value works like a wildcard.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid index.\\n        \\n        \"\"\"\\n        if not isinstance(idx, baseinteger):\\n            raise TypeError(\"idx can only be an instance of type baseinteger\")\\n        if not isinstance(idx_sub, baseinteger):\\n            raise TypeError(\"idx_sub can only be an instance of type baseinteger\")\\n        self._call(\"removeCPUIDLeaf\",\\n                     in_p=[idx, idx_sub])',\n",
              " 'def get_hw_virt_ex_property(self, property_p):\\n        \"\"\"Returns the value of the specified hardware virtualization boolean property.\\n\\n        in property_p of type :class:`HWVirtExPropertyType`\\n            Property type to query.\\n\\n        return value of type bool\\n            Property value.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid property.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, HWVirtExPropertyType):\\n            raise TypeError(\"property_p can only be an instance of type HWVirtExPropertyType\")\\n        value = self._call(\"getHWVirtExProperty\",\\n                     in_p=[property_p])\\n        return value',\n",
              " 'def set_hw_virt_ex_property(self, property_p, value):\\n        \"\"\"Sets a new value for the specified hardware virtualization boolean property.\\n\\n        in property_p of type :class:`HWVirtExPropertyType`\\n            Property type to set.\\n\\n        in value of type bool\\n            New property value.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid property.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, HWVirtExPropertyType):\\n            raise TypeError(\"property_p can only be an instance of type HWVirtExPropertyType\")\\n        if not isinstance(value, bool):\\n            raise TypeError(\"value can only be an instance of type bool\")\\n        self._call(\"setHWVirtExProperty\",\\n                     in_p=[property_p, value])',\n",
              " 'def set_settings_file_path(self, settings_file_path):\\n        \"\"\"Currently, it is an error to change this property on any machine.\\n        Later this will allow setting a new path for the settings file, with\\n        automatic relocation of all files (including snapshots and disk images)\\n        which are inside the base directory. This operation is only allowed\\n        when there are no pending unsaved settings.\\n        \\n        \\n        Setting this property to @c null or to an empty string is forbidden.\\n        When setting this property, the specified path must be absolute.\\n        The specified path may not exist, it will be created when necessary.\\n\\n        in settings_file_path of type str\\n            New settings file path, will be used to determine the new\\n            location for the attached media if it is in the same directory or\\n            below as the original settings file.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The operation is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(settings_file_path, basestring):\\n            raise TypeError(\"settings_file_path can only be an instance of type basestring\")\\n        progress = self._call(\"setSettingsFilePath\",\\n                     in_p=[settings_file_path])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def unregister(self, cleanup_mode):\\n        \"\"\"Unregisters a machine previously registered with\\n        :py:func:`IVirtualBox.register_machine`  and optionally do additional\\n        cleanup before the machine is unregistered.\\n        \\n        This method does not delete any files. It only changes the machine configuration and\\n        the list of registered machines in the VirtualBox object. To delete the files which\\n        belonged to the machine, including the XML file of the machine itself, call\\n        :py:func:`delete_config` , optionally with the array of IMedium objects which was returned\\n        from this method.\\n        \\n        How thoroughly this method cleans up the machine configuration before unregistering\\n        the machine depends on the @a cleanupMode argument.\\n        \\n        \\n        With \"UnregisterOnly\", the machine will only be unregistered, but no additional\\n        cleanup will be performed. The call will fail if the machine is in \"Saved\" state\\n        or has any snapshots or any media attached (see :py:class:`IMediumAttachment` ).\\n        It is the responsibility of the caller to delete all such configuration in this mode.\\n        In this mode, the API behaves like the former @c IVirtualBox::unregisterMachine() API\\n        which it replaces.\\n        With \"DetachAllReturnNone\", the call will succeed even if the machine is in \"Saved\"\\n        state or if it has snapshots or media attached. All media attached to the current machine\\n        state or in snapshots will be detached. No medium objects will be returned;\\n        all of the machine\\'s media will remain open.\\n        With \"DetachAllReturnHardDisksOnly\", the call will behave like with \"DetachAllReturnNone\",\\n        except that all the hard disk medium objects which were detached from the machine will\\n        be returned as an array. This allows for quickly passing them to the :py:func:`delete_config` \\n        API for closing and deletion.\\n        With \"Full\", the call will behave like with \"DetachAllReturnHardDisksOnly\", except\\n        that all media will be returned in the array, including removable media like DVDs and\\n        floppies. This might be useful if the user wants to inspect in detail which media were\\n        attached to the machine. Be careful when passing the media array to :py:func:`delete_config` \\n        in that case because users will typically want to preserve ISO and RAW image files.\\n        \\n        \\n        A typical implementation will use \"DetachAllReturnHardDisksOnly\" and then pass the\\n        resulting IMedium array to :py:func:`delete_config` . This way, the machine is completely\\n        deleted with all its saved states and hard disk images, but images for removable\\n        drives (such as ISO and RAW files) will remain on disk.\\n        \\n        This API does not verify whether the media files returned in the array are still\\n        attached to other machines (i.e. shared between several machines). If such a shared\\n        image is passed to :py:func:`delete_config`  however, closing the image will fail there\\n        and the image will be silently skipped.\\n        \\n        This API may, however, move media from this machine\\'s media registry to other media\\n        registries (see :py:class:`IMedium`  for details on media registries). For machines\\n        created with VirtualBox 4.0 or later, if media from this machine\\'s media registry\\n        are also attached to another machine (shared attachments), each such medium will be\\n        moved to another machine\\'s registry. This is because without this machine\\'s media\\n        registry, the other machine cannot find its media any more and would become inaccessible.\\n        \\n        This API implicitly calls :py:func:`save_settings`  to save all current machine settings\\n        before unregistering it. It may also silently call :py:func:`save_settings`  on other machines\\n        if media are moved to other machines\\' media registries.\\n        \\n        After successful method invocation, the :py:class:`IMachineRegisteredEvent`  event\\n        is fired.\\n        \\n        The call will fail if the machine is currently locked (see :py:class:`ISession` ).\\n        \\n        \\n        If the given machine is inaccessible (see :py:func:`accessible` ), it\\n        will be unregistered and fully uninitialized right afterwards. As a result,\\n        the returned machine object will be unusable and an attempt to call\\n        **any** method will return the \"Object not ready\" error.\\n\\n        in cleanup_mode of type :class:`CleanupMode`\\n            How to clean up after the machine has been unregistered.\\n\\n        return media of type :class:`IMedium`\\n            List of media detached from the machine, depending on the @a cleanupMode parameter.\\n\\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Machine is currently locked for a session.\\n        \\n        \"\"\"\\n        if not isinstance(cleanup_mode, CleanupMode):\\n            raise TypeError(\"cleanup_mode can only be an instance of type CleanupMode\")\\n        media = self._call(\"unregister\",\\n                     in_p=[cleanup_mode])\\n        media = [IMedium(a) for a in media]\\n        return media',\n",
              " 'def delete_config(self, media):\\n        \"\"\"Deletes the files associated with this machine from disk. If medium objects are passed\\n        in with the @a aMedia argument, they are closed and, if closing was successful, their\\n        storage files are deleted as well. For convenience, this array of media files can be\\n        the same as the one returned from a previous :py:func:`unregister`  call.\\n        \\n        This method must only be called on machines which are either write-locked (i.e. on instances\\n        returned by :py:func:`ISession.machine` ) or on unregistered machines (i.e. not yet\\n        registered machines created by :py:func:`IVirtualBox.create_machine`  or opened by\\n        :py:func:`IVirtualBox.open_machine` , or after having called :py:func:`unregister` ).\\n        \\n        The following files will be deleted by this method:\\n        \\n        If :py:func:`unregister`  had been previously called with a @a cleanupMode\\n        argument other than \"UnregisterOnly\", this will delete all saved state files that\\n        the machine had in use; possibly one if the machine was in \"Saved\" state and one\\n        for each online snapshot that the machine had.\\n        On each medium object passed in the @a aMedia array, this will call\\n        :py:func:`IMedium.close` . If that succeeds, this will attempt to delete the\\n        medium\\'s storage on disk. Since the :py:func:`IMedium.close`  call will fail if the medium is still\\n        in use, e.g. because it is still attached to a second machine; in that case the\\n        storage will not be deleted.\\n        Finally, the machine\\'s own XML file will be deleted.\\n        \\n        \\n        Since deleting large disk image files can be a time-consuming I/O operation, this\\n        method operates asynchronously and returns an IProgress object to allow the caller\\n        to monitor the progress. There will be one sub-operation for each file that is\\n        being deleted (saved state or medium storage file).\\n        \\n        \\n        :py:func:`settings_modified`  will return @c true after this\\n        method successfully returns.\\n\\n        in media of type :class:`IMedium`\\n            List of media to be closed and whose storage files will be deleted.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine is registered but not write-locked.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not delete the settings file.\\n        \\n        \"\"\"\\n        if not isinstance(media, list):\\n            raise TypeError(\"media can only be an instance of type list\")\\n        for a in media[:10]:\\n            if not isinstance(a, IMedium):\\n                raise TypeError(\\n                        \"array can only contain objects of type IMedium\")\\n        progress = self._call(\"deleteConfig\",\\n                     in_p=[media])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def export_to(self, appliance, location):\\n        \"\"\"Exports the machine to an OVF appliance. See :py:class:`IAppliance`  for the\\n        steps required to export VirtualBox machines to OVF.\\n\\n        in appliance of type :class:`IAppliance`\\n            Appliance to export this machine to.\\n\\n        in location of type str\\n            The target location.\\n\\n        return description of type :class:`IVirtualSystemDescription`\\n            VirtualSystemDescription object which is created for this machine.\\n\\n        \"\"\"\\n        if not isinstance(appliance, IAppliance):\\n            raise TypeError(\"appliance can only be an instance of type IAppliance\")\\n        if not isinstance(location, basestring):\\n            raise TypeError(\"location can only be an instance of type basestring\")\\n        description = self._call(\"exportTo\",\\n                     in_p=[appliance, location])\\n        description = IVirtualSystemDescription(description)\\n        return description',\n",
              " 'def find_snapshot(self, name_or_id):\\n        \"\"\"Returns a snapshot of this machine with the given name or UUID.\\n        \\n        Returns a snapshot of this machine with the given UUID.\\n        A @c null argument can be used to obtain the first snapshot\\n        taken on this machine. To traverse the whole tree of snapshots\\n        starting from the root, inspect the root snapshot\\'s\\n        :py:func:`ISnapshot.children`  attribute and recurse over those children.\\n\\n        in name_or_id of type str\\n            What to search for. Name or UUID of the snapshot to find\\n\\n        return snapshot of type :class:`ISnapshot`\\n            Snapshot object with the given name.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Virtual machine has no snapshots or snapshot not found.\\n        \\n        \"\"\"\\n        if not isinstance(name_or_id, basestring):\\n            raise TypeError(\"name_or_id can only be an instance of type basestring\")\\n        snapshot = self._call(\"findSnapshot\",\\n                     in_p=[name_or_id])\\n        snapshot = ISnapshot(snapshot)\\n        return snapshot',\n",
              " 'def get_guest_property(self, name):\\n        \"\"\"Reads an entry from the machine\\'s guest property store.\\n\\n        in name of type str\\n            The name of the property to read.\\n\\n        out value of type str\\n            The value of the property. If the property does not exist then this\\n            will be empty.\\n\\n        out timestamp of type int\\n            The time at which the property was last modified, as seen by the\\n            server process.\\n\\n        out flags of type str\\n            Additional property parameters, passed as a comma-separated list of\\n            \"name=value\" type entries.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        (value, timestamp, flags) = self._call(\"getGuestProperty\",\\n                     in_p=[name])\\n        return (value, timestamp, flags)',\n",
              " 'def get_guest_property_value(self, property_p):\\n        \"\"\"Reads a value from the machine\\'s guest property store.\\n\\n        in property_p of type str\\n            The name of the property to read.\\n\\n        return value of type str\\n            The value of the property. If the property does not exist then this\\n            will be empty.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, basestring):\\n            raise TypeError(\"property_p can only be an instance of type basestring\")\\n        value = self._call(\"getGuestPropertyValue\",\\n                     in_p=[property_p])\\n        return value',\n",
              " 'def set_guest_property(self, property_p, value, flags):\\n        \"\"\"Sets, changes or deletes an entry in the machine\\'s guest property\\n        store.\\n\\n        in property_p of type str\\n            The name of the property to set, change or delete.\\n\\n        in value of type str\\n            The new value of the property to set, change or delete. If the\\n            property does not yet exist and value is non-empty, it will be\\n            created. If the value is @c null or empty, the property will be\\n            deleted if it exists.\\n\\n        in flags of type str\\n            Additional property parameters, passed as a comma-separated list of\\n            \"name=value\" type entries.\\n\\n        raises :class:`OleErrorAccessdenied`\\n            Property cannot be changed.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid @a flags.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine is not mutable or session not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Cannot set transient property when machine not running.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, basestring):\\n            raise TypeError(\"property_p can only be an instance of type basestring\")\\n        if not isinstance(value, basestring):\\n            raise TypeError(\"value can only be an instance of type basestring\")\\n        if not isinstance(flags, basestring):\\n            raise TypeError(\"flags can only be an instance of type basestring\")\\n        self._call(\"setGuestProperty\",\\n                     in_p=[property_p, value, flags])',\n",
              " 'def set_guest_property_value(self, property_p, value):\\n        \"\"\"Sets or changes a value in the machine\\'s guest property\\n        store. The flags field will be left unchanged or created empty for a\\n        new property.\\n\\n        in property_p of type str\\n            The name of the property to set or change.\\n\\n        in value of type str\\n            The new value of the property to set or change. If the\\n            property does not yet exist and value is non-empty, it will be\\n            created.\\n\\n        raises :class:`OleErrorAccessdenied`\\n            Property cannot be changed.\\n        \\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine is not mutable or session not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Cannot set transient property when machine not running.\\n        \\n        \"\"\"\\n        if not isinstance(property_p, basestring):\\n            raise TypeError(\"property_p can only be an instance of type basestring\")\\n        if not isinstance(value, basestring):\\n            raise TypeError(\"value can only be an instance of type basestring\")\\n        self._call(\"setGuestPropertyValue\",\\n                     in_p=[property_p, value])',\n",
              " 'def delete_guest_property(self, name):\\n        \"\"\"Deletes an entry from the machine\\'s guest property store.\\n\\n        in name of type str\\n            The name of the property to delete.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"deleteGuestProperty\",\\n                     in_p=[name])',\n",
              " 'def enumerate_guest_properties(self, patterns):\\n        \"\"\"Return a list of the guest properties matching a set of patterns along\\n        with their values, timestamps and flags.\\n\\n        in patterns of type str\\n            The patterns to match the properties against, separated by \\'|\\'\\n            characters. If this is empty or @c null, all properties will match.\\n\\n        out names of type str\\n            The names of the properties returned.\\n\\n        out values of type str\\n            The values of the properties returned. The array entries match the\\n            corresponding entries in the @a name array.\\n\\n        out timestamps of type int\\n            The timestamps of the properties returned. The array entries match\\n            the corresponding entries in the @a name array.\\n\\n        out flags of type str\\n            The flags of the properties returned. The array entries match the\\n            corresponding entries in the @a name array.\\n\\n        \"\"\"\\n        if not isinstance(patterns, basestring):\\n            raise TypeError(\"patterns can only be an instance of type basestring\")\\n        (names, values, timestamps, flags) = self._call(\"enumerateGuestProperties\",\\n                     in_p=[patterns])\\n        return (names, values, timestamps, flags)',\n",
              " 'def query_saved_guest_screen_info(self, screen_id):\\n        \"\"\"Returns the guest dimensions from the saved state.\\n\\n        in screen_id of type int\\n            Saved guest screen to query info from.\\n\\n        out origin_x of type int\\n            The X position of the guest monitor top left corner.\\n\\n        out origin_y of type int\\n            The Y position of the guest monitor top left corner.\\n\\n        out width of type int\\n            Guest width at the time of the saved state was taken.\\n\\n        out height of type int\\n            Guest height at the time of the saved state was taken.\\n\\n        out enabled of type bool\\n            Whether the monitor is enabled in the guest.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        (origin_x, origin_y, width, height, enabled) = self._call(\"querySavedGuestScreenInfo\",\\n                     in_p=[screen_id])\\n        return (origin_x, origin_y, width, height, enabled)',\n",
              " 'def query_saved_screenshot_info(self, screen_id):\\n        \"\"\"Returns available formats and size of the screenshot from saved state.\\n\\n        in screen_id of type int\\n            Saved guest screen to query info from.\\n\\n        out width of type int\\n            Image width.\\n\\n        out height of type int\\n            Image height.\\n\\n        return bitmap_formats of type :class:`BitmapFormat`\\n            Formats supported by readSavedScreenshotToArray.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        (bitmap_formats, width, height) = self._call(\"querySavedScreenshotInfo\",\\n                     in_p=[screen_id])\\n        bitmap_formats = [BitmapFormat(a) for a in bitmap_formats]\\n        return (bitmap_formats, width, height)',\n",
              " 'def read_saved_screenshot_to_array(self, screen_id, bitmap_format):\\n        \"\"\"Screenshot in requested format is retrieved to an array of bytes.\\n\\n        in screen_id of type int\\n            Saved guest screen to read from.\\n\\n        in bitmap_format of type :class:`BitmapFormat`\\n            The requested format.\\n\\n        out width of type int\\n            Image width.\\n\\n        out height of type int\\n            Image height.\\n\\n        return data of type str\\n            Array with resulting image data.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(bitmap_format, BitmapFormat):\\n            raise TypeError(\"bitmap_format can only be an instance of type BitmapFormat\")\\n        (data, width, height) = self._call(\"readSavedScreenshotToArray\",\\n                     in_p=[screen_id, bitmap_format])\\n        return (data, width, height)',\n",
              " 'def hot_plug_cpu(self, cpu):\\n        \"\"\"Plugs a CPU into the machine.\\n\\n        in cpu of type int\\n            The CPU id to insert.\\n\\n        \"\"\"\\n        if not isinstance(cpu, baseinteger):\\n            raise TypeError(\"cpu can only be an instance of type baseinteger\")\\n        self._call(\"hotPlugCPU\",\\n                     in_p=[cpu])',\n",
              " 'def hot_unplug_cpu(self, cpu):\\n        \"\"\"Removes a CPU from the machine.\\n\\n        in cpu of type int\\n            The CPU id to remove.\\n\\n        \"\"\"\\n        if not isinstance(cpu, baseinteger):\\n            raise TypeError(\"cpu can only be an instance of type baseinteger\")\\n        self._call(\"hotUnplugCPU\",\\n                     in_p=[cpu])',\n",
              " 'def get_cpu_status(self, cpu):\\n        \"\"\"Returns the current status of the given CPU.\\n\\n        in cpu of type int\\n            The CPU id to check for.\\n\\n        return attached of type bool\\n            Status of the CPU.\\n\\n        \"\"\"\\n        if not isinstance(cpu, baseinteger):\\n            raise TypeError(\"cpu can only be an instance of type baseinteger\")\\n        attached = self._call(\"getCPUStatus\",\\n                     in_p=[cpu])\\n        return attached',\n",
              " 'def query_log_filename(self, idx):\\n        \"\"\"Queries for the VM log file name of an given index. Returns an empty\\n        string if a log file with that index doesn\\'t exists.\\n\\n        in idx of type int\\n            Which log file name to query. 0=current log file.\\n\\n        return filename of type str\\n            On return the full path to the log file or an empty string on error.\\n\\n        \"\"\"\\n        if not isinstance(idx, baseinteger):\\n            raise TypeError(\"idx can only be an instance of type baseinteger\")\\n        filename = self._call(\"queryLogFilename\",\\n                     in_p=[idx])\\n        return filename',\n",
              " 'def read_log(self, idx, offset, size):\\n        \"\"\"Reads the VM log file. The chunk size is limited, so even if you\\n        ask for a big piece there might be less data returned.\\n\\n        in idx of type int\\n            Which log file to read. 0=current log file.\\n\\n        in offset of type int\\n            Offset in the log file.\\n\\n        in size of type int\\n            Chunk size to read in the log file.\\n\\n        return data of type str\\n            Data read from the log file. A data size of 0 means end of file\\n            if the requested chunk size was not 0. This is the unprocessed\\n            file data, i.e. the line ending style depends on the platform of\\n            the system the server is running on.\\n\\n        \"\"\"\\n        if not isinstance(idx, baseinteger):\\n            raise TypeError(\"idx can only be an instance of type baseinteger\")\\n        if not isinstance(offset, baseinteger):\\n            raise TypeError(\"offset can only be an instance of type baseinteger\")\\n        if not isinstance(size, baseinteger):\\n            raise TypeError(\"size can only be an instance of type baseinteger\")\\n        data = self._call(\"readLog\",\\n                     in_p=[idx, offset, size])\\n        return data',\n",
              " 'def clone_to(self, target, mode, options):\\n        \"\"\"Creates a clone of this machine, either as a full clone (which means\\n        creating independent copies of the hard disk media, save states and so\\n        on), or as a linked clone (which uses its own differencing media,\\n        sharing the parent media with the source machine).\\n        \\n        The target machine object must have been created previously with :py:func:`IVirtualBox.create_machine` , and all the settings will be\\n        transferred except the VM name and the hardware UUID. You can set the\\n        VM name and the new hardware UUID when creating the target machine. The\\n        network MAC addresses are newly created for all enabled network\\n        adapters. You can change that behaviour with the options parameter.\\n        The operation is performed asynchronously, so the machine object will\\n        be not be usable until the @a progress object signals completion.\\n\\n        in target of type :class:`IMachine`\\n            Target machine object.\\n\\n        in mode of type :class:`CloneMode`\\n            Which states should be cloned.\\n\\n        in options of type :class:`CloneOptions`\\n            Options for the cloning operation.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            @a target is @c null.\\n        \\n        \"\"\"\\n        if not isinstance(target, IMachine):\\n            raise TypeError(\"target can only be an instance of type IMachine\")\\n        if not isinstance(mode, CloneMode):\\n            raise TypeError(\"mode can only be an instance of type CloneMode\")\\n        if not isinstance(options, list):\\n            raise TypeError(\"options can only be an instance of type list\")\\n        for a in options[:10]:\\n            if not isinstance(a, CloneOptions):\\n                raise TypeError(\\n                        \"array can only contain objects of type CloneOptions\")\\n        progress = self._call(\"cloneTo\",\\n                     in_p=[target, mode, options])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def move_to(self, folder, type_p):\\n        \"\"\"Move machine on to new place/folder\\n\\n        in folder of type str\\n            Target folder where machine is moved.\\n\\n        in type_p of type str\\n            Type of moving.\\n            Possible values:\\n            basic - Only the files which belong solely to this machine\\n            are moved from the original machine\\'s folder to\\n            a new folder.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            @a target is @c null.\\n        \\n        \"\"\"\\n        if not isinstance(folder, basestring):\\n            raise TypeError(\"folder can only be an instance of type basestring\")\\n        if not isinstance(type_p, basestring):\\n            raise TypeError(\"type_p can only be an instance of type basestring\")\\n        progress = self._call(\"moveTo\",\\n                     in_p=[folder, type_p])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def adopt_saved_state(self, saved_state_file):\\n        \"\"\"Associates the given saved state file to the virtual machine.\\n        \\n        On success, the machine will go to the Saved state. Next time it is\\n        powered up, it will be restored from the adopted saved state and\\n        continue execution from the place where the saved state file was\\n        created.\\n        \\n        The specified saved state file path may be absolute or relative to the\\n        folder the VM normally saves the state to (usually,\\n        :py:func:`snapshot_folder` ).\\n        \\n        \\n        It\\'s a caller\\'s responsibility to make sure the given saved state\\n        file is compatible with the settings of this virtual machine that\\n        represent its virtual hardware (memory size, storage disk configuration\\n        etc.). If there is a mismatch, the behavior of the virtual machine\\n        is undefined.\\n\\n        in saved_state_file of type str\\n            Path to the saved state file to adopt.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine state neither PoweredOff nor Aborted.\\n        \\n        \"\"\"\\n        if not isinstance(saved_state_file, basestring):\\n            raise TypeError(\"saved_state_file can only be an instance of type basestring\")\\n        self._call(\"adoptSavedState\",\\n                     in_p=[saved_state_file])',\n",
              " 'def discard_saved_state(self, f_remove_file):\\n        \"\"\"Forcibly resets the machine to \"Powered Off\" state if it is\\n        currently in the \"Saved\" state (previously created by :py:func:`save_state` ).\\n        Next time the machine is powered up, a clean boot will occur.\\n        \\n        This operation is equivalent to resetting or powering off\\n        the machine without doing a proper shutdown of the guest\\n        operating system; as with resetting a running phyiscal\\n        computer, it can can lead to data loss.\\n        \\n        If @a fRemoveFile is @c true, the file in the machine directory\\n        into which the machine state was saved is also deleted. If\\n        this is @c false, then the state can be recovered and later\\n        re-inserted into a machine using :py:func:`adopt_saved_state` .\\n        The location of the file can be found in the\\n        :py:func:`state_file_path`  attribute.\\n\\n        in f_remove_file of type bool\\n            Whether to also remove the saved state file.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine not in state Saved.\\n        \\n        \"\"\"\\n        if not isinstance(f_remove_file, bool):\\n            raise TypeError(\"f_remove_file can only be an instance of type bool\")\\n        self._call(\"discardSavedState\",\\n                     in_p=[f_remove_file])',\n",
              " 'def take_snapshot(self, name, description, pause):\\n        \"\"\"Saves the current execution state\\n        and all settings of the machine and creates differencing images\\n        for all normal (non-independent) media.\\n        See :py:class:`ISnapshot`  for an introduction to snapshots.\\n        \\n        This method can be called for a PoweredOff, Saved (see\\n        :py:func:`save_state` ), Running or\\n        Paused virtual machine. When the machine is PoweredOff, an\\n        offline snapshot is created. When the machine is Running a live\\n        snapshot is created, and an online snapshot is created when Paused.\\n        \\n        The taken snapshot is always based on the\\n        :py:func:`current_snapshot` current snapshot\\n        of the associated virtual machine and becomes a new current snapshot.\\n        \\n        \\n        This method implicitly calls :py:func:`save_settings`  to\\n        save all current machine settings before taking an offline snapshot.\\n\\n        in name of type str\\n            Short name for the snapshot.\\n\\n        in description of type str\\n            Optional description of the snapshot.\\n\\n        in pause of type bool\\n            Whether the VM should be paused while taking the snapshot. Only\\n            relevant when the VM is running, and distinguishes between online\\n            (@c true) and live (@c false) snapshots. When the VM is not running\\n            the result is always an offline snapshot.\\n\\n        out id_p of type str\\n            UUID of the snapshot which will be created. Useful for follow-up\\n            operations after the snapshot has been created.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine currently changing state.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(description, basestring):\\n            raise TypeError(\"description can only be an instance of type basestring\")\\n        if not isinstance(pause, bool):\\n            raise TypeError(\"pause can only be an instance of type bool\")\\n        (progress, id_p) = self._call(\"takeSnapshot\",\\n                     in_p=[name, description, pause])\\n        progress = IProgress(progress)\\n        return (progress, id_p)',\n",
              " 'def delete_snapshot_range(self, start_id, end_id):\\n        \"\"\"Starts deleting the specified snapshot range. This is limited to\\n        linear snapshot lists, which means there may not be any other child\\n        snapshots other than the direct sequence between the start and end\\n        snapshot. If the start and end snapshot point to the same snapshot this\\n        method is completely equivalent to :py:func:`delete_snapshot` . See\\n        :py:class:`ISnapshot`  for an introduction to snapshots. The\\n        conditions and many details are the same as with\\n        :py:func:`delete_snapshot` .\\n        \\n        This operation is generally faster than deleting snapshots one by one\\n        and often also needs less extra disk space before freeing up disk space\\n        by deleting the removed disk images corresponding to the snapshot.\\n        \\n        This API method is right now not implemented!\\n\\n        in start_id of type str\\n            UUID of the first snapshot to delete.\\n\\n        in end_id of type str\\n            UUID of the last snapshot to delete.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            The running virtual machine prevents deleting this snapshot. This\\nhappens only in very specific situations, usually snapshots can be\\ndeleted without trouble while a VM is running. The error message\\ntext explains the reason for the failure.\\n        \\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(start_id, basestring):\\n            raise TypeError(\"start_id can only be an instance of type basestring\")\\n        if not isinstance(end_id, basestring):\\n            raise TypeError(\"end_id can only be an instance of type basestring\")\\n        progress = self._call(\"deleteSnapshotRange\",\\n                     in_p=[start_id, end_id])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def restore_snapshot(self, snapshot):\\n        \"\"\"Starts resetting the machine\\'s current state to the state contained\\n        in the given snapshot, asynchronously. All current settings of the\\n        machine will be reset and changes stored in differencing media\\n        will be lost.\\n        See :py:class:`ISnapshot`  for an introduction to snapshots.\\n        \\n        After this operation is successfully completed, new empty differencing\\n        media are created for all normal media of the machine.\\n        \\n        If the given snapshot is an online snapshot, the machine will go to\\n        the :py:attr:`MachineState.saved` saved state, so that the\\n        next time it is powered on, the execution state will be restored\\n        from the state of the snapshot.\\n        \\n        \\n        The machine must not be running, otherwise the operation will fail.\\n        \\n        \\n        \\n        If the machine state is :py:attr:`MachineState.saved` Saved\\n        prior to this operation, the saved state file will be implicitly\\n        deleted (as if :py:func:`IMachine.discard_saved_state`  were\\n        called).\\n\\n        in snapshot of type :class:`ISnapshot`\\n            The snapshot to restore the VM state from.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine is running.\\n        \\n        \"\"\"\\n        if not isinstance(snapshot, ISnapshot):\\n            raise TypeError(\"snapshot can only be an instance of type ISnapshot\")\\n        progress = self._call(\"restoreSnapshot\",\\n                     in_p=[snapshot])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def apply_defaults(self, flags):\\n        \"\"\"Applies the defaults for the configured guest OS type. This is\\n        primarily for getting sane settings straight after creating a\\n        new VM, but it can also be applied later.\\n        \\n        \\n        This is primarily a shortcut, centralizing the tedious job of\\n        getting the recommended settings and translating them into\\n        settings updates. The settings are made at the end of the call,\\n        but not saved.\\n\\n        in flags of type str\\n            Additional flags, to be defined later.\\n\\n        raises :class:`OleErrorNotimpl`\\n            This method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(flags, basestring):\\n            raise TypeError(\"flags can only be an instance of type basestring\")\\n        self._call(\"applyDefaults\",\\n                     in_p=[flags])',\n",
              " 'def webcam_attach(self, path, settings):\\n        \"\"\"Attaches the emulated USB webcam to the VM, which will use a host video capture device.\\n\\n        in path of type str\\n            The host path of the capture device to use.\\n\\n        in settings of type str\\n            Optional settings.\\n\\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(settings, basestring):\\n            raise TypeError(\"settings can only be an instance of type basestring\")\\n        self._call(\"webcamAttach\",\\n                     in_p=[path, settings])',\n",
              " 'def webcam_detach(self, path):\\n        \"\"\"Detaches the emulated USB webcam from the VM\\n\\n        in path of type str\\n            The host path of the capture device to detach.\\n\\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        self._call(\"webcamDetach\",\\n                     in_p=[path])',\n",
              " 'def get_device_activity(self, type_p):\\n        \"\"\"Gets the current activity type of given devices or device groups.\\n\\n        in type_p of type :class:`DeviceType`\\n\\n        return activity of type :class:`DeviceActivity`\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid device type.\\n        \\n        \"\"\"\\n        if not isinstance(type_p, list):\\n            raise TypeError(\"type_p can only be an instance of type list\")\\n        for a in type_p[:10]:\\n            if not isinstance(a, DeviceType):\\n                raise TypeError(\\n                        \"array can only contain objects of type DeviceType\")\\n        activity = self._call(\"getDeviceActivity\",\\n                     in_p=[type_p])\\n        activity = [DeviceActivity(a) for a in activity]\\n        return activity',\n",
              " 'def teleport(self, hostname, tcpport, password, max_downtime):\\n        \"\"\"Teleport the VM to a different host machine or process.\\n        \\n        @todo Explain the details.\\n\\n        in hostname of type str\\n            The name or IP of the host to teleport to.\\n\\n        in tcpport of type int\\n            The TCP port to connect to (1..65535).\\n\\n        in password of type str\\n            The password.\\n\\n        in max_downtime of type int\\n            The maximum allowed downtime given as milliseconds. 0 is not a valid\\n            value. Recommended value: 250 ms.\\n            \\n            The higher the value is, the greater the chance for a successful\\n            teleportation. A small value may easily result in the teleportation\\n            process taking hours and eventually fail.\\n            \\n            \\n            The current implementation treats this a guideline, not as an\\n            absolute rule.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine not running or paused.\\n        \\n        \"\"\"\\n        if not isinstance(hostname, basestring):\\n            raise TypeError(\"hostname can only be an instance of type basestring\")\\n        if not isinstance(tcpport, baseinteger):\\n            raise TypeError(\"tcpport can only be an instance of type baseinteger\")\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        if not isinstance(max_downtime, baseinteger):\\n            raise TypeError(\"max_downtime can only be an instance of type baseinteger\")\\n        progress = self._call(\"teleport\",\\n                     in_p=[hostname, tcpport, password, max_downtime])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def add_disk_encryption_password(self, id_p, password, clear_on_suspend):\\n        \"\"\"Adds a password used for hard disk encryption/decryption.\\n\\n        in id_p of type str\\n            The identifier used for the password. Must match the identifier\\n            used when the encrypted medium was created.\\n\\n        in password of type str\\n            The password.\\n\\n        in clear_on_suspend of type bool\\n            Flag whether to clear the password on VM suspend (due to a suspending host\\n            for example). The password must be supplied again before the VM can resume.\\n\\n        raises :class:`VBoxErrorPasswordIncorrect`\\n            The password provided wasn\\'t correct for at least one disk using the provided\\nID.\\n        \\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        if not isinstance(clear_on_suspend, bool):\\n            raise TypeError(\"clear_on_suspend can only be an instance of type bool\")\\n        self._call(\"addDiskEncryptionPassword\",\\n                     in_p=[id_p, password, clear_on_suspend])',\n",
              " 'def add_disk_encryption_passwords(self, ids, passwords, clear_on_suspend):\\n        \"\"\"Adds a password used for hard disk encryption/decryption.\\n\\n        in ids of type str\\n            List of identifiers for the passwords. Must match the identifier\\n            used when the encrypted medium was created.\\n\\n        in passwords of type str\\n            List of passwords.\\n\\n        in clear_on_suspend of type bool\\n            Flag whether to clear the given passwords on VM suspend (due to a suspending host\\n            for example). The passwords must be supplied again before the VM can resume.\\n\\n        raises :class:`VBoxErrorPasswordIncorrect`\\n            The password provided wasn\\'t correct for at least one disk using the provided\\nID.\\n        \\n        \"\"\"\\n        if not isinstance(ids, list):\\n            raise TypeError(\"ids can only be an instance of type list\")\\n        for a in ids[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(passwords, list):\\n            raise TypeError(\"passwords can only be an instance of type list\")\\n        for a in passwords[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(clear_on_suspend, bool):\\n            raise TypeError(\"clear_on_suspend can only be an instance of type bool\")\\n        self._call(\"addDiskEncryptionPasswords\",\\n                     in_p=[ids, passwords, clear_on_suspend])',\n",
              " 'def remove_disk_encryption_password(self, id_p):\\n        \"\"\"Removes a password used for hard disk encryption/decryption from\\n        the running VM. As soon as the medium requiring this password\\n        is accessed the VM is paused with an error and the password must be\\n        provided again.\\n\\n        in id_p of type str\\n            The identifier used for the password. Must match the identifier\\n            used when the encrypted medium was created.\\n\\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        self._call(\"removeDiskEncryptionPassword\",\\n                     in_p=[id_p])',\n",
              " 'def enable_static_ip_config(self, ip_address, network_mask):\\n        \"\"\"sets and enables the static IP V4 configuration for the given interface.\\n\\n        in ip_address of type str\\n            IP address.\\n\\n        in network_mask of type str\\n            network mask.\\n\\n        \"\"\"\\n        if not isinstance(ip_address, basestring):\\n            raise TypeError(\"ip_address can only be an instance of type basestring\")\\n        if not isinstance(network_mask, basestring):\\n            raise TypeError(\"network_mask can only be an instance of type basestring\")\\n        self._call(\"enableStaticIPConfig\",\\n                     in_p=[ip_address, network_mask])',\n",
              " 'def enable_static_ip_config_v6(self, ipv6_address, ipv6_network_mask_prefix_length):\\n        \"\"\"sets and enables the static IP V6 configuration for the given interface.\\n\\n        in ipv6_address of type str\\n            IP address.\\n\\n        in ipv6_network_mask_prefix_length of type int\\n            network mask.\\n\\n        \"\"\"\\n        if not isinstance(ipv6_address, basestring):\\n            raise TypeError(\"ipv6_address can only be an instance of type basestring\")\\n        if not isinstance(ipv6_network_mask_prefix_length, baseinteger):\\n            raise TypeError(\"ipv6_network_mask_prefix_length can only be an instance of type baseinteger\")\\n        self._call(\"enableStaticIPConfigV6\",\\n                     in_p=[ipv6_address, ipv6_network_mask_prefix_length])',\n",
              " 'def get_processor_speed(self, cpu_id):\\n        \"\"\"Query the (approximate) maximum speed of a specified host CPU in\\n        Megahertz.\\n\\n        in cpu_id of type int\\n            Identifier of the CPU.\\n\\n        return speed of type int\\n            Speed value. 0 is returned if value is not known or @a cpuId is\\n            invalid.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        speed = self._call(\"getProcessorSpeed\",\\n                     in_p=[cpu_id])\\n        return speed',\n",
              " 'def get_processor_feature(self, feature):\\n        \"\"\"Query whether a CPU feature is supported or not.\\n\\n        in feature of type :class:`ProcessorFeature`\\n            CPU Feature identifier.\\n\\n        return supported of type bool\\n            Feature is supported or not.\\n\\n        \"\"\"\\n        if not isinstance(feature, ProcessorFeature):\\n            raise TypeError(\"feature can only be an instance of type ProcessorFeature\")\\n        supported = self._call(\"getProcessorFeature\",\\n                     in_p=[feature])\\n        return supported',\n",
              " 'def get_processor_description(self, cpu_id):\\n        \"\"\"Query the model string of a specified host CPU.\\n\\n        in cpu_id of type int\\n            Identifier of the CPU.\\n            \\n            The current implementation might not necessarily return the\\n            description for this exact CPU.\\n\\n        return description of type str\\n            Model string. An empty string is returned if value is not known or\\n            @a cpuId is invalid.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        description = self._call(\"getProcessorDescription\",\\n                     in_p=[cpu_id])\\n        return description',\n",
              " 'def get_processor_cpuid_leaf(self, cpu_id, leaf, sub_leaf):\\n        \"\"\"Returns the CPU cpuid information for the specified leaf.\\n\\n        in cpu_id of type int\\n            Identifier of the CPU. The CPU most be online.\\n            \\n            The current implementation might not necessarily return the\\n            description for this exact CPU.\\n\\n        in leaf of type int\\n            CPUID leaf index (eax).\\n\\n        in sub_leaf of type int\\n            CPUID leaf sub index (ecx). This currently only applies to cache\\n            information on Intel CPUs. Use 0 if retrieving values for\\n            :py:func:`IMachine.set_cpuid_leaf` .\\n\\n        out val_eax of type int\\n            CPUID leaf value for register eax.\\n\\n        out val_ebx of type int\\n            CPUID leaf value for register ebx.\\n\\n        out val_ecx of type int\\n            CPUID leaf value for register ecx.\\n\\n        out val_edx of type int\\n            CPUID leaf value for register edx.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        if not isinstance(leaf, baseinteger):\\n            raise TypeError(\"leaf can only be an instance of type baseinteger\")\\n        if not isinstance(sub_leaf, baseinteger):\\n            raise TypeError(\"sub_leaf can only be an instance of type baseinteger\")\\n        (val_eax, val_ebx, val_ecx, val_edx) = self._call(\"getProcessorCPUIDLeaf\",\\n                     in_p=[cpu_id, leaf, sub_leaf])\\n        return (val_eax, val_ebx, val_ecx, val_edx)',\n",
              " 'def create_host_only_network_interface(self):\\n        \"\"\"Creates a new adapter for Host Only Networking.\\n\\n        out host_interface of type :class:`IHostNetworkInterface`\\n            Created host interface object.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Host network interface @a name already exists.\\n        \\n        \"\"\"\\n        (progress, host_interface) = self._call(\"createHostOnlyNetworkInterface\")\\n        progress = IProgress(progress)\\n        host_interface = IHostNetworkInterface(host_interface)\\n        return (progress, host_interface)',\n",
              " 'def remove_host_only_network_interface(self, id_p):\\n        \"\"\"Removes the given Host Only Networking interface.\\n\\n        in id_p of type str\\n            Adapter GUID.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            No host network interface matching @a id found.\\n        \\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        progress = self._call(\"removeHostOnlyNetworkInterface\",\\n                     in_p=[id_p])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def create_usb_device_filter(self, name):\\n        \"\"\"Creates a new USB device filter. All attributes except\\n        the filter name are set to empty (any match),\\n        *active* is @c false (the filter is not active).\\n        \\n        The created filter can be added to the list of filters using\\n        :py:func:`insert_usb_device_filter` .\\n        \\n        :py:func:`usb_device_filters` \\n\\n        in name of type str\\n            Filter name. See :py:func:`IUSBDeviceFilter.name`  for more information.\\n\\n        return filter_p of type :class:`IHostUSBDeviceFilter`\\n            Created filter object.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        filter_p = self._call(\"createUSBDeviceFilter\",\\n                     in_p=[name])\\n        filter_p = IHostUSBDeviceFilter(filter_p)\\n        return filter_p',\n",
              " 'def insert_usb_device_filter(self, position, filter_p):\\n        \"\"\"Inserts the given USB device to the specified position\\n        in the list of filters.\\n        \\n        Positions are numbered starting from @c 0. If the specified\\n        position is equal to or greater than the number of elements in\\n        the list, the filter is added at the end of the collection.\\n        \\n        \\n        Duplicates are not allowed, so an attempt to insert a\\n        filter already in the list is an error.\\n        \\n        \\n        If USB functionality is not available in the given edition of\\n        VirtualBox, this method will set the result code to @c E_NOTIMPL.\\n        \\n        \\n        :py:func:`usb_device_filters` \\n\\n        in position of type int\\n            Position to insert the filter to.\\n\\n        in filter_p of type :class:`IHostUSBDeviceFilter`\\n            USB device filter to insert.\\n\\n        raises :class:`VBoxErrorInvalidObjectState`\\n            USB device filter is not created within this VirtualBox instance.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            USB device filter already in list.\\n        \\n        \"\"\"\\n        if not isinstance(position, baseinteger):\\n            raise TypeError(\"position can only be an instance of type baseinteger\")\\n        if not isinstance(filter_p, IHostUSBDeviceFilter):\\n            raise TypeError(\"filter_p can only be an instance of type IHostUSBDeviceFilter\")\\n        self._call(\"insertUSBDeviceFilter\",\\n                     in_p=[position, filter_p])',\n",
              " 'def remove_usb_device_filter(self, position):\\n        \"\"\"Removes a USB device filter from the specified position in the\\n        list of filters.\\n        \\n        Positions are numbered starting from @c 0. Specifying a\\n        position equal to or greater than the number of elements in\\n        the list will produce an error.\\n        \\n        \\n        If USB functionality is not available in the given edition of\\n        VirtualBox, this method will set the result code to @c E_NOTIMPL.\\n        \\n        \\n        :py:func:`usb_device_filters` \\n\\n        in position of type int\\n            Position to remove the filter from.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            USB device filter list empty or invalid @a position.\\n        \\n        \"\"\"\\n        if not isinstance(position, baseinteger):\\n            raise TypeError(\"position can only be an instance of type baseinteger\")\\n        self._call(\"removeUSBDeviceFilter\",\\n                     in_p=[position])',\n",
              " 'def find_host_dvd_drive(self, name):\\n        \"\"\"Searches for a host DVD drive with the given @c name.\\n\\n        in name of type str\\n            Name of the host drive to search for\\n\\n        return drive of type :class:`IMedium`\\n            Found host drive object\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Given @c name does not correspond to any host drive.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        drive = self._call(\"findHostDVDDrive\",\\n                     in_p=[name])\\n        drive = IMedium(drive)\\n        return drive',\n",
              " 'def find_host_network_interface_by_name(self, name):\\n        \"\"\"Searches through all host network interfaces for an interface with\\n        the given @c name.\\n        \\n        The method returns an error if the given @c name does not\\n        correspond to any host network interface.\\n\\n        in name of type str\\n            Name of the host network interface to search for.\\n\\n        return network_interface of type :class:`IHostNetworkInterface`\\n            Found host network interface object.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        network_interface = self._call(\"findHostNetworkInterfaceByName\",\\n                     in_p=[name])\\n        network_interface = IHostNetworkInterface(network_interface)\\n        return network_interface',\n",
              " 'def find_host_network_interface_by_id(self, id_p):\\n        \"\"\"Searches through all host network interfaces for an interface with\\n        the given GUID.\\n        \\n        The method returns an error if the given GUID does not\\n        correspond to any host network interface.\\n\\n        in id_p of type str\\n            GUID of the host network interface to search for.\\n\\n        return network_interface of type :class:`IHostNetworkInterface`\\n            Found host network interface object.\\n\\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        network_interface = self._call(\"findHostNetworkInterfaceById\",\\n                     in_p=[id_p])\\n        network_interface = IHostNetworkInterface(network_interface)\\n        return network_interface',\n",
              " 'def find_host_network_interfaces_of_type(self, type_p):\\n        \"\"\"Searches through all host network interfaces and returns a list of interfaces of the specified type\\n\\n        in type_p of type :class:`HostNetworkInterfaceType`\\n            type of the host network interfaces to search for.\\n\\n        return network_interfaces of type :class:`IHostNetworkInterface`\\n            Found host network interface objects.\\n\\n        \"\"\"\\n        if not isinstance(type_p, HostNetworkInterfaceType):\\n            raise TypeError(\"type_p can only be an instance of type HostNetworkInterfaceType\")\\n        network_interfaces = self._call(\"findHostNetworkInterfacesOfType\",\\n                     in_p=[type_p])\\n        network_interfaces = [IHostNetworkInterface(a) for a in network_interfaces]\\n        return network_interfaces',\n",
              " 'def find_usb_device_by_id(self, id_p):\\n        \"\"\"Searches for a USB device with the given UUID.\\n        \\n        \\n        \\n        :py:func:`IUSBDevice.id_p` \\n\\n        in id_p of type str\\n            UUID of the USB device to search for.\\n\\n        return device of type :class:`IHostUSBDevice`\\n            Found USB device object.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Given @c id does not correspond to any USB device.\\n        \\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        device = self._call(\"findUSBDeviceById\",\\n                     in_p=[id_p])\\n        device = IHostUSBDevice(device)\\n        return device',\n",
              " 'def find_usb_device_by_address(self, name):\\n        \"\"\"Searches for a USB device with the given host address.\\n        \\n        \\n        \\n        :py:func:`IUSBDevice.address` \\n\\n        in name of type str\\n            Address of the USB device (as assigned by the host) to\\n            search for.\\n\\n        return device of type :class:`IHostUSBDevice`\\n            Found USB device object.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Given @c name does not correspond to any USB device.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        device = self._call(\"findUSBDeviceByAddress\",\\n                     in_p=[name])\\n        device = IHostUSBDevice(device)\\n        return device',\n",
              " 'def add_usb_device_source(self, backend, id_p, address, property_names, property_values):\\n        \"\"\"Adds a new USB device source.\\n\\n        in backend of type str\\n            The backend to use as the new device source.\\n\\n        in id_p of type str\\n            Unique ID to identify the source.\\n\\n        in address of type str\\n            Address to use, the format is dependent on the backend.\\n            For USB/IP backends for example the notation is host[:port].\\n\\n        in property_names of type str\\n            Array of property names for more detailed configuration. Not used at the moment.\\n\\n        in property_values of type str\\n            Array of property values for more detailed configuration. Not used at the moment.\\n\\n        \"\"\"\\n        if not isinstance(backend, basestring):\\n            raise TypeError(\"backend can only be an instance of type basestring\")\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        if not isinstance(address, basestring):\\n            raise TypeError(\"address can only be an instance of type basestring\")\\n        if not isinstance(property_names, list):\\n            raise TypeError(\"property_names can only be an instance of type list\")\\n        for a in property_names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(property_values, list):\\n            raise TypeError(\"property_values can only be an instance of type list\")\\n        for a in property_values[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"addUSBDeviceSource\",\\n                     in_p=[backend, id_p, address, property_names, property_values])',\n",
              " 'def remove_usb_device_source(self, id_p):\\n        \"\"\"Removes a previously added USB device source.\\n\\n        in id_p of type str\\n            The identifier used when the source was added.\\n\\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        self._call(\"removeUSBDeviceSource\",\\n                     in_p=[id_p])',\n",
              " 'def get_max_network_adapters(self, chipset):\\n        \"\"\"Maximum total number of network adapters associated with every\\n        :py:class:`IMachine`  instance.\\n\\n        in chipset of type :class:`ChipsetType`\\n            The chipset type to get the value for.\\n\\n        return max_network_adapters of type int\\n            The maximum total number of network adapters allowed.\\n\\n        \"\"\"\\n        if not isinstance(chipset, ChipsetType):\\n            raise TypeError(\"chipset can only be an instance of type ChipsetType\")\\n        max_network_adapters = self._call(\"getMaxNetworkAdapters\",\\n                     in_p=[chipset])\\n        return max_network_adapters',\n",
              " 'def get_max_network_adapters_of_type(self, chipset, type_p):\\n        \"\"\"Maximum number of network adapters of a given attachment type,\\n        associated with every :py:class:`IMachine`  instance.\\n\\n        in chipset of type :class:`ChipsetType`\\n            The chipset type to get the value for.\\n\\n        in type_p of type :class:`NetworkAttachmentType`\\n            Type of attachment.\\n\\n        return max_network_adapters of type int\\n            The maximum number of network adapters allowed for\\n            particular chipset and attachment type.\\n\\n        \"\"\"\\n        if not isinstance(chipset, ChipsetType):\\n            raise TypeError(\"chipset can only be an instance of type ChipsetType\")\\n        if not isinstance(type_p, NetworkAttachmentType):\\n            raise TypeError(\"type_p can only be an instance of type NetworkAttachmentType\")\\n        max_network_adapters = self._call(\"getMaxNetworkAdaptersOfType\",\\n                     in_p=[chipset, type_p])\\n        return max_network_adapters',\n",
              " 'def get_max_devices_per_port_for_storage_bus(self, bus):\\n        \"\"\"Returns the maximum number of devices which can be attached to a port\\n        for the given storage bus.\\n\\n        in bus of type :class:`StorageBus`\\n            The storage bus type to get the value for.\\n\\n        return max_devices_per_port of type int\\n            The maximum number of devices which can be attached to the port for the given\\n            storage bus.\\n\\n        \"\"\"\\n        if not isinstance(bus, StorageBus):\\n            raise TypeError(\"bus can only be an instance of type StorageBus\")\\n        max_devices_per_port = self._call(\"getMaxDevicesPerPortForStorageBus\",\\n                     in_p=[bus])\\n        return max_devices_per_port',\n",
              " 'def get_min_port_count_for_storage_bus(self, bus):\\n        \"\"\"Returns the minimum number of ports the given storage bus supports.\\n\\n        in bus of type :class:`StorageBus`\\n            The storage bus type to get the value for.\\n\\n        return min_port_count of type int\\n            The minimum number of ports for the given storage bus.\\n\\n        \"\"\"\\n        if not isinstance(bus, StorageBus):\\n            raise TypeError(\"bus can only be an instance of type StorageBus\")\\n        min_port_count = self._call(\"getMinPortCountForStorageBus\",\\n                     in_p=[bus])\\n        return min_port_count',\n",
              " 'def get_max_port_count_for_storage_bus(self, bus):\\n        \"\"\"Returns the maximum number of ports the given storage bus supports.\\n\\n        in bus of type :class:`StorageBus`\\n            The storage bus type to get the value for.\\n\\n        return max_port_count of type int\\n            The maximum number of ports for the given storage bus.\\n\\n        \"\"\"\\n        if not isinstance(bus, StorageBus):\\n            raise TypeError(\"bus can only be an instance of type StorageBus\")\\n        max_port_count = self._call(\"getMaxPortCountForStorageBus\",\\n                     in_p=[bus])\\n        return max_port_count',\n",
              " 'def get_max_instances_of_storage_bus(self, chipset, bus):\\n        \"\"\"Returns the maximum number of storage bus instances which\\n        can be configured for each VM. This corresponds to the number of\\n        storage controllers one can have. Value may depend on chipset type\\n        used.\\n\\n        in chipset of type :class:`ChipsetType`\\n            The chipset type to get the value for.\\n\\n        in bus of type :class:`StorageBus`\\n            The storage bus type to get the value for.\\n\\n        return max_instances of type int\\n            The maximum number of instances for the given storage bus.\\n\\n        \"\"\"\\n        if not isinstance(chipset, ChipsetType):\\n            raise TypeError(\"chipset can only be an instance of type ChipsetType\")\\n        if not isinstance(bus, StorageBus):\\n            raise TypeError(\"bus can only be an instance of type StorageBus\")\\n        max_instances = self._call(\"getMaxInstancesOfStorageBus\",\\n                     in_p=[chipset, bus])\\n        return max_instances',\n",
              " 'def get_device_types_for_storage_bus(self, bus):\\n        \"\"\"Returns list of all the supported device types\\n        (:py:class:`DeviceType` ) for the given type of storage\\n        bus.\\n\\n        in bus of type :class:`StorageBus`\\n            The storage bus type to get the value for.\\n\\n        return device_types of type :class:`DeviceType`\\n            The list of all supported device types for the given storage bus.\\n\\n        \"\"\"\\n        if not isinstance(bus, StorageBus):\\n            raise TypeError(\"bus can only be an instance of type StorageBus\")\\n        device_types = self._call(\"getDeviceTypesForStorageBus\",\\n                     in_p=[bus])\\n        device_types = [DeviceType(a) for a in device_types]\\n        return device_types',\n",
              " 'def get_default_io_cache_setting_for_storage_controller(self, controller_type):\\n        \"\"\"Returns the default I/O cache setting for the\\n        given storage controller\\n\\n        in controller_type of type :class:`StorageControllerType`\\n            The storage controller type to get the setting for.\\n\\n        return enabled of type bool\\n            Returned flag indicating the default value\\n\\n        \"\"\"\\n        if not isinstance(controller_type, StorageControllerType):\\n            raise TypeError(\"controller_type can only be an instance of type StorageControllerType\")\\n        enabled = self._call(\"getDefaultIoCacheSettingForStorageController\",\\n                     in_p=[controller_type])\\n        return enabled',\n",
              " 'def get_storage_controller_hotplug_capable(self, controller_type):\\n        \"\"\"Returns whether the given storage controller supports\\n        hot-plugging devices.\\n\\n        in controller_type of type :class:`StorageControllerType`\\n            The storage controller to check the setting for.\\n\\n        return hotplug_capable of type bool\\n            Returned flag indicating whether the controller is hotplug capable\\n\\n        \"\"\"\\n        if not isinstance(controller_type, StorageControllerType):\\n            raise TypeError(\"controller_type can only be an instance of type StorageControllerType\")\\n        hotplug_capable = self._call(\"getStorageControllerHotplugCapable\",\\n                     in_p=[controller_type])\\n        return hotplug_capable',\n",
              " 'def get_max_instances_of_usb_controller_type(self, chipset, type_p):\\n        \"\"\"Returns the maximum number of USB controller instances which\\n        can be configured for each VM. This corresponds to the number of\\n        USB controllers one can have. Value may depend on chipset type\\n        used.\\n\\n        in chipset of type :class:`ChipsetType`\\n            The chipset type to get the value for.\\n\\n        in type_p of type :class:`USBControllerType`\\n            The USB controller type to get the value for.\\n\\n        return max_instances of type int\\n            The maximum number of instances for the given USB controller type.\\n\\n        \"\"\"\\n        if not isinstance(chipset, ChipsetType):\\n            raise TypeError(\"chipset can only be an instance of type ChipsetType\")\\n        if not isinstance(type_p, USBControllerType):\\n            raise TypeError(\"type_p can only be an instance of type USBControllerType\")\\n        max_instances = self._call(\"getMaxInstancesOfUSBControllerType\",\\n                     in_p=[chipset, type_p])\\n        return max_instances',\n",
              " 'def is_format_supported(self, format_p):\\n        \"\"\"Checks if a specific drag\\'n drop MIME / Content-type format is supported.\\n\\n        in format_p of type str\\n            Format to check for.\\n\\n        return supported of type bool\\n            Returns @c true if the specified format is supported, @c false if not.\\n\\n        \"\"\"\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        supported = self._call(\"isFormatSupported\",\\n                     in_p=[format_p])\\n        return supported',\n",
              " 'def add_formats(self, formats):\\n        \"\"\"Adds MIME / Content-type formats to the supported formats.\\n\\n        in formats of type str\\n            Collection of formats to add.\\n\\n        \"\"\"\\n        if not isinstance(formats, list):\\n            raise TypeError(\"formats can only be an instance of type list\")\\n        for a in formats[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"addFormats\",\\n                     in_p=[formats])',\n",
              " 'def drag_is_pending(self, screen_id):\\n        \"\"\"Ask the source if there is any drag and drop operation pending.\\n        If no drag and drop operation is pending currently, DnDAction_Ignore is returned.\\n\\n        in screen_id of type int\\n            The screen ID where the drag and drop event occurred.\\n\\n        out formats of type str\\n            On return the supported mime types.\\n\\n        out allowed_actions of type :class:`DnDAction`\\n            On return the actions which are allowed.\\n\\n        return default_action of type :class:`DnDAction`\\n            On return the default action to use.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        (default_action, formats, allowed_actions) = self._call(\"dragIsPending\",\\n                     in_p=[screen_id])\\n        default_action = DnDAction(default_action)\\n        allowed_actions = [DnDAction(a) for a in allowed_actions]\\n        return (default_action, formats, allowed_actions)',\n",
              " 'def drop(self, format_p, action):\\n        \"\"\"Informs the source that a drop event occurred for a pending\\n        drag and drop operation.\\n\\n        in format_p of type str\\n            The mime type the data must be in.\\n\\n        in action of type :class:`DnDAction`\\n            The action to use.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        if not isinstance(action, DnDAction):\\n            raise TypeError(\"action can only be an instance of type DnDAction\")\\n        progress = self._call(\"drop\",\\n                     in_p=[format_p, action])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def enter(self, screen_id, y, x, default_action, allowed_actions, formats):\\n        \"\"\"Informs the target about a drag and drop enter event.\\n\\n        in screen_id of type int\\n            The screen ID where the drag and drop event occurred.\\n\\n        in y of type int\\n            Y-position of the event.\\n\\n        in x of type int\\n            X-position of the event.\\n\\n        in default_action of type :class:`DnDAction`\\n            The default action to use.\\n\\n        in allowed_actions of type :class:`DnDAction`\\n            The actions which are allowed.\\n\\n        in formats of type str\\n            The supported MIME types.\\n\\n        return result_action of type :class:`DnDAction`\\n            The resulting action of this event.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(default_action, DnDAction):\\n            raise TypeError(\"default_action can only be an instance of type DnDAction\")\\n        if not isinstance(allowed_actions, list):\\n            raise TypeError(\"allowed_actions can only be an instance of type list\")\\n        for a in allowed_actions[:10]:\\n            if not isinstance(a, DnDAction):\\n                raise TypeError(\\n                        \"array can only contain objects of type DnDAction\")\\n        if not isinstance(formats, list):\\n            raise TypeError(\"formats can only be an instance of type list\")\\n        for a in formats[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        result_action = self._call(\"enter\",\\n                     in_p=[screen_id, y, x, default_action, allowed_actions, formats])\\n        result_action = DnDAction(result_action)\\n        return result_action',\n",
              " 'def leave(self, screen_id):\\n        \"\"\"Informs the target about a drag and drop leave event.\\n\\n        in screen_id of type int\\n            The screen ID where the drag and drop event occurred.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        self._call(\"leave\",\\n                     in_p=[screen_id])',\n",
              " 'def send_data(self, screen_id, format_p, data):\\n        \"\"\"Initiates sending data to the target.\\n\\n        in screen_id of type int\\n            The screen ID where the drag and drop event occurred.\\n\\n        in format_p of type str\\n            The MIME type the data is in.\\n\\n        in data of type str\\n            The actual data.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        if not isinstance(data, list):\\n            raise TypeError(\"data can only be an instance of type list\")\\n        for a in data[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        progress = self._call(\"sendData\",\\n                     in_p=[screen_id, format_p, data])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def copy_from_guest(self, sources, filters, flags, destination):\\n        \"\"\"Copies directories and/or files from guest to the host.\\n        \\n        This function requires several parallel arrays to be supplied, one\\n        set for each source.\\n\\n        in sources of type str\\n            Paths to directories and/or files on the guest side that should be\\n            copied to the host. If the path ends with a path delimiter, only\\n            the directory\\'s content is being copied. Guest path style.\\n\\n        in filters of type str\\n            Array of source filters. This uses the\\n            DOS/NT style wildcard characters \\'?\\' and \\'*\\'.\\n\\n        in flags of type str\\n            Array of comma-separated list of source flags.\\n            \\n            The following flags are available for directory sources:\\n            \\n            \\n            \\n            CopyIntoExisting\\n            Allow copying into an existing destination directory.\\n            \\n            \\n            \\n            The following flags are available for file sources:\\n            \\n            \\n            \\n            NoReplace\\n            Do not replace any destination object.\\n            \\n            \\n            FollowLinks\\n            Follows (and handles) (symbolic) links.\\n            \\n            \\n            Update\\n            Only copy when the source file is newer than the destination\\n            file or when the destination file is missing.\\n\\n        in destination of type str\\n            Where to put the sources on the host. Host path style.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation to completion.\\n\\n        \"\"\"\\n        if not isinstance(sources, list):\\n            raise TypeError(\"sources can only be an instance of type list\")\\n        for a in sources[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(filters, list):\\n            raise TypeError(\"filters can only be an instance of type list\")\\n        for a in filters[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(destination, basestring):\\n            raise TypeError(\"destination can only be an instance of type basestring\")\\n        progress = self._call(\"copyFromGuest\",\\n                     in_p=[sources, filters, flags, destination])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def directory_copy(self, source, destination, flags):\\n        \"\"\"Recursively copies a directory from one guest location to another.\\n\\n        in source of type str\\n            The path to the directory to copy (in the guest).  Guest path style.\\n\\n        in destination of type str\\n            The path to the target directory (in the guest).  Unless the\\n            :py:attr:`DirectoryCopyFlag.copy_into_existing`  flag is given, the\\n            directory shall not already exist.  Guest path style.\\n\\n        in flags of type :class:`DirectoryCopyFlag`\\n            Zero or more :py:class:`DirectoryCopyFlag`  values.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation to completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            Not yet implemented.\\n        \\n        \"\"\"\\n        if not isinstance(source, basestring):\\n            raise TypeError(\"source can only be an instance of type basestring\")\\n        if not isinstance(destination, basestring):\\n            raise TypeError(\"destination can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, DirectoryCopyFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type DirectoryCopyFlag\")\\n        progress = self._call(\"directoryCopy\",\\n                     in_p=[source, destination, flags])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def directory_create(self, path, mode, flags):\\n        \"\"\"Creates a directory in the guest.\\n\\n        in path of type str\\n            Path to the directory directory to be created. Guest path style.\\n\\n        in mode of type int\\n            The UNIX-style access mode mask to create the directory with.\\n            Whether/how all three access groups and associated access rights are\\n            realized is guest OS dependent.  The API does the best it can on each\\n            OS.\\n\\n        in flags of type :class:`DirectoryCreateFlag`\\n            Zero or more :py:class:`DirectoryCreateFlag`  flags.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Error while creating the directory.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(mode, baseinteger):\\n            raise TypeError(\"mode can only be an instance of type baseinteger\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, DirectoryCreateFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type DirectoryCreateFlag\")\\n        self._call(\"directoryCreate\",\\n                     in_p=[path, mode, flags])',\n",
              " 'def directory_create_temp(self, template_name, mode, path, secure):\\n        \"\"\"Creates a temporary directory in the guest.\\n\\n        in template_name of type str\\n            Template for the name of the directory to create. This must\\n            contain at least one \\'X\\' character. The first group of consecutive\\n            \\'X\\' characters in the template will be replaced by a random\\n            alphanumeric string to produce a unique name.\\n\\n        in mode of type int\\n            The UNIX-style access mode mask to create the directory with.\\n            Whether/how all three access groups and associated access rights are\\n            realized is guest OS dependent.  The API does the best it can on each\\n            OS.\\n            \\n            This parameter is ignore if the @a secure parameter is set to @c true.\\n            It is strongly recommended to use 0700.\\n\\n        in path of type str\\n            The path to the directory in which the temporary directory should\\n            be created. Guest path style.\\n\\n        in secure of type bool\\n            Whether to fail if the directory can not be securely created.\\n            Currently this means that another unprivileged user cannot\\n            manipulate the path specified or remove the temporary directory\\n            after it has been created. Also causes the mode specified to be\\n            ignored. May not be supported on all guest types.\\n\\n        return directory of type str\\n            On success this will contain the full path to the created\\n            directory. Guest path style.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            The operation is not possible as requested on this particular\\nguest type.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid argument. This includes an incorrectly formatted template,\\nor a non-absolute path.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            The temporary directory could not be created. Possible reasons\\ninclude a non-existing path or an insecure path when the secure\\noption was requested.\\n        \\n        \"\"\"\\n        if not isinstance(template_name, basestring):\\n            raise TypeError(\"template_name can only be an instance of type basestring\")\\n        if not isinstance(mode, baseinteger):\\n            raise TypeError(\"mode can only be an instance of type baseinteger\")\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(secure, bool):\\n            raise TypeError(\"secure can only be an instance of type bool\")\\n        directory = self._call(\"directoryCreateTemp\",\\n                     in_p=[template_name, mode, path, secure])\\n        return directory',\n",
              " 'def directory_open(self, path, filter_p, flags):\\n        \"\"\"Opens a directory in the guest and creates a :py:class:`IGuestDirectory` \\n        object that can be used for further operations.\\n        \\n        This method follows symbolic links by default at the moment, this\\n        may change in the future.\\n\\n        in path of type str\\n            Path to the directory to open. Guest path style.\\n\\n        in filter_p of type str\\n            Optional directory listing filter to apply.  This uses the DOS/NT\\n            style wildcard characters \\'?\\' and \\'*\\'.\\n\\n        in flags of type :class:`DirectoryOpenFlag`\\n            Zero or more :py:class:`DirectoryOpenFlag`  flags.\\n\\n        return directory of type :class:`IGuestDirectory`\\n            :py:class:`IGuestDirectory`  object containing the opened directory.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Directory to open was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error while opening the directory.\\n        \\n        raises :class:`VBoxErrorMaximumReached`\\n            The maximum of concurrent guest directories has been reached.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(filter_p, basestring):\\n            raise TypeError(\"filter_p can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, DirectoryOpenFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type DirectoryOpenFlag\")\\n        directory = self._call(\"directoryOpen\",\\n                     in_p=[path, filter_p, flags])\\n        directory = IGuestDirectory(directory)\\n        return directory',\n",
              " 'def directory_remove(self, path):\\n        \"\"\"Removes a guest directory if empty.\\n        \\n        Symbolic links in the final component will not be followed,\\n        instead an not-a-directory error is reported.\\n\\n        in path of type str\\n            Path to the directory that should be removed. Guest path style.\\n\\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        self._call(\"directoryRemove\",\\n                     in_p=[path])',\n",
              " 'def directory_remove_recursive(self, path, flags):\\n        \"\"\"Removes a guest directory recursively.\\n        \\n        <!--  Add this back when the warning can be removed:\\n        Unless :py:attr:`DirectoryRemoveRecFlag.content_and_dir`  or\\n        :py:attr:`DirectoryRemoveRecFlag.content_only`  is given, only the\\n        directory structure is removed.  Which means it will fail if there are\\n        directories which are not empty in the directory tree @a path points to.\\n        -->\\n        \\n        WARNING!! THE FLAGS ARE NOT CURRENTLY IMPLEMENTED.  THE IMPLEMENTATION\\n        WORKS AS IF FLAGS WAS SET TO :py:attr:`DirectoryRemoveRecFlag.content_and_dir` .\\n        \\n        \\n        If the final path component is a symbolic link, this method will\\n        fail as it can only be applied to directories.\\n\\n        in path of type str\\n            Path of the directory that is to be removed recursively. Guest\\n            path style.\\n\\n        in flags of type :class:`DirectoryRemoveRecFlag`\\n            Zero or more :py:class:`DirectoryRemoveRecFlag`  flags.\\n            WARNING! SPECIFYING :py:attr:`DirectoryRemoveRecFlag.content_and_dir`  IS\\n            MANDATORY AT THE MOMENT!!\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion. This is not implemented\\n            yet and therefore this method call will block until deletion is completed.\\n\\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, DirectoryRemoveRecFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type DirectoryRemoveRecFlag\")\\n        progress = self._call(\"directoryRemoveRecursive\",\\n                     in_p=[path, flags])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def environment_schedule_unset(self, name):\\n        \"\"\"Schedules unsetting (removing) an environment variable when creating\\n        the next guest process.  This affects the\\n        :py:func:`IGuestSession.environment_changes`  attribute.\\n\\n        in name of type str\\n            Name of the environment variable to unset.  This cannot be empty\\n            nor can it contain any equal signs.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"environmentScheduleUnset\",\\n                     in_p=[name])',\n",
              " 'def environment_does_base_variable_exist(self, name):\\n        \"\"\"Checks if the given environment variable exists in the session\\'s base\\n        environment (:py:func:`IGuestSession.environment_base` ).\\n\\n        in name of type str\\n            Name of the environment variable to look for.  This cannot be\\n            empty nor can it contain any equal signs.\\n\\n        return exists of type bool\\n            TRUE if the variable exists, FALSE if not.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            If the guest additions does not\\nsupport the session base environment feature.  Support for this was\\nintroduced with protocol version XXXX.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            If the guest additions has\\nyet to report the session base environment.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        exists = self._call(\"environmentDoesBaseVariableExist\",\\n                     in_p=[name])\\n        return exists',\n",
              " 'def file_copy(self, source, destination, flags):\\n        \"\"\"Copies a file from one guest location to another.\\n        \\n        Will overwrite the destination file unless\\n        :py:attr:`FileCopyFlag.no_replace`  is specified.\\n\\n        in source of type str\\n            The path to the file to copy (in the guest).  Guest path style.\\n\\n        in destination of type str\\n            The path to the target file (in the guest).  This cannot be a\\n            directory.  Guest path style.\\n\\n        in flags of type :class:`FileCopyFlag`\\n            Zero or more :py:class:`FileCopyFlag`  values.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation to completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            Not yet implemented.\\n        \\n        \"\"\"\\n        if not isinstance(source, basestring):\\n            raise TypeError(\"source can only be an instance of type basestring\")\\n        if not isinstance(destination, basestring):\\n            raise TypeError(\"destination can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, FileCopyFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type FileCopyFlag\")\\n        progress = self._call(\"fileCopy\",\\n                     in_p=[source, destination, flags])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def file_create_temp(self, template_name, mode, path, secure):\\n        \"\"\"Creates a temporary file in the guest.\\n\\n        in template_name of type str\\n            Template for the name of the file to create. This must contain\\n            at least one \\'X\\' character. The first group of consecutive \\'X\\'\\n            characters in the template will be replaced by a random\\n            alphanumeric string to produce a unique name.\\n\\n        in mode of type int\\n            The UNIX-style access mode mask to create the file with.\\n            Whether/how all three access groups and associated access rights are\\n            realized is guest OS dependent.  The API does the best it can on each\\n            OS.\\n            \\n            This parameter is ignore if the @a secure parameter is set to @c true.\\n            It is strongly recommended to use 0600.\\n\\n        in path of type str\\n            The path to the directory in which the temporary file should be\\n            created.\\n\\n        in secure of type bool\\n            Whether to fail if the file can not be securely created.\\n            Currently this means that another unprivileged user cannot\\n            manipulate the path specified or remove the temporary file after\\n            it has been created. Also causes the mode specified to be ignored.\\n            May not be supported on all guest types.\\n\\n        return file_p of type :class:`IGuestFile`\\n            On success this will contain an open file object for the new\\n            temporary file.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            The operation is not possible as requested on this particular\\nguest OS.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            Invalid argument. This includes an incorrectly formatted template,\\nor a non-absolute path.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            The temporary file could not be created. Possible reasons include\\na non-existing path or an insecure path when the secure\\noption was requested.\\n        \\n        \"\"\"\\n        if not isinstance(template_name, basestring):\\n            raise TypeError(\"template_name can only be an instance of type basestring\")\\n        if not isinstance(mode, baseinteger):\\n            raise TypeError(\"mode can only be an instance of type baseinteger\")\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(secure, bool):\\n            raise TypeError(\"secure can only be an instance of type bool\")\\n        file_p = self._call(\"fileCreateTemp\",\\n                     in_p=[template_name, mode, path, secure])\\n        file_p = IGuestFile(file_p)\\n        return file_p',\n",
              " 'def file_open(self, path, access_mode, open_action, creation_mode):\\n        \"\"\"Opens a file and creates a :py:class:`IGuestFile`  object that\\n        can be used for further operations.\\n\\n        in path of type str\\n            Path to file to open.  Guest path style.\\n\\n        in access_mode of type :class:`FileAccessMode`\\n            The file access mode (read, write and/or append).\\n            See :py:class:`FileAccessMode`  for details.\\n\\n        in open_action of type :class:`FileOpenAction`\\n            What action to take depending on whether the file exists or not.\\n            See :py:class:`FileOpenAction`  for details.\\n\\n        in creation_mode of type int\\n            The UNIX-style access mode mask to create the file with if @a openAction\\n            requested the file to be created (otherwise ignored).  Whether/how all\\n            three access groups and associated access rights are realized is guest\\n            OS dependent.  The API does the best it can on each OS.\\n\\n        return file_p of type :class:`IGuestFile`\\n            :py:class:`IGuestFile`  object representing the opened file.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            File to open was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error while opening the file.\\n        \\n        raises :class:`VBoxErrorMaximumReached`\\n            The maximum of concurrent guest files has been reached.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(access_mode, FileAccessMode):\\n            raise TypeError(\"access_mode can only be an instance of type FileAccessMode\")\\n        if not isinstance(open_action, FileOpenAction):\\n            raise TypeError(\"open_action can only be an instance of type FileOpenAction\")\\n        if not isinstance(creation_mode, baseinteger):\\n            raise TypeError(\"creation_mode can only be an instance of type baseinteger\")\\n        file_p = self._call(\"fileOpen\",\\n                     in_p=[path, access_mode, open_action, creation_mode])\\n        file_p = IGuestFile(file_p)\\n        return file_p',\n",
              " 'def file_open_ex(self, path, access_mode, open_action, sharing_mode, creation_mode, flags):\\n        \"\"\"Opens a file and creates a :py:class:`IGuestFile`  object that\\n        can be used for further operations, extended version.\\n\\n        in path of type str\\n            Path to file to open.  Guest path style.\\n\\n        in access_mode of type :class:`FileAccessMode`\\n            The file access mode (read, write and/or append).\\n            See :py:class:`FileAccessMode`  for details.\\n\\n        in open_action of type :class:`FileOpenAction`\\n            What action to take depending on whether the file exists or not.\\n            See :py:class:`FileOpenAction`  for details.\\n\\n        in sharing_mode of type :class:`FileSharingMode`\\n            The file sharing mode in the guest. This parameter is currently\\n            ignore for all guest OSes.  It will in the future be implemented for\\n            Windows, OS/2 and maybe Solaris guests only, the others will ignore it.\\n            Use :py:attr:`FileSharingMode.all_p` .\\n\\n        in creation_mode of type int\\n            The UNIX-style access mode mask to create the file with if @a openAction\\n            requested the file to be created (otherwise ignored).  Whether/how all\\n            three access groups and associated access rights are realized is guest\\n            OS dependent.  The API does the best it can on each OS.\\n\\n        in flags of type :class:`FileOpenExFlag`\\n            Zero or more :py:class:`FileOpenExFlag`  values.\\n\\n        return file_p of type :class:`IGuestFile`\\n            :py:class:`IGuestFile`  object representing the opened file.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            File to open was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error while opening the file.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(access_mode, FileAccessMode):\\n            raise TypeError(\"access_mode can only be an instance of type FileAccessMode\")\\n        if not isinstance(open_action, FileOpenAction):\\n            raise TypeError(\"open_action can only be an instance of type FileOpenAction\")\\n        if not isinstance(sharing_mode, FileSharingMode):\\n            raise TypeError(\"sharing_mode can only be an instance of type FileSharingMode\")\\n        if not isinstance(creation_mode, baseinteger):\\n            raise TypeError(\"creation_mode can only be an instance of type baseinteger\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, FileOpenExFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type FileOpenExFlag\")\\n        file_p = self._call(\"fileOpenEx\",\\n                     in_p=[path, access_mode, open_action, sharing_mode, creation_mode, flags])\\n        file_p = IGuestFile(file_p)\\n        return file_p',\n",
              " 'def file_query_size(self, path, follow_symlinks):\\n        \"\"\"Queries the size of a regular file in the guest.\\n\\n        in path of type str\\n            Path to the file which size is requested.  Guest path style.\\n\\n        in follow_symlinks of type bool\\n            It @c true, symbolic links in the final path component will be\\n            followed to their target, and the size of the target is returned.\\n            If @c false, symbolic links in the final path component will make\\n            the method call fail (symblink is not a regular file).\\n\\n        return size of type int\\n            Queried file size.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            File to was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error querying file size.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(follow_symlinks, bool):\\n            raise TypeError(\"follow_symlinks can only be an instance of type bool\")\\n        size = self._call(\"fileQuerySize\",\\n                     in_p=[path, follow_symlinks])\\n        return size',\n",
              " 'def fs_obj_exists(self, path, follow_symlinks):\\n        \"\"\"Checks whether a file system object (file, directory, etc) exists in\\n        the guest or not.\\n\\n        in path of type str\\n            Path to the file system object to check the existance of.  Guest\\n            path style.\\n\\n        in follow_symlinks of type bool\\n            If @c true, symbolic links in the final component will be followed\\n            and the method will instead check if the target exists.\\n            If @c false, symbolic links in the final component will satisfy the\\n            method and it will return @c true in @a exists.\\n\\n        return exists of type bool\\n            Returns @c true if the file exists, @c false if not.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Error while checking existence of the file specified.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(follow_symlinks, bool):\\n            raise TypeError(\"follow_symlinks can only be an instance of type bool\")\\n        exists = self._call(\"fsObjExists\",\\n                     in_p=[path, follow_symlinks])\\n        return exists',\n",
              " 'def fs_obj_query_info(self, path, follow_symlinks):\\n        \"\"\"Queries information about a file system object (file, directory, etc)\\n        in the guest.\\n\\n        in path of type str\\n            Path to the file system object to gather information about.\\n            Guest path style.\\n\\n        in follow_symlinks of type bool\\n            Information about symbolic links is returned if @c false.  Otherwise,\\n            symbolic links are followed and the returned information concerns\\n            itself with the symlink target if @c true.\\n\\n        return info of type :class:`IGuestFsObjInfo`\\n            :py:class:`IGuestFsObjInfo`  object containing the information.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            The file system object was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error while querying information.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(follow_symlinks, bool):\\n            raise TypeError(\"follow_symlinks can only be an instance of type bool\")\\n        info = self._call(\"fsObjQueryInfo\",\\n                     in_p=[path, follow_symlinks])\\n        info = IGuestFsObjInfo(info)\\n        return info',\n",
              " 'def fs_obj_remove(self, path):\\n        \"\"\"Removes a file system object (file, symlink, etc) in the guest.  Will\\n        not work on directories, use :py:func:`IGuestSession.directory_remove` \\n        to remove directories.\\n        \\n        This method will remove symbolic links in the final path\\n        component, not follow them.\\n\\n        in path of type str\\n            Path to the file system object to remove.  Guest style path.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method has not been implemented yet.\\n        \\n        raises :class:`VBoxErrorObjectNotFound`\\n            The file system object was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            For most other errors. We know this is unhelpful, will fix shortly...\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        self._call(\"fsObjRemove\",\\n                     in_p=[path])',\n",
              " 'def fs_obj_remove_array(self, path):\\n        \"\"\"Removes multiple file system objects (files, directories, symlinks, etc)\\n        in the guest. Use with caution.\\n        \\n        This method is not implemented yet and will return E_NOTIMPL.\\n        \\n        This method will remove symbolic links in the final path\\n        component, not follow them.\\n\\n        in path of type str\\n            Array of paths to the file system objects to remove.  Guest style path.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation to completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method has not been implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(path, list):\\n            raise TypeError(\"path can only be an instance of type list\")\\n        for a in path[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        progress = self._call(\"fsObjRemoveArray\",\\n                     in_p=[path])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def fs_obj_rename(self, old_path, new_path, flags):\\n        \"\"\"Renames a file system object (file, directory, symlink, etc) in the\\n        guest.\\n\\n        in old_path of type str\\n            The current path to the object.  Guest path style.\\n\\n        in new_path of type str\\n            The new path to the object.  Guest path style.\\n\\n        in flags of type :class:`FsObjRenameFlag`\\n            Zero or more :py:class:`FsObjRenameFlag`  values.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            The file system object was not found.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            For most other errors. We know this is unhelpful, will fix shortly...\\n        \\n        \"\"\"\\n        if not isinstance(old_path, basestring):\\n            raise TypeError(\"old_path can only be an instance of type basestring\")\\n        if not isinstance(new_path, basestring):\\n            raise TypeError(\"new_path can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, FsObjRenameFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type FsObjRenameFlag\")\\n        self._call(\"fsObjRename\",\\n                     in_p=[old_path, new_path, flags])',\n",
              " 'def fs_obj_move(self, source, destination, flags):\\n        \"\"\"Moves a file system object (file, directory, symlink, etc) from one\\n        guest location to another.\\n        \\n        This differs from :py:func:`IGuestSession.fs_obj_rename`  in that it\\n        can move accross file system boundraries.  In that case it will\\n        perform a copy and then delete the original.  For directories, this\\n        can take a while and is subject to races.\\n\\n        in source of type str\\n            Path to the file to move.  Guest path style.\\n\\n        in destination of type str\\n            Where to move the file to (file, not directory).  Guest path\\n            style.\\n\\n        in flags of type :class:`FsObjMoveFlag`\\n            Zero or more :py:class:`FsObjMoveFlag`  values.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation to completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            Not yet implemented.\\n        \\n        \"\"\"\\n        if not isinstance(source, basestring):\\n            raise TypeError(\"source can only be an instance of type basestring\")\\n        if not isinstance(destination, basestring):\\n            raise TypeError(\"destination can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, FsObjMoveFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type FsObjMoveFlag\")\\n        progress = self._call(\"fsObjMove\",\\n                     in_p=[source, destination, flags])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def fs_obj_set_acl(self, path, follow_symlinks, acl, mode):\\n        \"\"\"Sets the access control list (ACL) of a file system object (file,\\n        directory, etc) in the guest.\\n\\n        in path of type str\\n            Full path of the file system object which ACL to set\\n\\n        in follow_symlinks of type bool\\n            If @c true symbolic links in the final component will be followed,\\n            otherwise, if @c false, the method will work directly on a symbolic\\n            link in the final component.\\n\\n        in acl of type str\\n            The ACL specification string. To-be-defined.\\n\\n        in mode of type int\\n            UNIX-style mode mask to use if @a acl is empty. As mention in\\n            :py:func:`IGuestSession.directory_create`  this is realized on\\n            a best effort basis and the exact behavior depends on the Guest OS.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        if not isinstance(follow_symlinks, bool):\\n            raise TypeError(\"follow_symlinks can only be an instance of type bool\")\\n        if not isinstance(acl, basestring):\\n            raise TypeError(\"acl can only be an instance of type basestring\")\\n        if not isinstance(mode, baseinteger):\\n            raise TypeError(\"mode can only be an instance of type baseinteger\")\\n        self._call(\"fsObjSetACL\",\\n                     in_p=[path, follow_symlinks, acl, mode])',\n",
              " 'def process_create(self, executable, arguments, environment_changes, flags, timeout_ms):\\n        \"\"\"Creates a new process running in the guest. The new process will be\\n        started asynchronously, meaning on return of this function it is not\\n        be guaranteed that the guest process is in a started state. To wait for\\n        successful startup, use the :py:func:`IProcess.wait_for`  call.\\n        \\n        \\n        Starting at VirtualBox 4.2 guest process execution by is default limited\\n        to serve up to 255 guest processes at a time. If all 255 guest processes\\n        are active and running, creating a new guest process will result in an\\n        error.\\n        \\n        If ProcessCreateFlag_WaitForStdOut and/or ProcessCreateFlag_WaitForStdErr\\n        are set, the guest process will not enter the terminated state until\\n        all data from the specified streams have been read read.\\n\\n        in executable of type str\\n            Full path to the file to execute in the guest.  The file has to\\n            exists in the guest VM with executable right to the session user in\\n            order to succeed.  If empty/null, the first entry in the\\n            @a arguments array will be used instead (i.e. argv[0]).\\n\\n        in arguments of type str\\n            Array of arguments passed to the new process.\\n            \\n            Starting with VirtualBox 5.0 this array starts with argument 0\\n            instead of argument 1 as in previous versions.  Whether the zeroth\\n            argument can be passed to the guest depends on the VBoxService\\n            version running there.  If you depend on this, check that the\\n            :py:func:`IGuestSession.protocol_version`  is 3 or higher.\\n\\n        in environment_changes of type str\\n            Set of environment changes to complement\\n            :py:func:`IGuestSession.environment_changes` .  Takes precedence\\n            over the session ones.  The changes are in putenv format, i.e.\\n            \"VAR=VALUE\" for setting and \"VAR\" for unsetting.\\n            \\n            The changes are applied to the base environment of the impersonated\\n            guest user (:py:func:`IGuestSession.environment_base` ) when\\n            creating the process.  (This is done on the guest side of things in\\n            order to be compatible with older guest additions.  That is one of\\n            the motivations for not passing in the whole environment here.)\\n\\n        in flags of type :class:`ProcessCreateFlag`\\n            Process creation flags;\\n            see :py:class:`ProcessCreateFlag`  for more information.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) for limiting the guest process\\' running time.\\n            Pass 0 for an infinite timeout. On timeout the guest process will be\\n            killed and its status will be put to an appropriate value. See\\n            :py:class:`ProcessStatus`  for more information.\\n\\n        return guest_process of type :class:`IGuestProcess`\\n            Guest process object of the newly created process.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Error creating guest process.\\n        \\n        raises :class:`VBoxErrorMaximumReached`\\n            The maximum of concurrent guest processes has been reached.\\n        \\n        \"\"\"\\n        if not isinstance(executable, basestring):\\n            raise TypeError(\"executable can only be an instance of type basestring\")\\n        if not isinstance(arguments, list):\\n            raise TypeError(\"arguments can only be an instance of type list\")\\n        for a in arguments[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(environment_changes, list):\\n            raise TypeError(\"environment_changes can only be an instance of type list\")\\n        for a in environment_changes[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, ProcessCreateFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type ProcessCreateFlag\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        guest_process = self._call(\"processCreate\",\\n                     in_p=[executable, arguments, environment_changes, flags, timeout_ms])\\n        guest_process = IGuestProcess(guest_process)\\n        return guest_process',\n",
              " 'def process_create_ex(self, executable, arguments, environment_changes, flags, timeout_ms, priority, affinity):\\n        \"\"\"Creates a new process running in the guest with the extended options\\n        for setting the process priority and affinity.\\n        \\n        See :py:func:`IGuestSession.process_create`  for more information.\\n\\n        in executable of type str\\n            Full path to the file to execute in the guest.  The file has to\\n            exists in the guest VM with executable right to the session user in\\n            order to succeed.  If empty/null, the first entry in the\\n            @a arguments array will be used instead (i.e. argv[0]).\\n\\n        in arguments of type str\\n            Array of arguments passed to the new process.\\n            \\n            Starting with VirtualBox 5.0 this array starts with argument 0\\n            instead of argument 1 as in previous versions.  Whether the zeroth\\n            argument can be passed to the guest depends on the VBoxService\\n            version running there.  If you depend on this, check that the\\n            :py:func:`IGuestSession.protocol_version`  is 3 or higher.\\n\\n        in environment_changes of type str\\n            Set of environment changes to complement\\n            :py:func:`IGuestSession.environment_changes` .  Takes precedence\\n            over the session ones.  The changes are in putenv format, i.e.\\n            \"VAR=VALUE\" for setting and \"VAR\" for unsetting.\\n            \\n            The changes are applied to the base environment of the impersonated\\n            guest user (:py:func:`IGuestSession.environment_base` ) when\\n            creating the process.  (This is done on the guest side of things in\\n            order to be compatible with older guest additions.  That is one of\\n            the motivations for not passing in the whole environment here.)\\n\\n        in flags of type :class:`ProcessCreateFlag`\\n            Process creation flags, see :py:class:`ProcessCreateFlag`  for\\n            detailed description of available flags.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) for limiting the guest process\\' running time.\\n            Pass 0 for an infinite timeout. On timeout the guest process will be\\n            killed and its status will be put to an appropriate value. See\\n            :py:class:`ProcessStatus`  for more information.\\n\\n        in priority of type :class:`ProcessPriority`\\n            Process priority to use for execution, see :py:class:`ProcessPriority` \\n            for available priority levels.\\n            This is silently ignored if not supported by guest additions.\\n\\n        in affinity of type int\\n            Processor affinity to set for the new process.  This is a list of\\n            guest CPU numbers the process is allowed to run on.\\n            \\n            This is silently ignored if the guest does not support setting the\\n            affinity of processes, or if the guest additions does not implemet\\n            this feature.\\n\\n        return guest_process of type :class:`IGuestProcess`\\n            Guest process object of the newly created process.\\n\\n        \"\"\"\\n        if not isinstance(executable, basestring):\\n            raise TypeError(\"executable can only be an instance of type basestring\")\\n        if not isinstance(arguments, list):\\n            raise TypeError(\"arguments can only be an instance of type list\")\\n        for a in arguments[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(environment_changes, list):\\n            raise TypeError(\"environment_changes can only be an instance of type list\")\\n        for a in environment_changes[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, ProcessCreateFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type ProcessCreateFlag\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        if not isinstance(priority, ProcessPriority):\\n            raise TypeError(\"priority can only be an instance of type ProcessPriority\")\\n        if not isinstance(affinity, list):\\n            raise TypeError(\"affinity can only be an instance of type list\")\\n        for a in affinity[:10]:\\n            if not isinstance(a, baseinteger):\\n                raise TypeError(\\n                        \"array can only contain objects of type baseinteger\")\\n        guest_process = self._call(\"processCreateEx\",\\n                     in_p=[executable, arguments, environment_changes, flags, timeout_ms, priority, affinity])\\n        guest_process = IGuestProcess(guest_process)\\n        return guest_process',\n",
              " 'def process_get(self, pid):\\n        \"\"\"Gets a certain guest process by its process ID (PID).\\n\\n        in pid of type int\\n            Process ID (PID) to get guest process for.\\n\\n        return guest_process of type :class:`IGuestProcess`\\n            Guest process of specified process ID (PID).\\n\\n        \"\"\"\\n        if not isinstance(pid, baseinteger):\\n            raise TypeError(\"pid can only be an instance of type baseinteger\")\\n        guest_process = self._call(\"processGet\",\\n                     in_p=[pid])\\n        guest_process = IGuestProcess(guest_process)\\n        return guest_process',\n",
              " 'def symlink_create(self, symlink, target, type_p):\\n        \"\"\"Creates a symbolic link in the guest.\\n\\n        in symlink of type str\\n            Path to the symbolic link that should be created.  Guest path\\n            style.\\n\\n        in target of type str\\n            The path to the symbolic link target.  If not an absolute, this will\\n            be relative to the @a symlink location at access time.  Guest path\\n            style.\\n\\n        in type_p of type :class:`SymlinkType`\\n            The symbolic link type (mainly for Windows). See :py:class:`SymlinkType` \\n            for more information.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(symlink, basestring):\\n            raise TypeError(\"symlink can only be an instance of type basestring\")\\n        if not isinstance(target, basestring):\\n            raise TypeError(\"target can only be an instance of type basestring\")\\n        if not isinstance(type_p, SymlinkType):\\n            raise TypeError(\"type_p can only be an instance of type SymlinkType\")\\n        self._call(\"symlinkCreate\",\\n                     in_p=[symlink, target, type_p])',\n",
              " 'def symlink_exists(self, symlink):\\n        \"\"\"Checks whether a symbolic link exists in the guest.\\n\\n        in symlink of type str\\n            Path to the alleged symbolic link.  Guest path style.\\n\\n        return exists of type bool\\n            Returns @c true if the symbolic link exists.  Returns @c false if it\\n            does not exist, if the file system object identified by the path is\\n            not a symbolic link, or if the object type is inaccessible to the\\n            user, or if the @a symlink argument is empty.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(symlink, basestring):\\n            raise TypeError(\"symlink can only be an instance of type basestring\")\\n        exists = self._call(\"symlinkExists\",\\n                     in_p=[symlink])\\n        return exists',\n",
              " 'def symlink_read(self, symlink, flags):\\n        \"\"\"Reads the target value of a symbolic link in the guest.\\n\\n        in symlink of type str\\n            Path to the symbolic link to read.\\n\\n        in flags of type :class:`SymlinkReadFlag`\\n            Zero or more :py:class:`SymlinkReadFlag`  values.\\n\\n        return target of type str\\n            Target value of the symbolic link.  Guest path style.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(symlink, basestring):\\n            raise TypeError(\"symlink can only be an instance of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, SymlinkReadFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type SymlinkReadFlag\")\\n        target = self._call(\"symlinkRead\",\\n                     in_p=[symlink, flags])\\n        return target',\n",
              " 'def wait_for_array(self, wait_for, timeout_ms):\\n        \"\"\"Waits for one or more events to happen.\\n        Scriptable version of :py:func:`wait_for` .\\n\\n        in wait_for of type :class:`GuestSessionWaitForFlag`\\n            Specifies what to wait for;\\n            see :py:class:`GuestSessionWaitForFlag`  for more information.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return reason of type :class:`GuestSessionWaitResult`\\n            The overall wait result;\\n            see :py:class:`GuestSessionWaitResult`  for more information.\\n\\n        \"\"\"\\n        if not isinstance(wait_for, list):\\n            raise TypeError(\"wait_for can only be an instance of type list\")\\n        for a in wait_for[:10]:\\n            if not isinstance(a, GuestSessionWaitForFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type GuestSessionWaitForFlag\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        reason = self._call(\"waitForArray\",\\n                     in_p=[wait_for, timeout_ms])\\n        reason = GuestSessionWaitResult(reason)\\n        return reason',\n",
              " 'def wait_for(self, wait_for, timeout_ms):\\n        \"\"\"Waits for one or more events to happen.\\n\\n        in wait_for of type int\\n            Specifies what to wait for;\\n            see :py:class:`ProcessWaitForFlag`  for more information.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return reason of type :class:`ProcessWaitResult`\\n            The overall wait result;\\n            see :py:class:`ProcessWaitResult`  for more information.\\n\\n        \"\"\"\\n        if not isinstance(wait_for, baseinteger):\\n            raise TypeError(\"wait_for can only be an instance of type baseinteger\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        reason = self._call(\"waitFor\",\\n                     in_p=[wait_for, timeout_ms])\\n        reason = ProcessWaitResult(reason)\\n        return reason',\n",
              " 'def wait_for_array(self, wait_for, timeout_ms):\\n        \"\"\"Waits for one or more events to happen.\\n        Scriptable version of :py:func:`wait_for` .\\n\\n        in wait_for of type :class:`ProcessWaitForFlag`\\n            Specifies what to wait for;\\n            see :py:class:`ProcessWaitForFlag`  for more information.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return reason of type :class:`ProcessWaitResult`\\n            The overall wait result;\\n            see :py:class:`ProcessWaitResult`  for more information.\\n\\n        \"\"\"\\n        if not isinstance(wait_for, list):\\n            raise TypeError(\"wait_for can only be an instance of type list\")\\n        for a in wait_for[:10]:\\n            if not isinstance(a, ProcessWaitForFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type ProcessWaitForFlag\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        reason = self._call(\"waitForArray\",\\n                     in_p=[wait_for, timeout_ms])\\n        reason = ProcessWaitResult(reason)\\n        return reason',\n",
              " 'def write(self, handle, flags, data, timeout_ms):\\n        \"\"\"Writes data to a running process.\\n\\n        in handle of type int\\n            Handle to write to. Usually 0 is stdin, 1 is stdout and 2 is stderr.\\n\\n        in flags of type int\\n            A combination of :py:class:`ProcessInputFlag`  flags.\\n\\n        in data of type str\\n            Array of bytes to write. The size of the array also specifies\\n            how much to write.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return written of type int\\n            How many bytes were written.\\n\\n        \"\"\"\\n        if not isinstance(handle, baseinteger):\\n            raise TypeError(\"handle can only be an instance of type baseinteger\")\\n        if not isinstance(flags, baseinteger):\\n            raise TypeError(\"flags can only be an instance of type baseinteger\")\\n        if not isinstance(data, list):\\n            raise TypeError(\"data can only be an instance of type list\")\\n        for a in data[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        written = self._call(\"write\",\\n                     in_p=[handle, flags, data, timeout_ms])\\n        return written',\n",
              " 'def read(self, to_read, timeout_ms):\\n        \"\"\"Reads data from this file.\\n\\n        in to_read of type int\\n            Number of bytes to read.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return data of type str\\n            Array of data read.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(to_read, baseinteger):\\n            raise TypeError(\"to_read can only be an instance of type baseinteger\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        data = self._call(\"read\",\\n                     in_p=[to_read, timeout_ms])\\n        return data',\n",
              " 'def read_at(self, offset, to_read, timeout_ms):\\n        \"\"\"Reads data from an offset of this file.\\n\\n        in offset of type int\\n            Offset in bytes to start reading.\\n\\n        in to_read of type int\\n            Number of bytes to read.\\n\\n        in timeout_ms of type int\\n            Timeout (in ms) to wait for the operation to complete.\\n            Pass 0 for an infinite timeout.\\n\\n        return data of type str\\n            Array of data read.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(offset, baseinteger):\\n            raise TypeError(\"offset can only be an instance of type baseinteger\")\\n        if not isinstance(to_read, baseinteger):\\n            raise TypeError(\"to_read can only be an instance of type baseinteger\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        data = self._call(\"readAt\",\\n                     in_p=[offset, to_read, timeout_ms])\\n        return data',\n",
              " 'def seek(self, offset, whence):\\n        \"\"\"Changes the current file position of this file.\\n        \\n        The file current position always applies to the :py:func:`IFile.read` \\n        method.  Same for the :py:func:`IFile.write`  method it except when\\n        the :py:func:`IFile.access_mode`  is :py:attr:`FileAccessMode.append_only` \\n        or :py:attr:`FileAccessMode.append_read` .\\n\\n        in offset of type int\\n            Offset to seek relative to the position specified by @a whence.\\n\\n        in whence of type :class:`FileSeekOrigin`\\n            One of the :py:class:`FileSeekOrigin`  seek starting points.\\n\\n        return new_offset of type int\\n            The new file offset after the seek operation.\\n\\n        \"\"\"\\n        if not isinstance(offset, baseinteger):\\n            raise TypeError(\"offset can only be an instance of type baseinteger\")\\n        if not isinstance(whence, FileSeekOrigin):\\n            raise TypeError(\"whence can only be an instance of type FileSeekOrigin\")\\n        new_offset = self._call(\"seek\",\\n                     in_p=[offset, whence])\\n        return new_offset',\n",
              " 'def set_acl(self, acl, mode):\\n        \"\"\"Sets the ACL of this file.\\n\\n        in acl of type str\\n            The ACL specification string. To-be-defined.\\n\\n        in mode of type int\\n            UNIX-style mode mask to use if @a acl is empty. As mention in\\n            :py:func:`IGuestSession.directory_create`  this is realized on\\n            a best effort basis and the exact behavior depends on the Guest OS.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(acl, basestring):\\n            raise TypeError(\"acl can only be an instance of type basestring\")\\n        if not isinstance(mode, baseinteger):\\n            raise TypeError(\"mode can only be an instance of type baseinteger\")\\n        self._call(\"setACL\",\\n                     in_p=[acl, mode])',\n",
              " 'def set_size(self, size):\\n        \"\"\"Changes the file size.\\n\\n        in size of type int\\n            The new file size.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The method is not implemented yet.\\n        \\n        \"\"\"\\n        if not isinstance(size, baseinteger):\\n            raise TypeError(\"size can only be an instance of type baseinteger\")\\n        self._call(\"setSize\",\\n                     in_p=[size])',\n",
              " 'def internal_get_statistics(self):\\n        \"\"\"Internal method; do not use as it might change at any time.\\n\\n        out cpu_user of type int\\n            Percentage of processor time spent in user mode as seen by the guest.\\n\\n        out cpu_kernel of type int\\n            Percentage of processor time spent in kernel mode as seen by the guest.\\n\\n        out cpu_idle of type int\\n            Percentage of processor time spent idling as seen by the guest.\\n\\n        out mem_total of type int\\n            Total amount of physical guest RAM.\\n\\n        out mem_free of type int\\n            Free amount of physical guest RAM.\\n\\n        out mem_balloon of type int\\n            Amount of ballooned physical guest RAM.\\n\\n        out mem_shared of type int\\n            Amount of shared physical guest RAM.\\n\\n        out mem_cache of type int\\n            Total amount of guest (disk) cache memory.\\n\\n        out paged_total of type int\\n            Total amount of space in the page file.\\n\\n        out mem_alloc_total of type int\\n            Total amount of memory allocated by the hypervisor.\\n\\n        out mem_free_total of type int\\n            Total amount of free memory available in the hypervisor.\\n\\n        out mem_balloon_total of type int\\n            Total amount of memory ballooned by the hypervisor.\\n\\n        out mem_shared_total of type int\\n            Total amount of shared memory in the hypervisor.\\n\\n        \"\"\"\\n        (cpu_user, cpu_kernel, cpu_idle, mem_total, mem_free, mem_balloon, mem_shared, mem_cache, paged_total, mem_alloc_total, mem_free_total, mem_balloon_total, mem_shared_total) = self._call(\"internalGetStatistics\")\\n        return (cpu_user, cpu_kernel, cpu_idle, mem_total, mem_free, mem_balloon, mem_shared, mem_cache, paged_total, mem_alloc_total, mem_free_total, mem_balloon_total, mem_shared_total)',\n",
              " 'def get_facility_status(self, facility):\\n        \"\"\"Get the current status of a Guest Additions facility.\\n\\n        in facility of type :class:`AdditionsFacilityType`\\n            Facility to check status for.\\n\\n        out timestamp of type int\\n            Timestamp (in ms) of last status update seen by the host.\\n\\n        return status of type :class:`AdditionsFacilityStatus`\\n            The current (latest) facility status.\\n\\n        \"\"\"\\n        if not isinstance(facility, AdditionsFacilityType):\\n            raise TypeError(\"facility can only be an instance of type AdditionsFacilityType\")\\n        (status, timestamp) = self._call(\"getFacilityStatus\",\\n                     in_p=[facility])\\n        status = AdditionsFacilityStatus(status)\\n        return (status, timestamp)',\n",
              " 'def get_additions_status(self, level):\\n        \"\"\"Retrieve the current status of a certain Guest Additions run level.\\n\\n        in level of type :class:`AdditionsRunLevelType`\\n            Status level to check\\n\\n        return active of type bool\\n            Flag whether the status level has been reached or not\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            Wrong status level specified.\\n        \\n        \"\"\"\\n        if not isinstance(level, AdditionsRunLevelType):\\n            raise TypeError(\"level can only be an instance of type AdditionsRunLevelType\")\\n        active = self._call(\"getAdditionsStatus\",\\n                     in_p=[level])\\n        return active',\n",
              " 'def set_credentials(self, user_name, password, domain, allow_interactive_logon):\\n        \"\"\"Store login credentials that can be queried by guest operating\\n        systems with Additions installed. The credentials are transient\\n        to the session and the guest may also choose to erase them. Note\\n        that the caller cannot determine whether the guest operating system\\n        has queried or made use of the credentials.\\n\\n        in user_name of type str\\n            User name string, can be empty\\n\\n        in password of type str\\n            Password string, can be empty\\n\\n        in domain of type str\\n            Domain name (guest logon scheme specific), can be empty\\n\\n        in allow_interactive_logon of type bool\\n            Flag whether the guest should alternatively allow the user to\\n            interactively specify different credentials. This flag might\\n            not be supported by all versions of the Additions.\\n\\n        raises :class:`VBoxErrorVmError`\\n            VMM device is not available.\\n        \\n        \"\"\"\\n        if not isinstance(user_name, basestring):\\n            raise TypeError(\"user_name can only be an instance of type basestring\")\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        if not isinstance(domain, basestring):\\n            raise TypeError(\"domain can only be an instance of type basestring\")\\n        if not isinstance(allow_interactive_logon, bool):\\n            raise TypeError(\"allow_interactive_logon can only be an instance of type bool\")\\n        self._call(\"setCredentials\",\\n                     in_p=[user_name, password, domain, allow_interactive_logon])',\n",
              " 'def create_session(self, user, password, domain, session_name):\\n        \"\"\"Creates a new guest session for controlling the guest. The new session\\n        will be started asynchronously, meaning on return of this function it is\\n        not guaranteed that the guest session is in a started and/or usable state.\\n        To wait for successful startup, use the :py:func:`IGuestSession.wait_for` \\n        call.\\n        \\n        A guest session represents one impersonated user account in the guest, so\\n        every operation will use the same credentials specified when creating\\n        the session object via :py:func:`IGuest.create_session` . Anonymous\\n        sessions, that is, sessions without specifying a valid\\n        user account in the guest are not allowed reasons of security.\\n        \\n        There can be a maximum of 32 sessions at once per VM.  An error will\\n        be returned if this has been reached.\\n        \\n        For more information please consult :py:class:`IGuestSession` \\n\\n        in user of type str\\n            User name this session will be using to control the guest; has to exist\\n            and have the appropriate rights to execute programs in the VM. Must not\\n            be empty.\\n\\n        in password of type str\\n            Password of the user account to be used. Empty passwords are allowed.\\n\\n        in domain of type str\\n            Domain name of the user account to be used if the guest is part of\\n            a domain. Optional. This feature is not implemented yet.\\n\\n        in session_name of type str\\n            The session\\'s friendly name. Optional, can be empty.\\n\\n        return guest_session of type :class:`IGuestSession`\\n            The newly created session object.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Error creating guest session.\\n        \\n        raises :class:`VBoxErrorMaximumReached`\\n            The maximum of concurrent guest sessions has been reached.\\n        \\n        \"\"\"\\n        if not isinstance(user, basestring):\\n            raise TypeError(\"user can only be an instance of type basestring\")\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        if not isinstance(domain, basestring):\\n            raise TypeError(\"domain can only be an instance of type basestring\")\\n        if not isinstance(session_name, basestring):\\n            raise TypeError(\"session_name can only be an instance of type basestring\")\\n        guest_session = self._call(\"createSession\",\\n                     in_p=[user, password, domain, session_name])\\n        guest_session = IGuestSession(guest_session)\\n        return guest_session',\n",
              " 'def find_session(self, session_name):\\n        \"\"\"Finds guest sessions by their friendly name and returns an interface\\n        array with all found guest sessions.\\n\\n        in session_name of type str\\n            The session\\'s friendly name to find. Wildcards like ? and * are allowed.\\n\\n        return sessions of type :class:`IGuestSession`\\n            Array with all guest sessions found matching the name specified.\\n\\n        \"\"\"\\n        if not isinstance(session_name, basestring):\\n            raise TypeError(\"session_name can only be an instance of type basestring\")\\n        sessions = self._call(\"findSession\",\\n                     in_p=[session_name])\\n        sessions = [IGuestSession(a) for a in sessions]\\n        return sessions',\n",
              " 'def update_guest_additions(self, source, arguments, flags):\\n        \"\"\"Automatically updates already installed Guest Additions in a VM.\\n        \\n        At the moment only Windows guests are supported.\\n        \\n        Because the VirtualBox Guest Additions drivers are not WHQL-certified\\n        yet there might be warning dialogs during the actual Guest Additions\\n        update. These need to be confirmed manually in order to continue the\\n        installation process. This applies to Windows 2000 and Windows XP guests\\n        and therefore these guests can\\'t be updated in a fully automated fashion\\n        without user interaction. However, to start a Guest Additions update for\\n        the mentioned Windows versions anyway, the flag\\n        AdditionsUpdateFlag_WaitForUpdateStartOnly can be specified. See\\n        :py:class:`AdditionsUpdateFlag`  for more information.\\n\\n        in source of type str\\n            Path to the Guest Additions .ISO file to use for the update.\\n\\n        in arguments of type str\\n            Optional command line arguments to use for the Guest Additions\\n            installer. Useful for retrofitting features which weren\\'t installed\\n            before in the guest.\\n\\n        in flags of type :class:`AdditionsUpdateFlag`\\n            :py:class:`AdditionsUpdateFlag`  flags.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            Guest OS is not supported for automated Guest Additions updates or the\\nalready installed Guest Additions are not ready yet.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Error while updating.\\n        \\n        \"\"\"\\n        if not isinstance(source, basestring):\\n            raise TypeError(\"source can only be an instance of type basestring\")\\n        if not isinstance(arguments, list):\\n            raise TypeError(\"arguments can only be an instance of type list\")\\n        for a in arguments[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(flags, list):\\n            raise TypeError(\"flags can only be an instance of type list\")\\n        for a in flags[:10]:\\n            if not isinstance(a, AdditionsUpdateFlag):\\n                raise TypeError(\\n                        \"array can only contain objects of type AdditionsUpdateFlag\")\\n        progress = self._call(\"updateGuestAdditions\",\\n                     in_p=[source, arguments, flags])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def wait_for_completion(self, timeout):\\n        \"\"\"Waits until the task is done (including all sub-operations)\\n        with a given timeout in milliseconds; specify -1 for an indefinite wait.\\n        \\n        Note that the VirtualBox/XPCOM/COM/native event queues of the calling\\n        thread are not processed while waiting. Neglecting event queues may\\n        have dire consequences (degrade performance, resource hogs,\\n        deadlocks, etc.), this is specially so for the main thread on\\n        platforms using XPCOM. Callers are advised wait for short periods\\n        and service their event queues between calls, or to create a worker\\n        thread to do the waiting.\\n\\n        in timeout of type int\\n            Maximum time in milliseconds to wait or -1 to wait indefinitely.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Failed to wait for task completion.\\n        \\n        \"\"\"\\n        if not isinstance(timeout, baseinteger):\\n            raise TypeError(\"timeout can only be an instance of type baseinteger\")\\n        self._call(\"waitForCompletion\",\\n                     in_p=[timeout])',\n",
              " 'def wait_for_operation_completion(self, operation, timeout):\\n        \"\"\"Waits until the given operation is done with a given timeout in\\n        milliseconds; specify -1 for an indefinite wait.\\n        \\n        See :py:func:`wait_for_completion` for event queue considerations.\\n\\n        in operation of type int\\n            Number of the operation to wait for.\\n            Must be less than :py:func:`operation_count` .\\n\\n        in timeout of type int\\n            Maximum time in milliseconds to wait or -1 to wait indefinitely.\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Failed to wait for operation completion.\\n        \\n        \"\"\"\\n        if not isinstance(operation, baseinteger):\\n            raise TypeError(\"operation can only be an instance of type baseinteger\")\\n        if not isinstance(timeout, baseinteger):\\n            raise TypeError(\"timeout can only be an instance of type baseinteger\")\\n        self._call(\"waitForOperationCompletion\",\\n                     in_p=[operation, timeout])',\n",
              " 'def set_current_operation_progress(self, percent):\\n        \"\"\"Internal method, not to be called externally.\\n\\n        in percent of type int\\n\\n        \"\"\"\\n        if not isinstance(percent, baseinteger):\\n            raise TypeError(\"percent can only be an instance of type baseinteger\")\\n        self._call(\"setCurrentOperationProgress\",\\n                     in_p=[percent])',\n",
              " 'def wait_for_other_progress_completion(self, progress_other, timeout_ms):\\n        \"\"\"Internal method, not to be called externally.\\n        \\n        Waits until the other task is completed (including all sub-operations)\\n        and forward all changes from the other progress to this progress. This\\n        means sub-operation number, description, percent and so on.\\n        \\n        The caller is responsible for having at least the same count of\\n        sub-operations in this progress object as there are in the other\\n        progress object.\\n        \\n        If the other progress object supports cancel and this object gets any\\n        cancel request (when here enabled as well), it will be forwarded to\\n        the other progress object.\\n        \\n        Error information is automatically preserved (by transferring it to\\n        the current thread\\'s error information). If the caller wants to set it\\n        as the completion state of this progress it needs to be done separately.\\n\\n        in progress_other of type :class:`IProgress`\\n\\n        in timeout_ms of type int\\n            Timeout (in ms). Pass 0 for an infinite timeout.\\n\\n        raises :class:`VBoxErrorTimeout`\\n            Waiting time has expired.\\n        \\n        \"\"\"\\n        if not isinstance(progress_other, IProgress):\\n            raise TypeError(\"progress_other can only be an instance of type IProgress\")\\n        if not isinstance(timeout_ms, baseinteger):\\n            raise TypeError(\"timeout_ms can only be an instance of type baseinteger\")\\n        self._call(\"waitForOtherProgressCompletion\",\\n                     in_p=[progress_other, timeout_ms])',\n",
              " 'def set_next_operation(self, next_operation_description, next_operations_weight):\\n        \"\"\"Internal method, not to be called externally.\\n\\n        in next_operation_description of type str\\n\\n        in next_operations_weight of type int\\n\\n        \"\"\"\\n        if not isinstance(next_operation_description, basestring):\\n            raise TypeError(\"next_operation_description can only be an instance of type basestring\")\\n        if not isinstance(next_operations_weight, baseinteger):\\n            raise TypeError(\"next_operations_weight can only be an instance of type baseinteger\")\\n        self._call(\"setNextOperation\",\\n                     in_p=[next_operation_description, next_operations_weight])',\n",
              " 'def notify_complete(self, result_code, error_info):\\n        \"\"\"Internal method, not to be called externally.\\n\\n        in result_code of type int\\n\\n        in error_info of type :class:`IVirtualBoxErrorInfo`\\n\\n        \"\"\"\\n        if not isinstance(result_code, baseinteger):\\n            raise TypeError(\"result_code can only be an instance of type baseinteger\")\\n        if not isinstance(error_info, IVirtualBoxErrorInfo):\\n            raise TypeError(\"error_info can only be an instance of type IVirtualBoxErrorInfo\")\\n        self._call(\"notifyComplete\",\\n                     in_p=[result_code, error_info])',\n",
              " 'def set_ids(self, set_image_id, image_id, set_parent_id, parent_id):\\n        \"\"\"Changes the UUID and parent UUID for a hard disk medium.\\n\\n        in set_image_id of type bool\\n            Select whether a new image UUID is set or not.\\n\\n        in image_id of type str\\n            New UUID for the image. If an empty string is passed, then a new\\n            UUID is automatically created, provided that @a setImageId is @c true.\\n            Specifying a zero UUID is not allowed.\\n\\n        in set_parent_id of type bool\\n            Select whether a new parent UUID is set or not.\\n\\n        in parent_id of type str\\n            New parent UUID for the image. If an empty string is passed, then a\\n            new UUID is automatically created, provided @a setParentId is\\n            @c true. A zero UUID is valid.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            Invalid parameter combination.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Medium is not a hard disk medium.\\n        \\n        \"\"\"\\n        if not isinstance(set_image_id, bool):\\n            raise TypeError(\"set_image_id can only be an instance of type bool\")\\n        if not isinstance(image_id, basestring):\\n            raise TypeError(\"image_id can only be an instance of type basestring\")\\n        if not isinstance(set_parent_id, bool):\\n            raise TypeError(\"set_parent_id can only be an instance of type bool\")\\n        if not isinstance(parent_id, basestring):\\n            raise TypeError(\"parent_id can only be an instance of type basestring\")\\n        self._call(\"setIds\",\\n                     in_p=[set_image_id, image_id, set_parent_id, parent_id])',\n",
              " 'def get_snapshot_ids(self, machine_id):\\n        \"\"\"Returns an array of UUIDs of all snapshots of the given machine where\\n        this medium is attached to.\\n        \\n        If the medium is attached to the machine in the current state, then the\\n        first element in the array will always be the ID of the queried machine\\n        (i.e. the value equal to the @c machineId argument), followed by\\n        snapshot IDs (if any).\\n        \\n        If the medium is not attached to the machine in the current state, then\\n        the array will contain only snapshot IDs.\\n        \\n        The returned array may be @c null if this medium is not attached\\n        to the given machine at all, neither in the current state nor in one of\\n        the snapshots.\\n\\n        in machine_id of type str\\n            UUID of the machine to query.\\n\\n        return snapshot_ids of type str\\n            Array of snapshot UUIDs of the given machine using this medium.\\n\\n        \"\"\"\\n        if not isinstance(machine_id, basestring):\\n            raise TypeError(\"machine_id can only be an instance of type basestring\")\\n        snapshot_ids = self._call(\"getSnapshotIds\",\\n                     in_p=[machine_id])\\n        return snapshot_ids',\n",
              " 'def get_property(self, name):\\n        \"\"\"Returns the value of the custom medium property with the given name.\\n        \\n        The list of all properties supported by the given medium format can\\n        be obtained with :py:func:`IMediumFormat.describe_properties` .\\n        \\n        If this method returns an empty string in @a value, the requested\\n        property is supported but currently not assigned any value.\\n\\n        in name of type str\\n            Name of the property to get.\\n\\n        return value of type str\\n            Current property value.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Requested property does not exist (not supported by the format).\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            @a name is @c null or empty.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        value = self._call(\"getProperty\",\\n                     in_p=[name])\\n        return value',\n",
              " 'def set_property(self, name, value):\\n        \"\"\"Sets the value of the custom medium property with the given name.\\n        \\n        The list of all properties supported by the given medium format can\\n        be obtained with :py:func:`IMediumFormat.describe_properties` .\\n        \\n        Setting the property value to @c null or an empty string is\\n        equivalent to deleting the existing value. A default value (if it is\\n        defined for this property) will be used by the format backend in this\\n        case.\\n\\n        in name of type str\\n            Name of the property to set.\\n\\n        in value of type str\\n            Property value to set.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Requested property does not exist (not supported by the format).\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            @a name is @c null or empty.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(value, basestring):\\n            raise TypeError(\"value can only be an instance of type basestring\")\\n        self._call(\"setProperty\",\\n                     in_p=[name, value])',\n",
              " 'def get_properties(self, names):\\n        \"\"\"Returns values for a group of properties in one call.\\n        \\n        The names of the properties to get are specified using the @a names\\n        argument which is a list of comma-separated property names or\\n        an empty string if all properties are to be returned.\\n        Currently the value of this argument is ignored and the method\\n        always returns all existing properties.\\n        \\n        The list of all properties supported by the given medium format can\\n        be obtained with :py:func:`IMediumFormat.describe_properties` .\\n        \\n        The method returns two arrays, the array of property names corresponding\\n        to the @a names argument and the current values of these properties.\\n        Both arrays have the same number of elements with each element at the\\n        given index in the first array corresponds to an element at the same\\n        index in the second array.\\n        \\n        For properties that do not have assigned values, an empty string is\\n        returned at the appropriate index in the @a returnValues array.\\n\\n        in names of type str\\n            Names of properties to get.\\n\\n        out return_names of type str\\n            Names of returned properties.\\n\\n        return return_values of type str\\n            Values of returned properties.\\n\\n        \"\"\"\\n        if not isinstance(names, basestring):\\n            raise TypeError(\"names can only be an instance of type basestring\")\\n        (return_values, return_names) = self._call(\"getProperties\",\\n                     in_p=[names])\\n        return (return_values, return_names)',\n",
              " 'def set_properties(self, names, values):\\n        \"\"\"Sets values for a group of properties in one call.\\n        \\n        The names of the properties to set are passed in the @a names\\n        array along with the new values for them in the @a values array. Both\\n        arrays have the same number of elements with each element at the given\\n        index in the first array corresponding to an element at the same index\\n        in the second array.\\n        \\n        If there is at least one property name in @a names that is not valid,\\n        the method will fail before changing the values of any other properties\\n        from the @a names array.\\n        \\n        Using this method over :py:func:`set_property`  is preferred if you\\n        need to set several properties at once since it is more efficient.\\n        \\n        The list of all properties supported by the given medium format can\\n        be obtained with :py:func:`IMediumFormat.describe_properties` .\\n        \\n        Setting the property value to @c null or an empty string is equivalent\\n        to deleting the existing value. A default value (if it is defined for\\n        this property) will be used by the format backend in this case.\\n\\n        in names of type str\\n            Names of properties to set.\\n\\n        in values of type str\\n            Values of properties to set.\\n\\n        \"\"\"\\n        if not isinstance(names, list):\\n            raise TypeError(\"names can only be an instance of type list\")\\n        for a in names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(values, list):\\n            raise TypeError(\"values can only be an instance of type list\")\\n        for a in values[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"setProperties\",\\n                     in_p=[names, values])',\n",
              " 'def create_base_storage(self, logical_size, variant):\\n        \"\"\"Starts creating a hard disk storage unit (fixed/dynamic, according\\n        to the variant flags) in the background. The previous storage unit\\n        created for this object, if any, must first be deleted using\\n        :py:func:`delete_storage` , otherwise the operation will fail.\\n        \\n        Before the operation starts, the medium is placed in\\n        :py:attr:`MediumState.creating`  state. If the create operation\\n        fails, the medium will be placed back in :py:attr:`MediumState.not_created` \\n        state.\\n        \\n        After the returned progress object reports that the operation has\\n        successfully completed, the medium state will be set to :py:attr:`MediumState.created` , the medium will be remembered by this\\n        VirtualBox installation and may be attached to virtual machines.\\n\\n        in logical_size of type int\\n            Maximum logical size of the medium in bytes.\\n\\n        in variant of type :class:`MediumVariant`\\n            Exact image variant which should be created (as a combination of\\n            :py:class:`MediumVariant`  flags).\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            The variant of storage creation operation is not supported. See\\n        \\n        \"\"\"\\n        if not isinstance(logical_size, baseinteger):\\n            raise TypeError(\"logical_size can only be an instance of type baseinteger\")\\n        if not isinstance(variant, list):\\n            raise TypeError(\"variant can only be an instance of type list\")\\n        for a in variant[:10]:\\n            if not isinstance(a, MediumVariant):\\n                raise TypeError(\\n                        \"array can only contain objects of type MediumVariant\")\\n        progress = self._call(\"createBaseStorage\",\\n                     in_p=[logical_size, variant])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def create_diff_storage(self, target, variant):\\n        \"\"\"Starts creating an empty differencing storage unit based on this\\n        medium in the format and at the location defined by the @a target\\n        argument.\\n        \\n        The target medium must be in :py:attr:`MediumState.not_created` \\n        state (i.e. must not have an existing storage unit). Upon successful\\n        completion, this operation will set the type of the target medium to\\n        :py:attr:`MediumType.normal`  and create a storage unit necessary to\\n        represent the differencing medium data in the given format (according\\n        to the storage format of the target object).\\n        \\n        After the returned progress object reports that the operation is\\n        successfully complete, the target medium gets remembered by this\\n        VirtualBox installation and may be attached to virtual machines.\\n        \\n        \\n        The medium will be set to :py:attr:`MediumState.locked_read` \\n        state for the duration of this operation.\\n\\n        in target of type :class:`IMedium`\\n            Target medium.\\n\\n        in variant of type :class:`MediumVariant`\\n            Exact image variant which should be created (as a combination of\\n            :py:class:`MediumVariant`  flags).\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorObjectInUse`\\n            Medium not in @c NotCreated state.\\n        \\n        \"\"\"\\n        if not isinstance(target, IMedium):\\n            raise TypeError(\"target can only be an instance of type IMedium\")\\n        if not isinstance(variant, list):\\n            raise TypeError(\"variant can only be an instance of type list\")\\n        for a in variant[:10]:\\n            if not isinstance(a, MediumVariant):\\n                raise TypeError(\\n                        \"array can only contain objects of type MediumVariant\")\\n        progress = self._call(\"createDiffStorage\",\\n                     in_p=[target, variant])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def merge_to(self, target):\\n        \"\"\"Starts merging the contents of this medium and all intermediate\\n        differencing media in the chain to the given target medium.\\n        \\n        The target medium must be either a descendant of this medium or\\n        its ancestor (otherwise this method will immediately return a failure).\\n        It follows that there are two logical directions of the merge operation:\\n        from ancestor to descendant (*forward merge*) and from descendant to\\n        ancestor (*backward merge*). Let us consider the following medium\\n        chain:\\n        \\n        Base <- Diff_1 <- Diff_2\\n        \\n        Here, calling this method on the Base medium object with\\n        Diff_2 as an argument will be a forward merge; calling it on\\n        Diff_2 with Base as an argument will be a backward\\n        merge. Note that in both cases the contents of the resulting medium\\n        will be the same, the only difference is the medium object that takes\\n        the result of the merge operation. In case of the forward merge in the\\n        above example, the result will be written to Diff_2; in case of\\n        the backward merge, the result will be written to Base. In\\n        other words, the result of the operation is always stored in the target\\n        medium.\\n        \\n        Upon successful operation completion, the storage units of all media in\\n        the chain between this (source) medium and the target medium, including\\n        the source medium itself, will be automatically deleted and the\\n        relevant medium objects (including this medium) will become\\n        uninitialized. This means that any attempt to call any of\\n        their methods or attributes will fail with the\\n        \"Object not ready\" (E_ACCESSDENIED) error. Applied to the above\\n        example, the forward merge of Base to Diff_2 will\\n        delete and uninitialize both Base and Diff_1 media.\\n        Note that Diff_2 in this case will become a base medium\\n        itself since it will no longer be based on any other medium.\\n        \\n        Considering the above, all of the following conditions must be met in\\n        order for the merge operation to succeed:\\n        \\n        \\n        Neither this (source) medium nor any intermediate\\n        differencing medium in the chain between it and the target\\n        medium is attached to any virtual machine.\\n        \\n        \\n        Neither the source medium nor the target medium is an\\n        :py:attr:`MediumType.immutable`  medium.\\n        \\n        \\n        The part of the medium tree from the source medium to the\\n        target medium is a linear chain, i.e. all medium in this\\n        chain have exactly one child which is the next medium in this\\n        chain. The only exception from this rule is the target medium in\\n        the forward merge operation; it is allowed to have any number of\\n        child media because the merge operation will not change its\\n        logical contents (as it is seen by the guest OS or by children).\\n        \\n        \\n        None of the involved media are in\\n        :py:attr:`MediumState.locked_read`  or\\n        :py:attr:`MediumState.locked_write`  state.\\n        \\n        \\n        \\n        \\n        This (source) medium and all intermediates will be placed to :py:attr:`MediumState.deleting`  state and the target medium will be\\n        placed to :py:attr:`MediumState.locked_write`  state and for the\\n        duration of this operation.\\n\\n        in target of type :class:`IMedium`\\n            Target medium.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        \"\"\"\\n        if not isinstance(target, IMedium):\\n            raise TypeError(\"target can only be an instance of type IMedium\")\\n        progress = self._call(\"mergeTo\",\\n                     in_p=[target])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def move_to(self, location):\\n        \"\"\"Changes the location of this medium. Some medium types may support\\n        changing the storage unit location by simply changing the value of the\\n        associated property. In this case the operation is performed\\n        immediately, and @a progress is returning a @c null reference.\\n        Otherwise on success there is a progress object returned, which\\n        signals progress and completion of the operation. This distinction is\\n        necessary because for some formats the operation is very fast, while\\n        for others it can be very slow (moving the image file by copying all\\n        data), and in the former case it\\'d be a waste of resources to create\\n        a progress object which will immediately signal completion.\\n        \\n        When setting a location for a medium which corresponds to a/several\\n        regular file(s) in the host\\'s file system, the given file name may be\\n        either relative to the :py:func:`IVirtualBox.home_folder` VirtualBox\\n        home folder or absolute. Note that if the given location\\n        specification does not contain the file extension part then a proper\\n        default extension will be automatically appended by the implementation\\n        depending on the medium type.\\n\\n        in location of type str\\n            New location.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`OleErrorNotimpl`\\n            The operation is not implemented yet.\\n        \\n        raises :class:`VBoxErrorNotSupported`\\n            Medium format does not support changing the location.\\n        \\n        \"\"\"\\n        if not isinstance(location, basestring):\\n            raise TypeError(\"location can only be an instance of type basestring\")\\n        progress = self._call(\"moveTo\",\\n                     in_p=[location])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def resize(self, logical_size):\\n        \"\"\"Starts resizing this medium. This means that the nominal size of the\\n        medium is set to the new value. Both increasing and decreasing the\\n        size is possible, and there are no safety checks, since VirtualBox\\n        does not make any assumptions about the medium contents.\\n        \\n        Resizing usually needs additional disk space, and possibly also\\n        some temporary disk space. Note that resize does not create a full\\n        temporary copy of the medium, so the additional disk space requirement\\n        is usually much lower than using the clone operation.\\n        \\n        This medium will be placed to :py:attr:`MediumState.locked_write` \\n        state for the duration of this operation.\\n        \\n        Please note that the results can be either returned straight away,\\n        or later as the result of the background operation via the object\\n        returned via the @a progress parameter.\\n\\n        in logical_size of type int\\n            New nominal capacity of the medium in bytes.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            Medium format does not support resizing.\\n        \\n        \"\"\"\\n        if not isinstance(logical_size, baseinteger):\\n            raise TypeError(\"logical_size can only be an instance of type baseinteger\")\\n        progress = self._call(\"resize\",\\n                     in_p=[logical_size])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def change_encryption(self, current_password, cipher, new_password, new_password_id):\\n        \"\"\"Starts encryption of this medium. This means that the stored data in the\\n        medium is encrypted.\\n        \\n        This medium will be placed to :py:attr:`MediumState.locked_write` \\n        state.\\n        \\n        Please note that the results can be either returned straight away,\\n        or later as the result of the background operation via the object\\n        returned via the @a progress parameter.\\n\\n        in current_password of type str\\n            The current password the medium is protected with. Use an empty string to indicate\\n            that the medium isn\\'t encrypted.\\n\\n        in cipher of type str\\n            The cipher to use for encryption. An empty string indicates no encryption for the\\n            result.\\n\\n        in new_password of type str\\n            The new password the medium should be protected with. An empty password and password ID\\n            will result in the medium being encrypted with the current password.\\n\\n        in new_password_id of type str\\n            The ID of the new password when unlocking the medium.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            Encryption is not supported for this medium because it is attached to more than one VM\\nor has children.\\n        \\n        \"\"\"\\n        if not isinstance(current_password, basestring):\\n            raise TypeError(\"current_password can only be an instance of type basestring\")\\n        if not isinstance(cipher, basestring):\\n            raise TypeError(\"cipher can only be an instance of type basestring\")\\n        if not isinstance(new_password, basestring):\\n            raise TypeError(\"new_password can only be an instance of type basestring\")\\n        if not isinstance(new_password_id, basestring):\\n            raise TypeError(\"new_password_id can only be an instance of type basestring\")\\n        progress = self._call(\"changeEncryption\",\\n                     in_p=[current_password, cipher, new_password, new_password_id])\\n        progress = IProgress(progress)\\n        return progress',\n",
              " 'def check_encryption_password(self, password):\\n        \"\"\"Checks whether the supplied password is correct for the medium.\\n\\n        in password of type str\\n            The password to check.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            Encryption is not configured for this medium.\\n        \\n        raises :class:`VBoxErrorPasswordIncorrect`\\n            The given password is incorrect.\\n        \\n        \"\"\"\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        self._call(\"checkEncryptionPassword\",\\n                     in_p=[password])',\n",
              " 'def open_for_io(self, writable, password):\\n        \"\"\"Open the medium for I/O.\\n\\n        in writable of type bool\\n            Set this to open the medium for both reading and writing.  When\\n            not set the medium is opened readonly.\\n\\n        in password of type str\\n            Password for accessing an encrypted medium. Must be empty if not encrypted.\\n\\n        return medium_io of type :class:`IMediumIO`\\n            Medium I/O object.\\n\\n        \"\"\"\\n        if not isinstance(writable, bool):\\n            raise TypeError(\"writable can only be an instance of type bool\")\\n        if not isinstance(password, basestring):\\n            raise TypeError(\"password can only be an instance of type basestring\")\\n        medium_io = self._call(\"openForIO\",\\n                     in_p=[writable, password])\\n        medium_io = IMediumIO(medium_io)\\n        return medium_io',\n",
              " 'def describe_file_extensions(self):\\n        \"\"\"Returns two arrays describing the supported file extensions.\\n        \\n        The first array contains the supported extensions and the seconds one\\n        the type each extension supports. Both have the same size.\\n        \\n        Note that some backends do not work on files, so this array may be\\n        empty.\\n        \\n        :py:func:`IMediumFormat.capabilities` \\n\\n        out extensions of type str\\n            The array of supported extensions.\\n\\n        out types of type :class:`DeviceType`\\n            The array which indicates the device type for every given extension.\\n\\n        \"\"\"\\n        (extensions, types) = self._call(\"describeFileExtensions\")\\n        types = [DeviceType(a) for a in types]\\n        return (extensions, types)',\n",
              " 'def describe_properties(self):\\n        \"\"\"Returns several arrays describing the properties supported by this\\n        format.\\n        \\n        An element with the given index in each array describes one\\n        property. Thus, the number of elements in each returned array is the\\n        same and corresponds to the number of supported properties.\\n        \\n        The returned arrays are filled in only if the\\n        :py:attr:`MediumFormatCapabilities.properties`  flag is set.\\n        All arguments must be non-@c null.\\n        \\n        :py:class:`DataType` , :py:class:`DataFlags` \\n\\n        out names of type str\\n            Array of property names.\\n\\n        out descriptions of type str\\n            Array of property descriptions.\\n\\n        out types of type :class:`DataType`\\n            Array of property types.\\n\\n        out flags of type int\\n            Array of property flags.\\n\\n        out defaults of type str\\n            Array of default property values.\\n\\n        \"\"\"\\n        (names, descriptions, types, flags, defaults) = self._call(\"describeProperties\")\\n        types = [DataType(a) for a in types]\\n        return (names, descriptions, types, flags, defaults)',\n",
              " 'def write(self, offset, data):\\n        \"\"\"Write data to the medium.\\n\\n        in offset of type int\\n            The byte offset into the medium to start reading at.\\n\\n        in data of type str\\n            Array of data to write.\\n\\n        return written of type int\\n            How many bytes were actually written.\\n\\n        \"\"\"\\n        if not isinstance(offset, baseinteger):\\n            raise TypeError(\"offset can only be an instance of type baseinteger\")\\n        if not isinstance(data, list):\\n            raise TypeError(\"data can only be an instance of type list\")\\n        for a in data[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        written = self._call(\"write\",\\n                     in_p=[offset, data])\\n        return written',\n",
              " 'def format_fat(self, quick):\\n        \"\"\"Formats the medium as FAT.  Generally only useful for floppy images as\\n        no partition table will be created.\\n\\n        in quick of type bool\\n            Quick format it when set.\\n\\n        \"\"\"\\n        if not isinstance(quick, bool):\\n            raise TypeError(\"quick can only be an instance of type bool\")\\n        self._call(\"formatFAT\",\\n                     in_p=[quick])',\n",
              " 'def initialize_partition_table(self, format_p, whole_disk_in_one_entry):\\n        \"\"\"Writes an empty partition table to the disk.\\n\\n        in format_p of type :class:`PartitionTableType`\\n            The partition table format.\\n\\n        in whole_disk_in_one_entry of type bool\\n            When @c true a partition table entry for the whole disk is created.\\n            Otherwise the partition table is empty.\\n\\n        \"\"\"\\n        if not isinstance(format_p, PartitionTableType):\\n            raise TypeError(\"format_p can only be an instance of type PartitionTableType\")\\n        if not isinstance(whole_disk_in_one_entry, bool):\\n            raise TypeError(\"whole_disk_in_one_entry can only be an instance of type bool\")\\n        self._call(\"initializePartitionTable\",\\n                     in_p=[format_p, whole_disk_in_one_entry])',\n",
              " 'def convert_to_stream(self, format_p, variant, buffer_size):\\n        \"\"\"Converts the currently opened image into a stream of the specified\\n        image type/variant. It is sufficient to open the image in read-only\\n        mode. Only few types and variants are supported due to the inherent\\n        restrictions of the output style.\\n\\n        in format_p of type str\\n            Identifier of the storage format to use for output.\\n\\n        in variant of type :class:`MediumVariant`\\n            The partition table format.\\n\\n        in buffer_size of type int\\n            Requested buffer size (in bytes) for efficient conversion. Sizes\\n            which are too small or too large are silently truncated to suitable\\n            values. Tens to hundreds of Megabytes are a good choice.\\n\\n        out stream of type :class:`IDataStream`\\n            Data stream object for reading the target image.\\n\\n        return progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        raises :class:`VBoxErrorNotSupported`\\n            The requested format/variant combination cannot handle stream output.\\n        \\n        raises :class:`VBoxErrorFileError`\\n            An error occurred during the conversion.\\n        \\n        \"\"\"\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        if not isinstance(variant, list):\\n            raise TypeError(\"variant can only be an instance of type list\")\\n        for a in variant[:10]:\\n            if not isinstance(a, MediumVariant):\\n                raise TypeError(\\n                        \"array can only contain objects of type MediumVariant\")\\n        if not isinstance(buffer_size, baseinteger):\\n            raise TypeError(\"buffer_size can only be an instance of type baseinteger\")\\n        (progress, stream) = self._call(\"convertToStream\",\\n                     in_p=[format_p, variant, buffer_size])\\n        progress = IProgress(progress)\\n        stream = IDataStream(stream)\\n        return (progress, stream)',\n",
              " 'def put_scancode(self, scancode):\\n        \"\"\"Sends a scancode to the keyboard.\\n\\n        in scancode of type int\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Could not send scan code to virtual keyboard.\\n        \\n        \"\"\"\\n        if not isinstance(scancode, baseinteger):\\n            raise TypeError(\"scancode can only be an instance of type baseinteger\")\\n        self._call(\"putScancode\",\\n                     in_p=[scancode])',\n",
              " 'def put_scancodes(self, scancodes):\\n        \"\"\"Sends an array of scancodes to the keyboard.\\n\\n        in scancodes of type int\\n\\n        return codes_stored of type int\\n\\n        raises :class:`VBoxErrorIprtError`\\n            Could not send all scan codes to virtual keyboard.\\n        \\n        \"\"\"\\n        if not isinstance(scancodes, list):\\n            raise TypeError(\"scancodes can only be an instance of type list\")\\n        for a in scancodes[:10]:\\n            if not isinstance(a, baseinteger):\\n                raise TypeError(\\n                        \"array can only contain objects of type baseinteger\")\\n        codes_stored = self._call(\"putScancodes\",\\n                     in_p=[scancodes])\\n        return codes_stored',\n",
              " 'def put_mouse_event(self, dx, dy, dz, dw, button_state):\\n        \"\"\"Initiates a mouse event using relative pointer movements\\n        along x and y axis.\\n\\n        in dx of type int\\n            Amount of pixels the mouse should move to the right.\\n            Negative values move the mouse to the left.\\n\\n        in dy of type int\\n            Amount of pixels the mouse should move downwards.\\n            Negative values move the mouse upwards.\\n\\n        in dz of type int\\n            Amount of mouse wheel moves.\\n            Positive values describe clockwise wheel rotations,\\n            negative values describe counterclockwise rotations.\\n\\n        in dw of type int\\n            Amount of horizontal mouse wheel moves.\\n            Positive values describe a movement to the left,\\n            negative values describe a movement to the right.\\n\\n        in button_state of type int\\n            The current state of mouse buttons. Every bit represents\\n            a mouse button as follows:\\n            \\n            Bit 0 (0x01)left mouse button\\n            Bit 1 (0x02)right mouse button\\n            Bit 2 (0x04)middle mouse button\\n            \\n            A value of 1 means the corresponding button is pressed.\\n            otherwise it is released.\\n\\n        raises :class:`OleErrorAccessdenied`\\n            Console not powered up.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not send mouse event to virtual mouse.\\n        \\n        \"\"\"\\n        if not isinstance(dx, baseinteger):\\n            raise TypeError(\"dx can only be an instance of type baseinteger\")\\n        if not isinstance(dy, baseinteger):\\n            raise TypeError(\"dy can only be an instance of type baseinteger\")\\n        if not isinstance(dz, baseinteger):\\n            raise TypeError(\"dz can only be an instance of type baseinteger\")\\n        if not isinstance(dw, baseinteger):\\n            raise TypeError(\"dw can only be an instance of type baseinteger\")\\n        if not isinstance(button_state, baseinteger):\\n            raise TypeError(\"button_state can only be an instance of type baseinteger\")\\n        self._call(\"putMouseEvent\",\\n                     in_p=[dx, dy, dz, dw, button_state])',\n",
              " 'def put_mouse_event_absolute(self, x, y, dz, dw, button_state):\\n        \"\"\"Positions the mouse pointer using absolute x and y coordinates.\\n        These coordinates are expressed in pixels and\\n        start from [1,1] which corresponds to the top left\\n        corner of the virtual display.  The values [-1,-1] and\\n        [0x7fffffff,0x7fffffff] have special meanings as\\n        respectively \"no data\" (to signal that the host wishes to report\\n        absolute pointer data in future) and \"out of range\" (the host\\n        pointer is outside of all guest windows).\\n        \\n        \\n        \\n        \\n        This method will have effect only if absolute mouse\\n        positioning is supported by the guest OS.\\n        \\n        \\n        :py:func:`absolute_supported` \\n\\n        in x of type int\\n            X coordinate of the pointer in pixels, starting from @c 1.\\n\\n        in y of type int\\n            Y coordinate of the pointer in pixels, starting from @c 1.\\n\\n        in dz of type int\\n            Amount of mouse wheel moves.\\n            Positive values describe clockwise wheel rotations,\\n            negative values describe counterclockwise rotations.\\n\\n        in dw of type int\\n            Amount of horizontal mouse wheel moves.\\n            Positive values describe a movement to the left,\\n            negative values describe a movement to the right.\\n\\n        in button_state of type int\\n            The current state of mouse buttons. Every bit represents\\n            a mouse button as follows:\\n            \\n            Bit 0 (0x01)left mouse button\\n            Bit 1 (0x02)right mouse button\\n            Bit 2 (0x04)middle mouse button\\n            \\n            A value of @c 1 means the corresponding button is pressed.\\n            otherwise it is released.\\n\\n        raises :class:`OleErrorAccessdenied`\\n            Console not powered up.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not send mouse event to virtual mouse.\\n        \\n        \"\"\"\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(dz, baseinteger):\\n            raise TypeError(\"dz can only be an instance of type baseinteger\")\\n        if not isinstance(dw, baseinteger):\\n            raise TypeError(\"dw can only be an instance of type baseinteger\")\\n        if not isinstance(button_state, baseinteger):\\n            raise TypeError(\"button_state can only be an instance of type baseinteger\")\\n        self._call(\"putMouseEventAbsolute\",\\n                     in_p=[x, y, dz, dw, button_state])',\n",
              " 'def put_event_multi_touch(self, count, contacts, scan_time):\\n        \"\"\"Sends a multi-touch pointer event. The coordinates are expressed in\\n        pixels and start from [1,1] which corresponds to the top left\\n        corner of the virtual display.\\n        \\n        \\n        \\n        \\n        The guest may not understand or may choose to ignore this event.\\n        \\n        \\n        :py:func:`multi_touch_supported` \\n\\n        in count of type int\\n            Number of contacts in the event.\\n\\n        in contacts of type int\\n            Each array element contains packed information about one contact.\\n            Bits 0..15: X coordinate in pixels.\\n            Bits 16..31: Y coordinate in pixels.\\n            Bits 32..39: contact identifier.\\n            Bit 40: \"in contact\" flag, which indicates that there is a contact with the touch surface.\\n            Bit 41: \"in range\" flag, the contact is close enough to the touch surface.\\n            All other bits are reserved for future use and must be set to 0.\\n\\n        in scan_time of type int\\n            Timestamp of the event in milliseconds. Only relative time between events is important.\\n\\n        raises :class:`OleErrorAccessdenied`\\n            Console not powered up.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not send event to virtual device.\\n        \\n        \"\"\"\\n        if not isinstance(count, baseinteger):\\n            raise TypeError(\"count can only be an instance of type baseinteger\")\\n        if not isinstance(contacts, list):\\n            raise TypeError(\"contacts can only be an instance of type list\")\\n        for a in contacts[:10]:\\n            if not isinstance(a, baseinteger):\\n                raise TypeError(\\n                        \"array can only contain objects of type baseinteger\")\\n        if not isinstance(scan_time, baseinteger):\\n            raise TypeError(\"scan_time can only be an instance of type baseinteger\")\\n        self._call(\"putEventMultiTouch\",\\n                     in_p=[count, contacts, scan_time])',\n",
              " 'def put_event_multi_touch_string(self, count, contacts, scan_time):\\n        \"\"\":py:func:`put_event_multi_touch` \\n\\n        in count of type int\\n            :py:func:`put_event_multi_touch` \\n\\n        in contacts of type str\\n            Contains information about all contacts:\\n            \"id1,x1,y1,inContact1,inRange1;...;idN,xN,yN,inContactN,inRangeN\".\\n            For example for two contacts: \"0,10,20,1,1;1,30,40,1,1\"\\n\\n        in scan_time of type int\\n            :py:func:`put_event_multi_touch` \\n\\n        \"\"\"\\n        if not isinstance(count, baseinteger):\\n            raise TypeError(\"count can only be an instance of type baseinteger\")\\n        if not isinstance(contacts, basestring):\\n            raise TypeError(\"contacts can only be an instance of type basestring\")\\n        if not isinstance(scan_time, baseinteger):\\n            raise TypeError(\"scan_time can only be an instance of type baseinteger\")\\n        self._call(\"putEventMultiTouchString\",\\n                     in_p=[count, contacts, scan_time])',\n",
              " 'def query_bitmap_info(self):\\n        \"\"\"Information about the screen bitmap.\\n\\n        out address of type str\\n\\n        out width of type int\\n\\n        out height of type int\\n\\n        out bits_per_pixel of type int\\n\\n        out bytes_per_line of type int\\n\\n        out bitmap_format of type :class:`BitmapFormat`\\n\\n        \"\"\"\\n        (address, width, height, bits_per_pixel, bytes_per_line, bitmap_format) = self._call(\"queryBitmapInfo\")\\n        bitmap_format = BitmapFormat(bitmap_format)\\n        return (address, width, height, bits_per_pixel, bytes_per_line, bitmap_format)',\n",
              " 'def notify_update(self, x, y, width, height):\\n        \"\"\"Informs about an update.\\n        Gets called by the display object where this buffer is\\n        registered.\\n\\n        in x of type int\\n\\n        in y of type int\\n\\n        in width of type int\\n\\n        in height of type int\\n\\n        \"\"\"\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        self._call(\"notifyUpdate\",\\n                     in_p=[x, y, width, height])',\n",
              " 'def notify_update_image(self, x, y, width, height, image):\\n        \"\"\"Informs about an update and provides 32bpp bitmap.\\n\\n        in x of type int\\n\\n        in y of type int\\n\\n        in width of type int\\n\\n        in height of type int\\n\\n        in image of type str\\n            Array with 32BPP image data.\\n\\n        \"\"\"\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(image, list):\\n            raise TypeError(\"image can only be an instance of type list\")\\n        for a in image[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"notifyUpdateImage\",\\n                     in_p=[x, y, width, height, image])',\n",
              " 'def notify_change(self, screen_id, x_origin, y_origin, width, height):\\n        \"\"\"Requests a size change.\\n\\n        in screen_id of type int\\n            Logical guest screen number.\\n\\n        in x_origin of type int\\n            Location of the screen in the guest.\\n\\n        in y_origin of type int\\n            Location of the screen in the guest.\\n\\n        in width of type int\\n            Width of the guest display, in pixels.\\n\\n        in height of type int\\n            Height of the guest display, in pixels.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(x_origin, baseinteger):\\n            raise TypeError(\"x_origin can only be an instance of type baseinteger\")\\n        if not isinstance(y_origin, baseinteger):\\n            raise TypeError(\"y_origin can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        self._call(\"notifyChange\",\\n                     in_p=[screen_id, x_origin, y_origin, width, height])',\n",
              " 'def video_mode_supported(self, width, height, bpp):\\n        \"\"\"Returns whether the frame buffer implementation is willing to\\n        support a given video mode. In case it is not able to render\\n        the video mode (or for some reason not willing), it should\\n        return @c false. Usually this method is called when the guest\\n        asks the VMM device whether a given video mode is supported\\n        so the information returned is directly exposed to the guest.\\n        It is important that this method returns very quickly.\\n\\n        in width of type int\\n\\n        in height of type int\\n\\n        in bpp of type int\\n\\n        return supported of type bool\\n\\n        \"\"\"\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(bpp, baseinteger):\\n            raise TypeError(\"bpp can only be an instance of type baseinteger\")\\n        supported = self._call(\"videoModeSupported\",\\n                     in_p=[width, height, bpp])\\n        return supported',\n",
              " 'def get_visible_region(self, rectangles, count):\\n        \"\"\"Returns the visible region of this frame buffer.\\n        \\n        If the @a rectangles parameter is @c null then the value of the\\n        @a count parameter is ignored and the number of elements necessary to\\n        describe the current visible region is returned in @a countCopied.\\n        \\n        If @a rectangles is not @c null but @a count is less\\n        than the required number of elements to store region data, the method\\n        will report a failure. If @a count is equal or greater than the\\n        required number of elements, then the actual number of elements copied\\n        to the provided array will be returned in @a countCopied.\\n        \\n        \\n        The address of the provided array must be in the process space of\\n        this IFramebuffer object.\\n        \\n        \\n        Method not yet implemented.\\n\\n        in rectangles of type str\\n            Pointer to the @c RTRECT array to receive region data.\\n\\n        in count of type int\\n            Number of @c RTRECT elements in the @a rectangles array.\\n\\n        return count_copied of type int\\n            Number of elements copied to the @a rectangles array.\\n\\n        \"\"\"\\n        if not isinstance(rectangles, basestring):\\n            raise TypeError(\"rectangles can only be an instance of type basestring\")\\n        if not isinstance(count, baseinteger):\\n            raise TypeError(\"count can only be an instance of type baseinteger\")\\n        count_copied = self._call(\"getVisibleRegion\",\\n                     in_p=[rectangles, count])\\n        return count_copied',\n",
              " 'def set_visible_region(self, rectangles, count):\\n        \"\"\"Suggests a new visible region to this frame buffer. This region\\n        represents the area of the VM display which is a union of regions of\\n        all top-level windows of the guest operating system running inside the\\n        VM (if the Guest Additions for this system support this\\n        functionality). This information may be used by the frontends to\\n        implement the seamless desktop integration feature.\\n        \\n        \\n        The address of the provided array must be in the process space of\\n        this IFramebuffer object.\\n        \\n        \\n        The IFramebuffer implementation must make a copy of the provided\\n        array of rectangles.\\n        \\n        \\n        Method not yet implemented.\\n\\n        in rectangles of type str\\n            Pointer to the @c RTRECT array.\\n\\n        in count of type int\\n            Number of @c RTRECT elements in the @a rectangles array.\\n\\n        \"\"\"\\n        if not isinstance(rectangles, basestring):\\n            raise TypeError(\"rectangles can only be an instance of type basestring\")\\n        if not isinstance(count, baseinteger):\\n            raise TypeError(\"count can only be an instance of type baseinteger\")\\n        self._call(\"setVisibleRegion\",\\n                     in_p=[rectangles, count])',\n",
              " 'def process_vhwa_command(self, command, enm_cmd, from_guest):\\n        \"\"\"Posts a Video HW Acceleration Command to the frame buffer for processing.\\n        The commands used for 2D video acceleration (DDraw surface creation/destroying, blitting, scaling, color conversion, overlaying, etc.)\\n        are posted from quest to the host to be processed by the host hardware.\\n        \\n        \\n        The address of the provided command must be in the process space of\\n        this IFramebuffer object.\\n\\n        in command of type str\\n            Pointer to VBOXVHWACMD containing the command to execute.\\n\\n        in enm_cmd of type int\\n            The validated VBOXVHWACMD::enmCmd value from the command.\\n\\n        in from_guest of type bool\\n            Set when the command origins from the guest, clear if host.\\n\\n        \"\"\"\\n        if not isinstance(command, basestring):\\n            raise TypeError(\"command can only be an instance of type basestring\")\\n        if not isinstance(enm_cmd, baseinteger):\\n            raise TypeError(\"enm_cmd can only be an instance of type baseinteger\")\\n        if not isinstance(from_guest, bool):\\n            raise TypeError(\"from_guest can only be an instance of type bool\")\\n        self._call(\"processVHWACommand\",\\n                     in_p=[command, enm_cmd, from_guest])',\n",
              " 'def notify3_d_event(self, type_p, data):\\n        \"\"\"Notifies framebuffer about 3D backend event.\\n\\n        in type_p of type int\\n            event type. Currently only VBOX3D_NOTIFY_EVENT_TYPE_VISIBLE_3DDATA is supported.\\n\\n        in data of type str\\n            event-specific data, depends on the supplied event type\\n\\n        \"\"\"\\n        if not isinstance(type_p, baseinteger):\\n            raise TypeError(\"type_p can only be an instance of type baseinteger\")\\n        if not isinstance(data, list):\\n            raise TypeError(\"data can only be an instance of type list\")\\n        for a in data[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"notify3DEvent\",\\n                     in_p=[type_p, data])',\n",
              " 'def move(self, x, y):\\n        \"\"\"Changes the overlay\\'s position relative to the IFramebuffer.\\n\\n        in x of type int\\n\\n        in y of type int\\n\\n        \"\"\"\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        self._call(\"move\",\\n                     in_p=[x, y])',\n",
              " 'def get_screen_resolution(self, screen_id):\\n        \"\"\"Queries certain attributes such as display width, height, color depth\\n        and the X and Y origin for a given guest screen.\\n        \\n        The parameters @a xOrigin and @a yOrigin return the X and Y\\n        coordinates of the framebuffer\\'s origin.\\n        \\n        All return parameters are optional.\\n\\n        in screen_id of type int\\n\\n        out width of type int\\n\\n        out height of type int\\n\\n        out bits_per_pixel of type int\\n\\n        out x_origin of type int\\n\\n        out y_origin of type int\\n\\n        out guest_monitor_status of type :class:`GuestMonitorStatus`\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        (width, height, bits_per_pixel, x_origin, y_origin, guest_monitor_status) = self._call(\"getScreenResolution\",\\n                     in_p=[screen_id])\\n        guest_monitor_status = GuestMonitorStatus(guest_monitor_status)\\n        return (width, height, bits_per_pixel, x_origin, y_origin, guest_monitor_status)',\n",
              " 'def attach_framebuffer(self, screen_id, framebuffer):\\n        \"\"\"Sets the graphics update target for a screen.\\n\\n        in screen_id of type int\\n\\n        in framebuffer of type :class:`IFramebuffer`\\n\\n        return id_p of type str\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(framebuffer, IFramebuffer):\\n            raise TypeError(\"framebuffer can only be an instance of type IFramebuffer\")\\n        id_p = self._call(\"attachFramebuffer\",\\n                     in_p=[screen_id, framebuffer])\\n        return id_p',\n",
              " 'def detach_framebuffer(self, screen_id, id_p):\\n        \"\"\"Removes the graphics updates target for a screen.\\n\\n        in screen_id of type int\\n\\n        in id_p of type str\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        self._call(\"detachFramebuffer\",\\n                     in_p=[screen_id, id_p])',\n",
              " 'def query_framebuffer(self, screen_id):\\n        \"\"\"Queries the graphics updates targets for a screen.\\n\\n        in screen_id of type int\\n\\n        return framebuffer of type :class:`IFramebuffer`\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        framebuffer = self._call(\"queryFramebuffer\",\\n                     in_p=[screen_id])\\n        framebuffer = IFramebuffer(framebuffer)\\n        return framebuffer',\n",
              " 'def set_video_mode_hint(self, display, enabled, change_origin, origin_x, origin_y, width, height, bits_per_pixel):\\n        \"\"\"Asks VirtualBox to request the given video mode from\\n        the guest. This is just a hint and it cannot be guaranteed\\n        that the requested resolution will be used. Guest Additions\\n        are required for the request to be seen by guests. The caller\\n        should issue the request and wait for a resolution change and\\n        after a timeout retry.\\n        \\n        Specifying @c 0 for either @a width, @a height or @a bitsPerPixel\\n        parameters means that the corresponding values should be taken from the\\n        current video mode (i.e. left unchanged).\\n        \\n        If the guest OS supports multi-monitor configuration then the @a display\\n        parameter specifies the number of the guest display to send the hint to:\\n        @c 0 is the primary display, @c 1 is the first secondary and\\n        so on. If the multi-monitor configuration is not supported, @a display\\n        must be @c 0.\\n\\n        in display of type int\\n            The number of the guest display to send the hint to.\\n\\n        in enabled of type bool\\n            @c True, if this guest screen is enabled,\\n            @c False otherwise.\\n\\n        in change_origin of type bool\\n            @c True, if the origin of the guest screen should be changed,\\n            @c False otherwise.\\n\\n        in origin_x of type int\\n            The X origin of the guest screen.\\n\\n        in origin_y of type int\\n            The Y origin of the guest screen.\\n\\n        in width of type int\\n            The width of the guest screen.\\n\\n        in height of type int\\n            The height of the guest screen.\\n\\n        in bits_per_pixel of type int\\n            The number of bits per pixel of the guest screen.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            The @a display is not associated with any monitor.\\n        \\n        \"\"\"\\n        if not isinstance(display, baseinteger):\\n            raise TypeError(\"display can only be an instance of type baseinteger\")\\n        if not isinstance(enabled, bool):\\n            raise TypeError(\"enabled can only be an instance of type bool\")\\n        if not isinstance(change_origin, bool):\\n            raise TypeError(\"change_origin can only be an instance of type bool\")\\n        if not isinstance(origin_x, baseinteger):\\n            raise TypeError(\"origin_x can only be an instance of type baseinteger\")\\n        if not isinstance(origin_y, baseinteger):\\n            raise TypeError(\"origin_y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(bits_per_pixel, baseinteger):\\n            raise TypeError(\"bits_per_pixel can only be an instance of type baseinteger\")\\n        self._call(\"setVideoModeHint\",\\n                     in_p=[display, enabled, change_origin, origin_x, origin_y, width, height, bits_per_pixel])',\n",
              " 'def set_seamless_mode(self, enabled):\\n        \"\"\"Enables or disables seamless guest display rendering (seamless desktop\\n        integration) mode.\\n        \\n        Calling this method has no effect if :py:func:`IGuest.get_facility_status`  with facility @c Seamless\\n        does not return @c Active.\\n\\n        in enabled of type bool\\n\\n        \"\"\"\\n        if not isinstance(enabled, bool):\\n            raise TypeError(\"enabled can only be an instance of type bool\")\\n        self._call(\"setSeamlessMode\",\\n                     in_p=[enabled])',\n",
              " 'def take_screen_shot(self, screen_id, address, width, height, bitmap_format):\\n        \"\"\"Takes a screen shot of the requested size and format and copies it to the\\n        buffer allocated by the caller and pointed to by @a address.\\n        The buffer size must be enough for a 32 bits per pixel bitmap,\\n        i.e. width * height * 4 bytes.\\n        \\n        This API can be used only locally by a VM process through the\\n        COM/XPCOM C++ API as it requires pointer support. It is not\\n        available for scripting languages, Java or any webservice clients.\\n        Unless you are writing a new VM frontend use\\n        :py:func:`take_screen_shot_to_array` .\\n\\n        in screen_id of type int\\n\\n        in address of type str\\n\\n        in width of type int\\n\\n        in height of type int\\n\\n        in bitmap_format of type :class:`BitmapFormat`\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(address, basestring):\\n            raise TypeError(\"address can only be an instance of type basestring\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(bitmap_format, BitmapFormat):\\n            raise TypeError(\"bitmap_format can only be an instance of type BitmapFormat\")\\n        self._call(\"takeScreenShot\",\\n                     in_p=[screen_id, address, width, height, bitmap_format])',\n",
              " 'def take_screen_shot_to_array(self, screen_id, width, height, bitmap_format):\\n        \"\"\"Takes a guest screen shot of the requested size and format\\n        and returns it as an array of bytes.\\n\\n        in screen_id of type int\\n            The guest monitor to take screenshot from.\\n\\n        in width of type int\\n            Desired image width.\\n\\n        in height of type int\\n            Desired image height.\\n\\n        in bitmap_format of type :class:`BitmapFormat`\\n            The requested format.\\n\\n        return screen_data of type str\\n            Array with resulting screen data.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(bitmap_format, BitmapFormat):\\n            raise TypeError(\"bitmap_format can only be an instance of type BitmapFormat\")\\n        screen_data = self._call(\"takeScreenShotToArray\",\\n                     in_p=[screen_id, width, height, bitmap_format])\\n        return screen_data',\n",
              " 'def draw_to_screen(self, screen_id, address, x, y, width, height):\\n        \"\"\"Draws a 32-bpp image of the specified size from the given buffer\\n        to the given point on the VM display.\\n\\n        in screen_id of type int\\n            Monitor to take the screenshot from.\\n\\n        in address of type str\\n            Address to store the screenshot to\\n\\n        in x of type int\\n            Relative to the screen top left corner.\\n\\n        in y of type int\\n            Relative to the screen top left corner.\\n\\n        in width of type int\\n            Desired image width.\\n\\n        in height of type int\\n            Desired image height.\\n\\n        raises :class:`OleErrorNotimpl`\\n            Feature not implemented.\\n        \\n        raises :class:`VBoxErrorIprtError`\\n            Could not draw to screen.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(address, basestring):\\n            raise TypeError(\"address can only be an instance of type basestring\")\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        self._call(\"drawToScreen\",\\n                     in_p=[screen_id, address, x, y, width, height])',\n",
              " 'def invalidate_and_update_screen(self, screen_id):\\n        \"\"\"Redraw the specified VM screen.\\n\\n        in screen_id of type int\\n            The guest screen to redraw.\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        self._call(\"invalidateAndUpdateScreen\",\\n                     in_p=[screen_id])',\n",
              " 'def complete_vhwa_command(self, command):\\n        \"\"\"Signals that the Video HW Acceleration command has completed.\\n\\n        in command of type str\\n            Pointer to VBOXVHWACMD containing the completed command.\\n\\n        \"\"\"\\n        if not isinstance(command, basestring):\\n            raise TypeError(\"command can only be an instance of type basestring\")\\n        self._call(\"completeVHWACommand\",\\n                     in_p=[command])',\n",
              " 'def viewport_changed(self, screen_id, x, y, width, height):\\n        \"\"\"Signals that framebuffer window viewport has changed.\\n\\n        in screen_id of type int\\n            Monitor to take the screenshot from.\\n\\n        in x of type int\\n            Framebuffer x offset.\\n\\n        in y of type int\\n            Framebuffer y offset.\\n\\n        in width of type int\\n            Viewport width.\\n\\n        in height of type int\\n            Viewport height.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            The specified viewport data is invalid.\\n        \\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(x, baseinteger):\\n            raise TypeError(\"x can only be an instance of type baseinteger\")\\n        if not isinstance(y, baseinteger):\\n            raise TypeError(\"y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        self._call(\"viewportChanged\",\\n                     in_p=[screen_id, x, y, width, height])',\n",
              " 'def query_source_bitmap(self, screen_id):\\n        \"\"\"Obtains the guest screen bitmap parameters.\\n\\n        in screen_id of type int\\n\\n        out display_source_bitmap of type :class:`IDisplaySourceBitmap`\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        display_source_bitmap = self._call(\"querySourceBitmap\",\\n                     in_p=[screen_id])\\n        display_source_bitmap = IDisplaySourceBitmap(display_source_bitmap)\\n        return display_source_bitmap',\n",
              " 'def notify_scale_factor_change(self, screen_id, u32_scale_factor_w_multiplied, u32_scale_factor_h_multiplied):\\n        \"\"\"Notify OpenGL HGCM host service about graphics content scaling factor change.\\n\\n        in screen_id of type int\\n\\n        in u32_scale_factor_w_multiplied of type int\\n\\n        in u32_scale_factor_h_multiplied of type int\\n\\n        \"\"\"\\n        if not isinstance(screen_id, baseinteger):\\n            raise TypeError(\"screen_id can only be an instance of type baseinteger\")\\n        if not isinstance(u32_scale_factor_w_multiplied, baseinteger):\\n            raise TypeError(\"u32_scale_factor_w_multiplied can only be an instance of type baseinteger\")\\n        if not isinstance(u32_scale_factor_h_multiplied, baseinteger):\\n            raise TypeError(\"u32_scale_factor_h_multiplied can only be an instance of type baseinteger\")\\n        self._call(\"notifyScaleFactorChange\",\\n                     in_p=[screen_id, u32_scale_factor_w_multiplied, u32_scale_factor_h_multiplied])',\n",
              " 'def notify_hi_dpi_output_policy_change(self, f_unscaled_hi_dpi):\\n        \"\"\"Notify OpenGL HGCM host service about HiDPI monitor scaling policy change.\\n\\n        in f_unscaled_hi_dpi of type bool\\n\\n        \"\"\"\\n        if not isinstance(f_unscaled_hi_dpi, bool):\\n            raise TypeError(\"f_unscaled_hi_dpi can only be an instance of type bool\")\\n        self._call(\"notifyHiDPIOutputPolicyChange\",\\n                     in_p=[f_unscaled_hi_dpi])',\n",
              " 'def set_screen_layout(self, screen_layout_mode, guest_screen_info):\\n        \"\"\"Set video modes for the guest screens.\\n\\n        in screen_layout_mode of type :class:`ScreenLayoutMode`\\n\\n        in guest_screen_info of type :class:`IGuestScreenInfo`\\n\\n        \"\"\"\\n        if not isinstance(screen_layout_mode, ScreenLayoutMode):\\n            raise TypeError(\"screen_layout_mode can only be an instance of type ScreenLayoutMode\")\\n        if not isinstance(guest_screen_info, list):\\n            raise TypeError(\"guest_screen_info can only be an instance of type list\")\\n        for a in guest_screen_info[:10]:\\n            if not isinstance(a, IGuestScreenInfo):\\n                raise TypeError(\\n                        \"array can only contain objects of type IGuestScreenInfo\")\\n        self._call(\"setScreenLayout\",\\n                     in_p=[screen_layout_mode, guest_screen_info])',\n",
              " 'def detach_screens(self, screen_ids):\\n        \"\"\"Unplugs monitors from the virtual graphics card.\\n\\n        in screen_ids of type int\\n\\n        \"\"\"\\n        if not isinstance(screen_ids, list):\\n            raise TypeError(\"screen_ids can only be an instance of type list\")\\n        for a in screen_ids[:10]:\\n            if not isinstance(a, baseinteger):\\n                raise TypeError(\\n                        \"array can only contain objects of type baseinteger\")\\n        self._call(\"detachScreens\",\\n                     in_p=[screen_ids])',\n",
              " 'def create_guest_screen_info(self, display, status, primary, change_origin, origin_x, origin_y, width, height, bits_per_pixel):\\n        \"\"\"Make a IGuestScreenInfo object with the provided parameters.\\n\\n        in display of type int\\n            The number of the guest display.\\n\\n        in status of type :class:`GuestMonitorStatus`\\n            @c True, if this guest screen is enabled,\\n            @c False otherwise.\\n\\n        in primary of type bool\\n            Whether this guest monitor must be primary.\\n\\n        in change_origin of type bool\\n            @c True, if the origin of the guest screen should be changed,\\n            @c False otherwise.\\n\\n        in origin_x of type int\\n            The X origin of the guest screen.\\n\\n        in origin_y of type int\\n            The Y origin of the guest screen.\\n\\n        in width of type int\\n            The width of the guest screen.\\n\\n        in height of type int\\n            The height of the guest screen.\\n\\n        in bits_per_pixel of type int\\n            The number of bits per pixel of the guest screen.\\n\\n        return guest_screen_info of type :class:`IGuestScreenInfo`\\n            The created object.\\n\\n        \"\"\"\\n        if not isinstance(display, baseinteger):\\n            raise TypeError(\"display can only be an instance of type baseinteger\")\\n        if not isinstance(status, GuestMonitorStatus):\\n            raise TypeError(\"status can only be an instance of type GuestMonitorStatus\")\\n        if not isinstance(primary, bool):\\n            raise TypeError(\"primary can only be an instance of type bool\")\\n        if not isinstance(change_origin, bool):\\n            raise TypeError(\"change_origin can only be an instance of type bool\")\\n        if not isinstance(origin_x, baseinteger):\\n            raise TypeError(\"origin_x can only be an instance of type baseinteger\")\\n        if not isinstance(origin_y, baseinteger):\\n            raise TypeError(\"origin_y can only be an instance of type baseinteger\")\\n        if not isinstance(width, baseinteger):\\n            raise TypeError(\"width can only be an instance of type baseinteger\")\\n        if not isinstance(height, baseinteger):\\n            raise TypeError(\"height can only be an instance of type baseinteger\")\\n        if not isinstance(bits_per_pixel, baseinteger):\\n            raise TypeError(\"bits_per_pixel can only be an instance of type baseinteger\")\\n        guest_screen_info = self._call(\"createGuestScreenInfo\",\\n                     in_p=[display, status, primary, change_origin, origin_x, origin_y, width, height, bits_per_pixel])\\n        guest_screen_info = IGuestScreenInfo(guest_screen_info)\\n        return guest_screen_info',\n",
              " 'def get_property(self, key):\\n        \"\"\"Returns the value of the network attachment property with the given name.\\n        \\n        If the requested data @a key does not exist, this function will\\n        succeed and return an empty string in the @a value argument.\\n\\n        in key of type str\\n            Name of the property to get.\\n\\n        return value of type str\\n            Current property value.\\n\\n        raises :class:`OleErrorInvalidarg`\\n            @a name is @c null or empty.\\n        \\n        \"\"\"\\n        if not isinstance(key, basestring):\\n            raise TypeError(\"key can only be an instance of type basestring\")\\n        value = self._call(\"getProperty\",\\n                     in_p=[key])\\n        return value',\n",
              " 'def dump_guest_core(self, filename, compression):\\n        \"\"\"Takes a core dump of the guest.\\n        \\n        See include/VBox/dbgfcorefmt.h for details on the file format.\\n\\n        in filename of type str\\n            The name of the output file. The file must not exist.\\n\\n        in compression of type str\\n            Reserved for future compression method indicator.\\n\\n        \"\"\"\\n        if not isinstance(filename, basestring):\\n            raise TypeError(\"filename can only be an instance of type basestring\")\\n        if not isinstance(compression, basestring):\\n            raise TypeError(\"compression can only be an instance of type basestring\")\\n        self._call(\"dumpGuestCore\",\\n                     in_p=[filename, compression])',\n",
              " 'def info(self, name, args):\\n        \"\"\"Interfaces with the info dumpers (DBGFInfo).\\n        \\n        This feature is not implemented in the 4.0.0 release but it may show up\\n        in a dot release.\\n\\n        in name of type str\\n            The name of the info item.\\n\\n        in args of type str\\n            Arguments to the info dumper.\\n\\n        return info of type str\\n            The into string.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(args, basestring):\\n            raise TypeError(\"args can only be an instance of type basestring\")\\n        info = self._call(\"info\",\\n                     in_p=[name, args])\\n        return info',\n",
              " 'def modify_log_groups(self, settings):\\n        \"\"\"Modifies the group settings of the debug or release logger.\\n\\n        in settings of type str\\n            The group settings string. See iprt/log.h for details. To target the\\n            release logger, prefix the string with \"release:\".\\n\\n        \"\"\"\\n        if not isinstance(settings, basestring):\\n            raise TypeError(\"settings can only be an instance of type basestring\")\\n        self._call(\"modifyLogGroups\",\\n                     in_p=[settings])',\n",
              " 'def modify_log_flags(self, settings):\\n        \"\"\"Modifies the debug or release logger flags.\\n\\n        in settings of type str\\n            The flags settings string. See iprt/log.h for details. To target the\\n            release logger, prefix the string with \"release:\".\\n\\n        \"\"\"\\n        if not isinstance(settings, basestring):\\n            raise TypeError(\"settings can only be an instance of type basestring\")\\n        self._call(\"modifyLogFlags\",\\n                     in_p=[settings])',\n",
              " 'def modify_log_destinations(self, settings):\\n        \"\"\"Modifies the debug or release logger destinations.\\n\\n        in settings of type str\\n            The destination settings string. See iprt/log.h for details. To target the\\n            release logger, prefix the string with \"release:\".\\n\\n        \"\"\"\\n        if not isinstance(settings, basestring):\\n            raise TypeError(\"settings can only be an instance of type basestring\")\\n        self._call(\"modifyLogDestinations\",\\n                     in_p=[settings])',\n",
              " 'def read_physical_memory(self, address, size):\\n        \"\"\"Reads guest physical memory, no side effects (MMIO++).\\n        \\n        This feature is not implemented in the 4.0.0 release but may show up\\n        in a dot release.\\n\\n        in address of type int\\n            The guest physical address.\\n\\n        in size of type int\\n            The number of bytes to read.\\n\\n        return bytes_p of type str\\n            The bytes read.\\n\\n        \"\"\"\\n        if not isinstance(address, baseinteger):\\n            raise TypeError(\"address can only be an instance of type baseinteger\")\\n        if not isinstance(size, baseinteger):\\n            raise TypeError(\"size can only be an instance of type baseinteger\")\\n        bytes_p = self._call(\"readPhysicalMemory\",\\n                     in_p=[address, size])\\n        return bytes_p',\n",
              " 'def read_virtual_memory(self, cpu_id, address, size):\\n        \"\"\"Reads guest virtual memory, no side effects (MMIO++).\\n        \\n        This feature is not implemented in the 4.0.0 release but may show up\\n        in a dot release.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        in address of type int\\n            The guest virtual address.\\n\\n        in size of type int\\n            The number of bytes to read.\\n\\n        return bytes_p of type str\\n            The bytes read.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        if not isinstance(address, baseinteger):\\n            raise TypeError(\"address can only be an instance of type baseinteger\")\\n        if not isinstance(size, baseinteger):\\n            raise TypeError(\"size can only be an instance of type baseinteger\")\\n        bytes_p = self._call(\"readVirtualMemory\",\\n                     in_p=[cpu_id, address, size])\\n        return bytes_p',\n",
              " 'def write_virtual_memory(self, cpu_id, address, size, bytes_p):\\n        \"\"\"Writes guest virtual memory, access handles (MMIO++) are ignored.\\n        \\n        This feature is not implemented in the 4.0.0 release but may show up\\n        in a dot release.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        in address of type int\\n            The guest virtual address.\\n\\n        in size of type int\\n            The number of bytes to read.\\n\\n        in bytes_p of type str\\n            The bytes to write.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        if not isinstance(address, baseinteger):\\n            raise TypeError(\"address can only be an instance of type baseinteger\")\\n        if not isinstance(size, baseinteger):\\n            raise TypeError(\"size can only be an instance of type baseinteger\")\\n        if not isinstance(bytes_p, list):\\n            raise TypeError(\"bytes_p can only be an instance of type list\")\\n        for a in bytes_p[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"writeVirtualMemory\",\\n                     in_p=[cpu_id, address, size, bytes_p])',\n",
              " 'def load_plug_in(self, name):\\n        \"\"\"Loads a DBGF plug-in.\\n\\n        in name of type str\\n            The plug-in name or DLL. Special name \\'all\\' loads all installed plug-ins.\\n\\n        return plug_in_name of type str\\n            The name of the loaded plug-in.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        plug_in_name = self._call(\"loadPlugIn\",\\n                     in_p=[name])\\n        return plug_in_name',\n",
              " 'def unload_plug_in(self, name):\\n        \"\"\"Unloads a DBGF plug-in.\\n\\n        in name of type str\\n            The plug-in name or DLL. Special name \\'all\\' unloads all plug-ins.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"unloadPlugIn\",\\n                     in_p=[name])',\n",
              " 'def query_os_kernel_log(self, max_messages):\\n        \"\"\"Tries to get the kernel log (dmesg) of the guest OS.\\n\\n        in max_messages of type int\\n            Max number of messages to return, counting from the end of the\\n            log.  If 0, there is no limit.\\n\\n        return dmesg of type str\\n            The kernel log.\\n\\n        \"\"\"\\n        if not isinstance(max_messages, baseinteger):\\n            raise TypeError(\"max_messages can only be an instance of type baseinteger\")\\n        dmesg = self._call(\"queryOSKernelLog\",\\n                     in_p=[max_messages])\\n        return dmesg',\n",
              " 'def get_register(self, cpu_id, name):\\n        \"\"\"Gets one register.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        in name of type str\\n            The register name, case is ignored.\\n\\n        return value of type str\\n            The register value. This is usually a hex value (always 0x prefixed)\\n            but other format may be used for floating point registers (TBD).\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        value = self._call(\"getRegister\",\\n                     in_p=[cpu_id, name])\\n        return value',\n",
              " 'def get_registers(self, cpu_id):\\n        \"\"\"Gets all the registers for the given CPU.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        out names of type str\\n            Array containing the lowercase register names.\\n\\n        out values of type str\\n            Array parallel to the names holding the register values as if the\\n            register was returned by :py:func:`IMachineDebugger.get_register` .\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        (names, values) = self._call(\"getRegisters\",\\n                     in_p=[cpu_id])\\n        return (names, values)',\n",
              " 'def set_registers(self, cpu_id, names, values):\\n        \"\"\"Sets zero or more registers atomically.\\n        \\n        This feature is not implemented in the 4.0.0 release but may show up\\n        in a dot release.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        in names of type str\\n            Array containing the register names, case ignored.\\n\\n        in values of type str\\n            Array paralell to the names holding the register values. See\\n            :py:func:`IMachineDebugger.set_register`  for formatting\\n            guidelines.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        if not isinstance(names, list):\\n            raise TypeError(\"names can only be an instance of type list\")\\n        for a in names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(values, list):\\n            raise TypeError(\"values can only be an instance of type list\")\\n        for a in values[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        self._call(\"setRegisters\",\\n                     in_p=[cpu_id, names, values])',\n",
              " 'def dump_guest_stack(self, cpu_id):\\n        \"\"\"Produce a simple stack dump using the current guest state.\\n        \\n        This feature is not implemented in the 4.0.0 release but may show up\\n        in a dot release.\\n\\n        in cpu_id of type int\\n            The identifier of the Virtual CPU.\\n\\n        return stack of type str\\n            String containing the formatted stack dump.\\n\\n        \"\"\"\\n        if not isinstance(cpu_id, baseinteger):\\n            raise TypeError(\"cpu_id can only be an instance of type baseinteger\")\\n        stack = self._call(\"dumpGuestStack\",\\n                     in_p=[cpu_id])\\n        return stack',\n",
              " 'def reset_stats(self, pattern):\\n        \"\"\"Reset VM statistics.\\n\\n        in pattern of type str\\n            The selection pattern. A bit similar to filename globbing.\\n\\n        \"\"\"\\n        if not isinstance(pattern, basestring):\\n            raise TypeError(\"pattern can only be an instance of type basestring\")\\n        self._call(\"resetStats\",\\n                     in_p=[pattern])',\n",
              " 'def dump_stats(self, pattern):\\n        \"\"\"Dumps VM statistics.\\n\\n        in pattern of type str\\n            The selection pattern. A bit similar to filename globbing.\\n\\n        \"\"\"\\n        if not isinstance(pattern, basestring):\\n            raise TypeError(\"pattern can only be an instance of type basestring\")\\n        self._call(\"dumpStats\",\\n                     in_p=[pattern])',\n",
              " 'def get_stats(self, pattern, with_descriptions):\\n        \"\"\"Get the VM statistics in a XMLish format.\\n\\n        in pattern of type str\\n            The selection pattern. A bit similar to filename globbing.\\n\\n        in with_descriptions of type bool\\n            Whether to include the descriptions.\\n\\n        return stats of type str\\n            The XML document containing the statistics.\\n\\n        \"\"\"\\n        if not isinstance(pattern, basestring):\\n            raise TypeError(\"pattern can only be an instance of type basestring\")\\n        if not isinstance(with_descriptions, bool):\\n            raise TypeError(\"with_descriptions can only be an instance of type bool\")\\n        stats = self._call(\"getStats\",\\n                     in_p=[pattern, with_descriptions])\\n        return stats',\n",
              " 'def create_device_filter(self, name):\\n        \"\"\"Creates a new USB device filter. All attributes except\\n        the filter name are set to empty (any match),\\n        *active* is @c false (the filter is not active).\\n        \\n        The created filter can then be added to the list of filters using\\n        :py:func:`insert_device_filter` .\\n        \\n        \\n        \\n        :py:func:`device_filters` \\n\\n        in name of type str\\n            Filter name. See :py:func:`IUSBDeviceFilter.name` \\n            for more info.\\n\\n        return filter_p of type :class:`IUSBDeviceFilter`\\n            Created filter object.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            The virtual machine is not mutable.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        filter_p = self._call(\"createDeviceFilter\",\\n                     in_p=[name])\\n        filter_p = IUSBDeviceFilter(filter_p)\\n        return filter_p',\n",
              " 'def insert_device_filter(self, position, filter_p):\\n        \"\"\"Inserts the given USB device to the specified position\\n        in the list of filters.\\n        \\n        Positions are numbered starting from 0. If the specified\\n        position is equal to or greater than the number of elements in\\n        the list, the filter is added to the end of the collection.\\n        \\n        \\n        Duplicates are not allowed, so an attempt to insert a\\n        filter that is already in the collection, will return an\\n        error.\\n        \\n        \\n        \\n        \\n        :py:func:`device_filters` \\n\\n        in position of type int\\n            Position to insert the filter to.\\n\\n        in filter_p of type :class:`IUSBDeviceFilter`\\n            USB device filter to insert.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine is not mutable.\\n        \\n        raises :class:`OleErrorInvalidarg`\\n            USB device filter not created within this VirtualBox instance.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            USB device filter already in list.\\n        \\n        \"\"\"\\n        if not isinstance(position, baseinteger):\\n            raise TypeError(\"position can only be an instance of type baseinteger\")\\n        if not isinstance(filter_p, IUSBDeviceFilter):\\n            raise TypeError(\"filter_p can only be an instance of type IUSBDeviceFilter\")\\n        self._call(\"insertDeviceFilter\",\\n                     in_p=[position, filter_p])',\n",
              " 'def assign_machine(self, machine, lock_type, token):\\n        \"\"\"Assigns the machine object associated with this direct-type\\n        session or informs the session that it will be a remote one\\n        (if @a machine == @c null).\\n\\n        in machine of type :class:`IMachine`\\n\\n        in lock_type of type :class:`LockType`\\n\\n        in token of type :class:`IToken`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(machine, IMachine):\\n            raise TypeError(\"machine can only be an instance of type IMachine\")\\n        if not isinstance(lock_type, LockType):\\n            raise TypeError(\"lock_type can only be an instance of type LockType\")\\n        if not isinstance(token, IToken):\\n            raise TypeError(\"token can only be an instance of type IToken\")\\n        self._call(\"assignMachine\",\\n                     in_p=[machine, lock_type, token])',\n",
              " 'def assign_remote_machine(self, machine, console):\\n        \"\"\"Assigns the machine and the (remote) console object associated with\\n        this remote-type session.\\n\\n        in machine of type :class:`IMachine`\\n\\n        in console of type :class:`IConsole`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(machine, IMachine):\\n            raise TypeError(\"machine can only be an instance of type IMachine\")\\n        if not isinstance(console, IConsole):\\n            raise TypeError(\"console can only be an instance of type IConsole\")\\n        self._call(\"assignRemoteMachine\",\\n                     in_p=[machine, console])',\n",
              " 'def update_machine_state(self, machine_state):\\n        \"\"\"Updates the machine state in the VM process.\\n        Must be called only in certain cases\\n        (see the method implementation).\\n\\n        in machine_state of type :class:`MachineState`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(machine_state, MachineState):\\n            raise TypeError(\"machine_state can only be an instance of type MachineState\")\\n        self._call(\"updateMachineState\",\\n                     in_p=[machine_state])',\n",
              " 'def on_network_adapter_change(self, network_adapter, change_adapter):\\n        \"\"\"Triggered when settings of a network adapter of the\\n        associated virtual machine have changed.\\n\\n        in network_adapter of type :class:`INetworkAdapter`\\n\\n        in change_adapter of type bool\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(network_adapter, INetworkAdapter):\\n            raise TypeError(\"network_adapter can only be an instance of type INetworkAdapter\")\\n        if not isinstance(change_adapter, bool):\\n            raise TypeError(\"change_adapter can only be an instance of type bool\")\\n        self._call(\"onNetworkAdapterChange\",\\n                     in_p=[network_adapter, change_adapter])',\n",
              " 'def on_audio_adapter_change(self, audio_adapter):\\n        \"\"\"Triggerd when settings of the audio adapter of the\\n        associated virtual machine have changed.\\n\\n        in audio_adapter of type :class:`IAudioAdapter`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(audio_adapter, IAudioAdapter):\\n            raise TypeError(\"audio_adapter can only be an instance of type IAudioAdapter\")\\n        self._call(\"onAudioAdapterChange\",\\n                     in_p=[audio_adapter])',\n",
              " 'def on_serial_port_change(self, serial_port):\\n        \"\"\"Triggered when settings of a serial port of the\\n        associated virtual machine have changed.\\n\\n        in serial_port of type :class:`ISerialPort`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(serial_port, ISerialPort):\\n            raise TypeError(\"serial_port can only be an instance of type ISerialPort\")\\n        self._call(\"onSerialPortChange\",\\n                     in_p=[serial_port])',\n",
              " 'def on_parallel_port_change(self, parallel_port):\\n        \"\"\"Triggered when settings of a parallel port of the\\n        associated virtual machine have changed.\\n\\n        in parallel_port of type :class:`IParallelPort`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(parallel_port, IParallelPort):\\n            raise TypeError(\"parallel_port can only be an instance of type IParallelPort\")\\n        self._call(\"onParallelPortChange\",\\n                     in_p=[parallel_port])',\n",
              " 'def on_medium_change(self, medium_attachment, force):\\n        \"\"\"Triggered when attached media of the\\n        associated virtual machine have changed.\\n\\n        in medium_attachment of type :class:`IMediumAttachment`\\n            The medium attachment which changed.\\n\\n        in force of type bool\\n            If the medium change was forced.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(medium_attachment, IMediumAttachment):\\n            raise TypeError(\"medium_attachment can only be an instance of type IMediumAttachment\")\\n        if not isinstance(force, bool):\\n            raise TypeError(\"force can only be an instance of type bool\")\\n        self._call(\"onMediumChange\",\\n                     in_p=[medium_attachment, force])',\n",
              " 'def on_storage_device_change(self, medium_attachment, remove, silent):\\n        \"\"\"Triggered when attached storage devices of the\\n        associated virtual machine have changed.\\n\\n        in medium_attachment of type :class:`IMediumAttachment`\\n            The medium attachment which changed.\\n\\n        in remove of type bool\\n            TRUE if the device is removed, FALSE if it was added.\\n\\n        in silent of type bool\\n            TRUE if the device is is silently reconfigured without\\n            notifying the guest about it.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(medium_attachment, IMediumAttachment):\\n            raise TypeError(\"medium_attachment can only be an instance of type IMediumAttachment\")\\n        if not isinstance(remove, bool):\\n            raise TypeError(\"remove can only be an instance of type bool\")\\n        if not isinstance(silent, bool):\\n            raise TypeError(\"silent can only be an instance of type bool\")\\n        self._call(\"onStorageDeviceChange\",\\n                     in_p=[medium_attachment, remove, silent])',\n",
              " 'def on_vm_process_priority_change(self, priority):\\n        \"\"\"Triggered when process priority of the\\n        associated virtual machine have changed.\\n\\n        in priority of type :class:`VMProcPriority`\\n            The priority which set.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        raises :class:`VBoxErrorVmError`\\n            Error from underlying level. See additional error info.\\n        \\n        \"\"\"\\n        if not isinstance(priority, VMProcPriority):\\n            raise TypeError(\"priority can only be an instance of type VMProcPriority\")\\n        self._call(\"onVMProcessPriorityChange\",\\n                     in_p=[priority])',\n",
              " 'def on_clipboard_mode_change(self, clipboard_mode):\\n        \"\"\"Notification when the shared clipboard mode changes.\\n\\n        in clipboard_mode of type :class:`ClipboardMode`\\n            The new shared clipboard mode.\\n\\n        \"\"\"\\n        if not isinstance(clipboard_mode, ClipboardMode):\\n            raise TypeError(\"clipboard_mode can only be an instance of type ClipboardMode\")\\n        self._call(\"onClipboardModeChange\",\\n                     in_p=[clipboard_mode])',\n",
              " 'def on_dn_d_mode_change(self, dnd_mode):\\n        \"\"\"Notification when the drag\\'n drop mode changes.\\n\\n        in dnd_mode of type :class:`DnDMode`\\n            The new mode for drag\\'n drop.\\n\\n        \"\"\"\\n        if not isinstance(dnd_mode, DnDMode):\\n            raise TypeError(\"dnd_mode can only be an instance of type DnDMode\")\\n        self._call(\"onDnDModeChange\",\\n                     in_p=[dnd_mode])',\n",
              " 'def on_cpu_change(self, cpu, add):\\n        \"\"\"Notification when a CPU changes.\\n\\n        in cpu of type int\\n            The CPU which changed\\n\\n        in add of type bool\\n            Flag whether the CPU was added or removed\\n\\n        \"\"\"\\n        if not isinstance(cpu, baseinteger):\\n            raise TypeError(\"cpu can only be an instance of type baseinteger\")\\n        if not isinstance(add, bool):\\n            raise TypeError(\"add can only be an instance of type bool\")\\n        self._call(\"onCPUChange\",\\n                     in_p=[cpu, add])',\n",
              " 'def on_cpu_execution_cap_change(self, execution_cap):\\n        \"\"\"Notification when the CPU execution cap changes.\\n\\n        in execution_cap of type int\\n            The new CPU execution cap value. (1-100)\\n\\n        \"\"\"\\n        if not isinstance(execution_cap, baseinteger):\\n            raise TypeError(\"execution_cap can only be an instance of type baseinteger\")\\n        self._call(\"onCPUExecutionCapChange\",\\n                     in_p=[execution_cap])',\n",
              " 'def on_vrde_server_change(self, restart):\\n        \"\"\"Triggered when settings of the VRDE server object of the\\n        associated virtual machine have changed.\\n\\n        in restart of type bool\\n            Flag whether the server must be restarted\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(restart, bool):\\n            raise TypeError(\"restart can only be an instance of type bool\")\\n        self._call(\"onVRDEServerChange\",\\n                     in_p=[restart])',\n",
              " 'def on_recording_change(self, enable):\\n        \"\"\"Triggered when recording settings have changed.\\n\\n        in enable of type bool\\n            TODO\\n\\n        \"\"\"\\n        if not isinstance(enable, bool):\\n            raise TypeError(\"enable can only be an instance of type bool\")\\n        self._call(\"onRecordingChange\",\\n                     in_p=[enable])',\n",
              " 'def on_shared_folder_change(self, global_p):\\n        \"\"\"Triggered when a permanent (global or machine) shared folder has been\\n        created or removed.\\n        \\n        We don\\'t pass shared folder parameters in this notification because\\n        the order in which parallel notifications are delivered is not defined,\\n        therefore it could happen that these parameters were outdated by the\\n        time of processing this notification.\\n\\n        in global_p of type bool\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(global_p, bool):\\n            raise TypeError(\"global_p can only be an instance of type bool\")\\n        self._call(\"onSharedFolderChange\",\\n                     in_p=[global_p])',\n",
              " 'def on_usb_device_attach(self, device, error, masked_interfaces, capture_filename):\\n        \"\"\"Triggered when a request to capture a USB device (as a result\\n        of matched USB filters or direct call to\\n        :py:func:`IConsole.attach_usb_device` ) has completed.\\n        A @c null @a error object means success, otherwise it\\n        describes a failure.\\n\\n        in device of type :class:`IUSBDevice`\\n\\n        in error of type :class:`IVirtualBoxErrorInfo`\\n\\n        in masked_interfaces of type int\\n\\n        in capture_filename of type str\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(device, IUSBDevice):\\n            raise TypeError(\"device can only be an instance of type IUSBDevice\")\\n        if not isinstance(error, IVirtualBoxErrorInfo):\\n            raise TypeError(\"error can only be an instance of type IVirtualBoxErrorInfo\")\\n        if not isinstance(masked_interfaces, baseinteger):\\n            raise TypeError(\"masked_interfaces can only be an instance of type baseinteger\")\\n        if not isinstance(capture_filename, basestring):\\n            raise TypeError(\"capture_filename can only be an instance of type basestring\")\\n        self._call(\"onUSBDeviceAttach\",\\n                     in_p=[device, error, masked_interfaces, capture_filename])',\n",
              " 'def on_usb_device_detach(self, id_p, error):\\n        \"\"\"Triggered when a request to release the USB device (as a result\\n        of machine termination or direct call to\\n        :py:func:`IConsole.detach_usb_device` ) has completed.\\n        A @c null @a error object means success, otherwise it\\n        describes a failure.\\n\\n        in id_p of type str\\n\\n        in error of type :class:`IVirtualBoxErrorInfo`\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Session state prevents operation.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(id_p, basestring):\\n            raise TypeError(\"id_p can only be an instance of type basestring\")\\n        if not isinstance(error, IVirtualBoxErrorInfo):\\n            raise TypeError(\"error can only be an instance of type IVirtualBoxErrorInfo\")\\n        self._call(\"onUSBDeviceDetach\",\\n                     in_p=[id_p, error])',\n",
              " 'def on_show_window(self, check):\\n        \"\"\"Called by :py:func:`IMachine.can_show_console_window`  and by\\n        :py:func:`IMachine.show_console_window`  in order to notify\\n        console listeners\\n        :py:class:`ICanShowWindowEvent` \\n        and :py:class:`IShowWindowEvent` .\\n\\n        in check of type bool\\n\\n        out can_show of type bool\\n\\n        out win_id of type int\\n\\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type prevents operation.\\n        \\n        \"\"\"\\n        if not isinstance(check, bool):\\n            raise TypeError(\"check can only be an instance of type bool\")\\n        (can_show, win_id) = self._call(\"onShowWindow\",\\n                     in_p=[check])\\n        return (can_show, win_id)',\n",
              " 'def on_bandwidth_group_change(self, bandwidth_group):\\n        \"\"\"Notification when one of the bandwidth groups change.\\n\\n        in bandwidth_group of type :class:`IBandwidthGroup`\\n            The bandwidth group which changed.\\n\\n        \"\"\"\\n        if not isinstance(bandwidth_group, IBandwidthGroup):\\n            raise TypeError(\"bandwidth_group can only be an instance of type IBandwidthGroup\")\\n        self._call(\"onBandwidthGroupChange\",\\n                     in_p=[bandwidth_group])',\n",
              " 'def access_guest_property(self, name, value, flags, access_mode):\\n        \"\"\"Called by :py:func:`IMachine.get_guest_property`  and by\\n        :py:func:`IMachine.set_guest_property`  in order to read and\\n        modify guest properties.\\n\\n        in name of type str\\n\\n        in value of type str\\n\\n        in flags of type str\\n\\n        in access_mode of type int\\n            0 = get, 1 = set, 2 = delete.\\n\\n        out ret_value of type str\\n\\n        out ret_timestamp of type int\\n\\n        out ret_flags of type str\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type is not direct.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(value, basestring):\\n            raise TypeError(\"value can only be an instance of type basestring\")\\n        if not isinstance(flags, basestring):\\n            raise TypeError(\"flags can only be an instance of type basestring\")\\n        if not isinstance(access_mode, baseinteger):\\n            raise TypeError(\"access_mode can only be an instance of type baseinteger\")\\n        (ret_value, ret_timestamp, ret_flags) = self._call(\"accessGuestProperty\",\\n                     in_p=[name, value, flags, access_mode])\\n        return (ret_value, ret_timestamp, ret_flags)',\n",
              " 'def online_merge_medium(self, medium_attachment, source_idx, target_idx, progress):\\n        \"\"\"Triggers online merging of a hard disk. Used internally when deleting\\n        a snapshot while a VM referring to the same hard disk chain is running.\\n\\n        in medium_attachment of type :class:`IMediumAttachment`\\n            The medium attachment to identify the medium chain.\\n\\n        in source_idx of type int\\n            The index of the source image in the chain.\\n            Redundant, but drastically reduces IPC.\\n\\n        in target_idx of type int\\n            The index of the target image in the chain.\\n            Redundant, but drastically reduces IPC.\\n\\n        in progress of type :class:`IProgress`\\n            Progress object for this operation.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type is not direct.\\n        \\n        \"\"\"\\n        if not isinstance(medium_attachment, IMediumAttachment):\\n            raise TypeError(\"medium_attachment can only be an instance of type IMediumAttachment\")\\n        if not isinstance(source_idx, baseinteger):\\n            raise TypeError(\"source_idx can only be an instance of type baseinteger\")\\n        if not isinstance(target_idx, baseinteger):\\n            raise TypeError(\"target_idx can only be an instance of type baseinteger\")\\n        if not isinstance(progress, IProgress):\\n            raise TypeError(\"progress can only be an instance of type IProgress\")\\n        self._call(\"onlineMergeMedium\",\\n                     in_p=[medium_attachment, source_idx, target_idx, progress])',\n",
              " 'def reconfigure_medium_attachments(self, attachments):\\n        \"\"\"Reconfigure all specified medium attachments in one go, making sure\\n        the current state corresponds to the specified medium.\\n\\n        in attachments of type :class:`IMediumAttachment`\\n            Array containing the medium attachments which need to be\\n            reconfigured.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type is not direct.\\n        \\n        \"\"\"\\n        if not isinstance(attachments, list):\\n            raise TypeError(\"attachments can only be an instance of type list\")\\n        for a in attachments[:10]:\\n            if not isinstance(a, IMediumAttachment):\\n                raise TypeError(\\n                        \"array can only contain objects of type IMediumAttachment\")\\n        self._call(\"reconfigureMediumAttachments\",\\n                     in_p=[attachments])',\n",
              " 'def enable_vmm_statistics(self, enable):\\n        \"\"\"Enables or disables collection of VMM RAM statistics.\\n\\n        in enable of type bool\\n            True enables statistics collection.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Machine session is not open.\\n        \\n        raises :class:`VBoxErrorInvalidObjectState`\\n            Session type is not direct.\\n        \\n        \"\"\"\\n        if not isinstance(enable, bool):\\n            raise TypeError(\"enable can only be an instance of type bool\")\\n        self._call(\"enableVMMStatistics\",\\n                     in_p=[enable])',\n",
              " 'def pause_with_reason(self, reason):\\n        \"\"\"Internal method for triggering a VM pause with a specified reason code.\\n        The reason code can be interpreted by device/drivers and thus it might\\n        behave slightly differently than a normal VM pause.\\n        \\n        \\n        :py:func:`IConsole.pause` \\n\\n        in reason of type :class:`Reason`\\n            Specify the best matching reason code please.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine not in Running state.\\n        \\n        raises :class:`VBoxErrorVmError`\\n            Virtual machine error in suspend operation.\\n        \\n        \"\"\"\\n        if not isinstance(reason, Reason):\\n            raise TypeError(\"reason can only be an instance of type Reason\")\\n        self._call(\"pauseWithReason\",\\n                     in_p=[reason])',\n",
              " 'def resume_with_reason(self, reason):\\n        \"\"\"Internal method for triggering a VM resume with a specified reason code.\\n        The reason code can be interpreted by device/drivers and thus it might\\n        behave slightly differently than a normal VM resume.\\n        \\n        \\n        :py:func:`IConsole.resume` \\n\\n        in reason of type :class:`Reason`\\n            Specify the best matching reason code please.\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine not in Paused state.\\n        \\n        raises :class:`VBoxErrorVmError`\\n            Virtual machine error in resume operation.\\n        \\n        \"\"\"\\n        if not isinstance(reason, Reason):\\n            raise TypeError(\"reason can only be an instance of type Reason\")\\n        self._call(\"resumeWithReason\",\\n                     in_p=[reason])',\n",
              " 'def save_state_with_reason(self, reason, progress, snapshot, state_file_path, pause_vm):\\n        \"\"\"Internal method for triggering a VM save state with a specified reason\\n        code. The reason code can be interpreted by device/drivers and thus it\\n        might behave slightly differently than a normal VM save state.\\n        \\n        This call is fully synchronous, and the caller is expected to have set\\n        the machine state appropriately (and has to set the follow-up machine\\n        state if this call failed).\\n        \\n        \\n        :py:func:`IMachine.save_state` \\n\\n        in reason of type :class:`Reason`\\n            Specify the best matching reason code please.\\n\\n        in progress of type :class:`IProgress`\\n            Progress object to track the operation completion.\\n\\n        in snapshot of type :class:`ISnapshot`\\n            Snapshot object for which this save state operation is executed.\\n\\n        in state_file_path of type str\\n            File path the VM process must save the execution state to.\\n\\n        in pause_vm of type bool\\n            The VM should be paused before saving state. It is automatically\\n            unpaused on error in the \"vanilla save state\" case.\\n\\n        return left_paused of type bool\\n            Returns if the VM was left in paused state, which is necessary\\n            in many situations (snapshots, teleportation).\\n\\n        raises :class:`VBoxErrorInvalidVmState`\\n            Virtual machine state is not one of the expected values.\\n        \\n        raises :class:`VBoxErrorFileError`\\n            Failed to create directory for saved state file.\\n        \\n        \"\"\"\\n        if not isinstance(reason, Reason):\\n            raise TypeError(\"reason can only be an instance of type Reason\")\\n        if not isinstance(progress, IProgress):\\n            raise TypeError(\"progress can only be an instance of type IProgress\")\\n        if not isinstance(snapshot, ISnapshot):\\n            raise TypeError(\"snapshot can only be an instance of type ISnapshot\")\\n        if not isinstance(state_file_path, basestring):\\n            raise TypeError(\"state_file_path can only be an instance of type basestring\")\\n        if not isinstance(pause_vm, bool):\\n            raise TypeError(\"pause_vm can only be an instance of type bool\")\\n        left_paused = self._call(\"saveStateWithReason\",\\n                     in_p=[reason, progress, snapshot, state_file_path, pause_vm])\\n        return left_paused',\n",
              " 'def get_metrics(self, metric_names, objects):\\n        \"\"\"Returns parameters of specified metrics for a set of objects.\\n        \\n        @c Null metrics array means all metrics. @c Null object array means\\n        all existing objects.\\n\\n        in metric_names of type str\\n            Metric name filter. Currently, only a comma-separated list of metrics\\n            is supported.\\n\\n        in objects of type Interface\\n            Set of objects to return metric parameters for.\\n\\n        return metrics of type :class:`IPerformanceMetric`\\n            Array of returned metric parameters.\\n\\n        \"\"\"\\n        if not isinstance(metric_names, list):\\n            raise TypeError(\"metric_names can only be an instance of type list\")\\n        for a in metric_names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(objects, list):\\n            raise TypeError(\"objects can only be an instance of type list\")\\n        for a in objects[:10]:\\n            if not isinstance(a, Interface):\\n                raise TypeError(\\n                        \"array can only contain objects of type Interface\")\\n        metrics = self._call(\"getMetrics\",\\n                     in_p=[metric_names, objects])\\n        metrics = [IPerformanceMetric(a) for a in metrics]\\n        return metrics',\n",
              " 'def setup_metrics(self, metric_names, objects, period, count):\\n        \"\"\"Sets parameters of specified base metrics for a set of objects. Returns\\n        an array of :py:class:`IPerformanceMetric`  describing the metrics\\n        have been affected.\\n        \\n        @c Null or empty metric name array means all metrics. @c Null or\\n        empty object array means all existing objects. If metric name array\\n        contains a single element and object array contains many, the single\\n        metric name array element is applied to each object array element to\\n        form metric/object pairs.\\n\\n        in metric_names of type str\\n            Metric name filter. Comma-separated list of metrics with wildcard\\n            support.\\n\\n        in objects of type Interface\\n            Set of objects to setup metric parameters for.\\n\\n        in period of type int\\n            Time interval in seconds between two consecutive samples of\\n            performance data.\\n\\n        in count of type int\\n            Number of samples to retain in performance data history. Older\\n            samples get discarded.\\n\\n        return affected_metrics of type :class:`IPerformanceMetric`\\n            Array of metrics that have been modified by the call to this method.\\n\\n        \"\"\"\\n        if not isinstance(metric_names, list):\\n            raise TypeError(\"metric_names can only be an instance of type list\")\\n        for a in metric_names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(objects, list):\\n            raise TypeError(\"objects can only be an instance of type list\")\\n        for a in objects[:10]:\\n            if not isinstance(a, Interface):\\n                raise TypeError(\\n                        \"array can only contain objects of type Interface\")\\n        if not isinstance(period, baseinteger):\\n            raise TypeError(\"period can only be an instance of type baseinteger\")\\n        if not isinstance(count, baseinteger):\\n            raise TypeError(\"count can only be an instance of type baseinteger\")\\n        affected_metrics = self._call(\"setupMetrics\",\\n                     in_p=[metric_names, objects, period, count])\\n        affected_metrics = [IPerformanceMetric(a) for a in affected_metrics]\\n        return affected_metrics',\n",
              " 'def enable_metrics(self, metric_names, objects):\\n        \"\"\"Turns on collecting specified base metrics. Returns an array of\\n        :py:class:`IPerformanceMetric`  describing the metrics have been\\n        affected.\\n        \\n        @c Null or empty metric name array means all metrics. @c Null or\\n        empty object array means all existing objects. If metric name array\\n        contains a single element and object array contains many, the single\\n        metric name array element is applied to each object array element to\\n        form metric/object pairs.\\n\\n        in metric_names of type str\\n            Metric name filter. Comma-separated list of metrics with wildcard\\n            support.\\n\\n        in objects of type Interface\\n            Set of objects to enable metrics for.\\n\\n        return affected_metrics of type :class:`IPerformanceMetric`\\n            Array of metrics that have been modified by the call to this method.\\n\\n        \"\"\"\\n        if not isinstance(metric_names, list):\\n            raise TypeError(\"metric_names can only be an instance of type list\")\\n        for a in metric_names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(objects, list):\\n            raise TypeError(\"objects can only be an instance of type list\")\\n        for a in objects[:10]:\\n            if not isinstance(a, Interface):\\n                raise TypeError(\\n                        \"array can only contain objects of type Interface\")\\n        affected_metrics = self._call(\"enableMetrics\",\\n                     in_p=[metric_names, objects])\\n        affected_metrics = [IPerformanceMetric(a) for a in affected_metrics]\\n        return affected_metrics',\n",
              " 'def query_metrics_data(self, metric_names, objects):\\n        \"\"\"Queries collected metrics data for a set of objects.\\n        \\n        The data itself and related metric information are returned in seven\\n        parallel and one flattened array of arrays. Elements of\\n        returnMetricNames, returnObjects, returnUnits, returnScales,\\n        returnSequenceNumbers, returnDataIndices and returnDataLengths with\\n        the same index describe one set of values corresponding to a single\\n        metric.\\n        \\n        The returnData parameter is a flattened array of arrays. Each\\n        start and length of a sub-array is indicated by\\n        returnDataIndices and returnDataLengths. The first\\n        value for metric metricNames[i] is at\\n        returnData[returnIndices[i]].\\n        \\n        \\n        @c Null or empty metric name array means all metrics. @c Null or\\n        empty object array means all existing objects. If metric name array\\n        contains a single element and object array contains many, the single\\n        metric name array element is applied to each object array element to\\n        form metric/object pairs.\\n        \\n        \\n        Data collection continues behind the scenes after call to\\n        @c queryMetricsData. The return data can be seen as the snapshot of\\n        the current state at the time of @c queryMetricsData call. The\\n        internally kept metric values are not cleared by the call. This\\n        allows querying different subsets of metrics or aggregates with\\n        subsequent calls. If periodic querying is needed it is highly\\n        suggested to query the values with @c interval*count period to avoid\\n        confusion. This way a completely new set of data values will be\\n        provided by each query.\\n\\n        in metric_names of type str\\n            Metric name filter. Comma-separated list of metrics with wildcard\\n            support.\\n\\n        in objects of type Interface\\n            Set of objects to query metrics for.\\n\\n        out return_metric_names of type str\\n            Names of metrics returned in @c returnData.\\n\\n        out return_objects of type Interface\\n            Objects associated with metrics returned in @c returnData.\\n\\n        out return_units of type str\\n            Units of measurement for each returned metric.\\n\\n        out return_scales of type int\\n            Divisor that should be applied to return values in order to get\\n            floating point values. For example:\\n            (double)returnData[returnDataIndices[0]+i] / returnScales[0]\\n            will retrieve the floating point value of i-th sample of the first\\n            metric.\\n\\n        out return_sequence_numbers of type int\\n            Sequence numbers of the first elements of value sequences of\\n            particular metrics returned in @c returnData. For aggregate metrics\\n            it is the sequence number of the sample the aggregate started\\n            calculation from.\\n\\n        out return_data_indices of type int\\n            Indices of the first elements of value sequences of particular\\n            metrics returned in @c returnData.\\n\\n        out return_data_lengths of type int\\n            Lengths of value sequences of particular metrics.\\n\\n        return return_data of type int\\n            Flattened array of all metric data containing sequences of values for\\n            each metric.\\n\\n        \"\"\"\\n        if not isinstance(metric_names, list):\\n            raise TypeError(\"metric_names can only be an instance of type list\")\\n        for a in metric_names[:10]:\\n            if not isinstance(a, basestring):\\n                raise TypeError(\\n                        \"array can only contain objects of type basestring\")\\n        if not isinstance(objects, list):\\n            raise TypeError(\"objects can only be an instance of type list\")\\n        for a in objects[:10]:\\n            if not isinstance(a, Interface):\\n                raise TypeError(\\n                        \"array can only contain objects of type Interface\")\\n        (return_data, return_metric_names, return_objects, return_units, return_scales, return_sequence_numbers, return_data_indices, return_data_lengths) = self._call(\"queryMetricsData\",\\n                     in_p=[metric_names, objects])\\n        return_objects = [Interface(a) for a in return_objects]\\n        return (return_data, return_metric_names, return_objects, return_units, return_scales, return_sequence_numbers, return_data_indices, return_data_lengths)',\n",
              " 'def set_network_settings(self, mtu, sock_snd, sock_rcv, tcp_wnd_snd, tcp_wnd_rcv):\\n        \"\"\"Sets network configuration of the NAT engine.\\n\\n        in mtu of type int\\n            MTU (maximum transmission unit) of the NAT engine in bytes.\\n\\n        in sock_snd of type int\\n            Capacity of the socket send buffer in bytes when creating a new socket.\\n\\n        in sock_rcv of type int\\n            Capacity of the socket receive buffer in bytes when creating a new socket.\\n\\n        in tcp_wnd_snd of type int\\n            Initial size of the NAT engine\\'s sending TCP window in bytes when\\n            establishing a new TCP connection.\\n\\n        in tcp_wnd_rcv of type int\\n            Initial size of the NAT engine\\'s receiving TCP window in bytes when\\n            establishing a new TCP connection.\\n\\n        \"\"\"\\n        if not isinstance(mtu, baseinteger):\\n            raise TypeError(\"mtu can only be an instance of type baseinteger\")\\n        if not isinstance(sock_snd, baseinteger):\\n            raise TypeError(\"sock_snd can only be an instance of type baseinteger\")\\n        if not isinstance(sock_rcv, baseinteger):\\n            raise TypeError(\"sock_rcv can only be an instance of type baseinteger\")\\n        if not isinstance(tcp_wnd_snd, baseinteger):\\n            raise TypeError(\"tcp_wnd_snd can only be an instance of type baseinteger\")\\n        if not isinstance(tcp_wnd_rcv, baseinteger):\\n            raise TypeError(\"tcp_wnd_rcv can only be an instance of type baseinteger\")\\n        self._call(\"setNetworkSettings\",\\n                     in_p=[mtu, sock_snd, sock_rcv, tcp_wnd_snd, tcp_wnd_rcv])',\n",
              " 'def get_network_settings(self):\\n        \"\"\"Returns network configuration of NAT engine. See :py:func:`set_network_settings` \\n        for parameter descriptions.\\n\\n        out mtu of type int\\n\\n        out sock_snd of type int\\n\\n        out sock_rcv of type int\\n\\n        out tcp_wnd_snd of type int\\n\\n        out tcp_wnd_rcv of type int\\n\\n        \"\"\"\\n        (mtu, sock_snd, sock_rcv, tcp_wnd_snd, tcp_wnd_rcv) = self._call(\"getNetworkSettings\")\\n        return (mtu, sock_snd, sock_rcv, tcp_wnd_snd, tcp_wnd_rcv)',\n",
              " 'def add_redirect(self, name, proto, host_ip, host_port, guest_ip, guest_port):\\n        \"\"\"Adds a new NAT port-forwarding rule.\\n\\n        in name of type str\\n            The name of the rule. An empty name is acceptable, in which case the NAT engine\\n            auto-generates one using the other parameters.\\n\\n        in proto of type :class:`NATProtocol`\\n            Protocol handled with the rule.\\n\\n        in host_ip of type str\\n            IP of the host interface to which the rule should apply. An empty ip address is\\n            acceptable, in which case the NAT engine binds the handling socket to any interface.\\n\\n        in host_port of type int\\n            The port number to listen on.\\n\\n        in guest_ip of type str\\n            The IP address of the guest which the NAT engine will forward matching packets\\n            to. An empty IP address is acceptable, in which case the NAT engine will forward\\n            packets to the first DHCP lease (x.x.x.15).\\n\\n        in guest_port of type int\\n            The port number to forward.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(proto, NATProtocol):\\n            raise TypeError(\"proto can only be an instance of type NATProtocol\")\\n        if not isinstance(host_ip, basestring):\\n            raise TypeError(\"host_ip can only be an instance of type basestring\")\\n        if not isinstance(host_port, baseinteger):\\n            raise TypeError(\"host_port can only be an instance of type baseinteger\")\\n        if not isinstance(guest_ip, basestring):\\n            raise TypeError(\"guest_ip can only be an instance of type basestring\")\\n        if not isinstance(guest_port, baseinteger):\\n            raise TypeError(\"guest_port can only be an instance of type baseinteger\")\\n        self._call(\"addRedirect\",\\n                     in_p=[name, proto, host_ip, host_port, guest_ip, guest_port])',\n",
              " 'def remove_redirect(self, name):\\n        \"\"\"Removes a port-forwarding rule that was previously registered.\\n\\n        in name of type str\\n            The name of the rule to delete.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"removeRedirect\",\\n                     in_p=[name])',\n",
              " 'def query_license(self, preferred_locale, preferred_language, format_p):\\n        \"\"\"Full feature version of the license attribute.\\n\\n        in preferred_locale of type str\\n            The preferred license locale. Pass an empty string to get the default\\n            license.\\n\\n        in preferred_language of type str\\n            The preferred license language. Pass an empty string to get the\\n            default language for the locale.\\n\\n        in format_p of type str\\n            The license format: html, rtf or txt. If a license is present there\\n            will always be an HTML of it, the rich text format (RTF) and plain\\n            text (txt) versions are optional. If\\n\\n        return license_text of type str\\n            The license text.\\n\\n        \"\"\"\\n        if not isinstance(preferred_locale, basestring):\\n            raise TypeError(\"preferred_locale can only be an instance of type basestring\")\\n        if not isinstance(preferred_language, basestring):\\n            raise TypeError(\"preferred_language can only be an instance of type basestring\")\\n        if not isinstance(format_p, basestring):\\n            raise TypeError(\"format_p can only be an instance of type basestring\")\\n        license_text = self._call(\"queryLicense\",\\n                     in_p=[preferred_locale, preferred_language, format_p])\\n        return license_text',\n",
              " 'def query_object(self, obj_uuid):\\n        \"\"\"Queries the IUnknown interface to an object in the extension pack\\n        main module. This allows plug-ins and others to talk directly to an\\n        extension pack.\\n\\n        in obj_uuid of type str\\n            The object ID. What exactly this is\\n\\n        return return_interface of type Interface\\n            The queried interface.\\n\\n        \"\"\"\\n        if not isinstance(obj_uuid, basestring):\\n            raise TypeError(\"obj_uuid can only be an instance of type basestring\")\\n        return_interface = self._call(\"queryObject\",\\n                     in_p=[obj_uuid])\\n        return_interface = Interface(return_interface)\\n        return return_interface',\n",
              " 'def install(self, replace, display_info):\\n        \"\"\"Install the extension pack.\\n\\n        in replace of type bool\\n            Set this to automatically uninstall any existing extension pack with\\n            the same name as the one being installed.\\n\\n        in display_info of type str\\n            Platform specific display information. Reserved for future hacks.\\n\\n        return progess of type :class:`IProgress`\\n            Progress object for the operation.\\n\\n        \"\"\"\\n        if not isinstance(replace, bool):\\n            raise TypeError(\"replace can only be an instance of type bool\")\\n        if not isinstance(display_info, basestring):\\n            raise TypeError(\"display_info can only be an instance of type basestring\")\\n        progess = self._call(\"install\",\\n                     in_p=[replace, display_info])\\n        progess = IProgress(progess)\\n        return progess',\n",
              " 'def find(self, name):\\n        \"\"\"Returns the extension pack with the specified name if found.\\n\\n        in name of type str\\n            The name of the extension pack to locate.\\n\\n        return return_data of type :class:`IExtPack`\\n            The extension pack if found.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            No extension pack matching @a name was found.\\n        \\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        return_data = self._call(\"find\",\\n                     in_p=[name])\\n        return_data = IExtPack(return_data)\\n        return return_data',\n",
              " 'def open_ext_pack_file(self, path):\\n        \"\"\"Attempts to open an extension pack file in preparation for\\n        installation.\\n\\n        in path of type str\\n            The path of the extension pack tarball. This can optionally be\\n            followed by a \"::SHA-256=hex-digit\" of the tarball.\\n\\n        return file_p of type :class:`IExtPackFile`\\n            The interface of the extension pack file object.\\n\\n        \"\"\"\\n        if not isinstance(path, basestring):\\n            raise TypeError(\"path can only be an instance of type basestring\")\\n        file_p = self._call(\"openExtPackFile\",\\n                     in_p=[path])\\n        file_p = IExtPackFile(file_p)\\n        return file_p',\n",
              " 'def uninstall(self, name, forced_removal, display_info):\\n        \"\"\"Uninstalls an extension pack, removing all related files.\\n\\n        in name of type str\\n            The name of the extension pack to uninstall.\\n\\n        in forced_removal of type bool\\n            Forced removal of the extension pack. This means that the uninstall\\n            hook will not be called.\\n\\n        in display_info of type str\\n            Platform specific display information. Reserved for future hacks.\\n\\n        return progess of type :class:`IProgress`\\n            Progress object for the operation.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(forced_removal, bool):\\n            raise TypeError(\"forced_removal can only be an instance of type bool\")\\n        if not isinstance(display_info, basestring):\\n            raise TypeError(\"display_info can only be an instance of type basestring\")\\n        progess = self._call(\"uninstall\",\\n                     in_p=[name, forced_removal, display_info])\\n        progess = IProgress(progess)\\n        return progess',\n",
              " 'def query_all_plug_ins_for_frontend(self, frontend_name):\\n        \"\"\"Gets the path to all the plug-in modules for a given frontend.\\n        \\n        This is a convenience method that is intended to simplify the plug-in\\n        loading process for a frontend.\\n\\n        in frontend_name of type str\\n            The name of the frontend or component.\\n\\n        return plug_in_modules of type str\\n            Array containing the plug-in modules (full paths).\\n\\n        \"\"\"\\n        if not isinstance(frontend_name, basestring):\\n            raise TypeError(\"frontend_name can only be an instance of type basestring\")\\n        plug_in_modules = self._call(\"queryAllPlugInsForFrontend\",\\n                     in_p=[frontend_name])\\n        return plug_in_modules',\n",
              " 'def is_ext_pack_usable(self, name):\\n        \"\"\"Check if the given extension pack is loaded and usable.\\n\\n        in name of type str\\n            The name of the extension pack to check for.\\n\\n        return usable of type bool\\n            Is the given extension pack loaded and usable.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        usable = self._call(\"isExtPackUsable\",\\n                     in_p=[name])\\n        return usable',\n",
              " 'def create_bandwidth_group(self, name, type_p, max_bytes_per_sec):\\n        \"\"\"Creates a new bandwidth group.\\n\\n        in name of type str\\n            Name of the bandwidth group.\\n\\n        in type_p of type :class:`BandwidthGroupType`\\n            The type of the bandwidth group (network or disk).\\n\\n        in max_bytes_per_sec of type int\\n            The maximum number of bytes which can be transfered by all\\n            entities attached to this group during one second.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        if not isinstance(type_p, BandwidthGroupType):\\n            raise TypeError(\"type_p can only be an instance of type BandwidthGroupType\")\\n        if not isinstance(max_bytes_per_sec, baseinteger):\\n            raise TypeError(\"max_bytes_per_sec can only be an instance of type baseinteger\")\\n        self._call(\"createBandwidthGroup\",\\n                     in_p=[name, type_p, max_bytes_per_sec])',\n",
              " 'def delete_bandwidth_group(self, name):\\n        \"\"\"Deletes a new bandwidth group.\\n\\n        in name of type str\\n            Name of the bandwidth group to delete.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        self._call(\"deleteBandwidthGroup\",\\n                     in_p=[name])',\n",
              " 'def get_bandwidth_group(self, name):\\n        \"\"\"Get a bandwidth group by name.\\n\\n        in name of type str\\n            Name of the bandwidth group to get.\\n\\n        return bandwidth_group of type :class:`IBandwidthGroup`\\n            Where to store the bandwidth group on success.\\n\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise TypeError(\"name can only be an instance of type basestring\")\\n        bandwidth_group = self._call(\"getBandwidthGroup\",\\n                     in_p=[name])\\n        bandwidth_group = IBandwidthGroup(bandwidth_group)\\n        return bandwidth_group',\n",
              " 'def get_all_bandwidth_groups(self):\\n        \"\"\"Get all managed bandwidth groups.\\n\\n        return bandwidth_groups of type :class:`IBandwidthGroup`\\n            The array of managed bandwidth groups.\\n\\n        \"\"\"\\n        bandwidth_groups = self._call(\"getAllBandwidthGroups\")\\n        bandwidth_groups = [IBandwidthGroup(a) for a in bandwidth_groups]\\n        return bandwidth_groups',\n",
              " 'def check_machine_error(self, machine):\\n        \"\"\"Perform error checking before using an :py:class:`IMachine`  object.\\n        Generally useful before starting a VM and all other uses. If anything\\n        is not as it should be then this method will return an appropriate\\n        error.\\n\\n        in machine of type :class:`IMachine`\\n            The machine object to check.\\n\\n        \"\"\"\\n        if not isinstance(machine, IMachine):\\n            raise TypeError(\"machine can only be an instance of type IMachine\")\\n        self._call(\"checkMachineError\",\\n                     in_p=[machine])',\n",
              " 'def create_aggregator(self, subordinates):\\n        \"\"\"Creates an aggregator event source, collecting events from multiple sources.\\n        This way a single listener can listen for events coming from multiple sources,\\n        using a single blocking :py:func:`get_event`  on the returned aggregator.\\n\\n        in subordinates of type :class:`IEventSource`\\n            Subordinate event source this one aggregates.\\n\\n        return result of type :class:`IEventSource`\\n            Event source aggregating passed sources.\\n\\n        \"\"\"\\n        if not isinstance(subordinates, list):\\n            raise TypeError(\"subordinates can only be an instance of type list\")\\n        for a in subordinates[:10]:\\n            if not isinstance(a, IEventSource):\\n                raise TypeError(\\n                        \"array can only contain objects of type IEventSource\")\\n        result = self._call(\"createAggregator\",\\n                     in_p=[subordinates])\\n        result = IEventSource(result)\\n        return result',\n",
              " 'def register_listener(self, listener, interesting, active):\\n        \"\"\"Register an event listener.\\n        \\n        \\n        To avoid system overload, the VirtualBox server process checks if passive event\\n        listeners call :py:func:`IEventSource.get_event`  frequently enough. In the\\n        current implementation, if more than 500 pending events are detected for a passive\\n        event listener, it is forcefully unregistered by the system, and further\\n        :py:func:`get_event`  calls will return @c VBOX_E_OBJECT_NOT_FOUND.\\n\\n        in listener of type :class:`IEventListener`\\n            Listener to register.\\n\\n        in interesting of type :class:`VBoxEventType`\\n            Event types listener is interested in. One can use wildcards like -\\n            :py:attr:`VBoxEventType.any_p`  to specify wildcards, matching more\\n            than one event.\\n\\n        in active of type bool\\n            Which mode this listener is operating in.\\n            In active mode, :py:func:`IEventListener.handle_event`  is called directly.\\n            In passive mode, an internal event queue is created for this this IEventListener.\\n            For each event coming in, it is added to queues for all interested registered passive\\n            listeners. It is then up to the external code to call the listener\\'s\\n            :py:func:`IEventListener.handle_event`  method. When done with an event, the\\n            external code must call :py:func:`event_processed` .\\n\\n        \"\"\"\\n        if not isinstance(listener, IEventListener):\\n            raise TypeError(\"listener can only be an instance of type IEventListener\")\\n        if not isinstance(interesting, list):\\n            raise TypeError(\"interesting can only be an instance of type list\")\\n        for a in interesting[:10]:\\n            if not isinstance(a, VBoxEventType):\\n                raise TypeError(\\n                        \"array can only contain objects of type VBoxEventType\")\\n        if not isinstance(active, bool):\\n            raise TypeError(\"active can only be an instance of type bool\")\\n        self._call(\"registerListener\",\\n                     in_p=[listener, interesting, active])',\n",
              " 'def unregister_listener(self, listener):\\n        \"\"\"Unregister an event listener. If listener is passive, and some waitable events are still\\n        in queue they are marked as processed automatically.\\n\\n        in listener of type :class:`IEventListener`\\n            Listener to unregister.\\n\\n        \"\"\"\\n        if not isinstance(listener, IEventListener):\\n            raise TypeError(\"listener can only be an instance of type IEventListener\")\\n        self._call(\"unregisterListener\",\\n                     in_p=[listener])',\n",
              " 'def fire_event(self, event, timeout):\\n        \"\"\"Fire an event for this source.\\n\\n        in event of type :class:`IEvent`\\n            Event to deliver.\\n\\n        in timeout of type int\\n            Maximum time to wait for event processing (if event is waitable), in ms;\\n            0 = no wait, -1 = indefinite wait.\\n\\n        return result of type bool\\n            true if an event was delivered to all targets, or is non-waitable.\\n\\n        \"\"\"\\n        if not isinstance(event, IEvent):\\n            raise TypeError(\"event can only be an instance of type IEvent\")\\n        if not isinstance(timeout, baseinteger):\\n            raise TypeError(\"timeout can only be an instance of type baseinteger\")\\n        result = self._call(\"fireEvent\",\\n                     in_p=[event, timeout])\\n        return result',\n",
              " 'def get_event(self, listener, timeout):\\n        \"\"\"Get events from this peer\\'s event queue (for passive mode). Calling this method\\n        regularly is required for passive event listeners to avoid system overload;\\n        see :py:func:`IEventSource.register_listener`  for details.\\n\\n        in listener of type :class:`IEventListener`\\n            Which listener to get data for.\\n\\n        in timeout of type int\\n            Maximum time to wait for events, in ms;\\n            0 = no wait, -1 = indefinite wait.\\n\\n        return event of type :class:`IEvent`\\n            Event retrieved, or null if none available.\\n\\n        raises :class:`VBoxErrorObjectNotFound`\\n            Listener is not registered, or autounregistered.\\n        \\n        \"\"\"\\n        if not isinstance(listener, IEventListener):\\n            raise TypeError(\"listener can only be an instance of type IEventListener\")\\n        if not isinstance(timeout, baseinteger):\\n            raise TypeError(\"timeout can only be an instance of type baseinteger\")\\n        event = self._call(\"getEvent\",\\n                     in_p=[listener, timeout])\\n        event = IEvent(event)\\n        return event',\n",
              " 'def event_processed(self, listener, event):\\n        \"\"\"Must be called for waitable events after a particular listener finished its\\n        event processing. When all listeners of a particular event have called this\\n        method, the system will then call :py:func:`IEvent.set_processed` .\\n\\n        in listener of type :class:`IEventListener`\\n            Which listener processed event.\\n\\n        in event of type :class:`IEvent`\\n            Which event.\\n\\n        \"\"\"\\n        if not isinstance(listener, IEventListener):\\n            raise TypeError(\"listener can only be an instance of type IEventListener\")\\n        if not isinstance(event, IEvent):\\n            raise TypeError(\"event can only be an instance of type IEvent\")\\n        self._call(\"eventProcessed\",\\n                     in_p=[listener, event])',\n",
              " 'def handle_event(self, event):\\n        \"\"\"Handle event callback for active listeners. It is not called for\\n        passive listeners. After calling :py:func:`handle_event`  on all active listeners\\n        and having received acknowledgement from all passive listeners via\\n        :py:func:`IEventSource.event_processed` , the event is marked as\\n        processed and :py:func:`IEvent.wait_processed`  will return\\n        immediately.\\n\\n        in event of type :class:`IEvent`\\n            Event available.\\n\\n        \"\"\"\\n        if not isinstance(event, IEvent):\\n            raise TypeError(\"event can only be an instance of type IEvent\")\\n        self._call(\"handleEvent\",\\n                     in_p=[event])',\n",
              " 'def wait_processed(self, timeout):\\n        \"\"\"Wait until time outs, or this event is processed. Event must be waitable for this operation to have\\n        described semantics, for non-waitable returns true immediately.\\n\\n        in timeout of type int\\n            Maximum time to wait for event processing, in ms;\\n            0 = no wait, -1 = indefinite wait.\\n\\n        return result of type bool\\n            If this event was processed before timeout.\\n\\n        \"\"\"\\n        if not isinstance(timeout, baseinteger):\\n            raise TypeError(\"timeout can only be an instance of type baseinteger\")\\n        result = self._call(\"waitProcessed\",\\n                     in_p=[timeout])\\n        return result',\n",
              " 'def add_veto(self, reason):\\n        \"\"\"Adds a veto on this event.\\n\\n        in reason of type str\\n            Reason for veto, could be null or empty string.\\n\\n        \"\"\"\\n        if not isinstance(reason, basestring):\\n            raise TypeError(\"reason can only be an instance of type basestring\")\\n        self._call(\"addVeto\",\\n                     in_p=[reason])']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training a new tokenizer from pretrained tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "acc534b5e77f4196ba1dc97a5f3642a6",
            "4e34fc443e8146cf83aa7c124297ac6b",
            "6c25c2b9c8d84c999038003e4ff80fee",
            "4b9f257dd5274f81bc2102075c36e769",
            "f0200445412840128331d3312f33a4cb",
            "c1a9dab0fd3c45efa84026d20405ed86",
            "729dedb4ae034e8391dcd1afe8d115a1",
            "5cb1fb43f4b043d4aae01c2254823c64",
            "95ac75f6f742428190bc02d70ea89e42",
            "a64532f3725f458494c1b7ef651fa842",
            "02cb706af9d840b2b190e56a982bb00a",
            "1e23209f83cc4d649906088ffb9c963e",
            "aab26e0c11724c7e9faeb6258ff57242",
            "d0e12b5721fd49b7b411cf85ef06b491",
            "899e9827300448e4a26163fbd3f00c44",
            "cbbd043ce86149b8837891d65aef3180",
            "6f40edc124d6489c88018edbdf724b7b",
            "e440f3c8e7634466b76ae9611ff16761",
            "71bf96931af94855bb0af90ef5a4211c",
            "d232d6515b144e8ea4eafcf0accd9ccb",
            "ef355b5ce01b410695645f1408db62b3",
            "7dd30177f4924527b44948b2bc069c48",
            "7d2ebd98d38a4126b86e394003595040",
            "10df03706c334d53a0b8eadd0c105c4a",
            "43a3419d0314421d8efeb1740646e67b",
            "0e5aecd6321d4a2795f8989d58124a9b",
            "b8de4a3e767c45808e876417b6a44a6d",
            "05795f578a724298893b0cddcfb302c1",
            "c656c19246a643a2b44e816331019ec4",
            "637a759ee9d24e67994af7ae75f83880",
            "4582cf6eb8fc4054bfc7ec71bd82ecc4",
            "2108359836d14bb584b697a2e6875f4c",
            "90eff44863864a2fad4ba04e1314e117",
            "22d50dee5a82480b8d1fddbeedeef9cc",
            "c9044b7e776a4ff5be018ee43ae73787",
            "37df6a80f68042999fd6013fe80a2a24",
            "dd7027f6d2874a87a64be31fbc8b51ca",
            "c0b8f109707545bc805f75c4466755ce",
            "9f39c08f8c2e4719a7692c37f9976cfd",
            "52f8275a53ac46d8ac05f578edc6dea5",
            "077238a875a543e18648b2490007404b",
            "75a606b7144c41f6a0b30a4878c83ce0",
            "f06d053a68a54fa7ace3e81a91b53349",
            "670ffd26ed1849ac9605fe1f1a2bf528"
          ]
        },
        "id": "9UfgZlR1mbRu",
        "outputId": "5ee2d974-6382-4ca7-9180-422005cbbc87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acc534b5e77f4196ba1dc97a5f3642a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e23209f83cc4d649906088ffb9c963e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d2ebd98d38a4126b86e394003595040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22d50dee5a82480b8d1fddbeedeef9cc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#observing tokenizer pretrained on not so specific data\n",
        "tokenizer.tokenize(raw_dataset[\"train\"][0][\"whole_func_string\"] )"
      ],
      "metadata": {
        "id": "aaFH__gHm_j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training new tokenizer from pretrained tokenizer on our specific data\n",
        "new_tokenizer = tokenizer.train_new_from_iterator(training_corpus, 52000)"
      ],
      "metadata": {
        "id": "ya4ESc-9nggL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(raw_dataset[\"train\"][5][\"whole_func_string\"])                               # inspecting result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJw_f83Yn6rr",
        "outputId": "5f1ef58f-a475-4548-9458-50ef8e7a2f94"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['def',\n",
              " 'Ġ_',\n",
              " 'serial',\n",
              " 'ize',\n",
              " '_',\n",
              " 'dict',\n",
              " '(',\n",
              " 'cl',\n",
              " 's',\n",
              " ',',\n",
              " 'Ġdata',\n",
              " '):',\n",
              " 'Ċ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " \"Ġ'\",\n",
              " \"''\",\n",
              " 'Ċ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġserial',\n",
              " 'izes',\n",
              " 'Ġa',\n",
              " 'Ġdictionary',\n",
              " 'ĊĊ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ:',\n",
              " 'param',\n",
              " 'Ġdata',\n",
              " ':',\n",
              " 'Ġdata',\n",
              " 'Ġto',\n",
              " 'Ġserial',\n",
              " 'ize',\n",
              " 'Ċ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " \"Ġ'\",\n",
              " \"''\",\n",
              " 'Ċ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġ',\n",
              " 'Ġreturn',\n",
              " 'Ġb',\n",
              " '64',\n",
              " 'en',\n",
              " 'code',\n",
              " '(',\n",
              " 'z',\n",
              " 'lib',\n",
              " '.',\n",
              " 'comp',\n",
              " 'ress',\n",
              " '(',\n",
              " 'c',\n",
              " 'Pick',\n",
              " 'le',\n",
              " '.',\n",
              " 'd',\n",
              " 'umps',\n",
              " '(',\n",
              " 'data',\n",
              " ',',\n",
              " 'Ġprotocol',\n",
              " '=',\n",
              " '2',\n",
              " '))',\n",
              " ').',\n",
              " 'dec',\n",
              " 'ode',\n",
              " '()']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tokenizer.tokenize(raw_dataset[\"train\"][5][\"whole_func_string\"])                                # inspecting result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iLhi8oqrOQn",
        "outputId": "e9ad00bf-0311-4c15-c2f7-30e8c456502b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['def',\n",
              " 'Ġ_',\n",
              " 'serialize',\n",
              " '_',\n",
              " 'dict',\n",
              " '(',\n",
              " 'cls',\n",
              " ',',\n",
              " 'Ġdata',\n",
              " '):',\n",
              " 'ĊĠĠĠĠĠĠĠ',\n",
              " \"Ġ'''\",\n",
              " 'ĊĠĠĠĠĠĠĠ',\n",
              " 'Ġserializes',\n",
              " 'Ġa',\n",
              " 'Ġdictionary',\n",
              " 'ĊĊĠĠĠĠĠĠĠ',\n",
              " 'Ġ:',\n",
              " 'param',\n",
              " 'Ġdata',\n",
              " ':',\n",
              " 'Ġdata',\n",
              " 'Ġto',\n",
              " 'Ġserialize',\n",
              " 'ĊĠĠĠĠĠĠĠ',\n",
              " \"Ġ'''\",\n",
              " 'ĊĠĠĠĠĠĠĠ',\n",
              " 'Ġreturn',\n",
              " 'Ġb',\n",
              " '64',\n",
              " 'encode',\n",
              " '(',\n",
              " 'zlib',\n",
              " '.',\n",
              " 'compress',\n",
              " '(',\n",
              " 'c',\n",
              " 'Pickle',\n",
              " '.',\n",
              " 'dumps',\n",
              " '(',\n",
              " 'data',\n",
              " ',',\n",
              " 'Ġprotocol',\n",
              " '=',\n",
              " '2',\n",
              " '))).',\n",
              " 'decode',\n",
              " '()']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e5b7fea71f3e4e5499537c51e5d6087a",
            "b6c915a84ce7449785007bb3d3eee20b",
            "eedba1ac65be4ef89b412ef057d32ee9",
            "c7462a587b434a7c95ed2ed75295dbf2",
            "ab4ec019b2b24c8787bcac2120885823",
            "d16a1366c05c40f5b5b40c7ffd9b152a",
            "09c05eb970244a72a22374fe123d4353",
            "342c9f96d62742e9bb7780c554b774d0",
            "98c09c0228d84460b3a29c6b9f57d02e",
            "3ba7aa597e324bd1b4ac81813f297361",
            "67914d252256431bacf57db529b7e384",
            "115b1a2371f245edb07d9c070d3693a9",
            "c50d03b673a2403f8dfa5b08789245a3",
            "905ac4703aca4a72aefb9ec68a4edb71",
            "c88117409ba840be982ffdb9596fe3d2",
            "c49dd5564a134f7e9b9651704f025f84",
            "8fb3483657e84c15815683927e020adf",
            "c00e4f85c98b4c00ac8e48a8d9d3dc78",
            "14d6d45ca460488d9fc74c20ef80f52b",
            "f606b2cd36154badbb8969f5ee333409",
            "b168ce39b1024fe7a64c8c0f725aefa4",
            "9f150582f6b149ea8641c2b1d321752d",
            "22ac7b6fe3bb4b08a4a705c11ac2e017",
            "00cac6a63ecb45e99fa5bdf7e46c70f9",
            "de13064efea2492788b2e5e7ba1a4119",
            "0c1d7178fa614bde86903533792d417f",
            "53b6df818b2a4db4847c428fb4e202d6",
            "43ae61b95da748d8a5932eea0ca041ed",
            "5ed5bd1d90db42f386b2b677a62d862d",
            "b2f21a93f76f4f329a55410c0e30418b",
            "a188be61ad6746bbbe143e2b8babca3c",
            "d5495d3288e64fd593124a867d28222c"
          ]
        },
        "id": "yZpS4G5UxcXd",
        "outputId": "1fcf5e21-aa1d-4c20-f0fd-da8c038e20a1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5b7fea71f3e4e5499537c51e5d6087a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tokenizer.push_to_hub(\"tokenizer_code_search_net_python\")                                 # pushing tokenizer to hub for reusing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6gSxOngssHMS",
        "outputId": "99041e68-8394-4ff9-c40a-aa5c6bf86180"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Utshav/tokenizer_code_search_net_python/commit/85d3598bd668abe98998a8cadfe67b36406f187e', commit_message='Upload tokenizer', commit_description='', oid='85d3598bd668abe98998a8cadfe67b36406f187e', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJ3_5puxxylT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}